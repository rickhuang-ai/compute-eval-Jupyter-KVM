{"task_id": "CUDA/0", "date": "2025-03-31", "prompt": "Implement a function called `launch` that launches a kernel function named `kernel` with the provided grid and block dimensions using triple chevrons. The x,y,z grid sizes and block sizes will be provided as parameters\nto the `launch` function. Assume that the `kernel` function is already defined. \n\nThe signature of the `kernel` function is\n```cuda\n__global__ void kernel(int *output, const int *input) \n```\n\nThe function signature is \n```cuda\nvoid launch(int gridSizeX, int blockSizeX, int gridSizeY = 1, int blockSizeY = 1, int gridSizeZ = 1, int blockSizeZ = 1)\n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_70 -arch=sm_60", "ld_flags": "", "declaration": "#include <cuda.h>\n#include \"cuda_runtime.h\"\n#include <iostream>\n\nusing namespace std;\n\n#define cudaCheckErrors(msg)                                                                 \\\n    do                                                                                       \\\n    {                                                                                        \\\n        cudaError_t __err = cudaGetLastError();                                              \\\n        if (__err != cudaSuccess)                                                            \\\n        {                                                                                    \\\n            fprintf(stderr, \"Fatal error: %s (%s at %s:%d)\", msg, cudaGetErrorString(__err), \\\n                    __FILE__, __LINE__);                                                     \\\n            fprintf(stderr, \"*** FAILED - ABORTING\");                                        \\\n            exit(1);                                                                         \\\n        }                                                                                    \\\n    }                                                                                        \\\n    while (0)\n\n\n__global__ void kernel(int *output, const int *input)\n{\n    int id     = threadIdx.x + blockIdx.x * blockDim.x;\n    output[id] = input[id];\n}\n", "test": "int main() {\nlaunch(4, 1024);\ncudaCheckErrors(\"kernel launch failed\");\nlaunch(4, 32, 4, 32);\ncudaCheckErrors(\"kernel launch failed\");\nlaunch(4, 16, 4, 16, 4, 4);\ncudaCheckErrors(\"kernel launch failed\");\n\n}\n", "example_test": "", "cuda_toolkit": "12.0"}
{"task_id": "CUDA/1", "date": "2025-03-31", "prompt": "Implement a function called `launch` that launches a kernel function named `kernel` with the provided grid and block dimensions using triple chevrons and also allocates dynamic shared memory. The x,y,z grid sizes and block sizes will be provided as parameters\nto the `launch` function. Assume that the `kernel` function is already defined. \n\nThe signature of the `kernel` function is\n```cuda\n__global__ void kernel(int *output, const int *input) \n```\n\nThe function signature is \n```cuda\nvoid launch(int gridSizeX, int blockSizeX, int gridSizeY = 1, int blockSizeY = 1, int gridSizeZ = 1, int blockSizeZ = 1)\n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_70 -arch=sm_60", "ld_flags": "", "declaration": "#include <cuda.h>\n#include \"cuda_runtime.h\"\n#include <iostream>\n\nusing namespace std;\n\n#define cudaCheckErrors(msg)                                                                 \\\n    do                                                                                       \\\n    {                                                                                        \\\n        cudaError_t __err = cudaGetLastError();                                              \\\n        if (__err != cudaSuccess)                                                            \\\n        {                                                                                    \\\n            fprintf(stderr, \"Fatal error: %s (%s at %s:%d)\", msg, cudaGetErrorString(__err), \\\n                    __FILE__, __LINE__);                                                     \\\n            fprintf(stderr, \"*** FAILED - ABORTING\");                                        \\\n            exit(1);                                                                         \\\n        }                                                                                    \\\n    }                                                                                        \\\n    while (0)\n\n\n__global__ void kernel(int *output, const int *input)\n{\n    int id     = threadIdx.x + blockIdx.x * blockDim.x;\n    output[id] = input[id];\n}\n\n", "test": "int main() {\nlaunch(4, 256);\ncudaCheckErrors(\"kernel launch failed\");\nlaunch(4, 16, 4, 16);\ncudaCheckErrors(\"kernel launch failed\");\nlaunch(4, 16, 4, 16, 4, 1);\ncudaCheckErrors(\"kernel launch failed\");\n\n}\n", "example_test": "@example_test\n", "cuda_toolkit": "12.0"}
{"task_id": "CUDA/2", "date": "2025-03-31", "prompt": "Implement a function called `launch` that launches a kernel function named `kernel` with the provided grid and block dimensions using triple chevrons, allocates dynamic shared memory and also uses cuda streams. The x,y,z grid sizes and block sizes will be provided as parameters\nto the `launch` function. Assume that the `kernel` function is already defined. \n\nThe signature of the `kernel` function is\n```cuda\n__global__ void kernel(int *output, const int *input) \n```\n\nThe function signature is \n```cuda\nvoid launch(int gridSizeX, int blockSizeX, int gridSizeY = 1, int blockSizeY = 1, int gridSizeZ = 1, int blockSizeZ = 1)\n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_70 -arch=sm_60", "ld_flags": "", "declaration": "#include <cuda.h>\n#include \"cuda_runtime.h\"\n#include <iostream>\n\nusing namespace std;\n\n#define cudaCheckErrors(msg)                                                                 \\\n    do                                                                                       \\\n    {                                                                                        \\\n        cudaError_t __err = cudaGetLastError();                                              \\\n        if (__err != cudaSuccess)                                                            \\\n        {                                                                                    \\\n            fprintf(stderr, \"Fatal error: %s (%s at %s:%d)\", msg, cudaGetErrorString(__err), \\\n                    __FILE__, __LINE__);                                                     \\\n            fprintf(stderr, \"*** FAILED - ABORTING\");                                        \\\n            exit(1);                                                                         \\\n        }                                                                                    \\\n    }                                                                                        \\\n    while (0)\n\n__global__ void kernel(int *output, const int *input)\n{\n}\n\n", "test": "int main() {\nlaunch(4, 256);\ncudaCheckErrors(\"kernel launch failed\");\nlaunch(4, 16, 4, 16);\ncudaCheckErrors(\"kernel launch failed\");\nlaunch(4, 16, 4, 16, 4, 1);\ncudaCheckErrors(\"kernel launch failed\");\n}\n", "example_test": "@example_test\n", "cuda_toolkit": "12.0"}
{"task_id": "CUDA/3", "date": "2025-03-31", "prompt": "Implement a function called `launch` that launches a kernel function named `kernel` without using triple chevrons. The x,y,z grid and dimensions will be provided as parameters\nto the `launch` function. Assume that the `kernel` function is already defined. \n\nThe signature of the `kernel` function is\n```cuda\n__global__ void kernel(int *output, const int *input) \n```\n\nThe function signature is \n```cuda\nvoid launch(int gridSizeX, int blockSizeX, int gridSizeY = 1, int blockSizeY = 1, int gridSizeZ = 1, int blockSizeZ = 1)\n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_70 -arch=sm_60", "ld_flags": "", "declaration": "#include <cuda.h>\n#include \"cuda_runtime.h\"\n#include <fstream>\n#include <iostream>\n\nusing namespace std;\n\n#define cudaCheckErrors(msg)                                                                 \\\n    do                                                                                       \\\n    {                                                                                        \\\n        cudaError_t __err = cudaGetLastError();                                              \\\n        if (__err != cudaSuccess)                                                            \\\n        {                                                                                    \\\n            fprintf(stderr, \"Fatal error: %s (%s at %s:%d)\", msg, cudaGetErrorString(__err), \\\n                    __FILE__, __LINE__);                                                     \\\n            fprintf(stderr, \"*** FAILED - ABORTING\");                                        \\\n            exit(1);                                                                         \\\n        }                                                                                    \\\n    }                                                                                        \\\n    while (0)\n\n__global__ void kernel(int *output, const int *input)\n{\n    int id     = threadIdx.x + blockIdx.x * blockDim.x;\n    output[id] = input[id];\n}\n\nstd::string trim(const std::string& str) {\n    size_t first = str.find_first_not_of(' ');\n    if (std::string::npos == first) {\n        return str;\n    }\n    size_t last = str.find_last_not_of(' ');\n    return str.substr(first, last - first + 1);\n}\n", "test": "int main() {\n    auto static_test = [] () {\n        const char* path = std::getenv(\"COMPUTE_EVAL_SRC_FILE\");\n        if (path == nullptr) {\n            std::cerr << \"Environment variable not found!\" << std::endl;\n            std::exit(1);\n        }\n\n        std::ifstream file(path);\n        if (!file.is_open()) {\n            std::cerr << \"File not found!\" << std::endl;\n            std::exit(1);\n        }\n\n        std::string line;\n\n        // Skip until the beginning of the completion block\n        while (std::getline(file, line)) {\n\n            if (line.find(\"completion-begin\") != std::string::npos && \n                line.find(\"std::string::npos\") == std::string::npos) {\n                break;\n            }\n        }\n\n        // Search for the CUDA kernel launch API call\n        bool found = false;\n        while (std::getline(file, line)) {\n\n            std::string trimmedLine = trim(line);\n\n            // If the line contains the completion-end marker, stop searching\n            if (trimmedLine.find(\"completion-end\") != std::string::npos) {\n                break;\n            }\n\n            // ignore commented lines\n            if (trimmedLine.find(\"//\") == 0) continue;\n            \n            if (trimmedLine.find(\"cudaLaunchKernelEx\") != std::string::npos) {\n                found = true;\n                break;\n            }\n\n        }\n\n        if (!found) {\n            std::cerr << \"Test failed because the generated code doesn't use CUDA kernel launch API!\" << std::endl;\n            std::exit(1);\n        }\n    };\n\n    auto dynamic_test = [] () {\n        int *output, *input;\n        launch(4, 256);\n        cudaCheckErrors(\"kernel launch failed\");\n        launch(4, 16, 4, 16);\n        cudaCheckErrors(\"kernel launch failed\");\n        launch(4, 16, 4, 16, 4, 1);\n        cudaCheckErrors(\"kernel launch failed\");\n    };\n\n    static_test();\n    dynamic_test();\n}\n", "example_test": "@example_test\n", "cuda_toolkit": "12.0"}
{"task_id": "CUDA/4", "date": "2025-03-31", "prompt": "Implement a function called `launch` that launches a kernel function named `kernel` with thread block clusters and wihout using triple chevrons. The x,y,z grid and dimensions will be provided as parameters\nto the `launch` function. Assume that the `kernel` function is already defined. \n\nThe signature of the `kernel` function is\n```cuda\n__global__ void kernel(int *output, const int *input) \n```\n\nThe function signature is \n```cuda\nvoid launch(int gridSizeX, int blockSizeX, int gridSizeY = 1, int blockSizeY = 1, int gridSizeZ = 1, int blockSizeZ = 1)\n", "cc_flags": "-arch=sm_90a", "ld_flags": "", "declaration": "#include <cuda.h>\n#include \"cuda_runtime.h\"\n#include <iostream>\n#include <fstream>\n\nusing namespace std;\n\n#define cudaCheckErrors(msg)                                                                 \\\n    do                                                                                      \\\n    {                                                                                        \\\n        cudaError_t __err = cudaGetLastError();                                              \\\n        if (__err == cudaErrorInvalidKernelImage || __err == cudaErrorNoKernelImageForDevice) \\\n        {                                                                                     \\\n            fprintf(stderr, \"Invalid GPU architecture: %s (%s at %s:%d)\", msg, cudaGetErrorString(__err), \\\n                    __FILE__, __LINE__);                                                     \\\n            fprintf(stderr, \"*** FAILED - ABORTING\");                                        \\\n            exit(200);                                                                       \\\n        }                                                                                       \\\n        else if (__err != cudaSuccess)                                                            \\\n        {                                                                                    \\\n            fprintf(stderr, \"Fatal error: %s (%s at %s:%d)\", msg, cudaGetErrorString(__err), \\\n                    __FILE__, __LINE__);                                                     \\\n            fprintf(stderr, \"*** FAILED - ABORTING\");                                        \\\n            exit(1);                                                                         \\\n        }                                                                                    \\\n    }                                                                                        \\\n    while (0)\n\n__global__ void kernel(int *output, const int *input)\n{\n\n}\n\nstd::string trim(const std::string& str) {\n    size_t first = str.find_first_not_of(' ');\n    if (std::string::npos == first) {\n        return str;\n    }\n    size_t last = str.find_last_not_of(' ');\n    return str.substr(first, last - first + 1);\n}\n", "test": "int main() {\nauto static_test = [] () {\n        const char* path = std::getenv(\"COMPUTE_EVAL_SRC_FILE\");\n        if (path == nullptr) {\n            std::cerr << \"Environment variable not found!\" << std::endl;\n            std::exit(1);\n        }\n\n        std::ifstream file(path);\n        if (!file.is_open()) {\n            std::cerr << \"File not found!\" << std::endl;\n            std::exit(1);\n        }\n\n        std::string line;\n\n        // Skip until the beginning of the completion block\n        while (std::getline(file, line)) {\n\n            if (line.find(\"completion-begin\") != std::string::npos && \n                line.find(\"std::string::npos\") == std::string::npos) {\n                break;\n            }\n        }\n\n        // Search for the CUDA kernel launch API call\n        bool foundKernelLaunch = false, foundClusterDim = false;\n        while (std::getline(file, line)) {\n\n            std::string trimmedLine = trim(line);\n\n            // If the line contains the completion-end marker, stop searching\n            if (trimmedLine.find(\"completion-end\") != std::string::npos) {\n                break;\n            }\n\n            // ignore commented lines\n            if (trimmedLine.find(\"//\") == 0) continue;\n            \n            if (trimmedLine.find(\"cudaLaunchKernelEx\") != std::string::npos) foundKernelLaunch = true;\n            if (trimmedLine.find(\"cudaLaunchAttributeClusterDimension\") != std::string::npos) foundClusterDim = true;\n\n            if (foundKernelLaunch && foundClusterDim) break;\n\n        }\n\n        if (!foundKernelLaunch) {\n            std::cerr << \"Test failed because the generated code doesn't use CUDA kernel launch API!\" << std::endl;\n            std::exit(1);\n        }\n\n        if (!foundClusterDim) {\n            std::cerr << \"Test failed because the generated code doesn't use cluster dimension attribute!\" << std::endl;\n            std::exit(1);\n        }\n    };\n\n    auto dynamic_test = [] () {\n        int *output, *input;\n        launch(4, 256);\n        cudaCheckErrors(\"kernel launch failed\");\n        launch(4, 16, 4, 16);\n        cudaCheckErrors(\"kernel launch failed\");\n        launch(4, 16, 4, 16, 4, 1);\n        cudaCheckErrors(\"kernel launch failed\");\n    };\n\n    static_test();\n    dynamic_test();\n}\n", "example_test": "@example_test\n", "cuda_toolkit": "12.0"}
{"task_id": "CUDA/5", "date": "2025-03-31", "prompt": "Implement a kernel called `kernel` that has launch bounds set to ensure optimal execution efficiency by limiting the maximum number of threads per block to MAX_THREADS_PER_BLOCK and the minimum number of blocks per multiprocessor to MIN_BLOCKS_PER_MULTIPROCESSOR. \nThis ensures that the kernel runs efficiently on the GPU by maximizing occupancy while maintaining sufficient resources per block.\n\nAssume that the following constants are defined:\n- `MAX_THREADS_PER_BLOCK`: the maximum number of threads that can be assigned to a block\n- `MIN_BLOCKS_PER_MULTIPROCESSOR`: the minimum number of blocks that can be to multiprocessor core.\n\nImplement the kernel function that takes an int* and const int* as parameters.\n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_70 -arch=sm_60", "ld_flags": "", "declaration": "#include <cuda.h>\n#include \"cuda_runtime.h\"\n#include <iostream>\n\n\n#define cudaCheckErrors(msg)                                                                 \\\n    do                                                                                       \\\n    {                                                                                        \\\n        cudaError_t __err = cudaGetLastError();                                              \\\n        if (__err != cudaSuccess)                                                            \\\n        {                                                                                    \\\n            fprintf(stderr, \"Fatal error: %s (%s at %s:%d)\", msg, cudaGetErrorString(__err), \\\n                    __FILE__, __LINE__);                                                     \\\n            fprintf(stderr, \"*** FAILED - ABORTING\");                                        \\\n            exit(1);                                                                         \\\n        }                                                                                    \\\n    }                                                                                        \\\n    while (0)\n\n#define cudaCheckSuccess(msg)                                                                 \\\n    do                                                                                       \\\n    {                                                                                        \\\n        cudaError_t __err = cudaGetLastError();                                              \\\n        if (__err == cudaSuccess)                                                            \\\n        {                                                                                    \\\n            fprintf(stderr, \"Fatal error: %s (%s at %s:%d)\", msg, cudaGetErrorString(__err), \\\n                    __FILE__, __LINE__);                                                     \\\n            fprintf(stderr, \"*** FAILED - ABORTING\");                                        \\\n            exit(1);                                                                         \\\n        }                                                                                    \\\n    }                                                                                        \\\n    while (0)\n\nstatic const int MAX_THREADS_PER_BLOCK         = 128;\nstatic const int MIN_BLOCKS_PER_MULTIPROCESSOR = 1;\n\n__global__ void kernel(int*, const int*);\n\nvoid launch()\n{\n    int *output, *input;\n    kernel<<<dim3(1, 1, 1), dim3(128, 1, 1)>>>(output, input);\n    cudaCheckErrors(\"kernel launch failed\");\n\n    kernel<<<dim3(1, 1, 1), dim3(2 * MAX_THREADS_PER_BLOCK, 1, 1)>>>(output, input);\n    cudaCheckSuccess(\"kernel launch has should have failed, because the number of threads exceeds the maximum allowed\");\n\n}\n", "test": "int main() {\nlaunch();\n\n}\n", "example_test": "@example_test\n", "cuda_toolkit": "12.0"}
{"task_id": "CUDA/6", "date": "2025-03-31", "prompt": "Implement a kernel called `kernel` that has launch bounds set to ensure optimal execution efficiency by limiting the maximum number of threads per block to MAX_THREADS_PER_BLOCK, the minimum number of blocks per multiprocessor to MIN_BLOCKS_PER_MULTIPROCESSOR and the maximum number of thread blocks in a cluster to MAX_BLOCKS_PER_CLUSTER. \n\nAssume that the following constants are defined:\n- `MAX_THREADS_PER_BLOCK`: the maximum number of threads that can be assigned to a block\n- `MIN_BLOCKS_PER_MULTIPROCESSOR`: the minimum number of blocks that can be to multiprocessor core.\n- `MAX_BLOCKS_PER_CLUSTER`:  the maximum number of thread blocks per cluster\n\nImplement the kernel function that takes an int* and const int* as parameters.\n", "cc_flags": "-arch=sm_90a", "ld_flags": "", "declaration": "#include <cuda.h>\n#include \"cuda_runtime.h\"\n#include <iostream>\n\n\n#define cudaCheckErrors(msg)                                                                 \\\n    do                                                                                       \\\n    {                                                                                        \\\n        cudaError_t __err = cudaGetLastError();                                              \\\n        if (__err == cudaErrorInvalidKernelImage || __err == cudaErrorNoKernelImageForDevice) \\\n        {                                                                                     \\\n            fprintf(stderr, \"Invalid GPU architecture: %s (%s at %s:%d)\", msg, cudaGetErrorString(__err), \\\n                    __FILE__, __LINE__);                                                     \\\n            fprintf(stderr, \"*** FAILED - ABORTING\");                                        \\\n            exit(200);                                                                       \\\n        }                                              \\\n        else if (__err != cudaSuccess)                                                            \\\n        {                                                                                    \\\n            fprintf(stderr, \"Fatal error: %s (%s at %s:%d)\", msg, cudaGetErrorString(__err), \\\n                    __FILE__, __LINE__);                                                     \\\n            fprintf(stderr, \"*** FAILED - ABORTING\");                                        \\\n            exit(1);                                                                         \\\n        }                                                                                    \\\n    }                                                                                        \\\n    while (0)\n\n#define cudaCheckSuccess(msg)                                                                 \\\n    do                                                                                       \\\n    {                                                                                        \\\n        cudaError_t __err = cudaGetLastError();                                              \\\n        if (__err == cudaSuccess)                                                            \\\n        {                                                                                    \\\n            fprintf(stderr, \"This should not have succeded: %s (%s at %s:%d)\", msg, cudaGetErrorString(__err), \\\n                    __FILE__, __LINE__);                                                     \\\n            fprintf(stderr, \"*** FAILED - ABORTING\");                                        \\\n            exit(1);                                                                         \\\n        }                                                                                    \\\n    }                                                                                        \\\n    while (0)\n\nstatic const int MAX_THREADS_PER_BLOCK         = 128;\nstatic const int MIN_BLOCKS_PER_MULTIPROCESSOR = 1;\nstatic const int MAX_BLOCKS_PER_CLUSTER        = 32;\n\n__global__ void kernel(int*, const int*);\n\nvoid launch()\n{\n    int *output, *input;\n    kernel<<<dim3(1, 1, 1), dim3(128, 1, 1)>>>(output, input);\n    cudaCheckErrors(\"kernel launch failed\");\n\n    kernel<<<dim3(1, 1, 1), dim3(2 * MAX_THREADS_PER_BLOCK, 1, 1)>>>(output, input);\n    cudaCheckSuccess(\"kernel launch has should have failed, because the number of threads exceeds the maximum allowed\");\n\n    kernel<<<dim3(MAX_BLOCKS_PER_CLUSTER + 1, 1, 1), dim3(MAX_THREADS_PER_BLOCK, 1, 1)>>>(output, input);\n    cudaCheckSuccess(\"kernel launch has should have failed, because the number of thread blocks per cluster exceeds the maximum allowed\");\n\n}\n", "test": "int main() {\nlaunch();\n\n}\n", "example_test": "@example_test\n", "cuda_toolkit": "12.0"}
{"task_id": "CUDA/7", "date": "2025-03-31", "prompt": "Implement a CUDA kernel called conv2d_kernel that performs a 2-dimensional convolution on the input\nfloat matrix and populates the output matrix with these values. Assume that the input matrix is in\nrow-major order and ensure that the output matrix is populated in row-major order as well. You can\nassume that there is no padding in this convolution and the stride is 1.\n\nThe signature of the function is\n```cuda\n__global__ void conv2d_kernel(float *input, float *output, unsigned int W, unsigned int H, unsigned\nint oW, unsigned int oH)\n```\nwhere W, H are the input width and heights and oW, oH are the output width and height\n\nAssume that the following constants are defined:\n- `MASK_RADIUS`:  the mask radius is the distance from the center of the convolution mask or kernel\nto its outermost elements.\n- `MASK_DIM`: The mask dimension (or kernel dimension) refers to the spatial dimensions or the shape\nof the convolution mask. Defined as 2 * MASK_RADIUS + 1\n\nAdditionally, assume that the mask is stored in constant memory as a 2d array named `mask_c`.\n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_70 -arch=sm_60", "ld_flags": "", "declaration": "#include <cassert>\n#include <chrono>\n#include <iostream>\n#include <random>\nusing namespace std;\n\n#define cudaCheckErrors(msg)                                                                 \\\n    do                                                                                       \\\n    {                                                                                        \\\n        cudaError_t __err = cudaGetLastError();                                              \\\n        if (__err != cudaSuccess)                                                            \\\n        {                                                                                    \\\n            fprintf(stderr, \"Fatal error: %s (%s at %s:%d)\", msg, cudaGetErrorString(__err), \\\n                    __FILE__, __LINE__);                                                     \\\n            fprintf(stderr, \"*** FAILED - ABORTING\");                                        \\\n            exit(1);                                                                         \\\n        }                                                                                    \\\n    }                                                                                        \\\n    while (0)\n\n#define MASK_RADIUS 2\n#define MASK_DIM ((MASK_RADIUS)*2 + 1)\n\n__global__ void conv2d_kernel(float *input, float *output, unsigned int W, unsigned int H,\n                              unsigned int oW, unsigned int oH);\n\n__constant__ float mask_c[MASK_DIM][MASK_DIM];\n\nbool validate_convolution(float mask[][MASK_DIM], float *input, float *output, unsigned int W,\n                          unsigned int H)\n{\n    unsigned int out_W = W - MASK_DIM + 1;   // here we assume there is no padding, and stride is 1\n    unsigned int out_H = H - MASK_DIM + 1;   // here we assume there is no padding, and stride is 1\n    for (unsigned int orow = 0; orow < out_H; orow++)\n    {\n        for (unsigned int ocol = 0; ocol < out_W; ocol++)\n        {\n            float sum = 0.0f;\n\n            for (int i = 0; i < MASK_DIM; i++)\n            {\n                for (int j = 0; j < MASK_DIM; j++)\n                {\n                    int irow = orow + (i - MASK_RADIUS);\n                    int icol = ocol + (j - MASK_RADIUS);\n                    if (irow >= 0 && irow < H && icol >= 0 && icol < W)\n                    {\n                        sum += mask[i][j] * input[irow * W + icol];\n                    }\n                }\n            }\n            if (fabs(output[orow * out_W + ocol] - sum) > 1e-5)\n            {\n                return false;\n            }\n        }\n    }\n    return true;\n}\n\nvoid conv2d(float mask[][MASK_DIM], float *input, float *output, unsigned int W, unsigned int H)\n{\n    // Allocate the memory on the GPU\n    unsigned int out_W = W - MASK_DIM + 1;   // here we assume there is no padding, and stride is 1\n    unsigned int out_H = H - MASK_DIM + 1;   // here we assume there is no padding, and stride is 1\n    float *input_d, *output_d;\n    cudaMalloc(&input_d, W * H * sizeof(float));\n    cudaMalloc(&output_d, out_W * out_H * sizeof(float));\n    cudaCheckErrors(\"cudaMalloc failed\");\n\n    // Copy the memory from the host to the GPU\n    cudaMemcpy(input_d, input, W * H * sizeof(float), cudaMemcpyHostToDevice);\n    cudaCheckErrors(\"cudaMemcpy H2D failed\");\n\n    // Allocate the mask on constant memory\n    cudaMemcpyToSymbol(mask_c, mask, MASK_DIM * MASK_DIM * sizeof(float));\n    cudaCheckErrors(\"cudaMemcpy Constant Memory failed\");\n\n    // Perform the convolution operation\n    dim3 numberOfThreadsPerBlock(32, 32);\n    dim3 numberOfBlocks((W + numberOfThreadsPerBlock.x - 1) / numberOfThreadsPerBlock.x,\n                        (H + numberOfThreadsPerBlock.y - 1) / numberOfThreadsPerBlock.y);\n    conv2d_kernel<<<numberOfBlocks, numberOfThreadsPerBlock>>>(input_d, output_d, W, H, out_W,\n                                                               out_H);\n    cudaCheckErrors(\"kernel launch failed\");\n\n    // Copy the result back to the host\n    cudaMemcpy(output, output_d, out_W * out_H * sizeof(float), cudaMemcpyDeviceToHost);\n    cudaCheckErrors(\"cudaMemcpy D2H failed\");\n\n    // Free the GPU Memory\n    cudaFree(input_d);\n    cudaFree(output_d);\n}\n\nvoid test(unsigned int W, unsigned int H)\n{\n    unsigned int oW = W - MASK_DIM + 1;\n    unsigned int oH = H - MASK_DIM + 1;\n    float mask[MASK_DIM][MASK_DIM];\n\n    // Allocate host memory\n    float *img = (float *)malloc(H * W * sizeof(float));\n    float *out = (float *)malloc(oH * oW * sizeof(float));\n\n    // Populate the arrays with random values\n    for (int i = 0; i < H * W; i++)\n    {\n        img[i] = static_cast<float>(rand()) / RAND_MAX;\n    }\n    for (int i = 0; i < MASK_DIM; i++)\n    {\n        for (int j = 0; j < MASK_DIM; j++)\n        {\n            mask[i][j] = static_cast<float>(rand()) / RAND_MAX;\n        }\n    }\n\n    // Perform the GPU operation\n    conv2d(mask, img, out, W, H);\n\n    // Validate the convolution operation\n    assert(validate_convolution(mask, img, out, W, H));\n\n    free(img);\n    free(out);\n}\n\nvoid launch()\n{\n    cudaDeviceSynchronize();\n\n    // Seed the random number generator\n    srand(static_cast<unsigned int>(time(nullptr)));\n\n    const int NUM_TESTS = 5;\n    // the lenght of the Ws and Hs must be TESTS\n    unsigned int Ws[] = {1 << 5, 1 << 12, 1983, 1 << 13, 10};\n    unsigned int Hs[] = {1 << 5, 1 << 12, 1285, 10, 1 << 13};\n    for (int i = 0; i < NUM_TESTS; i++)\n    {\n        test(Ws[i], Hs[i]);\n    }\n}\n\n// This function takes the input array and applies the mask that is present in constant memory and\n// stores the resultant value in the output variable. The input matrix is stored in row-major order\n// and the output matrix matrix should also be stored in row-major order.\n__global__ void conv2d_kernel(float *input, float *output, unsigned int W, unsigned int H,\n                              unsigned int oW, unsigned int oH)\n{\n", "test": "int main() {\n    launch();\n\n}\n", "example_test": "    @example_test\n", "cuda_toolkit": "12.0"}
{"task_id": "CUDA/8", "date": "2025-03-31", "prompt": "Implement a CUDA function called `run_cuda_graph` that sets up and executes a CUDA graph for\nprocessing an image represented as a 1D array. The function signature is `void run_cuda_graph(float*\nd_img, float* h_result, int width, int height)`. In this function, you will create a CUDA graph to\napply several image processing steps: edge detection, normalization, blurring, combining results,\nand a final transformation. You will use the following kernels in your graph:\n\n- `apply_edge_detection(float* img, float* result, int width, int height)`\n- `normalize_image(float* img, int width, int height)`\n- `apply_blur_filter(float* img, float* result, int width, int height)`\n- `combine_filtered_results(float* edge_result, float* blur_result, float* combined_result, int\nwidth, int height)`\n- `final_transformation(float* img, int width, int height)`\n\nAllocate the necessary device memory and configure the graph nodes with appropriate parameters.\nFirst, apply the edge detection filter to the input image and normalize the resulting image values.\nThen, apply a blur filter to the normalized image. Combine the results of the edge detection and the\nblur filters. Perform a final transformation on the combined result.\n\nUse a block size of 256 threads and ensure the graph executes 100 times. After executing the graph,\ncopy the final result back to the host.\n\nThe signature of the function is:\n```cuda\nvoid run_cuda_graph(float* d_img, float* h_result, int width, int height)\n```\n\nYou should assume the kernels are already defined.\n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_70 -arch=sm_60", "ld_flags": "", "declaration": "#include <cuda_runtime.h>\n#include <cassert>\n#include <cstdlib>\n#include <ctime>\n#include <iostream>\n\n// CUDA kernel to apply edge detection\n__global__ void apply_edge_detection(float* img, float* result, int width, int height)\n{\n    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n    if (idx < width * height)\n    {\n        result[idx] = img[idx] * 1.5f;   // Simplified edge detection operation\n    }\n}\n\n// CUDA kernel to normalize image values\n__global__ void normalize_image(float* img, int width, int height)\n{\n    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n    if (idx < width * height)\n    {\n        img[idx] /= 255.0f;   // Normalize to range [0, 1]\n    }\n}\n\n// CUDA kernel to apply blur filter\n__global__ void apply_blur_filter(float* img, float* result, int width, int height)\n{\n    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n    if (idx < width * height)\n    {\n        result[idx] = img[idx] * 0.8f;   // Simplified blur operation\n    }\n}\n\n// CUDA kernel to combine filtered results\n__global__ void combine_filtered_results(float* edge_result, float* blur_result,\n                                         float* combined_result, int width, int height)\n{\n    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n    if (idx < width * height)\n    {\n        combined_result[idx] = edge_result[idx] + blur_result[idx];\n    }\n}\n\n// CUDA kernel to apply final transformation\n__global__ void final_transformation(float* img, int width, int height)\n{\n    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n    if (idx < width * height)\n    {\n        img[idx] *= 2.0f;\n    }\n}\n\nvoid run_cuda_graph(float* d_img, float* h_result, int width, int height);\n\nint launch()\n{\n    const int width  = 256;\n    const int height = 256;\n    const int size   = width * height;\n    float* h_img     = (float*)malloc(size * sizeof(float));\n    float* h_result  = (float*)malloc(size * sizeof(float));\n\n    // Initialize the image with random values for testing\n    std::srand(std::time(0));\n    for (int i = 0; i < size; ++i)\n    {\n        h_img[i] = static_cast<float>(std::rand() % 256);\n    }\n\n    float* d_img;\n    cudaMalloc(&d_img, size * sizeof(float));\n    cudaMemcpy(d_img, h_img, size * sizeof(float), cudaMemcpyHostToDevice);\n\n    // Run the CUDA graph\n    run_cuda_graph(d_img, h_result, width, height);\n\n    // Check the results using assertions\n    for (int i = 0; i < size; ++i)\n    {\n        float expected = 2 * ((1.5f * h_img[i] / 255.0f) * 0.8f + (1.5f * h_img[i] / 255.0f));\n        assert(h_result[i] == expected && \"Assertion failed!\");\n    }\n\n    free(h_img);\n    free(h_result);\n    cudaFree(d_img);\n    return 0;\n}\n\n// Function to set up and execute the CUDA graph\nvoid run_cuda_graph(float* d_img, float* h_result, int width, int height)\n{\n", "test": "int main() {\n    launch();\n\n}\n", "example_test": "    @example_test\n", "cuda_toolkit": "12.0"}
{"task_id": "CUDA/9", "date": "2025-03-31", "prompt": "Write a CUDA function called `dot_product` that calculates the dot product of two vectors using\ndynamic shared memory. The function should efficiently handle cases where the size of the vectors\nmay be larger than the total number of available threads.\n\nThe signature of the function is:\n```cuda\n__global__ void dot_product(const float *A, const float *B, float *result, int ds)\n```\n\nImplement the body of the function. Use dynamic shared memory to store the partial sums within each\nblock.\n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_70 -arch=sm_60", "ld_flags": "", "declaration": "#include <assert.h>\n#include <stdio.h>\n\n#define cudaCheckErrors(msg)                                                                 \\\n    do                                                                                       \\\n    {                                                                                        \\\n        cudaError_t __err = cudaGetLastError();                                              \\\n        if (__err != cudaSuccess)                                                            \\\n        {                                                                                    \\\n            fprintf(stderr, \"Fatal error: %s (%s at %s:%d)\", msg, cudaGetErrorString(__err), \\\n                    __FILE__, __LINE__);                                                     \\\n            fprintf(stderr, \"*** FAILED - ABORTING\");                                        \\\n            exit(1);                                                                         \\\n        }                                                                                    \\\n    }                                                                                        \\\n    while (0)\n\n__global__ void dot_product(const float *A, const float *B, float *result, int ds);\n\nvoid test_dot_product(int ds, const float *h_A, const float *h_B, float expected_result)\n{\n    float *d_A, *d_B, *d_result;\n    float h_result = 0.0f;\n\n    cudaMalloc(&d_A, ds * sizeof(float));\n    cudaMalloc(&d_B, ds * sizeof(float));\n    cudaMalloc(&d_result, sizeof(float));\n    cudaCheckErrors(\"cudaMalloc failure\");\n\n    cudaMemcpy(d_A, h_A, ds * sizeof(float), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_B, h_B, ds * sizeof(float), cudaMemcpyHostToDevice);\n    cudaCheckErrors(\"cudaMemcpy H2D failure\");\n\n    int block_size      = 256;\n    int grid_size       = (ds + block_size - 1) / block_size;\n    int shared_mem_size = block_size * sizeof(float);\n    dot_product<<<grid_size, block_size, shared_mem_size>>>(d_A, d_B, d_result, ds);\n    cudaCheckErrors(\"kernel launch failure\");\n\n    cudaMemcpy(&h_result, d_result, sizeof(float), cudaMemcpyDeviceToHost);\n    cudaCheckErrors(\"cudaMemcpy D2H failure\");\n\n    assert(fabs(h_result - expected_result) < 1e-5);\n\n    cudaFree(d_A);\n    cudaFree(d_B);\n    cudaFree(d_result);\n    cudaCheckErrors(\"cudaFree failure\");\n}\n\nint launch()\n{\n    // Test case 1: Simple vectors with all ones\n    int ds1     = 1 << 24;   // 16M elements\n    float *h_A1 = new float[ds1];\n    float *h_B1 = new float[ds1];\n    for (int i = 0; i < ds1; ++i)\n    {\n        h_A1[i] = 1.0f;\n        h_B1[i] = 1.0f;\n    }\n    float expected_result1 = ds1;\n    test_dot_product(ds1, h_A1, h_B1, expected_result1);\n\n    delete[] h_A1;\n    delete[] h_B1;\n\n    // Test case 2: Vectors with increasing sequence\n    int ds2     = 1 << 10;   // 1024 elements to avoid overflow of integer\n    float *h_A2 = new float[ds2];\n    float *h_B2 = new float[ds2];\n    for (int i = 0; i < ds2; ++i)\n    {\n        h_A2[i] = static_cast<float>(i);\n        h_B2[i] = static_cast<float>(i);\n    }\n    float expected_result2 = (ds2 - 1) * (ds2) * (2 * ds2 - 1) / 6.0f;   // Sum of squares formula\n    test_dot_product(ds2, h_A2, h_B2, expected_result2);\n\n    delete[] h_A2;\n    delete[] h_B2;\n\n    // Test case 3: Vectors with alternating pattern\n    int ds3     = 1 << 18;   // 256K elements\n    float *h_A3 = new float[ds3];\n    float *h_B3 = new float[ds3];\n    for (int i = 0; i < ds3; ++i)\n    {\n        h_A3[i] = (i % 2 == 0) ? 1.0f : -1.0f;\n        h_B3[i] = (i % 2 == 0) ? -1.0f : 1.0f;\n    }\n    float expected_result3 = -ds3;   // Each pair contributes -1 to the dot product\n    test_dot_product(ds3, h_A3, h_B3, expected_result3);\n\n    delete[] h_A3;\n    delete[] h_B3;\n\n    return 0;\n}\n\n// This CUDA function calculates the dot product of two vectors using dynamic shared memory.\n// It efficiently handles cases where the size of the vectors may be larger than the total number of\n// available threads.\n__global__ void dot_product(const float *A, const float *B, float *result, int ds)\n{\n", "test": "int main() {\n    launch();\n}\n", "example_test": "    @example_test\n", "cuda_toolkit": "12.0"}
{"task_id": "CUDA/10", "date": "2025-03-31", "prompt": "Write a CUDA function called `gpuRecursiveReduce` that performs recursive reduction on an input\narray using dynamic parallelism and dynamic shared memory.\n\nThe signature of the function is:\n```cuda\n__global__ void gpuRecursiveReduce(int *g_idata, int *g_odata, unsigned int isize)\n```\n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_70 -arch=sm_60", "ld_flags": "-rdc=true -lcudadevrt", "declaration": "#include <assert.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <time.h>\n\n#define cudaCheckErrors(msg)                                                                   \\\n    do                                                                                         \\\n    {                                                                                          \\\n        cudaError_t __err = cudaGetLastError();                                                \\\n        if (__err != cudaSuccess)                                                              \\\n        {                                                                                      \\\n            fprintf(stderr, \"Fatal error: %s (%s at %s:%d)\\n\", msg, cudaGetErrorString(__err), \\\n                    __FILE__, __LINE__);                                                       \\\n            fprintf(stderr, \"*** FAILED - ABORTING\\n\");                                        \\\n            exit(1);                                                                           \\\n        }                                                                                      \\\n    }                                                                                          \\\n    while (0)\n\n__global__ void gpuRecursiveReduce(int *g_idata, int *g_odata, unsigned int isize);\n\nvoid initializeArray(int *data, int size)\n{\n    for (int i = 0; i < size; i++)\n    {\n        // set random seed\n        srand(time(NULL));\n\n        data[i] = rand() % 100;\n    }\n}\n\nint cpuReduce(int *data, int size)\n{\n    int sum = 0;\n    for (int i = 0; i < size; i++)\n    {\n        sum += data[i];\n    }\n    return sum;\n}\n\nint launch(void)\n{\n    int isize    = 1 << 20;   // 2^20 elements\n    int *h_idata = (int *)malloc(isize * sizeof(int));\n    int *h_odata = (int *)malloc(isize * sizeof(int));\n    int *d_idata, *d_odata;\n\n    initializeArray(h_idata, isize);\n\n    int cpu_sum = cpuReduce(h_idata, isize);\n\n    cudaMalloc(&d_idata, isize * sizeof(int));\n    cudaMalloc(&d_odata, isize * sizeof(int));\n\n    cudaMemcpy(d_idata, h_idata, isize * sizeof(int), cudaMemcpyHostToDevice);\n\n    int threads = 256;\n    int blocks  = (isize + threads - 1) / threads;\n    gpuRecursiveReduce<<<blocks, threads, threads * sizeof(int)>>>(d_idata, d_odata, isize);\n    cudaCheckErrors(\"Kernel launch failure\");\n\n    cudaMemcpy(h_odata, d_odata, blocks * sizeof(int), cudaMemcpyDeviceToHost);\n    cudaCheckErrors(\"Memcpy failure\");\n\n    int gpu_sum = cpuReduce(h_odata, blocks);\n\n    assert(cpu_sum == gpu_sum);\n\n    free(h_idata);\n    free(h_odata);\n    cudaFree(d_idata);\n    cudaFree(d_odata);\n\n    return 0;\n}\n\n__global__ void gpuRecursiveReduce(int *g_idata, int *g_odata, unsigned int isize)\n{\n", "test": "int main() {\n    launch();\n\n}\n", "example_test": "    @example_test\n", "cuda_toolkit": "12.0"}
{"task_id": "CUDA/11", "date": "2025-03-31", "prompt": "Implement a CUDA kernel function called `histogram` that efficiently calculates the histogram of a large input array of non-negative integers. The number of histogram bins is determined by the `num_bins` parameter. Use dynamic shared memory for storing the block-level histogram bins. The function should be optimized for performance and handle input arrays that are larger than the number of threads in a block.\n\nThe signature of the function is:\n```cuda\n__global__ void histogram(int *input, int *bins, int size, int num_bins)\n```\n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_70 -arch=sm_60", "ld_flags": "", "declaration": "#include <cstdio>\n#include <cassert>\n#include <cstdlib>\n\n#define cudaCheckErrors(msg) \\\n    do { \\\n        cudaError_t __err = cudaGetLastError(); \\\n        if (__err != cudaSuccess) { \\\n            fprintf(stderr, \"Fatal error: %s (%s at %s:%d)\", \\\n                msg, cudaGetErrorString(__err), \\\n                __FILE__, __LINE__); \\\n            fprintf(stderr, \"*** FAILED - ABORTING\"); \\\n            exit(1); \\\n        } \\\n    } while (0)\n\n__global__ void histogram(int *input, int *bins, int size, int num_bins);\n\n\nbool validate(const int *input, const int *bins, int size, int num_bins) {\n    int *reference_bins = new int[num_bins]{0};\n\n    for (int i = 0; i < size; ++i) {\n        int value = input[i];\n        if (value >= 0 && value < num_bins) {\n            reference_bins[value]++;\n        }\n    }\n\n    for (int i = 0; i < num_bins; ++i) {\n        if (bins[i] != reference_bins[i]) {\n            delete[] reference_bins;\n            return false;\n        }\n    }\n\n    delete[] reference_bins;\n    return true;\n}\n\nint launch() {\n    int size = (1 << 24) + 1;  // 16M + 1 elements\n    int num_bins = 128;\n    const int BLOCK_SIZE = 256;\n\n    int *h_input = new int[size];\n    int *h_bins = new int[num_bins]{0};\n\n    for (int i = 0; i < size; ++i) {\n        h_input[i] = rand() % num_bins;\n    }\n\n    int *d_input, *d_bins;\n    cudaMalloc(&d_input, size * sizeof(int));\n    cudaMalloc(&d_bins, num_bins * sizeof(int));\n    cudaCheckErrors(\"cudaMalloc failure\");\n\n    cudaMemcpy(d_input, h_input, size * sizeof(int), cudaMemcpyHostToDevice);\n    cudaCheckErrors(\"cudaMemcpy H2D failure\");\n\n    int gridSize = (size + BLOCK_SIZE - 1) / BLOCK_SIZE;\n    int shared_memory_size = num_bins * sizeof(int);\n    histogram<<<gridSize, BLOCK_SIZE, shared_memory_size>>>(d_input, d_bins, size, num_bins);\n    cudaCheckErrors(\"kernel launch failure\");\n\n    cudaMemcpy(h_bins, d_bins, num_bins * sizeof(int), cudaMemcpyDeviceToHost);\n    cudaCheckErrors(\"cudaMemcpy D2H failure\");\n\n    assert(validate(h_input, h_bins, size, num_bins));\n\n    delete[] h_input;\n    delete[] h_bins;\n    cudaFree(d_input);\n    cudaFree(d_bins);\n\n    return 0;\n}\n\n// This CUDA kernel efficiently calculates the histogram of a large input array of non-negative integers.\n// It is optimized for performance and handles input arrays larger than the number of threads in a block.\n// The histogram bins are stored in global memory.\n__global__ void histogram(int *input, int *bins, int size, int num_bins)\n{\n", "test": "int main() {\n    launch();\n\n}\n", "example_test": "    @example_test\n", "cuda_toolkit": "12.0"}
{"task_id": "CUDA/12", "date": "2025-03-31", "prompt": "Implement a CUDA kernel function called `histogram_2d` to calculate the 2D histogram of an input\narray of non-negative integer pairs. Each pair represents coordinates in a 2D space. The histogram\nbins, determined by `num_bins_x` and `num_bins_y`, should be stored in global memory as a 1D array\nin row-major order.\n\nThe input array `input` is a 1D array of size `2 * size`, where each pair of consecutive elements\nrepresents the x and y coordinates of a point. Use dynamic shared memory for the histogram bins\nwithin each block.\n\nThe function signature is:\n```cuda\n__global__ void histogram_2d(int *input, int *bins, int size, int num_bins_x, int num_bins_y)\n```\n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_70 -arch=sm_60", "ld_flags": "", "declaration": "#include <cassert>\n#include <cstdio>\n#include <cstdlib>\n\n#define cudaCheckErrors(msg)                                                                 \\\n    do                                                                                       \\\n    {                                                                                        \\\n        cudaError_t __err = cudaGetLastError();                                              \\\n        if (__err != cudaSuccess)                                                            \\\n        {                                                                                    \\\n            fprintf(stderr, \"Fatal error: %s (%s at %s:%d)\", msg, cudaGetErrorString(__err), \\\n                    __FILE__, __LINE__);                                                     \\\n            fprintf(stderr, \"*** FAILED - ABORTING\");                                        \\\n            exit(1);                                                                         \\\n        }                                                                                    \\\n    }                                                                                        \\\n    while (0)\n\n__global__ void histogram_2d(int *input, int *bins, int size, int num_bins_x, int num_bins_y);\n\nint launch()\n{\n    const int size       = 1024 * 1024 * 16;\n    const int num_bins_x = 100;\n    const int num_bins_y = 100;\n\n    int *input = new int[2 * size];\n    int *bins  = new int[num_bins_x * num_bins_y];\n\n    // Initialize input array with random values\n    for (int i = 0; i < size; i++)\n    {\n        input[2 * i]     = random() % num_bins_x;\n        input[2 * i + 1] = random() % num_bins_y;\n    }\n\n    int *d_input;\n    int *d_bins;\n    cudaMalloc(&d_input, 2 * size * sizeof(int));\n    cudaMalloc(&d_bins, num_bins_x * num_bins_y * sizeof(int));\n    cudaCheckErrors(\"cudaMalloc\");\n\n    cudaMemcpy(d_input, input, 2 * size * sizeof(int), cudaMemcpyHostToDevice);\n    cudaMemset(d_bins, 0, num_bins_x * num_bins_y * sizeof(int));\n    cudaCheckErrors(\"cudaMemcpy/cudaMemset\");\n\n    int block_size      = 256;\n    int num_blocks      = (size + block_size - 1) / block_size;\n    int shared_mem_size = num_bins_x * num_bins_y * sizeof(int);\n\n    histogram_2d<<<num_blocks, block_size, shared_mem_size>>>(d_input, d_bins, size, num_bins_x,\n                                                              num_bins_y);\n    cudaCheckErrors(\"histogram_2d kernel\");\n\n    cudaMemcpy(bins, d_bins, num_bins_x * num_bins_y * sizeof(int), cudaMemcpyDeviceToHost);\n    cudaCheckErrors(\"cudaMemcpy\");\n\n    // Compute histogram on CPU for comparison\n    int *cpu_bins = new int[num_bins_x * num_bins_y];\n    memset(cpu_bins, 0, num_bins_x * num_bins_y * sizeof(int));\n\n    for (int i = 0; i < size; i++)\n    {\n        int x = input[2 * i];\n        int y = input[2 * i + 1];\n        cpu_bins[y * num_bins_x + x]++;\n    }\n\n    // Verify the histogram\n    for (int i = 0; i < num_bins_x * num_bins_y; i++)\n    {\n        assert(bins[i] == cpu_bins[i]);\n    }\n\n    // Clean up\n    delete[] input;\n    delete[] bins;\n    delete[] cpu_bins;\n    cudaFree(d_input);\n    cudaFree(d_bins);\n\n    return 0;\n}\n\n// This CUDA kernel efficiently calculates the 2D histogram of a large input array of non-negative\n// integer pairs. It is optimized for performance and handles input arrays larger than the number of\n// threads in a block. The histogram bins are stored in global memory as a 1D array in row-major\n// order.\n__global__ void histogram_2d(int *input, int *bins, int size, int num_bins_x, int num_bins_y)\n{\n", "test": "int main() {\n    launch();\n\n}\n", "example_test": "    @example_test\n", "cuda_toolkit": "12.0"}
{"task_id": "CUDA/13", "date": "2025-03-31", "prompt": "Write a CUDA function called `inc` that increments a large array on the GPU. The function should be\nable to handle arrays that are larger than the total number of threads launched in the grid.\n\nThe signature of the function is:\n```cuda\n__global__ void inc(int *array, size_t n)\n```\n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_70 -arch=sm_60", "ld_flags": "", "declaration": "#include <cassert>\n#include <cstdio>\n#include <cstdlib>\n#include <cstring>\n#include <ctime>\n\n#define cudaCheckErrors(msg)                                                                 \\\n    do                                                                                       \\\n    {                                                                                        \\\n        cudaError_t __err = cudaGetLastError();                                              \\\n        if (__err != cudaSuccess)                                                            \\\n        {                                                                                    \\\n            fprintf(stderr, \"Fatal error: %s (%s at %s:%d)\", msg, cudaGetErrorString(__err), \\\n                    __FILE__, __LINE__);                                                     \\\n            fprintf(stderr, \"*** FAILED - ABORTING\");                                        \\\n            exit(1);                                                                         \\\n        }                                                                                    \\\n    }                                                                                        \\\n    while (0)\n\n__global__ void inc(int *array, size_t n);\n\nconst size_t ds = 32ULL * 1024ULL * 1024ULL;\n\ntemplate <typename T>\nvoid alloc_bytes(T &ptr, size_t num_bytes)\n{\n    cudaMallocManaged(&ptr, num_bytes);\n}\n\nint launch()\n{\n    int *h_array;\n    int *h_array_original;   // To store the original values for validation\n    alloc_bytes(h_array, ds * sizeof(h_array[0]));\n    alloc_bytes(h_array_original, ds * sizeof(h_array_original[0]));\n    cudaCheckErrors(\"cudaMallocManaged Error\");\n\n    // Initialize random seed\n    srand(time(NULL));\n\n    // Initialize the array with random numbers and save original values\n    for (size_t i = 0; i < ds; i++)\n    {\n        h_array[i]          = rand() % 100;   // Random numbers between 0 and 99\n        h_array_original[i] = h_array[i];\n    }\n\n    cudaMemPrefetchAsync(h_array, ds * sizeof(h_array[0]), 0);\n\n    inc<<<256, 256>>>(h_array, ds);\n    cudaCheckErrors(\"kernel launch error\");\n\n    cudaMemPrefetchAsync(h_array, ds * sizeof(h_array[0]), cudaCpuDeviceId);\n    cudaDeviceSynchronize();\n    cudaCheckErrors(\"kernel execution error\");\n\n    // Validate the results inside the main function\n    for (size_t i = 0; i < ds; i++)\n    {\n        assert(h_array[i] == h_array_original[i] + 1);\n    }\n\n    cudaFree(h_array);\n    cudaFree(h_array_original);\n    return 0;\n}\n\n// This CUDA kernel increments each element of the input array by 1.\n// It can handle arrays of any size, even those larger than the total number of threads in the grid.\n__global__ void inc(int *array, size_t n)\n{\n", "test": "int main() {\n    launch();\n}\n", "example_test": "    @example_test\n", "cuda_toolkit": "12.0"}
{"task_id": "CUDA/14", "date": "2025-03-31", "prompt": "Write a CUDA function called `mmul` that performs matrix multiplication of two square matrices using\nstatically allocated shared memory. Assume that the block size is already defined as a constant\n`block_size`. Use it appropriately in your function.\n\nThe signature of the function is:\n```cuda\n__global__ void mmul(const float *A, const float *B, float *C, int ds)\n```\n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_70 -arch=sm_60", "ld_flags": "", "declaration": "#include <assert.h>\n#include <stdio.h>\n#include <time.h>\n#include <cstdlib>\n\n#define cudaCheckErrors(msg)                                                                   \\\n    do                                                                                         \\\n    {                                                                                          \\\n        cudaError_t __err = cudaGetLastError();                                                \\\n        if (__err != cudaSuccess)                                                              \\\n        {                                                                                      \\\n            fprintf(stderr, \"Fatal error: %s (%s at %s:%d)\\n\", msg, cudaGetErrorString(__err), \\\n                    __FILE__, __LINE__);                                                       \\\n            fprintf(stderr, \"*** FAILED - ABORTING\\n\");                                        \\\n            exit(1);                                                                           \\\n        }                                                                                      \\\n    }                                                                                          \\\n    while (0)\n\nconst int DSIZE      = 4096;\nconst int block_size = 32;\n\n__global__ void mmul(const float *A, const float *B, float *C, int ds);\n\nint launch()\n{\n    float *h_A, *h_B, *h_C, *d_A, *d_B, *d_C;\n\n    h_A = new float[DSIZE * DSIZE];\n    h_B = new float[DSIZE * DSIZE];\n    h_C = new float[DSIZE * DSIZE];\n\n    // Initialize random seed\n    srand(time(NULL));\n\n    // Initialize the matrices with random numbers from 1 to 10\n    for (int i = 0; i < DSIZE * DSIZE; i++)\n    {\n        h_A[i] = static_cast<float>(rand() % 10 + 1);\n        h_B[i] = static_cast<float>(rand() % 10 + 1);\n        h_C[i] = 0;\n    }\n\n    cudaMalloc(&d_A, DSIZE * DSIZE * sizeof(float));\n    cudaMalloc(&d_B, DSIZE * DSIZE * sizeof(float));\n    cudaMalloc(&d_C, DSIZE * DSIZE * sizeof(float));\n    cudaCheckErrors(\"cudaMalloc failure\");\n\n    cudaMemcpy(d_A, h_A, DSIZE * DSIZE * sizeof(float), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_B, h_B, DSIZE * DSIZE * sizeof(float), cudaMemcpyHostToDevice);\n    cudaCheckErrors(\"cudaMemcpy H2D failure\");\n\n    dim3 block(block_size, block_size);\n    dim3 grid((DSIZE + block.x - 1) / block.x, (DSIZE + block.y - 1) / block.y);\n\n    mmul<<<grid, block>>>(d_A, d_B, d_C, DSIZE);\n    cudaCheckErrors(\"kernel launch failure\");\n\n    cudaMemcpy(h_C, d_C, DSIZE * DSIZE * sizeof(float), cudaMemcpyDeviceToHost);\n    cudaCheckErrors(\"kernel execution failure or cudaMemcpy H2D failure\");\n\n    // Validate the results using a subset of the elements\n    // as the original matrices are too large to compare all elements within a reasonable time\n    const int num_checks = 2048;\n    for (int i = 0; i < num_checks; i++)\n    {\n        int row              = rand() % DSIZE;\n        int col              = rand() % DSIZE;\n        float expected_value = 0;\n        for (int k = 0; k < DSIZE; k++)\n        {\n            expected_value += h_A[row * DSIZE + k] * h_B[k * DSIZE + col];\n        }\n        assert(fabs(h_C[row * DSIZE + col] - expected_value) < 1e-3);\n    }\n\n    cudaFree(d_A);\n    cudaFree(d_B);\n    cudaFree(d_C);\n    delete[] h_A;\n    delete[] h_B;\n    delete[] h_C;\n\n    return 0;\n}\n\n// This CUDA kernel multiplies two matrices A and B using shared memory\n// and stores the result in matrix C.\n__global__ void mmul(const float *A, const float *B, float *C, int ds)\n{\n", "test": "int main() {\n    launch();\n}\n", "example_test": "    @example_test\n", "cuda_toolkit": "12.0"}
{"task_id": "CUDA/15", "date": "2025-03-31", "prompt": "Write CUDA functions to perform parallel reductions using specific partitioning strategies:\n\n1. A device function called `reduce`, which uses a cooperative group to perform a reduction on\nintegers stored in dynamic shared memory. This function should return the reduced result from shared\nmemory.\n2. Multiple kernel functions demonstrating different partitioning strategies:\n   - `block_reduce_kernel` uses the entire block as a single group.\n   - `tile32_reduce_kernel` uses tiled partitioning with a tile size of 32.\n\nThe following headers are already defined and should not be included in the response:\n```\n#include <cooperative_groups.h>\nusing namespace cooperative_groups;\n```\n\nImplement the functions in the following order using the provided signatures:\n```cuda\n__device__ int reduce(thread_group g, int *x, int val);\n__global__ void block_reduce_kernel(int *data, int *result, int size);\n__global__ void tile32_reduce_kernel(int *data, int *result, int size);\n```\n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_70 -arch=sm_60", "ld_flags": "", "declaration": "#include <assert.h>\n#include <cooperative_groups.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <time.h>\n\nusing namespace cooperative_groups;\n\n#define cudaCheckErrors(msg)                                                                   \\\n    do                                                                                         \\\n    {                                                                                          \\\n        cudaError_t __err = cudaGetLastError();                                                \\\n        if (__err != cudaSuccess)                                                              \\\n        {                                                                                      \\\n            fprintf(stderr, \"Fatal error: %s (%s at %s:%d)\\n\", msg, cudaGetErrorString(__err), \\\n                    __FILE__, __LINE__);                                                       \\\n            fprintf(stderr, \"*** FAILED - ABORTING\\n\");                                        \\\n            exit(1);                                                                           \\\n        }                                                                                      \\\n    }                                                                                          \\\n    while (0)\n\n__global__ void tile32_reduce_kernel(int *data, int *result, int size);\n__global__ void block_reduce_kernel(int *data, int *result, int size);\n\nvoid test_kernel(void (*kernel)(int *, int *, int), int size, const int *h_data,\n                 int expected_result, int block_size, int grid_size)\n{\n    int *d_data, *d_result;\n    int h_result = 0;\n\n    cudaMalloc(&d_data, size * sizeof(int));\n    cudaMalloc(&d_result, sizeof(int));\n    cudaCheckErrors(\"cudaMalloc failure\");\n\n    cudaMemcpy(d_data, h_data, size * sizeof(int), cudaMemcpyHostToDevice);\n    cudaCheckErrors(\"cudaMemcpy H2D failure\");\n\n    cudaMemset(d_result, 0, sizeof(int));\n    cudaCheckErrors(\"cudaMemset failure\");\n\n    int shared_mem_size = block_size * sizeof(int);\n    kernel<<<grid_size, block_size, shared_mem_size>>>(d_data, d_result, size);\n    cudaCheckErrors(\"Kernel launch failure\");\n\n    cudaMemcpy(&h_result, d_result, sizeof(int), cudaMemcpyDeviceToHost);\n    cudaCheckErrors(\"cudaMemcpy D2H failure\");\n\n    assert(fabs(h_result - expected_result) < 1e-5);\n    cudaFree(d_data);\n    cudaFree(d_result);\n    cudaCheckErrors(\"cudaFree failure\");\n}\n\nvoid launch()\n{\n    srand(time(NULL));\n\n    const int size   = 2 << 20;   // 2M elements\n    int *h_data      = new int[size];\n    int expected_sum = 0;\n    for (int i = 0; i < size; ++i)\n    {\n        h_data[i] = rand() % 100;   // Random values between 0 and 99\n        expected_sum += h_data[i];\n    }\n\n    int block_size = 256;\n    int normal_grid_size =\n        (size + block_size - 1) / block_size;   // this will be (2M + 256 - 1) / 256 = 8192\n    int limited_grid_size =\n        min(normal_grid_size, 512);   // Force a smaller grid size to test striding\n\n    // Test with normal grid size, where size >= block_size * grid_size\n    test_kernel(block_reduce_kernel, size, h_data, expected_sum, block_size, normal_grid_size);\n    test_kernel(tile32_reduce_kernel, size, h_data, expected_sum, block_size, normal_grid_size);\n\n    // Test with limited grid size, where size < block_size * grid_size\n    test_kernel(block_reduce_kernel, size, h_data, expected_sum, block_size, limited_grid_size);\n    test_kernel(tile32_reduce_kernel, size, h_data, expected_sum, block_size, limited_grid_size);\n\n    delete[] h_data;\n}\n\n", "test": "int main() {\nlaunch();\n\n}\n", "example_test": "@example_test\n", "cuda_toolkit": "12.0"}
{"task_id": "CUDA/16", "date": "2025-03-31", "prompt": "Write a CUDA function called `performComplexConcurrentOperations` that takes three input arrays and\nan output array, performs a series of operations using CUDA kernels, and returns the processed data\nback to the host. The CUDA kernel functions you need to apply are defined as follows:\n\n```cuda\n__global__ void kernelSquare(int *data, int size) {\n    int i = blockIdx.x * blockDim.x + threadIdx.x;\n    if (i < size) {\n        data[i] = data[i] * data[i];\n    }\n}\n\n__global__ void kernelIncrement(int *data, int size) {\n    int i = blockIdx.x * blockDim.x + threadIdx.x;\n    if (i < size) {\n        data[i] += 1;\n    }\n}\n\n__global__ void kernelDouble(int *data, int size) {\n    int i = blockIdx.x * blockDim.x + threadIdx.x;\n    if (i < size) {\n        data[i] *= 2;\n    }\n}\n\n__global__ void kernelAdd(int *result, const int *a, const int *b, int size) {\n    int i = blockIdx.x * blockDim.x + threadIdx.x;\n    if (i < size) {\n        result[i] = a[i] + b[i];\n    }\n}\n```\n\nIn the `performComplexConcurrentOperations` function, use CUDA streams to perform the following\noperations efficiently: compute the intermediate arrays \\( X' = X^2 \\), \\( Y' = Y + 1 \\), and \\( Z'\n= 2Z \\); then calculate \\( A = X' + Y' \\) and \\( B = Y + Z' \\); and finally compute the result as \\(\n\\text{result} = (A + B)^2 \\). Ensure the use of appropriate concurrency mechanisms to optimize\nperformance.\n\nThe signature of the `performComplexConcurrentOperations` function is:\n```cuda\nvoid performComplexConcurrentOperations(int *result, const int *arrayX, const int *arrayY, const int\n*arrayZ, int size)\n```\n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_70 -arch=sm_60", "ld_flags": "", "declaration": "#include <cassert>\n#include <cstdlib>\n\n__global__ void kernelSquare(int *data, int size)\n{\n    int i = blockIdx.x * blockDim.x + threadIdx.x;\n    if (i < size)\n    {\n        data[i] = data[i] * data[i];\n    }\n}\n\n__global__ void kernelIncrement(int *data, int size)\n{\n    int i = blockIdx.x * blockDim.x + threadIdx.x;\n    if (i < size)\n    {\n        data[i] += 1;\n    }\n}\n\n__global__ void kernelDouble(int *data, int size)\n{\n    int i = blockIdx.x * blockDim.x + threadIdx.x;\n    if (i < size)\n    {\n        data[i] *= 2;\n    }\n}\n\n__global__ void kernelAdd(int *result, const int *a, const int *b, int size)\n{\n    int i = blockIdx.x * blockDim.x + threadIdx.x;\n    if (i < size)\n    {\n        result[i] = a[i] + b[i];\n    }\n}\nvoid performComplexConcurrentOperations(int *result, const int *arrayX, const int *arrayY,\n                                        const int *arrayZ, int size);\n\n// CPU function to calculate the expected result\nvoid calculateOnCPU(int *result, const int *arrayX, const int *arrayY, const int *arrayZ, int size)\n{\n    for (int i = 0; i < size; ++i)\n    {\n        int X_prime = arrayX[i] * arrayX[i];\n        int Y_prime = arrayY[i] + 1;\n        int Z_prime = arrayZ[i] * 2;\n        int A       = X_prime + Y_prime;\n        int B       = arrayY[i] + Z_prime;\n        result[i]   = (A + B) * (A + B);\n    }\n}\n\nint launch()\n{\n    const int size = 1 << 20;   // 1M elements\n    int *arrayX    = new int[size];\n    int *arrayY    = new int[size];\n    int *arrayZ    = new int[size];\n    int *result    = new int[size];\n    int *expected  = new int[size];\n\n    // Generate random test data\n    for (int i = 0; i < size; ++i)\n    {\n        arrayX[i] = rand() % 100;\n        arrayY[i] = rand() % 10;\n        arrayZ[i] = rand() % 50;\n    }\n    // Perform the operations on the GPU\n    performComplexConcurrentOperations(result, arrayX, arrayY, arrayZ, size);\n\n    // Calculate the expected results on the CPU\n    calculateOnCPU(expected, arrayX, arrayY, arrayZ, size);\n\n    // Verify the results\n    for (int i = 0; i < size; ++i)\n    {\n        assert(result[i] == expected[i]);\n    }\n\n    // Clean up\n    delete[] arrayX;\n    delete[] arrayY;\n    delete[] arrayZ;\n    delete[] result;\n    delete[] expected;\n\n    return 0;\n}\n\n// CUDA function prototypes\nvoid performComplexConcurrentOperations(int *result, const int *arrayX, const int *arrayY,\n                                        const int *arrayZ, int size)\n{\n", "test": "int main() {\n    launch();\n}\n", "example_test": "    @example_test\n", "cuda_toolkit": "12.0"}
{"task_id": "CUDA/17", "date": "2025-03-31", "prompt": "Write a CUDA function called `reduce` that performs a max-finding reduction to find the maximum\nvalue in an array using a parallel-sweep-reduction technique. Assume that `BLOCK_SIZE` is defined as\na constant. Use `BLOCK_SIZE` appropriately in your function.\n\nThe signature of the function is:\n```cuda\n__global__ void reduce(float *gdata, float *out, size_t n)\n```\n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_70 -arch=sm_60", "ld_flags": "", "declaration": "#include <assert.h>\n#include <float.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <time.h>\n\n#define cudaCheckErrors(msg)                                                                 \\\n    do                                                                                       \\\n    {                                                                                        \\\n        cudaError_t __err = cudaGetLastError();                                              \\\n        if (__err != cudaSuccess)                                                            \\\n        {                                                                                    \\\n            fprintf(stderr, \"Fatal error: %s (%s at %s:%d)\", msg, cudaGetErrorString(__err), \\\n                    __FILE__, __LINE__);                                                     \\\n            fprintf(stderr, \"*** FAILED - ABORTING\");                                        \\\n            exit(1);                                                                         \\\n        }                                                                                    \\\n    }                                                                                        \\\n    while (0)\n\nconst int BLOCK_SIZE = 256;\n\n__global__ void reduce(float *gdata, float *out, size_t n);\n\nbool validate(float *h_A, float *h_sum, size_t n)\n{\n    float max_val = -FLT_MAX;\n    for (size_t i = 0; i < n; i++)\n    {\n        if (h_A[i] > max_val)\n        {\n            max_val = h_A[i];\n        }\n    }\n    return fabs(*h_sum - max_val) < 1e-5;\n}\n\n// This CUDA kernel finds the maximum value in the 'gdata' array\n// using parallel reduction and stores the result in the 'out' array.\n__global__ void reduce(float *gdata, float *out, size_t n)\n{\n", "test": "int main() {\n\n    auto launch = []() -> void {\n\n        float *h_A, *h_sum, *d_A, *d_sums;\n        const int blocks = 640;\n        const size_t N   = 8ULL * 1024ULL * 1024ULL;\n        h_A              = new float[N];\n        h_sum            = new float;\n\n        // Initialize random seed\n        srand(time(NULL));\n\n        // Initialize the array with random numbers\n        float max_val = -FLT_MAX;\n        for (size_t i = 0; i < N; i++)\n        {\n            h_A[i] = static_cast<float>(rand()) / RAND_MAX;\n            if (h_A[i] > max_val)\n            {\n                max_val = h_A[i];\n            }\n        }\n\n        cudaMalloc(&d_A, N * sizeof(float));\n        cudaMalloc(&d_sums, blocks * sizeof(float));\n        cudaCheckErrors(\"cudaMalloc failure\");\n\n        cudaMemcpy(d_A, h_A, N * sizeof(float), cudaMemcpyHostToDevice);\n        cudaCheckErrors(\"cudaMemcpy H2D failure\");\n\n        reduce<<<blocks, BLOCK_SIZE>>>(d_A, d_sums, N);\n        cudaCheckErrors(\"reduction kernel launch failure\");\n\n        reduce<<<1, BLOCK_SIZE>>>(d_sums, d_A, blocks);\n        cudaCheckErrors(\"reduction kernel launch failure\");\n\n        cudaMemcpy(h_sum, d_A, sizeof(float), cudaMemcpyDeviceToHost);\n        cudaCheckErrors(\"reduction w/atomic kernel execution failure or cudaMemcpy D2H failure\");\n\n        assert(validate(h_A, h_sum, N));\n\n\n        // Put the maximum value at the end of the array to check if the program correctly handles arrays longer than the no of threads\n        max_val = 1.1;\n        h_A[N - 1] = max_val;\n\n        cudaMemcpy(d_A, h_A, N * sizeof(float), cudaMemcpyHostToDevice);\n        cudaCheckErrors(\"cudaMemcpy H2D failure\");\n\n        reduce<<<blocks, BLOCK_SIZE>>>(d_A, d_sums, N);\n        cudaCheckErrors(\"reduction kernel launch failure\");\n\n        reduce<<<1, BLOCK_SIZE>>>(d_sums, d_A, blocks);\n        cudaCheckErrors(\"reduction kernel launch failure\");\n\n        cudaMemcpy(h_sum, d_A, sizeof(float), cudaMemcpyDeviceToHost);\n        cudaCheckErrors(\"reduction w/atomic kernel execution failure or cudaMemcpy D2H failure\");\n\n        cudaMemcpy(h_sum, d_A, sizeof(float), cudaMemcpyDeviceToHost);\n        cudaCheckErrors(\"reduction w/atomic kernel execution failure or cudaMemcpy D2H failure\");\n\n        assert(validate(h_A, h_sum, N));\n\n        delete[] h_A;\n        delete h_sum;\n        cudaFree(d_A);\n        cudaFree(d_sums);\n    };\n\n    launch();\n\n}\n", "example_test": "    @example_test\n", "cuda_toolkit": "12.0"}
{"task_id": "CUDA/18", "date": "2025-03-31", "prompt": "Write a CUDA function called `row_sums` that performs a simple matrix row sum.\n\nThe signature of the function is:\n```cuda\n__global__ void row_sums(const float *A, float *sums, size_t ds)\n```\n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_70 -arch=sm_60", "ld_flags": "", "declaration": "#include <assert.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <time.h>\n#include <cmath>\n\n#define cudaCheckErrors(msg)                                                                 \\\n    do                                                                                       \\\n    {                                                                                        \\\n        cudaError_t __err = cudaGetLastError();                                              \\\n        if (__err != cudaSuccess)                                                            \\\n        {                                                                                    \\\n            fprintf(stderr, \"Fatal error: %s (%s at %s:%d)\", msg, cudaGetErrorString(__err), \\\n                    __FILE__, __LINE__);                                                     \\\n            fprintf(stderr, \"*** FAILED - ABORTING\");                                        \\\n            exit(1);                                                                         \\\n        }                                                                                    \\\n    }                                                                                        \\\n    while (0)\n\n__global__ void row_sums(const float *A, float *sums, size_t ds);\n\nint launch()\n{\n    const int block_size = 256;\n\n    // Initialize random seed\n    srand(time(NULL));\n\n    for (int i = 1; i <= 32; i *= 4)\n    {\n        int DSIZE = 256 * i;\n\n        float *h_A, *h_sums, *d_A, *d_sums;\n        h_A    = new float[DSIZE * DSIZE];\n        h_sums = new float[DSIZE]();\n\n        // Initialize host arrays with random numbers\n        for (int i = 0; i < DSIZE * DSIZE; i++)\n        {\n            h_A[i] = static_cast<float>(rand()) / RAND_MAX * 100;\n        }\n\n        cudaMalloc(&d_A, DSIZE * DSIZE * sizeof(float));\n        cudaMalloc(&d_sums, DSIZE * sizeof(float));\n        cudaCheckErrors(\"cudaMalloc failure\");\n\n        cudaMemcpy(d_A, h_A, DSIZE * DSIZE * sizeof(float), cudaMemcpyHostToDevice);\n        cudaCheckErrors(\"cudaMemcpy H2D failure\");\n\n        row_sums<<<(DSIZE + block_size - 1) / block_size, block_size>>>(d_A, d_sums, DSIZE);\n        cudaCheckErrors(\"kernel launch failure\");\n\n        cudaMemcpy(h_sums, d_sums, DSIZE * sizeof(float), cudaMemcpyDeviceToHost);\n        cudaCheckErrors(\"kernel execution failure or cudaMemcpy D2H failure\");\n\n        // Validate the results inside the main function\n        for (size_t j = 0; j < DSIZE; j++)\n        {\n            float expected_sum = 0.0f;\n            for (size_t k = 0; k < DSIZE; k++)\n            {\n                expected_sum += h_A[j * DSIZE + k];\n            }\n            assert(fabs(h_sums[j] - expected_sum) < 1e-5);\n        }\n\n        cudaFree(d_A);\n        cudaFree(d_sums);\n        delete[] h_A;\n        delete[] h_sums;\n    }\n\n    return 0;\n}\n\n__global__ void row_sums(const float *A, float *sums, size_t ds)\n{\n", "test": "int main() {\n    launch();\n}\n", "example_test": "    @example_test\n", "cuda_toolkit": "12.0"}
{"task_id": "CUDA/19", "date": "2025-03-31", "prompt": "Write a CUDA function called `process_data_on_gpu` that takes in a large dataset of floating-point\nvalues, applies a special operation to each element using a separate CUDA kernel, and returns the\nprocessed data back to the host. The CUDA kernel function you need to apply is defined as follows:\n\n```\n__global__ void apply_special_operation(float *data, size_t n) {\nsize_t idx = threadIdx.x + blockDim.x * blockIdx.x;\nif (idx < n) {\n    if (data[idx] > 0 && data[idx] < 10) {\n        data[idx] *= 2;\n    } else if (data[idx] >= 10) {\n        data[idx] -= 10;\n    } else {\n        data[idx] = 0;\n    }\n}\n```\n\nIn the `process_data_on_gpu` function, allocate memory for the input and output data on the GPU,\ntransfer the input data from the host to the GPU, launch the kernel aove with an appropriate number\nof blocks and threads to process the entire dataset, transfer the output data back to the host, and\nfree the allocated memory on the GPU.\n\nThe signature of the `process_data_on_gpu` function is:\n```cuda\nvoid process_data_on_gpu(float *h_input, float *h_output, size_t n)\n```\n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_70 -arch=sm_60", "ld_flags": "", "declaration": "#include <assert.h>\n#include <cuda_runtime.h>\n#include <math.h>\n#include <stdio.h>\n\n#define cudaCheckErrors(msg)                                                                 \\\n    do                                                                                       \\\n    {                                                                                        \\\n        cudaError_t __err = cudaGetLastError();                                              \\\n        if (__err != cudaSuccess)                                                            \\\n        {                                                                                    \\\n            fprintf(stderr, \"Fatal error: %s (%s at %s:%d)\", msg, cudaGetErrorString(__err), \\\n                    __FILE__, __LINE__);                                                     \\\n            fprintf(stderr, \"*** FAILED - ABORTING\");                                        \\\n            exit(1);                                                                         \\\n        }                                                                                    \\\n    }                                                                                        \\\n    while (0)\n\n__global__ void apply_special_operation(float *data, size_t n)\n{\n    size_t idx = threadIdx.x + blockDim.x * blockIdx.x;\n    if (idx < n)\n    {\n        if (data[idx] > 0 && data[idx] < 10)\n        {\n            data[idx] *= 2;\n        }\n        else if (data[idx] >= 10)\n        {\n            data[idx] -= 10;\n        }\n        else\n        {\n            data[idx] = 0;\n        }\n    }\n}\n\nvoid process_data_on_gpu(float *h_input, float *h_output, size_t n);\n\nint launch()\n{\n    const int N     = 10000;\n    float *h_input  = new float[N];\n    float *h_output = new float[N];\n\n    // Initialize input data\n    for (int i = 0; i < N; i++)\n    {\n        h_input[i] = static_cast<float>(rand()) / RAND_MAX * 20.0f;\n    }\n\n    // Process data on GPU\n    process_data_on_gpu(h_input, h_output, N);\n\n    // Validate results\n    for (int i = 0; i < N; i++)\n    {\n        float expected;\n        if (h_input[i] > 0 && h_input[i] < 10)\n        {\n            expected = h_input[i] * 2;\n        }\n        else if (h_input[i] >= 10)\n        {\n            expected = h_input[i] - 10;\n        }\n        else\n        {\n            expected = 0;\n        }\n        assert(fabs(h_output[i] - expected) < 1e-5);\n    }\n\n    // Free memory\n    delete[] h_input;\n    delete[] h_output;\n\n    return 0;\n}\n\n\nvoid process_data_on_gpu(float *h_input, float *h_output, size_t n)\n{\n", "test": "int main() {\n    launch();\n}\n", "example_test": "    @example_test\n", "cuda_toolkit": "12.0"}
{"task_id": "CUDA/20", "date": "2025-03-31", "prompt": "Write a CUDA kernel function called `stencil_1d` that performs a 1D stencil operation on a large 1D\narray. The stencil operation should calculate the sum of each element and its neighboring elements\nwithin a specified radius. The function should handle array sizes larger than the number of threads\nin a block and utilize statical shared memory for optimization.\n\nAssume that the following constants are defined:\n- `BLOCK_SIZE`: The number of threads per block\n- `RADIUS`: The radius of the stencil\n\nThe signature of the function is:\n```cuda\n__global__ void stencil_1d(int *in, int *out)\n```\n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_70 -arch=sm_60", "ld_flags": "", "declaration": "#include <cassert>\n#include <cstdio>\n\n#define cudaCheckErrors(msg)                                                                 \\\n    do                                                                                       \\\n    {                                                                                        \\\n        cudaError_t __err = cudaGetLastError();                                              \\\n        if (__err != cudaSuccess)                                                            \\\n        {                                                                                    \\\n            fprintf(stderr, \"Fatal error: %s (%s at %s:%d)\", msg, cudaGetErrorString(__err), \\\n                    __FILE__, __LINE__);                                                     \\\n            fprintf(stderr, \"*** FAILED - ABORTING\");                                        \\\n            exit(1);                                                                         \\\n        }                                                                                    \\\n    }                                                                                        \\\n    while (0)\n\nconst int BLOCK_SIZE = 256;\nconst int RADIUS     = 3;\n\n__global__ void stencil_1d(int *in, int *out);\n\nbool validate(const int *input, const int *output, int size)\n{\n    for (int i = 0; i < size; ++i)\n    {\n        int expected = 0;\n        for (int j = -RADIUS; j <= RADIUS; ++j)\n        {\n            int index = i + j;\n            if (index >= 0 && index < size)\n            {\n                expected += input[index];\n            }\n        }\n        if (output[i] != expected)\n        {\n            return false;\n        }\n    }\n    return true;\n}\n\nint launch()\n{\n    int size = 1 << 24;   // 16M elements\n\n    int *h_input  = new int[size];\n    int *h_output = new int[size];\n\n    for (int i = 0; i < size; ++i)\n    {\n        h_input[i] = rand() % 100;\n    }\n\n    int *d_input, *d_output;\n    cudaMalloc(&d_input, size * sizeof(int));\n    cudaMalloc(&d_output, size * sizeof(int));\n    cudaCheckErrors(\"cudaMalloc failure\");\n\n    cudaMemcpy(d_input, h_input, size * sizeof(int), cudaMemcpyHostToDevice);\n    cudaCheckErrors(\"cudaMemcpy H2D failure\");\n\n    int gridSize = (size + BLOCK_SIZE - 1) / BLOCK_SIZE;\n    stencil_1d<<<gridSize, BLOCK_SIZE>>>(d_input, d_output);\n    cudaCheckErrors(\"kernel launch failure\");\n\n    cudaMemcpy(h_output, d_output, size * sizeof(int), cudaMemcpyDeviceToHost);\n    cudaCheckErrors(\"cudaMemcpy D2H failure\");\n\n    assert(validate(h_input, h_output, size));\n\n    delete[] h_input;\n    delete[] h_output;\n    cudaFree(d_input);\n    cudaFree(d_output);\n\n    return 0;\n}\n\n// This CUDA kernel performs a 1D stencil operation on a large 1D array.\n// The stencil operation calculates the sum of each element and its neighboring elements within a\n// specified radius. The function handles array sizes larger than the number of threads in a block\n// and utilizes shared memory for optimization.\n__global__ void stencil_1d(int *in, int *out)\n{\n", "test": "int main() {\n    launch();\n}\n", "example_test": "    @example_test\n", "cuda_toolkit": "12.0"}
{"task_id": "CUDA/21", "date": "2025-03-31", "prompt": "Implement a CUDA kernel called stencil3d_kernel that performs a 3d stencil operation on the input\nfloat matrix and populates the output matrix with these values. The stencil operation should\ncalculate the sum of each element and its neighboring elements within a specified radius weighted by\na two values (C0) and (C1). C0 indicates how much a The function should handle array sizes larger\nthan the number of threads in a block and utilize statical shared memory and thread coarsening for\noptimization.\n\nAssume that the following constants are defined:\n- `BLOCK_DIM`: The number of threads per block\n- `C0`: the weight of the element itself\n- `C1`: the weight of the neighbouring elements\n- `IN_TILE_DIM`: the tile size on the input array\n- `OUT_TILE_DIM`: the tile size on the output array\n\n\nThe signature of the function is:\n```cuda\n__global__ void stencil3d_kernel(float *input, float *output, unsigned int N)\n```\n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_70 -arch=sm_60", "ld_flags": "", "declaration": "#include <cassert>\n#include <cstdlib>\n#include <ctime>\n#include <iostream>\n#include <random>\nusing namespace std;\n\n#define cudaCheckErrors(msg)                                                                 \\\n    do                                                                                       \\\n    {                                                                                        \\\n        cudaError_t __err = cudaGetLastError();                                              \\\n        if (__err != cudaSuccess)                                                            \\\n        {                                                                                    \\\n            fprintf(stderr, \"Fatal error: %s (%s at %s:%d)\", msg, cudaGetErrorString(__err), \\\n                    __FILE__, __LINE__);                                                     \\\n            fprintf(stderr, \"*** FAILED - ABORTING\");                                        \\\n            exit(1);                                                                         \\\n        }                                                                                    \\\n    }                                                                                        \\\n    while (0)\n\n#define BLOCK_DIM 8\n#define IN_TILE_DIM BLOCK_DIM\n#define OUT_TILE_DIM ((IN_TILE_DIM)-2)\n\n#define C0 0.95\n#define C1 0.05\n\n__global__ void stencil3d_kernel(float *input, float *output, unsigned int N);\n\nvoid stencil3d(float *input, float *output, unsigned int N)\n{\n    float *input_d, *output_d;\n    cudaMalloc(&input_d, N * N * N * sizeof(float));\n    cudaMalloc(&output_d, N * N * N * sizeof(float));\n    cudaCheckErrors(\"cudaMalloc failed\");\n\n    // Copy the memory from the host to the GPU\n    cudaMemcpy(input_d, input, N * N * N * sizeof(float), cudaMemcpyHostToDevice);\n    cudaCheckErrors(\"cudaMemcpu H2D failed\");\n\n    // Perform the 3d stencil operation\n    dim3 numberOfThreadsPerBlock(BLOCK_DIM, BLOCK_DIM, BLOCK_DIM);\n    dim3 numberOfBlocks((N + BLOCK_DIM - 1) / BLOCK_DIM, (N + BLOCK_DIM - 1) / BLOCK_DIM,\n                        (N + BLOCK_DIM - 1) / BLOCK_DIM);\n    stencil3d_kernel<<<numberOfBlocks, numberOfThreadsPerBlock>>>(input_d, output_d, N);\n    cudaCheckErrors(\"kernel execution failed\");\n\n    // Copy the result back to the host\n    cudaMemcpy(output, output_d, N * N * N * sizeof(float), cudaMemcpyDeviceToHost);\n    cudaCheckErrors(\"cudaMemcpy D2H failed\");\n\n    // Free the GPU Memory\n    cudaFree(input_d);\n    cudaFree(output_d);\n}\n\nvoid test(unsigned int N)\n{\n    // Allocate host memory\n    float *img = (float *)malloc(N * N * N * sizeof(float));\n    float *out = (float *)malloc(N * N * N * sizeof(float));\n\n    // Populate the arrays\n    for (int i = 0; i < N * N * N; i++)\n    {\n        img[i] = static_cast<float>(rand()) / RAND_MAX;\n    }\n\n    // Time the GPU operation\n    stencil3d(img, out, N);\n\n    // Free the allocated memory\n    free(img);\n    free(out);\n}\n\nvoid launch()\n{\n    cudaDeviceSynchronize();\n\n    // Seed the random number generator\n    srand(static_cast<unsigned int>(time(nullptr)));\n\n    const unsigned int TESTS = 2;\n    unsigned int Ns[]        = {1 << 6, 4096};\n    for (int i = 0; i < TESTS; i++)\n    {\n        test(Ns[i]);\n    }\n}\n\n// This CUDA kernel performs a 3D stencil operation on a large 3D array.\n// The stencil operation calculates the sum of each element and its neighboring elements within a\n// specified radius. The function handles array sizes larger than the number of threads in a block\n// and utilizes shared memory, and thread coarsening for optimization.\n__global__ void stencil3d_kernel(float *input, float *output, unsigned int N)\n{\n", "test": "int main() {\n    launch();\n}\n", "example_test": "    @example_test\n", "cuda_toolkit": "12.0"}
{"task_id": "CUDA/22", "date": "2025-03-31", "prompt": "Write a CUDA function called `transpose` that performs matrix transpose on a non-square matrix using\nstatically allocated shared memory. The input matrix is stored in row-major order, and the output\nmatrix should also be stored in row-major order.\n\nAssume that the following constant is defined:\n- `BLOCK_SIZE`: The size of the square thread block\n\nThe matrix dimensions, `width` and `height`, can be larger than `BLOCK_SIZE`. The function should\nhandle non-square matrices efficiently.\n\nThe signature of the function is:\n```cuda\n__global__ void transpose(const float *input, float *output, int width, int height)\n```\n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_70 -arch=sm_60", "ld_flags": "", "declaration": "#include <assert.h>\n#include <stdio.h>\n\n#define BLOCK_SIZE 16\n\n#define cudaCheckErrors(msg)                                                                 \\\n    do                                                                                       \\\n    {                                                                                        \\\n        cudaError_t __err = cudaGetLastError();                                              \\\n        if (__err != cudaSuccess)                                                            \\\n        {                                                                                    \\\n            fprintf(stderr, \"Fatal error: %s (%s at %s:%d)\", msg, cudaGetErrorString(__err), \\\n                    __FILE__, __LINE__);                                                     \\\n            fprintf(stderr, \"*** FAILED - ABORTING\");                                        \\\n            exit(1);                                                                         \\\n        }                                                                                    \\\n    }                                                                                        \\\n    while (0)\n\n__global__ void transpose(const float *input, float *output, int width, int height);\n\nbool validate_transpose(const float *input, const float *output, int width, int height)\n{\n    for (int i = 0; i < height; ++i)\n    {\n        for (int j = 0; j < width; ++j)\n        {\n            if (input[i * width + j] != output[j * height + i])\n            {\n                return false;\n            }\n        }\n    }\n    return true;\n}\n\nint launch()\n{\n    int width       = 1024;\n    int height      = 768;\n    int size        = width * height;\n    float *h_input  = new float[size];\n    float *h_output = new float[size];\n\n    for (int i = 0; i < size; ++i)\n    {\n        h_input[i] = static_cast<float>(i);\n    }\n\n    float *d_input, *d_output;\n    cudaMalloc(&d_input, size * sizeof(float));\n    cudaMalloc(&d_output, size * sizeof(float));\n    cudaCheckErrors(\"cudaMalloc failure\");\n\n    cudaMemcpy(d_input, h_input, size * sizeof(float), cudaMemcpyHostToDevice);\n    cudaCheckErrors(\"cudaMemcpy H2D failure\");\n\n    dim3 block_size(BLOCK_SIZE, BLOCK_SIZE);\n    dim3 grid_size((width + BLOCK_SIZE - 1) / BLOCK_SIZE, (height + BLOCK_SIZE - 1) / BLOCK_SIZE);\n    transpose<<<grid_size, block_size>>>(d_input, d_output, width, height);\n    cudaCheckErrors(\"kernel launch failure\");\n\n    cudaMemcpy(h_output, d_output, size * sizeof(float), cudaMemcpyDeviceToHost);\n    cudaCheckErrors(\"cudaMemcpy D2H failure\");\n\n    assert(validate_transpose(h_input, h_output, width, height));\n\n    delete[] h_input;\n    delete[] h_output;\n    cudaFree(d_input);\n    cudaFree(d_output);\n\n    return 0;\n}\n\n// This CUDA function performs matrix transpose on a non-square matrix using statically allocated\n// shared memory. The input matrix is stored in row-major order, and the output matrix is also\n// stored in row-major order.\n__global__ void transpose(const float *input, float *output, int width, int height)\n{\n", "test": "int main() {\n    launch();\n}\n", "example_test": "    @example_test\n", "cuda_toolkit": "12.0"}
{"task_id": "CUDA/23", "date": "2025-03-31", "prompt": "Implement a function called `transposeSquareMatrixManaged` that uses CUDA's Unified Memory to\ntranspose a square matrix. Below is the CUDA kernel `transposeSquareMatrixKernel` that performs the\nmatrix transposition which you can use in your function.\n\n```cuda\n__global__ void transposeSquareMatrixKernel(float* out, const float* in, int N) {\n    extern __shared__ float tile[];\n    int x = blockIdx.x * blockDim.x + threadIdx.x;\n    int y = blockIdx.y * blockDim.y + threadIdx.y;\n    int width = blockDim.x;\n\n    if (x < N && y < N) {\n        tile[threadIdx.y * width + threadIdx.x] = in[y * N + x];\n    }\n    __syncthreads();\n\n    x = blockIdx.y * blockDim.y + threadIdx.x; // transpose block offset\n    y = blockIdx.x * blockDim.x + threadIdx.y;\n\n    if (x < N && y < N) {\n        out[y * N + x] = tile[threadIdx.x * width + threadIdx.y];\n    }\n}\n```\n\nUse a block size of \\( 16 \\times 16 \\) for the CUDA kernel launch.\n\nThe signature of the function is:\n```cuda\nvoid transposeSquareMatrixManaged(float* h_in, float* h_out, int N)\n```\n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_70 -arch=sm_60", "ld_flags": "", "declaration": "#include <cuda_runtime.h>\n#include <cassert>\n#include <cstdlib>\n#include <ctime>\n\n__global__ void transposeSquareMatrixKernel(float* out, const float* in, int N)\n{\n    extern __shared__ float tile[];\n    int x     = blockIdx.x * blockDim.x + threadIdx.x;\n    int y     = blockIdx.y * blockDim.y + threadIdx.y;\n    int width = blockDim.x;\n\n    if (x < N && y < N)\n    {\n        tile[threadIdx.y * width + threadIdx.x] = in[y * N + x];\n    }\n    __syncthreads();\n\n    x = blockIdx.y * blockDim.y + threadIdx.x;   // transpose block offset\n    y = blockIdx.x * blockDim.x + threadIdx.y;\n\n    if (x < N && y < N)\n    {\n        out[y * N + x] = tile[threadIdx.x * width + threadIdx.y];\n    }\n}\n\nvoid transposeSquareMatrixManaged(float* h_in, float* h_out, int N);\n\nint launch()\n{\n    const int N = 256;   // Size of the square matrix\n    float h_in[N * N];\n    float h_out[N * N];\n\n    // Initialize random seed\n    std::srand(std::time(nullptr));\n\n    // Fill the input matrix with random values\n    for (int i = 0; i < N * N; ++i)\n    {\n        h_in[i] = static_cast<float>(std::rand()) / RAND_MAX;\n    }\n\n    // Call the function\n    transposeSquareMatrixManaged(h_in, h_out, N);\n\n    // Verify the transposed matrix\n    for (int i = 0; i < N; ++i)\n    {\n        for (int j = 0; j < N; ++j)\n        {\n            assert(h_out[i * N + j] == h_in[j * N + i]);\n        }\n    }\n\n    return 0;\n}\n\nvoid transposeSquareMatrixManaged(float* h_in, float* h_out, int N)\n{\n", "test": "int main() {\n    launch();\n\n}\n", "example_test": "    @example_test\n", "cuda_toolkit": "12.0"}
{"task_id": "CUDA/24", "date": "2025-03-31", "prompt": "Write a CUDA function called `vadd` that adds two vectors, the parameters are A and B.\n\nThe signature of the function is:\n```cuda\n__global__ void vadd(const float *A, const float *B, float *C, int ds)\n```\n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_70 -arch=sm_60", "ld_flags": "", "declaration": "#include <assert.h>\n#include <cuda.h>\n#include <math.h>\n#include <stdio.h>\n#include <stdlib.h>\n\n#define cudaCheckErrors(msg)                                                                   \\\n    do                                                                                         \\\n    {                                                                                          \\\n        cudaError_t __err = cudaGetLastError();                                                \\\n        if (__err != cudaSuccess)                                                              \\\n        {                                                                                      \\\n            fprintf(stderr, \"Fatal error: %s (%s at %s:%d)\\n\", msg, cudaGetErrorString(__err), \\\n                    __FILE__, __LINE__);                                                       \\\n            fprintf(stderr, \"*** FAILED - ABORTING \");                                         \\\n            exit(1);                                                                           \\\n        }                                                                                      \\\n    }                                                                                          \\\n    while (0)\n\n__global__ void vadd(const float *A, const float *B, float *C, int ds);\n\nvoid launch()\n{\n    const int block_size = 256;\n\n    // Initialize random seed\n    srand(time(NULL));\n\n    // Loop through different vector sizes\n    for (int DSIZE = 3; DSIZE < 150; DSIZE *= 2)\n    {\n        // Allocate and initialize host and device memory\n        float *h_A, *h_B, *h_C, *d_A, *d_B, *d_C;\n        h_A = new float[DSIZE];\n        h_B = new float[DSIZE];\n        h_C = new float[DSIZE];\n\n        // Initialize host arrays with random numbers from 0 to 100\n        for (int i = 0; i < DSIZE; i++)\n        {\n            h_A[i] = static_cast<float>(rand()) / RAND_MAX * 100;\n            h_B[i] = static_cast<float>(rand()) / RAND_MAX * 100;\n            h_C[i] = 0;\n        }\n\n        cudaMalloc(&d_A, DSIZE * sizeof(float));\n        cudaMalloc(&d_B, DSIZE * sizeof(float));\n        cudaMalloc(&d_C, DSIZE * sizeof(float));\n        cudaCheckErrors(\"cudaMalloc failure\");\n\n        cudaMemcpy(d_A, h_A, DSIZE * sizeof(float), cudaMemcpyHostToDevice);\n        cudaMemcpy(d_B, h_B, DSIZE * sizeof(float), cudaMemcpyHostToDevice);\n        cudaCheckErrors(\"cudaMemcpy H2D failure\");\n\n        // Launch the vadd kernel with the current size\n        vadd<<<(DSIZE + block_size - 1) / block_size, block_size>>>(d_A, d_B, d_C, DSIZE);\n        cudaCheckErrors(\"kernel launch failure\");\n\n        // Copy the results back to the host\n        cudaMemcpy(h_C, d_C, DSIZE * sizeof(float), cudaMemcpyDeviceToHost);\n        cudaCheckErrors(\"cudaMemcpy D2H failure\");\n\n        // Validate the results inside the main function\n        for (int i = 0; i < DSIZE; ++i)\n        {\n            assert(fabs(h_C[i] - (h_A[i] + h_B[i])) < 1e-5);\n        }\n\n        // Free the allocated memory\n        cudaFree(d_A);\n        cudaFree(d_B);\n        cudaFree(d_C);\n        cudaCheckErrors(\"cudaFree failure\");\n\n        delete[] h_A;\n        delete[] h_B;\n        delete[] h_C;\n    }\n}\n\n__global__ void vadd(const float *A, const float *B, float *C, int ds)\n{\n", "test": "int main() {\n    launch();\n\n}\n", "example_test": "    @example_test\n", "cuda_toolkit": "12.0"}
{"task_id": "CUDA/25", "date": "2025-03-31", "prompt": "Write 2 device level functions called `reduce_warp` and `reduce_threadblock` to reduce data spread across threads in a thread block.\nThis includes performing a reduction operation within a warp and then across the entire thread block using shared memory. Use warp-level primitives to achieve this task.\nThe `reduce_warp` function should support the following warp sizes: 2, 4, 8, 16, and 32.\n\nA CUDA kernel will call these functions. The definition for the kernel `kernel` is \n```cuda\n__global__ void kernel(float *pOut, const float *pIn) {\n    /// this kernel assumes the threadblock size is 1024\n    extern __shared__ char smem_[];\n    float *smem = reinterpret_cast<float *>(smem_);\n    int tx = threadIdx.x;\n    float v = pIn[tx];\n    v = reduce_warp(v);\n    v = reduce_threadblock(v, smem);\n    if (threadIdx.x == 0) {\n        pOut[0] = v;\n    }\n```\n\nThe functions signatures are \n```cuda\ntemplate <int WARP_SIZE> __device__ float reduce_warp(float v)\ntemplate <int WARP_SIZE> __device__ float reduce_threadblock(float v, float *smem)\n```\n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_70 -arch=sm_60", "ld_flags": "", "declaration": "#include <cuda.h>\n#include \"cuda_runtime.h\"\n\ntemplate <int WARP_SIZE = 32>\n__device__ float reduce_warp(float);\ntemplate <int WARP_SIZE = 32>\n__device__ float reduce_threadblock(float, float *);\n\n__global__ void kernel(float *pOut, const float *pIn)\n{\n    /// this kernel assumes the threadblock size is 1024\n    extern __shared__ char smem_[];\n    float *smem = reinterpret_cast<float *>(smem_);\n    int tx      = threadIdx.x;\n    float v     = pIn[tx];\n    v           = reduce_warp(v);\n    v           = reduce_threadblock(v, smem);\n    if (threadIdx.x == 0)\n    {\n        pOut[0] = v;\n    }\n}\n\nvoid launch(int blockSize)\n{\n    float *output, *input;\n    dim3 threadsPerBlock(blockSize);\n    dim3 numBlocks(1);\n\n    cudaLaunchConfig_t config = {0};\n    config.gridDim            = numBlocks;\n    config.blockDim           = threadsPerBlock;\n    config.dynamicSmemBytes   = (config.blockDim.x / 32) * 4;\n    cudaLaunchKernelEx(&config, kernel, output, input);\n}\n\n", "test": "int main() {\nlaunch(1024);\n\n}\n", "example_test": "@example_test\n", "cuda_toolkit": "12.0"}
{"task_id": "CUDA/26", "date": "2025-03-31", "prompt": "Write 2 device level functions called `reduce_warp` and `reduce_threadblock` to minimize data spread across threads within a warp to enhance data locality and performance. \nUse warp-level primitives to achieve this task.  \nA CUDA kernel will call these functions. The definition of the kernel is \n\n```cuda\n__global__ void kernel(float *pOut, const float *pIn) {\n    extern __shared__ char smem_[];\n    float *smem = reinterpret_cast<float *>(smem_);\n    int tx = threadIdx.x;\n    float v = pIn[tx];\n    v = reduce_warp(v);\n    v = reduce_threadblock(v, smem);\n    if (threadIdx.x == 0) {\n        pOut[0] = v;\n    }\n}\n```\n\nThe signature of the functions must be \n```cuda\n__device__ float reduce_warp(float v)\n__device__ float reduce_threadblock(float v, float *smem)\n```\n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_70 -arch=sm_60", "ld_flags": "", "declaration": "#include <cuda.h>\n#include \"cuda_runtime.h\"\n\n__device__ float reduce_warp(float);\n__device__ float reduce_threadblock(float, float *);\n\n__global__ void kernel(float *pOut, const float *pIn)\n{\n    extern __shared__ char smem_[];\n    float *smem = reinterpret_cast<float *>(smem_);\n    int tx      = threadIdx.x;\n    float v     = pIn[tx];\n    v           = reduce_warp(v);\n    v           = reduce_threadblock(v, smem);\n    if (threadIdx.x == 0)\n    {\n        pOut[0] = v;\n    }\n}\n\nvoid launch(int blockSize)\n{\n    float *output, *input;\n    dim3 threadsPerBlock(blockSize);\n    dim3 numBlocks(1);\n\n    cudaLaunchConfig_t config = {0};\n    config.gridDim            = numBlocks;\n    config.blockDim           = threadsPerBlock;\n    config.dynamicSmemBytes   = (config.blockDim.x / 32) * 4;\n    cudaLaunchKernelEx(&config, kernel, output, input);\n}\n\n", "test": "int main() {\nlaunch(1024);\n\n}\n", "example_test": "@example_test\n", "cuda_toolkit": "12.0"}
{"task_id": "CUDA/27", "date": "2025-03-31", "prompt": "Implement 2 functions `reduce_warp` and `reduce_threadblock` that perform partial sum reduction across a thread block. \nThe reduction should minimize data spread across threads using warp-level and thread block-level reduction techniques\nWrite 2 device-level functions to handle the warp-wide reduction and thread block-wide reduction, ensuring that the final sum is correctly computed across all thread blocks.\n\nThe definition for the kernel is \n```cuda\n__global__ void kernel_partialsum(float *pOut, const float *pIn, int N) {\n    extern __shared__ char smem_[];\n    float *smem = reinterpret_cast<float *>(smem_);\n    int index = threadIdx.x + blockIdx.x * blockDim.x;\n\n    float v = 0.0f;\n\n    if (index < N) {\n        v = pIn[index];\n        v = reduce_warp(v);\n        v = reduce_threadblock(v, smem);\n        if (threadIdx.x == 0) {\n            pOut[blockIdx.x] = v;\n        }\n    }\n}\n```\n\nThe functions signatures are \n```cuda\n__device__ float reduce_warp(float v)\n__device__ float reduce_threadblock(float v, float *smem)\n```\n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_70 -arch=sm_60", "ld_flags": "", "declaration": "#include <cuda.h>\n#include \"cuda_runtime.h\"\n\n__device__ float reduce_warp(float);\n__device__ float reduce_threadblock(float, float *);\n\n__global__ void kernel_partialsum(float *pOut, const float *pIn, int N)\n{\n    extern __shared__ char smem_[];\n    float *smem = reinterpret_cast<float *>(smem_);\n\n    int index = threadIdx.x + blockIdx.x * blockDim.x;\n\n    float v = 0.0f;\n\n    if (index < N)\n    {\n        v = pIn[index];\n        v = reduce_warp(v);\n        v = reduce_threadblock(v, smem);\n        if (threadIdx.x == 0)\n        {\n            pOut[blockIdx.x] = v;\n        }\n    }\n}\n\nvoid launch(int length)\n{\n    float *output, *input;\n    dim3 threadsPerBlock(1024);\n    dim3 numBlocks(length / 1024);\n\n    cudaLaunchConfig_t config = {0};\n    config.gridDim            = numBlocks;\n    config.blockDim           = threadsPerBlock;\n    config.dynamicSmemBytes   = (config.blockDim.x / 32) * 4;\n    // launch first kernel to reduce data inside a single threadblock\n    cudaLaunchKernelEx(&config, kernel_partialsum, output, input, length);\n    // when the first kernel is done, all the partial sums will be\n    // in contiguous location. we launch the kernel again to do\n    // final sum on partial sums\n    config.gridDim = dim3((numBlocks.x - 1024) / 1024 + 1);\n    cudaLaunchKernelEx(&config, kernel_partialsum, output, output, length);\n    // output[0] should have the final sum\n}\n\n", "test": "int main() {\nlaunch(1024 * 1024);\n\n}\n", "example_test": "@example_test\n", "cuda_toolkit": "12.0"}
{"task_id": "CUDA/28", "date": "2025-03-31", "prompt": "Write a device level function called `reduce_warp` to minimize data spread across threads in a warp.\nImplement a summation of floating point data across threads in a warp using shuffle instructions in CUDA.\nThe function should support the following warp sizes: 2, 4, 8, 16, and 32. \n\nA CUDA kernel will call this function `reduce_warp`. The definition of the kernel is \n```cuda\n__global__ void kernel(float *pOut, const float *pIn) {\n    int tx  = threadIdx.x;\n    float v = pIn[tx];\n    v = reduce_warp(v);\n    if (threadIdx.x == 0) {\n        pOut[0] = v;\n    }\n}\n```\n\nThe function signature is \n```cuda\ntemplate <int WARP_SIZE> __device__ float reduce_warp(float);\n```\n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_70 -arch=sm_60", "ld_flags": "", "declaration": "#include <cuda.h>\n#include \"cuda_runtime.h\"\n\ntemplate <int WARP_SIZE = 32>\n__device__ float reduce_warp(float);\n\n__global__ void kernel(float *pOut, const float *pIn)\n{\n    int tx  = threadIdx.x;\n    float v = pIn[tx];\n    v       = reduce_warp(v);\n    if (threadIdx.x == 0)\n    {\n        pOut[0] = v;\n    }\n}\n\nvoid launch(int blockSize)\n{\n    float *output, *input;\n    dim3 threadsPerBlock(blockSize);\n    dim3 numBlocks(1);\n\n    cudaLaunchConfig_t config = {0};\n    config.gridDim            = numBlocks;\n    config.blockDim           = threadsPerBlock;\n\n    cudaLaunchKernelEx(&config, kernel, output, input);\n}\n\n", "test": "int main() {\nlaunch(32);\n\n}\n", "example_test": "@example_test\n", "cuda_toolkit": "12.0"}
{"task_id": "CUDA/29", "date": "2025-03-31", "prompt": "Write a device level function called `reduce_warp` to minimize data spread across threads in a warp.\nImplement a summation of floating point data across threads in a warp using shuffle instructions in CUDA. \n\nA CUDA kernel will call this function `reduce_warp`. The definition of the kernel is \n```cuda\n__global__ void kernel(float *pOut, const float *pIn) {\n    int tx  = threadIdx.x;\n    float v = pIn[tx];\n    v = reduce_warp(v);\n    if (threadIdx.x == 0) {\n        pOut[0] = v;\n    }\n}\n```\n\nThe function signature is \n```cuda\n__device__ float reduce_warp(float v)\n```\n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_70 -arch=sm_60", "ld_flags": "", "declaration": "#include <cuda.h>\n#include \"cuda_runtime.h\"\n\n__device__ float reduce_warp(float);\n\n__global__ void kernel(float *pOut, const float *pIn)\n{\n    int tx  = threadIdx.x;\n    float v = pIn[tx];\n    v       = reduce_warp(v);\n    if (threadIdx.x == 0)\n    {\n        pOut[0] = v;\n    }\n}\n\nvoid launch(int blockSize)\n{\n    float *output, *input;\n    dim3 threadsPerBlock(blockSize);\n    dim3 numBlocks(1);\n\n    cudaLaunchConfig_t config = {0};\n    config.gridDim            = numBlocks;\n    config.blockDim           = threadsPerBlock;\n\n    cudaLaunchKernelEx(&config, kernel, output, input);\n}\n\n", "test": "int main() {\nlaunch(32);\n\n}\n", "example_test": "@example_test\n", "cuda_toolkit": "12.0"}
{"task_id": "CUDA/30", "date": "2025-03-31", "prompt": "Write CUDA functions to perform grid synchronization using cooperative groups:\n\n1. A kernel function called `sync_kernel` that uses cooperative groups to synchronize grid. \n   This kernel should invoke `pre_sync()` before the grid sync and `post_sync()` after the grid sync.\n   The beginning of the kernel should look like:\n   ```cuda\n   template <class PreSync, class PostSync>\n   __global__ void sync_kernel(PreSync pre_sync, PostSync post_sync) {\n      pre_sync();\n   ```\n   followed by the cooperative groups grid synchronization, followed by `post_sync()` invocation.\n2. A host function called `launch` that launches the `sync_kernel` using `cudaLaunchCooperativeKernel`.\n\nThe following headers are already defined and should not be included in the response:\n```cuda\n#include <cooperative_groups.h>\n```\n\nImplement the functions in the following order using the provided signatures:\n```cuda\ntemplate <class PreSync, class PostSync>\n__global__ void sync_kernel(PreSync pre_sync, PostSync post_sync);\n\ntemplate <class PreSync, class PostSync>\nvoid launch(int num_blocks, int block_size, PreSync pre_sync, PostSync post_sync);\n```\n", "cc_flags": "-arch=sm_90a --extended-lambda -arch=sm_89 --extended-lambda -arch=sm_80 --extended-lambda -arch=sm_70 --extended-lambda -arch=sm_60 --extended-lambda", "ld_flags": "", "declaration": "#include <cooperative_groups.h>\n#include <cuda_runtime_api.h>\n#include <cstdlib>\n#include <fstream>\n#include <iostream>\n\ntemplate <class PreSync, class PostSync>\n__global__ void sync_kernel(PreSync pre_sync, PostSync post_sync);\n\ntemplate <class PreSync, class PostSync>\nvoid launch(int num_blocks, int block_size, PreSync pre_sync, PostSync post_sync);\n\n", "test": "int main() {\n\nint num_blocks = 2;\nint *d_data{};\ncudaMalloc(&d_data, 2 * sizeof(int));\ncudaMemset(d_data, 0, 2 * sizeof(int));\n\nauto pre_sync = [d_data]__device__() {\n  if (blockIdx.x == 0) {\n    if (threadIdx.x == 0) {\n      while (atomicAdd(&d_data[0], 0) == 0) {}\n    }\n    __syncthreads();\n    __threadfence();\n\n    if (threadIdx.x == 0) {\n      d_data[0] = 42;\n    }\n  } else if (blockIdx.x == 1) {\n    if (threadIdx.x == 0) {\n      atomicAdd(&d_data[0], 1);\n    }\n  }\n};\nauto post_sync = [d_data, num_blocks]__device__() {\n  if (blockIdx.x == 1) {\n    if (threadIdx.x == 0) {\n      if (d_data[0] != 42 || num_blocks != gridDim.x || 1 != blockDim.x) {\n        d_data[1] = 0;\n      } else { \n        d_data[1] = 4242;\n      }\n    }\n  }\n};\n\nauto dynamic_test = [&]() {\n  launch(num_blocks, 1, pre_sync, post_sync);\n  int result{};\n  cudaMemcpy(&result, d_data + 1, sizeof(int), cudaMemcpyDeviceToHost);\n\n  if (result != 4242) {\n    std::cerr << \"Test failed!\" << std::endl;\n    std::exit(1);\n  }\n};\n\nauto static_test = []() {\n  const char* path = std::getenv(\"COMPUTE_EVAL_SRC_FILE\");\n  if (path == nullptr) {\n    std::cerr << \"Environment variable not found!\" << std::endl;\n    std::exit(1);\n  }\n\n  std::ifstream file(path);\n  if (!file.is_open()) {\n    std::cerr << \"File not found!\" << std::endl;\n    std::exit(1);\n  }\n\n  std::string line;\n\n  // Skip until the beginning of the completion block\n  while (std::getline(file, line)) {\n    if (line.find(\"completion-begin\") != std::string::npos && \n        line.find(\"std::string::npos\") == std::string::npos) {\n      break;\n    }\n  }\n\n  // Search for the thrust::transform call\n  bool found = false;\n  while (std::getline(file, line)) {\n    if (line.find(\"cudaLaunchCooperativeKernel\") != std::string::npos) {\n      found = true;\n      break;\n    }\n  }\n\n  if (!found) {\n    std::cerr << \"Test failed!\" << std::endl;\n    std::exit(1);\n  }\n};\n\n// static_test();\ndynamic_test();\n\n}\n", "example_test": "@example_test\n", "cuda_toolkit": "12.0"}
{"task_id": "CUDA/31", "date": "2025-03-31", "prompt": "Write a function `void add(int num_items, const int *in, int *out)` that adds `num_items` elements on GPU using CUB library. \nThe resulting sum should be stored in `out`.  \nThe following headers are already defined and should not be included in the response:\n```cuda\n#include <cub/device/device_reduce.cuh>\n```\n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_70 -arch=sm_60", "ld_flags": "", "declaration": "#include <cstdlib>\n#include <fstream>\n#include <iostream>\n#include <thrust/device_vector.h>\n#include <cub/device/device_reduce.cuh>\n\nvoid add(int num_items, const int* in, int *out);\n\n", "test": "int main() {\n\nauto dynamic_test = []() {\n  const int num_items = 1 << 14;\n  thrust::device_vector<int> in(num_items, 1);\n  thrust::device_vector<int> out(1);\n\n  add(num_items, in.data().get(), out.data().get());\n\n  if (out[0] != num_items) {\n    std::cerr << \"Test failed!\" << std::endl;\n    std::exit(1);\n  }\n};\n\nauto static_test = []() {\n  const char* path = std::getenv(\"COMPUTE_EVAL_SRC_FILE\");\n  if (path == nullptr) {\n    std::cerr << \"Environment variable not found!\" << std::endl;\n    std::exit(1);\n  }\n\n  std::ifstream file(path);\n  if (!file.is_open()) {\n    std::cerr << \"File not found!\" << std::endl;\n    std::exit(1);\n  }\n\n  std::string line;\n\n  // Skip until the beginning of the completion block\n  while (std::getline(file, line)) {\n    if (line.find(\"completion-begin\") != std::string::npos && \n        line.find(\"std::string::npos\") == std::string::npos) {\n      break;\n    }\n  }\n\n  // Search for the thrust::transform call\n  bool found = false;\n  while (std::getline(file, line)) {\n    if (line.find(\"cub::DeviceReduce\") != std::string::npos) {\n      found = true;\n      break;\n    }\n  }\n\n  if (!found) {\n    std::cerr << \"Test failed!\" << std::endl;\n    std::exit(1);\n  }\n};\n\nstatic_test();\ndynamic_test();\n\n}\n", "example_test": "@example_test\n", "cuda_toolkit": "12.0"}
{"task_id": "CUDA/32", "date": "2025-03-31", "prompt": "Write a function `void scan(int num_items, const int *in, int *out)` that computes exclusive prefix sum of `num_items` elements on GPU using CUB library. \nThe resulting should be stored in `out`.  \nThe following headers are already defined and should not be included in the response:\n```cuda\n#include <cub/device/device_scan.cuh>\n```\n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_70 -arch=sm_60", "ld_flags": "", "declaration": "#include <cstdlib>\n#include <fstream>\n#include <iostream>\n#include <thrust/device_vector.h>\n#include <cub/device/device_scan.cuh>\n\nvoid scan(int num_items, const int* in, int *out);\n\n", "test": "int main() {\n\nauto dynamic_test = []() {\n  thrust::device_vector<int> in{ 1, 4, 0 };\n  thrust::device_vector<int> out(in.size());\n\n  scan(in.size(), in.data().get(), out.data().get());\n\n  if (out[0] != 0 || out[1] != 1 || out[2] != 5) {\n    std::cerr << \"Test failed!\" << std::endl;\n    std::exit(1);\n  }\n};\n\nauto static_test = []() {\n  const char* path = std::getenv(\"COMPUTE_EVAL_SRC_FILE\");\n  if (path == nullptr) {\n    std::cerr << \"Environment variable not found!\" << std::endl;\n    std::exit(1);\n  }\n\n  std::ifstream file(path);\n  if (!file.is_open()) {\n    std::cerr << \"File not found!\" << std::endl;\n    std::exit(1);\n  }\n\n  std::string line;\n\n  // Skip until the beginning of the completion block\n  while (std::getline(file, line)) {\n    if (line.find(\"completion-begin\") != std::string::npos && \n        line.find(\"std::string::npos\") == std::string::npos) {\n      break;\n    }\n  }\n\n  // Search for the thrust::transform call\n  bool found = false;\n  while (std::getline(file, line)) {\n    if (line.find(\"cub::DeviceScan\") != std::string::npos) {\n      found = true;\n      break;\n    }\n  }\n\n  if (!found) {\n    std::cerr << \"Test failed!\" << std::endl;\n    std::exit(1);\n  }\n};\n\nstatic_test();\ndynamic_test();\n\n}\n", "example_test": "@example_test\n", "cuda_toolkit": "12.0"}
{"task_id": "CUDA/33", "date": "2025-03-31", "prompt": "Write a function `void sort(int num_items, const int *in, int *out)` that sorts `num_items` elements on GPU using radix sort from CUB library. \nThe resulting should be stored in `out`.  \nThe following headers are already defined and should not be included in the response:\n```cuda\n#include <cub/device/device_radix_sort.cuh>\n```\n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_70 -arch=sm_60", "ld_flags": "", "declaration": "#include <cstdlib>\n#include <fstream>\n#include <iostream>\n#include <thrust/device_vector.h>\n#include <cub/device/device_radix_sort.cuh>\n\nvoid sort(int num_items, const int* in, int *out);\n\n", "test": "int main() {\n\nauto dynamic_test = []() {\n  thrust::device_vector<int> in{ 1, 4, 0, 3 };\n  thrust::device_vector<int> out(in.size());\n\n  sort(in.size(), in.data().get(), out.data().get());\n\n  if (out[0] != 0 || out[1] != 1 || out[2] != 3 || out[3] != 4) {\n    std::cerr << \"Test failed!\" << std::endl;\n    std::exit(1);\n  }\n};\n\nauto static_test = []() {\n  const char* path = std::getenv(\"COMPUTE_EVAL_SRC_FILE\");\n  if (path == nullptr) {\n    std::cerr << \"Environment variable not found!\" << std::endl;\n    std::exit(1);\n  }\n\n  std::ifstream file(path);\n  if (!file.is_open()) {\n    std::cerr << \"File not found!\" << std::endl;\n    std::exit(1);\n  }\n\n  std::string line;\n\n  // Skip until the beginning of the completion block\n  while (std::getline(file, line)) {\n    if (line.find(\"completion-begin\") != std::string::npos && \n        line.find(\"std::string::npos\") == std::string::npos) {\n      break;\n    }\n  }\n\n  // Search for the thrust::transform call\n  bool found = false;\n  while (std::getline(file, line)) {\n    if (line.find(\"cub::DeviceRadixSort\") != std::string::npos) {\n      found = true;\n      break;\n    }\n  }\n\n  if (!found) {\n    std::cerr << \"Test failed!\" << std::endl;\n    std::exit(1);\n  }\n};\n\nstatic_test();\ndynamic_test();\n\n}\n", "example_test": "@example_test\n", "cuda_toolkit": "12.0"}
{"task_id": "CUDA/34", "date": "2025-03-31", "prompt": "Write a CUDA kernel where each thread uses cuda::atomic_ref from libcu++ to increment a value in a device memory by one. \nUse device scope for atomic increment. The kernel should have the following signature:\n```cuda\n__global__ void kernel(int *ptr);\n```\n\nThe following headers are already defined and should not be included in the response:\n```cuda\n#include <cuda/atomic>\n```\n", "cc_flags": "-arch=sm_90a --extended-lambda -arch=sm_89 --extended-lambda -arch=sm_80 --extended-lambda -arch=sm_70 --extended-lambda", "ld_flags": "", "declaration": "#include <cuda/atomic>\n#include <cuda_runtime_api.h>\n#include <cstdlib>\n#include <fstream>\n#include <iostream>\n\n__global__ void kernel(int *ptr);\n\n", "test": "int main() {\n\nauto dynamic_test = [&]() {\n  int *d_data{};\n  cudaMalloc(&d_data, sizeof(int));\n  cudaMemset(d_data, 0, sizeof(int));\n\n  const int threads = 64;\n  const int blocks = 42;\n\n  kernel<<<blocks, threads>>>(d_data);\n\n  int result;\n  cudaMemcpy(&result, d_data, sizeof(int), cudaMemcpyDeviceToHost);\n\n  if (result != blocks * threads) {\n    std::cerr << \"Test failed!\" << std::endl;\n    std::exit(1);\n  }\n};\n\nauto static_test = []() {\n  const char* path = std::getenv(\"COMPUTE_EVAL_SRC_FILE\");\n  if (path == nullptr) {\n    std::cerr << \"Environment variable not found!\" << std::endl;\n    std::exit(1);\n  }\n\n  std::ifstream file(path);\n  if (!file.is_open()) {\n    std::cerr << \"File not found!\" << std::endl;\n    std::exit(1);\n  }\n\n  std::string line;\n\n  // Skip until the beginning of the completion block\n  while (std::getline(file, line)) {\n    if (line.find(\"completion-begin\") != std::string::npos && \n        line.find(\"std::string::npos\") == std::string::npos) {\n      break;\n    }\n  }\n\n  // Search for the thrust::transform call\n  bool found = false;\n  while (std::getline(file, line)) {\n    if (line.find(\"fetch_add\") != std::string::npos) {\n      found = true;\n      break;\n    }\n  }\n\n  if (!found) {\n    std::cerr << \"Test failed!\" << std::endl;\n    std::exit(1);\n  }\n};\n\n// static_test();\ndynamic_test();\n\n}\n", "example_test": "@example_test\n", "cuda_toolkit": "12.0"}
{"task_id": "CUDA/35", "date": "2025-03-31", "prompt": "Write a function `thrust::device_vector<int> scan(const thrust::device_vector<int>& vec)` that\ncomputes exclusive prefix sum of the input vector on GPU using thrust algorithm.\n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_70 -arch=sm_60", "ld_flags": "", "declaration": "#include <thrust/device_vector.h>\n#include <thrust/execution_policy.h>\n#include <thrust/scan.h>\n#include <cstdlib>\n#include <fstream>\n#include <iostream>\n\nthrust::device_vector<int> scan(const thrust::device_vector<int> &vec);\n\n", "test": "int main() {\n\nauto dynamic_test = []() {\n    const thrust::device_vector<int> in {1, 4, 0};\n    thrust::device_vector<int> out = scan(in);\n\n    if (out[0] != 0 || out[1] != 1 || out[2] != 5)\n    {\n        std::cerr << \"Test failed!\" << std::endl;\n        std::exit(1);\n    }\n};\n\nauto static_test = []() {\n    const char *path = std::getenv(\"COMPUTE_EVAL_SRC_FILE\");\n    if (path == nullptr)\n    {\n        std::cerr << \"Environment variable not found!\" << std::endl;\n        std::exit(1);\n    }\n\n    std::ifstream file(path);\n    if (!file.is_open())\n    {\n        std::cerr << \"File not found!\" << std::endl;\n        std::exit(1);\n    }\n\n    std::string line;\n\n    // Skip until the beginning of the completion block\n    while (std::getline(file, line))\n    {\n        if (line.find(\"completion-begin\") != std::string::npos &&\n            line.find(\"std::string::npos\") == std::string::npos)\n        {\n            break;\n        }\n    }\n\n    // Search for the thrust::exclusive_scan call\n    bool found = false;\n    while (std::getline(file, line))\n    {\n        if (line.find(\"thrust::exclusive_scan\") != std::string::npos)\n        {\n            found = true;\n            break;\n        }\n\n        if (line.find(\"completion-end\") != std::string::npos)\n        {\n            break;\n        }\n    }\n\n    if (!found)\n    {\n        std::cerr << \"Test failed!\" << std::endl;\n        std::exit(1);\n    }\n};\n\nstatic_test();\ndynamic_test();\n\n}\n", "example_test": "@example_test\n", "cuda_toolkit": "12.0"}
{"task_id": "CUDA/36", "date": "2025-03-31", "prompt": "Write a function `float sum(const thrust::device_vector<float>& vec)` that adds all elements of a\nvector on GPU using thrust algorithm.\n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_70 -arch=sm_60", "ld_flags": "", "declaration": "#include <thrust/device_vector.h>\n#include <thrust/reduce.h>\n#include <cstdlib>\n#include <fstream>\n#include <iostream>\n\nfloat sum(const thrust::device_vector<float> &vec);\n\n", "test": "int main() {\n\nauto dynamic_test = []() {\n    thrust::device_vector<float> vec {1.0f, 2.0f, 3.0f};\n\n    if (sum(vec) != 6.0f)\n    {\n        std::cerr << \"Test failed!\" << std::endl;\n        std::exit(1);\n    }\n};\n\nauto static_test = []() {\n    const char *path = std::getenv(\"COMPUTE_EVAL_SRC_FILE\");\n    if (path == nullptr)\n    {\n        std::cerr << \"Environment variable not found!\" << std::endl;\n        std::exit(1);\n    }\n\n    std::ifstream file(path);\n    if (!file.is_open())\n    {\n        std::cerr << \"File not found!\" << std::endl;\n        std::exit(1);\n    }\n\n    std::string line;\n\n    // Skip until the beginning of the completion block\n    while (std::getline(file, line))\n    {\n        if (line.find(\"completion-begin\") != std::string::npos &&\n            line.find(\"std::string::npos\") == std::string::npos)\n        {\n            break;\n        }\n    }\n\n    // Search for the thrust::reduce call\n    bool found = false;\n    while (std::getline(file, line))\n    {\n        if (line.find(\"thrust::reduce\") != std::string::npos)\n        {\n            found = true;\n            break;\n        }\n\n        if (line.find(\"completion-end\") != std::string::npos)\n        {\n            break;\n        }\n    }\n\n    if (!found)\n    {\n        std::cerr << \"Test failed!\" << std::endl;\n        std::exit(1);\n    }\n};\n\nstatic_test();\ndynamic_test();\n\n}\n", "example_test": "@example_test\n", "cuda_toolkit": "12.0"}
{"task_id": "CUDA/37", "date": "2025-03-31", "prompt": "Write a function `thrust::device_vector<int> sort(const thrust::device_vector<int>& vec)` that sorts\nthe input vector on GPU using thrust algorithm.\n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_70 -arch=sm_60", "ld_flags": "", "declaration": "#include <thrust/device_vector.h>\n#include <thrust/execution_policy.h>\n#include <thrust/sort.h>\n#include <cstdlib>\n#include <fstream>\n#include <iostream>\n\nthrust::device_vector<int> sort(const thrust::device_vector<int> &vec);\n\n", "test": "int main() {\n\nauto dynamic_test = []() {\n    const thrust::device_vector<int> in {3, 1, 4, 0};\n    thrust::device_vector<int> out = sort(in);\n\n    if (out[0] != 0 || out[1] != 1 || out[2] != 3 || out[3] != 4)\n    {\n        std::cerr << \"Test failed!\" << std::endl;\n        std::exit(1);\n    }\n};\n\nauto static_test = []() {\n    const char *path = std::getenv(\"COMPUTE_EVAL_SRC_FILE\");\n    if (path == nullptr)\n    {\n        std::cerr << \"Environment variable not found!\" << std::endl;\n        std::exit(1);\n    }\n\n    std::ifstream file(path);\n    if (!file.is_open())\n    {\n        std::cerr << \"File not found!\" << std::endl;\n        std::exit(1);\n    }\n\n    std::string line;\n\n    // Skip until the beginning of the completion block\n    while (std::getline(file, line))\n    {\n        if (line.find(\"completion-begin\") != std::string::npos &&\n            line.find(\"std::string::npos\") == std::string::npos)\n        {\n            break;\n        }\n    }\n\n    // Search for the thrust::sort call\n    bool found = false;\n    while (std::getline(file, line))\n    {\n        if (line.find(\"thrust::sort\") != std::string::npos)\n        {\n            found = true;\n            break;\n        }\n\n        if (line.find(\"completion-end\") != std::string::npos)\n        {\n            break;\n        }\n    }\n\n    if (!found)\n    {\n        std::cerr << \"Test failed!\" << std::endl;\n        std::exit(1);\n    }\n};\n\nstatic_test();\ndynamic_test();\n\n}\n", "example_test": "@example_test\n", "cuda_toolkit": "12.0"}
{"task_id": "CUDA/38", "date": "2025-03-31", "prompt": "Write a function `thrust::device_vector<float> vadd(const thrust::device_vector<float>& x, const\nthrust::device_vector<float>& y)` that adds two vectors on GPU.\n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_70 -arch=sm_60", "ld_flags": "", "declaration": "#include <thrust/device_vector.h>\n#include <thrust/transform.h>\n#include <cstdlib>\n#include <fstream>\n#include <iostream>\n\nthrust::device_vector<float> vadd(const thrust::device_vector<float> &x,\n                                  const thrust::device_vector<float> &y);\n\n", "test": "int main() {\n\nauto dynamic_test = []() {\n    float x_arr[3] = {1.0f, 2.0f, 3.0f};\n    float y_arr[3] = {3.0f, 2.0f, 1.0f};\n    thrust::device_vector<float> x(x_arr, x_arr + 3);\n    thrust::device_vector<float> y(y_arr, y_arr + 3);\n    thrust::device_vector<float> xy = vadd(x, y);\n\n    for (int i = 0; i < xy.size(); i++)\n    {\n        const float product  = xy[i];\n        const float expected = x[i] + y[i];\n\n        if (product != expected)\n        {\n            std::cerr << \"Test failed!\" << std::endl;\n            std::exit(1);\n        }\n    }\n};\n\nauto static_test = []() {\n    const char *path = std::getenv(\"COMPUTE_EVAL_SRC_FILE\");\n    if (path == nullptr)\n    {\n        std::cerr << \"Environment variable not found!\" << std::endl;\n        std::exit(1);\n    }\n\n    std::ifstream file(path);\n    if (!file.is_open())\n    {\n        std::cerr << \"File not found!\" << std::endl;\n        std::exit(1);\n    }\n\n    std::string line;\n\n    // Skip until the beginning of the completion block\n    while (std::getline(file, line))\n    {\n        if (line.find(\"completion-begin\") != std::string::npos &&\n            line.find(\"std::string::npos\") == std::string::npos)\n        {\n            break;\n        }\n    }\n\n    // Search for the thrust::transform call\n    bool found = false;\n    while (std::getline(file, line))\n    {\n        if (line.find(\"thrust::transform\") != std::string::npos)\n        {\n            found = true;\n            break;\n        }\n\n        if (line.find(\"completion-end\") != std::string::npos)\n        {\n            break;\n        }\n    }\n\n    if (!found)\n    {\n        std::cerr << \"Test failed!\" << std::endl;\n        std::exit(1);\n    }\n};\n\nstatic_test();\ndynamic_test();\n\n}\n", "example_test": "@example_test\n", "cuda_toolkit": "12.0"}
{"task_id": "CUDA/39", "date": "2025-03-31", "prompt": "Write a function `thrust::device_vector<int>::iterator find(thrust::device_vector<int>&\nvec, int target)` that finds the first occurrence of the target value in the input vector.\n\nDo not include any code outside the function. Wrap the completed function code, including the\nprovided signature, inside a ```cuda markdown code block.\n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_70 -arch=sm_60", "ld_flags": "", "declaration": "#include <thrust/device_vector.h>\n#include <thrust/find.h>\n#include <cstdlib>\n#include <fstream>\n#include <iostream>\n\nthrust::device_vector<int>::iterator find(thrust::device_vector<int> &vec, int target);\n\n", "test": "int main() {\n\nauto dynamic_test = []() {\n    thrust::device_vector<int> x {42, 0, 4, 2, 4};\n\n    auto it    = find(x, 4);\n    auto index = thrust::distance(x.begin(), it);\n\n    if (index != 2)\n    {\n        std::cerr << \"Error: expected 2, got \" << index << std::endl;\n        std::exit(1);\n    }\n\n    it    = find(x, -1);\n    index = thrust::distance(x.begin(), it);\n\n    if (index != 5)\n    {\n        std::cerr << \"Error: expected 5 (last), got \" << index << std::endl;\n        std::exit(1);\n    }\n};\n\nauto static_test = []() {\n    const char *path = std::getenv(\"COMPUTE_EVAL_SRC_FILE\");\n    if (path == nullptr)\n    {\n        std::cerr << \"Environment variable not found!\" << std::endl;\n        std::exit(1);\n    }\n\n    std::ifstream file(path);\n    if (!file.is_open())\n    {\n        std::cerr << \"File not found!\" << std::endl;\n        std::exit(1);\n    }\n\n    std::string line;\n\n    // Skip until the beginning of the completion block\n    while (std::getline(file, line))\n    {\n        if (line.find(\"completion-begin\") != std::string::npos &&\n            line.find(\"std::string::npos\") == std::string::npos)\n        {\n            break;\n        }\n    }\n\n    // Search for the thrust::find call\n    bool found = false;\n    while (std::getline(file, line))\n    {\n        if (line.find(\"thrust::find\") != std::string::npos)\n        {\n            found = true;\n            break;\n        }\n\n        if (line.find(\"completion-end\") != std::string::npos)\n        {\n            break;\n        }\n    }\n\n    if (!found)\n    {\n        std::cerr << \"Test failed!\" << std::endl;\n        std::exit(1);\n    }\n};\n\nstatic_test();\ndynamic_test();\n\n}\n", "example_test": "@example_test\n", "cuda_toolkit": "12.0"}
{"task_id": "CUDA/40", "date": "2025-03-31", "prompt": "Write a function `void inclusive_add(thrust::device_vector<int>& x)` that\ncomputes an inclusive prefix sum in all the values of the array. It should do it inplace\nand the resulting array should stay on the device.\nDo not include any code outside the function. Wrap the completed function\ncode, including the provided signature, inside a ```cuda markdown code block.\n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_70 -arch=sm_60", "ld_flags": "", "declaration": "#include <thrust/device_vector.h>\n#include <thrust/scan.h>\n#include <thrust/transform.h>\n#include <cstdlib>\n#include <fstream>\n#include <iostream>\n\nvoid inclusive_add(thrust::device_vector<int> &x);\n\n", "test": "int main() {\n\nauto dynamic_test = []() {\n    thrust::device_vector<int> x {1, 2, 3, 4, 5};\n    inclusive_add(x);\n\n    int expected_result[] = {1, 3, 6, 10, 15};\n    for (int i = 0; i < x.size(); i++)\n    {\n        if (x[i] != expected_result[i])\n        {\n            std::cerr << \"Test failed!\" << std::endl;\n            std::exit(1);\n        }\n    }\n};\n\nauto static_test = []() {\n    const char *path = std::getenv(\"COMPUTE_EVAL_SRC_FILE\");\n    if (path == nullptr)\n    {\n        std::cerr << \"Environment variable not found!\" << std::endl;\n        std::exit(1);\n    }\n\n    std::ifstream file(path);\n    if (!file.is_open())\n    {\n        std::cerr << \"File not found!\" << std::endl;\n        std::exit(1);\n    }\n\n    std::string line;\n\n    // Skip until the beginning of the completion block\n    while (std::getline(file, line))\n    {\n        if (line.find(\"completion-begin\") != std::string::npos &&\n            line.find(\"std::string::npos\") == std::string::npos)\n        {\n            break;\n        }\n    }\n\n    // Search for the thrust::transform call\n    bool found = false;\n    while (std::getline(file, line))\n    {\n        if (line.find(\"thrust::inclusive_scan\") != std::string::npos)\n        {\n            found = true;\n            break;\n        }\n\n        if (line.find(\"completion-end\") != std::string::npos)\n        {\n            break;\n        }\n    }\n\n    if (!found)\n    {\n        std::cerr << \"Test failed!\" << std::endl;\n        std::exit(1);\n    }\n};\n\ndynamic_test();\nstatic_test();\n\n}\n", "example_test": "@example_test\n", "cuda_toolkit": "12.0"}
{"task_id": "CUDA/41", "date": "2025-03-31", "prompt": "Write a function `int partitionVector(thrust::device_vector<int>& vec)` that takes a device vector\nas input and reorders the vector elements. The first elements should be less than 10 followed by the\nitems who are greater. The operation should be inplace and the function should return the index of\nthe first element that does not satisfy the condition.\n\nDo not include any code outside the function. Wrap the completed function code, including the\nprovided signature, inside a ```cuda markdown code block.\n", "cc_flags": "-arch=sm_90a --extended-lambda -arch=sm_89 --extended-lambda -arch=sm_80 --extended-lambda -arch=sm_70 --extended-lambda -arch=sm_60 --extended-lambda", "ld_flags": "", "declaration": "#include <thrust/device_vector.h>\n#include <thrust/partition.h>\n#include <thrust/sort.h>\n#include <cstdlib>\n#include <fstream>\n#include <iostream>\n\nint partitionVector(thrust::device_vector<int>& vec);\n\n", "test": "int main() {\n\nauto dynamic_test = []() {\n    thrust::device_vector<int> vec {41, 1, 42, 2, 43, 3};\n    int middle = partitionVector(vec);\n\n    if (middle != 3)\n    {\n        std::cout << \"Test failed. Middle of the partition should be 3\" << std::endl;\n        std::exit(1);\n    }\n\n    // Verify elements are partitioned correctly:\n    // partition doesn't guarantee the order of elements\n    // sort each partition to simplify the test\n    thrust::sort(vec.begin(), vec.begin() + 3);\n    thrust::sort(vec.begin() + 3, vec.end());\n\n    thrust::device_vector<int> expected {1, 2, 3, 41, 42, 43};\n    if (vec != expected)\n    {\n        std::cout << \"Test failed!\" << std::endl;\n        std::exit(1);\n    }\n};\n\nauto static_test = []() {\n    const char* path = std::getenv(\"COMPUTE_EVAL_SRC_FILE\");\n    if (path == nullptr)\n    {\n        std::cerr << \"Environment variable not found!\" << std::endl;\n        std::exit(1);\n    }\n\n    std::ifstream file(path);\n    if (!file.is_open())\n    {\n        std::cerr << \"File not found!\" << std::endl;\n        std::exit(1);\n    }\n\n    std::string line;\n\n    // Skip until the beginning of the completion block\n    while (std::getline(file, line))\n    {\n        if (line.find(\"completion-begin\") != std::string::npos &&\n            line.find(\"std::string::npos\") == std::string::npos)\n        {\n            break;\n        }\n    }\n\n    // Search for the thrust::partition call\n    bool found = false;\n    while (std::getline(file, line))\n    {\n        if (line.find(\"thrust::partition\") != std::string::npos)\n        {\n            found = true;\n            break;\n        }\n\n        if (line.find(\"completion-end\") != std::string::npos)\n        {\n            break;\n        }\n    }\n\n    if (!found)\n    {\n        std::cerr << \"Test failed!\" << std::endl;\n        std::exit(1);\n    }\n};\n\nstatic_test();\ndynamic_test();\n\n}\n", "example_test": "@example_test\n", "cuda_toolkit": "12.0"}
{"task_id": "CUDA/42", "date": "2025-03-31", "prompt": "Write a function `int partitionVector(thrust::device_vector<int>& vec)` that takes a device vector\nas input and reorders the vector elements. The function should preserve relative order of the input.\nThe first elements should be less than 10 followed by the elements who are greater. The operation\nshould be inplace and the function should return the index of the first element that does not\nsatisfy the condition.\n\nDo not include any code outside the function. Wrap the completed function code, including the\nprovided signature, inside a ```cuda markdown code block.\n", "cc_flags": "-arch=sm_90a --extended-lambda -arch=sm_89 --extended-lambda -arch=sm_80 --extended-lambda -arch=sm_70 --extended-lambda -arch=sm_60 --extended-lambda", "ld_flags": "", "declaration": "#include <thrust/device_vector.h>\n#include <thrust/partition.h>\n#include <thrust/sort.h>\n#include <cstdlib>\n#include <fstream>\n#include <iostream>\n\nint partitionVector(thrust::device_vector<int>& vec);\n\n", "test": "int main() {\n\nauto dynamic_test = []() {\n    thrust::device_vector<int> vec {51, 1, 42, 2, 33, 3};\n    int middle = partitionVector(vec);\n\n    if (middle != 3)\n    {\n        std::cout << \"Test failed. Middle of the partition should be 3\" << std::endl;\n        std::exit(1);\n    }\n\n    thrust::device_vector<int> expected {1, 2, 3, 51, 42, 33};\n    if (vec != expected)\n    {\n        std::cout << \"Test failed!\" << std::endl;\n        std::exit(1);\n    }\n};\n\nauto static_test = []() {\n    const char* path = std::getenv(\"COMPUTE_EVAL_SRC_FILE\");\n    if (path == nullptr)\n    {\n        std::cerr << \"Environment variable not found!\" << std::endl;\n        std::exit(1);\n    }\n\n    std::ifstream file(path);\n    if (!file.is_open())\n    {\n        std::cerr << \"File not found!\" << std::endl;\n        std::exit(1);\n    }\n\n    std::string line;\n\n    // Skip until the beginning of the completion block\n    while (std::getline(file, line))\n    {\n        if (line.find(\"completion-begin\") != std::string::npos &&\n            line.find(\"std::string::npos\") == std::string::npos)\n        {\n            break;\n        }\n    }\n\n    // Search for the thrust::partition call\n    bool found = false;\n    while (std::getline(file, line))\n    {\n        if (line.find(\"thrust::stable_partition\") != std::string::npos)\n        {\n            found = true;\n            break;\n        }\n\n        if (line.find(\"completion-end\") != std::string::npos)\n        {\n            break;\n        }\n    }\n\n    if (!found)\n    {\n        std::cerr << \"Test failed!\" << std::endl;\n        std::exit(1);\n    }\n};\n\nstatic_test();\ndynamic_test();\n\n}\n", "example_test": "@example_test\n", "cuda_toolkit": "12.0"}
{"task_id": "CUDA/43", "date": "2025-03-31", "prompt": "Write a function `void copy(const thrust::device_vector<float>& src,\nthrust::device_vector<float>& dst)` that copies half the elements of a src\nvector in GPU to a dst vector in GPU.\n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_70 -arch=sm_60", "ld_flags": "", "declaration": "#include <thrust/copy.h>\n#include <thrust/device_vector.h>\n#include <cstdlib>\n#include <fstream>\n#include <iostream>\n\nvoid copy(const thrust::device_vector<float> &src, thrust::device_vector<float> &dst);\n\n", "test": "int main() {\nauto dynamic_test = []() {\n    thrust::device_vector<float> x {0, 1, 2, 3, 4};\n    thrust::device_vector<float> y(x.size() / 2);\n    copy(x, y);\n\n    thrust::device_vector<float> expected {0, 1};\n\n    for (std::size_t i = 0; i < y.size(); i++)\n    {\n        if (y[i] != expected[i])\n        {\n            std::cerr << \"Test failed!\" << std::endl;\n            std::exit(1);\n        }\n    }\n};\n\nauto static_test = []() {\n    const char *path = std::getenv(\"COMPUTE_EVAL_SRC_FILE\");\n    if (path == nullptr)\n    {\n        std::cerr << \"Environment variable not found!\" << std::endl;\n        std::exit(1);\n    }\n\n    std::ifstream file(path);\n    if (!file.is_open())\n    {\n        std::cerr << \"File not found!\" << std::endl;\n        std::exit(1);\n    }\n\n    std::string line;\n\n    // Skip until the beginning of the completion block\n    while (std::getline(file, line))\n    {\n        if (line.find(\"completion-begin\") != std::string::npos &&\n            line.find(\"std::string::npos\") == std::string::npos)\n        {\n            break;\n        }\n    }\n\n    // Search for the thrust::copy call\n    bool found = false;\n    while (std::getline(file, line))\n    {\n        if (line.find(\"thrust::copy\") != std::string::npos)\n        {\n            found = true;\n            break;\n        }\n\n        if (line.find(\"completion-end\") != std::string::npos)\n        {\n            break;\n        }\n    }\n\n    if (!found)\n    {\n        std::cerr << \"Test failed!\" << std::endl;\n        std::exit(1);\n    }\n};\n\nstatic_test();\ndynamic_test();\n\n}\n", "example_test": "@example_test\n", "cuda_toolkit": "12.0"}
{"task_id": "CUDA/44", "date": "2025-03-31", "prompt": "Write a function `void fill_vector_increasingly(thrust::device_vector<int>& vec)` that fills a\nvector with sequentially increasing numbers starting from 0 to `.size() - 1` using thrust\nalgorithm.\n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_70 -arch=sm_60", "ld_flags": "", "declaration": "#include <thrust/device_vector.h>\n#include <thrust/execution_policy.h>\n#include <thrust/sequence.h>\n#include <cstdlib>\n#include <fstream>\n#include <iostream>\n\nvoid fill_vector_increasingly(thrust::device_vector<int> &vec);\n\n", "test": "int main() {\nauto dynamic_test = []() {\n    thrust::device_vector<int> x(5);\n    fill_vector_increasingly(x);\n\n    thrust::device_vector<int> expected {0, 1, 2, 3, 4};\n\n    for (std::size_t i = 0; i < x.size(); i++)\n    {\n        if (x[i] != expected[i])\n        {\n            std::cerr << \"Test failed!\" << std::endl;\n            std::exit(1);\n        }\n    }\n};\n\nauto static_test = []() {\n    const char *path = std::getenv(\"COMPUTE_EVAL_SRC_FILE\");\n    if (path == nullptr)\n    {\n        std::cerr << \"Environment variable not found!\" << std::endl;\n        std::exit(1);\n    }\n\n    std::ifstream file(path);\n    if (!file.is_open())\n    {\n        std::cerr << \"File not found!\" << std::endl;\n        std::exit(1);\n    }\n\n    std::string line;\n\n    // Skip until the beginning of the completion block\n    while (std::getline(file, line))\n    {\n        if (line.find(\"completion-begin\") != std::string::npos &&\n            line.find(\"std::string::npos\") == std::string::npos)\n        {\n            break;\n        }\n    }\n\n    // Search for the thrust::sequence call\n    bool found = false;\n    while (std::getline(file, line))\n    {\n        if (line.find(\"thrust::sequence\") != std::string::npos)\n        {\n            found = true;\n            break;\n        }\n\n        if (line.find(\"completion-end\") != std::string::npos)\n        {\n            break;\n        }\n    }\n\n    if (!found)\n    {\n        std::cerr << \"Test failed!\" << std::endl;\n        std::exit(1);\n    }\n};\n\nstatic_test();\ndynamic_test();\n\n}\n", "example_test": "@example_test\n", "cuda_toolkit": "12.0"}
{"task_id": "CUDA/45", "date": "2025-03-31", "prompt": "Write a function `thrust::device_vector<int> combine_ranges(thrust::device_vector<int> const& vec1,\nthrust::device_vector<int> const& vec2)` that combines two sorted vectors into a single sorted\nvector in the GPU using a thrust algorithm.\n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_70 -arch=sm_60", "ld_flags": "", "declaration": "#include <thrust/device_vector.h>\n#include <thrust/execution_policy.h>\n#include <thrust/merge.h>\n#include <cstdlib>\n#include <fstream>\n#include <iostream>\n\nthrust::device_vector<int> combine_ranges(thrust::device_vector<int> const &vec1,\n                                          thrust::device_vector<int> const &vec2);\n\n", "test": "int main() {\nauto dynamic_test = []() {\n    thrust::device_vector<int> x {1, 3, 5, 7};\n    thrust::device_vector<int> y {0, 2, 4, 6, 8};\n\n    auto result_vec = combine_ranges(x, y);\n\n    thrust::device_vector<int> expected {0, 1, 2, 3, 4, 5, 6, 7, 8};\n\n    for (std::size_t i = 0; i < result_vec.size(); i++)\n    {\n        if (result_vec[i] != expected[i])\n        {\n            std::cerr << \"Test failed!\" << std::endl;\n            std::exit(1);\n        }\n    }\n};\n\nauto static_test = []() {\n    const char *path = std::getenv(\"COMPUTE_EVAL_SRC_FILE\");\n    if (path == nullptr)\n    {\n        std::cerr << \"Environment variable not found!\" << std::endl;\n        std::exit(1);\n    }\n\n    std::ifstream file(path);\n    if (!file.is_open())\n    {\n        std::cerr << \"File not found!\" << std::endl;\n        std::exit(1);\n    }\n\n    std::string line;\n\n    // Skip until the beginning of the completion block\n    while (std::getline(file, line))\n    {\n        if (line.find(\"completion-begin\") != std::string::npos &&\n            line.find(\"std::string::npos\") == std::string::npos)\n        {\n            break;\n        }\n    }\n\n    // Search for the thrust::merge call\n    bool found = false;\n    while (std::getline(file, line))\n    {\n        if (line.find(\"thrust::merge\") != std::string::npos)\n        {\n            found = true;\n            break;\n        }\n\n        if (line.find(\"completion-end\") != std::string::npos)\n        {\n            break;\n        }\n    }\n\n    if (!found)\n    {\n        std::cerr << \"Test failed!\" << std::endl;\n        std::exit(1);\n    }\n};\n\nstatic_test();\ndynamic_test();\n\n}\n", "example_test": "@example_test\n", "cuda_toolkit": "12.0"}
{"task_id": "CUDA/46", "date": "2025-03-31", "prompt": "Write a function `thrust::device_vector<int> redistribute_elements(thrust::device_vector<int> const&\nvec, thrust::device_vector<int> const& map)` that takes an input vector and a map vector (of equal\nsize) that holds indices. It returns a new vector where each element from source is redistributed\naccording to the index pointed by the corresponding element in the map vector using a thrust\nalgorithm.\n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_70 -arch=sm_60", "ld_flags": "", "declaration": "#include <thrust/device_vector.h>\n#include <thrust/scatter.h>\n#include <cstdlib>\n#include <fstream>\n#include <iostream>\n\nthrust::device_vector<int> redistribute_elements(thrust::device_vector<int> const &vec,\n                                                 thrust::device_vector<int> const &map);\n\n", "test": "int main() {\n\nauto dynamic_test = []() {\n    thrust::device_vector<int> x {10, 30, 20, 40, 50};\n    thrust::device_vector<int> map {2, 4, 0, 1, 3};\n\n    thrust::device_vector<int> result = redistribute_elements(x, map);\n    thrust::device_vector<int> ref {20, 40, 10, 50, 30};\n\n    for (int i = 0; i < result.size(); i++)\n    {\n        if (result[i] != ref[i])\n        {\n            std::cerr << \"Error: error at index \" << i << \" got \" << result[i] << \" expected \"\n                      << ref[i] << std::endl;\n            std::exit(1);\n        }\n    }\n};\n\nauto static_test = []() {\n    const char *path = std::getenv(\"COMPUTE_EVAL_SRC_FILE\");\n    if (path == nullptr)\n    {\n        std::cerr << \"Environment variable not found!\" << std::endl;\n        std::exit(1);\n    }\n\n    std::ifstream file(path);\n    if (!file.is_open())\n    {\n        std::cerr << \"File not found!\" << std::endl;\n        std::exit(1);\n    }\n\n    std::string line;\n\n    // Skip until the beginning of the completion block\n    while (std::getline(file, line))\n    {\n        if (line.find(\"completion-begin\") != std::string::npos &&\n            line.find(\"std::string::npos\") == std::string::npos)\n        {\n            break;\n        }\n    }\n\n    // Search for the thrust::scatter call\n    bool found = false;\n    while (std::getline(file, line))\n    {\n        if (line.find(\"thrust::scatter\") != std::string::npos)\n        {\n            found = true;\n            break;\n        }\n\n        if (line.find(\"completion-end\") != std::string::npos)\n        {\n            break;\n        }\n    }\n\n    if (!found)\n    {\n        std::cerr << \"Test failed!\" << std::endl;\n        std::exit(1);\n    }\n};\n\nstatic_test();\ndynamic_test();\n\n}\n", "example_test": "@example_test\n", "cuda_toolkit": "12.0"}
{"task_id": "CUDA/47", "date": "2025-03-31", "prompt": "Write a function `thrust::device_vector<int> remap_elements(thrust::device_vector<int> const& vec,\nthrust::device_vector<int> const& map)` that takes an input vector and a map vector and returns a\nnew vector (equal size to map.size()) where each element is being picked from the source according to the index\nindicated by map using a thrust algorithm.\n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_70 -arch=sm_60", "ld_flags": "", "declaration": "#include <thrust/device_vector.h>\n#include <thrust/gather.h>\n#include <cstdlib>\n#include <fstream>\n#include <iostream>\n\nthrust::device_vector<int> remap_elements(thrust::device_vector<int> const &vec,\n                                          thrust::device_vector<int> const &map);\n\n", "test": "int main() {\n\nauto dynamic_test = []() {\n    thrust::device_vector<int> x {1, 3, 2, 10, 3};\n    thrust::device_vector<int> map {0, 4, 1, 1};\n\n    thrust::device_vector<int> result = remap_elements(x, map);\n    thrust::device_vector<int> ref {1, 3, 3, 3};\n\n    for (int i = 0; i < result.size(); i++)\n    {\n        if (result[i] != ref[i])\n        {\n            std::cerr << \"Error: error at index \" << i << \" got \" << result[i] << \" expected \"\n                      << ref[i] << std::endl;\n            std::exit(1);\n        }\n    }\n};\n\nauto static_test = []() {\n    const char *path = std::getenv(\"COMPUTE_EVAL_SRC_FILE\");\n    if (path == nullptr)\n    {\n        std::cerr << \"Environment variable not found!\" << std::endl;\n        std::exit(1);\n    }\n\n    std::ifstream file(path);\n    if (!file.is_open())\n    {\n        std::cerr << \"File not found!\" << std::endl;\n        std::exit(1);\n    }\n\n    std::string line;\n\n    // Skip until the beginning of the completion block\n    while (std::getline(file, line))\n    {\n        if (line.find(\"completion-begin\") != std::string::npos &&\n            line.find(\"std::string::npos\") == std::string::npos)\n        {\n            break;\n        }\n    }\n\n    // Search for the thrust::gather call\n    bool found = false;\n    while (std::getline(file, line))\n    {\n        if (line.find(\"thrust::gather\") != std::string::npos)\n        {\n            found = true;\n            break;\n        }\n\n        if (line.find(\"completion-end\") != std::string::npos)\n        {\n            break;\n        }\n    }\n\n    if (!found)\n    {\n        std::cerr << \"Test failed!\" << std::endl;\n        std::exit(1);\n    }\n};\n\nstatic_test();\ndynamic_test();\n\n}\n", "example_test": "@example_test\n", "cuda_toolkit": "12.0"}
{"task_id": "CUDA/48", "date": "2025-03-31", "prompt": "Write a function `std::size_t find_partition_barrier(thrust::device_vector<int> const& vec)` that\ntakes an already partitioned device vector where its first partition is even numbers and its second\npartition is odd numbers as input and finds the index at which the partition takes place. Use a\nsingle thrust algorithm.\n\nDo not include any code outside the function. Wrap the completed function code, including the\nprovided signature, inside a ```cuda markdown code block.\n", "cc_flags": "-arch=sm_90a --extended-lambda -arch=sm_89 --extended-lambda -arch=sm_80 --extended-lambda -arch=sm_70 --extended-lambda -arch=sm_60 --extended-lambda", "ld_flags": "", "declaration": "#include <thrust/device_vector.h>\n#include <thrust/partition.h>\n#include <thrust/sort.h>\n#include <cstdlib>\n#include <fstream>\n#include <iostream>\n\nstd::size_t find_partition_barrier(thrust::device_vector<int> const & vec);\n\n", "test": "int main() {\n\nauto dynamic_test = []() {\n    thrust::device_vector<int> vec {2, 4, 6, 8, 10, 1, 3, 5, 7, 9};\n    auto result = find_partition_barrier(vec);\n\n    if (result != 5)\n    {\n        std::cerr << \"Test failed. Partition point should be 5.\" << std::endl;\n        std::exit(1);\n    }\n};\n\nauto static_test = []() {\n    const char* path = std::getenv(\"COMPUTE_EVAL_SRC_FILE\");\n    if (path == nullptr)\n    {\n        std::cerr << \"Environment variable not found!\" << std::endl;\n        std::exit(1);\n    }\n\n    std::ifstream file(path);\n    if (!file.is_open())\n    {\n        std::cerr << \"File not found!\" << std::endl;\n        std::exit(1);\n    }\n\n    std::string line;\n\n    // Skip until the beginning of the completion block\n    while (std::getline(file, line))\n    {\n        if (line.find(\"completion-begin\") != std::string::npos &&\n            line.find(\"std::string::npos\") == std::string::npos)\n        {\n            break;\n        }\n    }\n\n    // Search for the thrust::partition_point call\n    bool found = false;\n    while (std::getline(file, line))\n    {\n        if (line.find(\"thrust::partition_point\") != std::string::npos)\n        {\n            found = true;\n            break;\n        }\n\n        if (line.find(\"completion-end\") != std::string::npos)\n        {\n            break;\n        }\n    }\n\n    if (!found)\n    {\n        std::cerr << \"Test failed!\" << std::endl;\n        std::exit(1);\n    }\n};\n\nstatic_test();\ndynamic_test();\n\n}\n", "example_test": "@example_test\n", "cuda_toolkit": "12.0"}
{"task_id": "CUDA/49", "date": "2025-03-31", "prompt": "Write a function `void shift_by_5(thrust::device_vector<int>::iterator& it)` that takes a device\nvector iterator and shifts it ahead it by 5 elements using one thrust algorithm.\n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_70 -arch=sm_60", "ld_flags": "", "declaration": "#include <thrust/advance.h>\n#include <thrust/device_vector.h>\n#include <cstdlib>\n#include <fstream>\n#include <iostream>\n\nvoid shift_by_5(thrust::device_vector<int>::iterator &it);\n\n", "test": "int main() {\n\nauto dynamic_test = []() {\n    thrust::device_vector<int> v1 {0, -1, -2, -3, -4, -5, -6};\n    thrust::device_vector<int>::iterator it = v1.begin();\n    shift_by_5(it);\n\n    auto dst = thrust::distance(v1.begin(), it);\n\n    if (dst != 5)\n    {\n        std::cerr << \"Error, expected 5 got \" << dst << std::endl;\n        std::exit(1);\n    }\n};\n\nauto static_test = []() {\n    const char *path = std::getenv(\"COMPUTE_EVAL_SRC_FILE\");\n    if (path == nullptr)\n    {\n        std::cerr << \"Environment variable not found!\" << std::endl;\n        std::exit(1);\n    }\n\n    std::ifstream file(path);\n    if (!file.is_open())\n    {\n        std::cerr << \"File not found!\" << std::endl;\n        std::exit(1);\n    }\n\n    std::string line;\n\n    // Skip until the beginning of the completion block\n    while (std::getline(file, line))\n    {\n        if (line.find(\"completion-begin\") != std::string::npos &&\n            line.find(\"std::string::npos\") == std::string::npos)\n        {\n            break;\n        }\n    }\n\n    // Search for the thrust::advance call\n    bool found = false;\n    while (std::getline(file, line))\n    {\n        if (line.find(\"thrust::advance\") != std::string::npos)\n        {\n            found = true;\n            break;\n        }\n\n        if (line.find(\"completion-end\") != std::string::npos)\n        {\n            break;\n        }\n    }\n\n    if (!found)\n    {\n        std::cerr << \"Test failed!\" << std::endl;\n        std::exit(1);\n    }\n};\n\nstatic_test();\ndynamic_test();\n\n}\n", "example_test": "@example_test\n", "cuda_toolkit": "12.0"}
{"task_id": "CUDA/50", "date": "2025-03-31", "prompt": "Write a function `void flip_values(thrust::device_vector<int> &vec1, thrust::device_vector<int>\n&vec2)` that accepts two device vectors and exchanges their values with each other using a thrust\nalgorithm.\n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_70 -arch=sm_60", "ld_flags": "", "declaration": "#include <thrust/device_vector.h>\n#include <thrust/swap.h>\n#include <cstdlib>\n#include <fstream>\n#include <iostream>\n\nvoid flip_values(thrust::device_vector<int> &vec1, thrust::device_vector<int> &vec2);\n\n", "test": "int main() {\n\nauto dynamic_test = []() {\n    thrust::device_vector<int> x {42, 0, 4, 2, 4};\n    thrust::device_vector<int> y {-1, -2, -3, -4, -5};\n\n    flip_values(x, y);\n\n    thrust::device_vector<int> x_ref {-1, -2, -3, -4, -5};\n    thrust::device_vector<int> y_ref {42, 0, 4, 2, 4};\n    if (x_ref != x || y_ref != y)\n    {\n        std::cerr << \"Error: flip_values failed!\" << std::endl;\n        std::exit(1);\n    }\n};\n\nauto static_test = []() {\n    const char *path = std::getenv(\"COMPUTE_EVAL_SRC_FILE\");\n    if (path == nullptr)\n    {\n        std::cerr << \"Environment variable not found!\" << std::endl;\n        std::exit(1);\n    }\n\n    std::ifstream file(path);\n    if (!file.is_open())\n    {\n        std::cerr << \"File not found!\" << std::endl;\n        std::exit(1);\n    }\n\n    std::string line;\n\n    // Skip until the beginning of the completion block\n    while (std::getline(file, line))\n    {\n        if (line.find(\"completion-begin\") != std::string::npos &&\n            line.find(\"std::string::npos\") == std::string::npos)\n        {\n            break;\n        }\n    }\n\n    // Search for the thrust::swap call\n    bool found = false;\n    while (std::getline(file, line))\n    {\n        if (line.find(\"thrust::swap\") != std::string::npos)\n        {\n            found = true;\n            break;\n        }\n\n        if (line.find(\"completion-end\") != std::string::npos)\n        {\n            break;\n        }\n    }\n\n    if (!found)\n    {\n        std::cerr << \"Test failed!\" << std::endl;\n        std::exit(1);\n    }\n};\n\nstatic_test();\ndynamic_test();\n\n}\n", "example_test": "@example_test\n", "cuda_toolkit": "12.0"}
{"task_id": "CUDA/51", "date": "2025-03-31", "prompt": "Write a function `\nthrust::device_vector<char> find_the_word(\n  thrust::device_vector<char> const& chunk1,\n  thrust::device_vector<int> const& keys1,\n  thrust::device_vector<char> const& chunk2,\n  thrust::device_vector<int> const& keys2)` that merges the two input chunk vectors that hold\ncharacters according to their corresponding key vectors in the GPU. You are required to use only\none thrust algorithm. The resulting device vector should hold all the merged characters from chunk1,\nchunk2 in order according to keys1, keys2 to form the final word.\n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_70 -arch=sm_60", "ld_flags": "", "declaration": "#include <thrust/device_vector.h>\n#include <thrust/execution_policy.h>\n#include <thrust/host_vector.h>\n#include <thrust/merge.h>\n#include <cstdlib>\n#include <fstream>\n#include <iostream>\n\nthrust::device_vector<char> find_the_word(thrust::device_vector<char> const & chunk1,\n                                          thrust::device_vector<int> const & keys1,\n                                          thrust::device_vector<char> const & chunk2,\n                                          thrust::device_vector<int> const & keys2);\n\n", "test": "int main() {\nauto dynamic_test = []() {\n    thrust::device_vector<int> k1 {0, 3, 4, 6, 9, 10, 13};\n    thrust::device_vector<char> ch1 {'m', 't', 'i', 'h', 'a', 'd', 'g'};\n\n    thrust::device_vector<int> k2 {1, 2, 5, 7, 8, 11, 12};\n    thrust::device_vector<char> ch2 {'u', 'l', 't', 'r', 'e', 'i', 'n'};\n\n    auto word = find_the_word(ch1, k1, ch2, k2);\n\n    thrust::host_vector<char> h_word(word);\n    std::string word_string(h_word.begin(), h_word.end());\n    std::string ref = \"multithreading\";\n    if (word_string != ref)\n    {\n        std::cerr << \"Test failed, expected \" << ref << \", got \" << word_string << std::endl;\n        std::exit(1);\n    }\n};\n\nauto static_test = []() {\n    const char* path = std::getenv(\"COMPUTE_EVAL_SRC_FILE\");\n    if (path == nullptr)\n    {\n        std::cerr << \"Environment variable not found!\" << std::endl;\n        std::exit(1);\n    }\n\n    std::ifstream file(path);\n    if (!file.is_open())\n    {\n        std::cerr << \"File not found!\" << std::endl;\n        std::exit(1);\n    }\n\n    std::string line;\n\n    // Skip until the beginning of the completion block\n    while (std::getline(file, line))\n    {\n        if (line.find(\"completion-begin\") != std::string::npos &&\n            line.find(\"std::string::npos\") == std::string::npos)\n        {\n            break;\n        }\n    }\n\n    // Search for the thrust::merge_by_key call\n    bool found = false;\n    while (std::getline(file, line))\n    {\n        if (line.find(\"thrust::merge_by_key\") != std::string::npos)\n        {\n            found = true;\n            break;\n        }\n\n        if (line.find(\"completion-end\") != std::string::npos)\n        {\n            break;\n        }\n    }\n\n    if (!found)\n    {\n        std::cerr << \"Test failed!\" << std::endl;\n        std::exit(1);\n    }\n};\n\nstatic_test();\ndynamic_test();\n\n}\n", "example_test": "@example_test\n", "cuda_toolkit": "12.0"}
{"task_id": "CUDA/52", "date": "2025-03-31", "prompt": "Write a function `thrust::device_vector<float> local_prefix_maxima(thrust::device_vector<float>\nconst &vec, thrust::device_vector<int> const &keys);` that given an input vector and a keys vector\ncalculates the prefix maximum for each group of input elements that correspond to the same keys\nusing one thrust algorithm. Returns a new vector with equal size to the input vector that holds\nprefix maximum values.\n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_70 -arch=sm_60", "ld_flags": "", "declaration": "#include <thrust/device_vector.h>\n#include <thrust/host_vector.h>\n#include <thrust/scan.h>\n#include <cstdlib>\n#include <fstream>\n#include <iostream>\n\nthrust::device_vector<float> local_prefix_maxima(thrust::device_vector<float> const &vec,\n                                                 thrust::device_vector<int> const &keys);\n\n", "test": "int main() {\n\nauto dynamic_test = []() {\n    thrust::device_vector<float> vec {1.2, 1.3, 1.0, 2.7, 2.8, 2.1, 2.9, 4.9, 5.1, 5.4, 5.3};\n    thrust::device_vector<int> keys {0, 0, 0, 1, 1, 1, 1, 2, 3, 3, 3};\n\n    auto res = local_prefix_maxima(vec, keys);\n    thrust::host_vector<float> res_host(res);\n\n    thrust::host_vector<float> expected {1.2, 1.3, 1.3, 2.7, 2.8, 2.8, 2.9, 4.9, 5.1, 5.4, 5.4};\n\n    for (size_t i = 0; i < res_host.size(); i++)\n    {\n        if (res_host[i] != expected[i])\n        {\n            std::cerr << \"Error, expected \" << expected[i] << \" but got \" << res_host[i]\n                      << \" at index \" << i << std::endl;\n            std::exit(1);\n        }\n    }\n};\n\nauto static_test = []() {\n    const char *path = std::getenv(\"COMPUTE_EVAL_SRC_FILE\");\n    if (path == nullptr)\n    {\n        std::cerr << \"Environment variable not found!\" << std::endl;\n        std::exit(1);\n    }\n\n    std::ifstream file(path);\n    if (!file.is_open())\n    {\n        std::cerr << \"File not found!\" << std::endl;\n        std::exit(1);\n    }\n\n    std::string line;\n\n    // Skip until the beginning of the completion block\n    while (std::getline(file, line))\n    {\n        if (line.find(\"completion-begin\") != std::string::npos &&\n            line.find(\"std::string::npos\") == std::string::npos)\n        {\n            break;\n        }\n    }\n\n    // Search for the thrust::inclusive_scan_by_key call\n    bool found = false;\n    while (std::getline(file, line))\n    {\n        if (line.find(\"thrust::inclusive_scan_by_key\") != std::string::npos)\n        {\n            found = true;\n            break;\n        }\n\n        if (line.find(\"completion-end\") != std::string::npos)\n        {\n            break;\n        }\n    }\n\n    if (!found)\n    {\n        std::cerr << \"Test failed!\" << std::endl;\n        std::exit(1);\n    }\n};\n\nstatic_test();\ndynamic_test();\n\n}\n", "example_test": "@example_test\n", "cuda_toolkit": "12.0"}
{"task_id": "CUDA/53", "date": "2025-03-31", "prompt": "Write a function `void remove_consecutive_duplicates(thrust::device_vector<int> &vec)` that removes\nduplicate elements from the input vector on GPU using thrust algorithm.\n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_70 -arch=sm_60", "ld_flags": "", "declaration": "#include <thrust/device_vector.h>\n#include <thrust/execution_policy.h>\n#include <thrust/unique.h>\n#include <cstdlib>\n#include <fstream>\n#include <iostream>\n\nvoid remove_consecutive_duplicates(thrust::device_vector<int> &vec);\n\n", "test": "int main() {\n\nauto dynamic_test = []() {\n    thrust::device_vector<int> in {3, 1, 1, 4, 1, 0, 0};\n    remove_consecutive_duplicates(in);\n\n    thrust::device_vector<int> expected {3, 1, 4, 1, 0};\n\n    for (std::size_t i = 0; i < in.size(); i++)\n    {\n        if (in[i] != expected[i])\n        {\n            std::cerr << \"Test failed!\" << std::endl;\n            std::exit(1);\n        }\n    }\n};\n\nauto static_test = []() {\n    const char *path = std::getenv(\"COMPUTE_EVAL_SRC_FILE\");\n    if (path == nullptr)\n    {\n        std::cerr << \"Environment variable not found!\" << std::endl;\n        std::exit(1);\n    }\n\n    std::ifstream file(path);\n    if (!file.is_open())\n    {\n        std::cerr << \"File not found!\" << std::endl;\n        std::exit(1);\n    }\n\n    std::string line;\n\n    // Skip until the beginning of the completion block\n    while (std::getline(file, line))\n    {\n        if (line.find(\"completion-begin\") != std::string::npos &&\n            line.find(\"std::string::npos\") == std::string::npos)\n        {\n            break;\n        }\n    }\n\n    // Search for the thrust::unique call\n    bool found = false;\n    while (std::getline(file, line))\n    {\n        if (line.find(\"thrust::unique\") != std::string::npos)\n        {\n            found = true;\n            break;\n        }\n\n        if (line.find(\"completion-end\") != std::string::npos)\n        {\n            break;\n        }\n    }\n\n    if (!found)\n    {\n        std::cerr << \"Test failed!\" << std::endl;\n        std::exit(1);\n    }\n};\n\nstatic_test();\ndynamic_test();\n\n}\n", "example_test": "@example_test\n", "cuda_toolkit": "12.0"}
{"task_id": "CUDA/54", "date": "2025-03-31", "prompt": "Write a function `thrust::device_vector<int>\nlocal_prefix_exclusive_sum(thrust::device_vector<int> const &vec, thrust::device_vector<int>\nconst &keys);` that given an input vector and a keys vector calculates the exclusive prefix sum\nfor each group of input elements that correspond to the same keys. Use only one thrust algorithm.\n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_70 -arch=sm_60", "ld_flags": "", "declaration": "#include <thrust/device_vector.h>\n#include <thrust/host_vector.h>\n#include <thrust/scan.h>\n#include <cstdlib>\n#include <fstream>\n#include <iostream>\n\nthrust::device_vector<int> local_prefix_exclusive_sum(thrust::device_vector<int> const &vec,\n                                                      thrust::device_vector<int> const &keys);\n\n", "test": "int main() {\n\nauto dynamic_test = []() {\n    thrust::device_vector<int> vec {1, 2, 3, 2, 2, 3, 3, 5, 3, 2};\n    thrust::device_vector<int> keys {0, 0, 0, 1, 1, 1, 1, 2, 3, 3, 3};\n\n    auto res = local_prefix_exclusive_sum(vec, keys);\n    thrust::host_vector<int> res_host(res);\n\n    thrust::host_vector<int> expected {0, 1, 3, 0, 2, 4, 7, 0, 0, 3};\n\n    for (size_t i = 0; i < res_host.size(); i++)\n    {\n        if (res_host[i] != expected[i])\n        {\n            std::cerr << \"Error, expected \" << expected[i] << \" but got \" << res_host[i]\n                      << \" at index \" << i << std::endl;\n            std::exit(1);\n        }\n    }\n};\n\nauto static_test = []() {\n    const char *path = std::getenv(\"COMPUTE_EVAL_SRC_FILE\");\n    if (path == nullptr)\n    {\n        std::cerr << \"Environment variable not found!\" << std::endl;\n        std::exit(1);\n    }\n\n    std::ifstream file(path);\n    if (!file.is_open())\n    {\n        std::cerr << \"File not found!\" << std::endl;\n        std::exit(1);\n    }\n\n    std::string line;\n\n    // Skip until the beginning of the completion block\n    while (std::getline(file, line))\n    {\n        if (line.find(\"completion-begin\") != std::string::npos &&\n            line.find(\"std::string::npos\") == std::string::npos)\n        {\n            break;\n        }\n    }\n\n    // Search for the thrust::exclusive_scan_by_key call\n    bool found = false;\n    while (std::getline(file, line))\n    {\n        if (line.find(\"thrust::exclusive_scan_by_key\") != std::string::npos)\n        {\n            found = true;\n            break;\n        }\n\n        if (line.find(\"completion-end\") != std::string::npos)\n        {\n            break;\n        }\n    }\n\n    if (!found)\n    {\n        std::cerr << \"Test failed!\" << std::endl;\n        std::exit(1);\n    }\n};\n\nstatic_test();\ndynamic_test();\n\n}\n", "example_test": "@example_test\n", "cuda_toolkit": "12.0"}
{"task_id": "CUDA/55", "date": "2025-03-31", "prompt": "Write a function `int negate_and_add(const thrust::device_vector<int> &vec)` that negates all\nelements of the input vector and then adds them all together on GPU using one thrust algorithm.\nRetiurn the sum.\n", "cc_flags": "-arch=sm_90a --extended-lambda -arch=sm_89 --extended-lambda -arch=sm_80 --extended-lambda -arch=sm_70 --extended-lambda -arch=sm_60 --extended-lambda", "ld_flags": "", "declaration": "#include <thrust/device_vector.h>\n#include <thrust/transform_reduce.h>\n#include <cstdlib>\n#include <fstream>\n#include <iostream>\n\nint negate_and_add(const thrust::device_vector<int> &vec);\n\n", "test": "int main() {\n\nauto dynamic_test = []() {\n    thrust::device_vector<int> vec {1, -3, 2, -4, 5};\n    auto res = negate_and_add(vec);\n\n    if (res != -1)\n    {\n        std::cerr << \"Test failed, expected -1, got \" << res << std::endl;\n        std::exit(1);\n    }\n};\n\nauto static_test = []() {\n    const char *path = std::getenv(\"COMPUTE_EVAL_SRC_FILE\");\n    if (path == nullptr)\n    {\n        std::cerr << \"Environment variable not found!\" << std::endl;\n        std::exit(1);\n    }\n\n    std::ifstream file(path);\n    if (!file.is_open())\n    {\n        std::cerr << \"File not found!\" << std::endl;\n        std::exit(1);\n    }\n\n    std::string line;\n\n    // Skip until the beginning of the completion block\n    while (std::getline(file, line))\n    {\n        if (line.find(\"completion-begin\") != std::string::npos &&\n            line.find(\"std::string::npos\") == std::string::npos)\n        {\n            break;\n        }\n    }\n\n    // Search for the thrust::transform_reduce call\n    bool found = false;\n    while (std::getline(file, line))\n    {\n        if (line.find(\"thrust::transform_reduce\") != std::string::npos)\n        {\n            found = true;\n            break;\n        }\n\n        if (line.find(\"completion-end\") != std::string::npos)\n        {\n            break;\n        }\n    }\n\n    if (!found)\n    {\n        std::cerr << \"Test failed!\" << std::endl;\n        std::exit(1);\n    }\n};\n\nstatic_test();\ndynamic_test();\n\n}\n", "example_test": "@example_test\n", "cuda_toolkit": "12.0"}
{"task_id": "CUDA/56", "date": "2025-03-31", "prompt": "Write a function `void replace_twos(thrust::device_vector<int>& vec)` that replaces the elements of\na vector with the value 2 with the value -2 using a Thrust algorithm.\n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_70 -arch=sm_60", "ld_flags": "", "declaration": "#include <thrust/device_vector.h>\n#include <thrust/replace.h>\n#include <cstddef>\n#include <cstdlib>\n#include <fstream>\n#include <iostream>\n\nvoid replace_twos(thrust::device_vector<int>& vec);\n\n", "test": "int main() {\nauto dynamic_test = []() {\n    thrust::device_vector<int> x {2, 1, 2, 3, -2};\n    replace_twos(x);\n\n    thrust::device_vector<int> expected {-2, 1, -2, 3, -2};\n\n    for (std::size_t i = 0; i < x.size(); i++)\n    {\n        if (x[i] != expected[i])\n        {\n            std::cerr << \"Test failed!\" << std::endl;\n            std::exit(1);\n        }\n    }\n};\n\nauto static_test = []() {\n    const char* path = std::getenv(\"COMPUTE_EVAL_SRC_FILE\");\n    if (path == nullptr)\n    {\n        std::cerr << \"Environment variable not found!\" << std::endl;\n        std::exit(1);\n    }\n\n    std::ifstream file(path);\n    if (!file.is_open())\n    {\n        std::cerr << \"File not found!\" << std::endl;\n        std::exit(1);\n    }\n\n    std::string line;\n\n    // Skip until the beginning of the completion block\n    while (std::getline(file, line))\n    {\n        if (line.find(\"completion-begin\") != std::string::npos &&\n            line.find(\"std::string::npos\") == std::string::npos)\n        {\n            break;\n        }\n    }\n\n    // Search for the thrust::replace call\n    bool found = false;\n    while (std::getline(file, line))\n    {\n        if (line.find(\"thrust::replace\") != std::string::npos)\n        {\n            found = true;\n            break;\n        }\n\n        if (line.find(\"completion-end\") != std::string::npos)\n        {\n            break;\n        }\n    }\n\n    if (!found)\n    {\n        std::cerr << \"Test failed!\" << std::endl;\n        std::exit(1);\n    }\n};\n\nstatic_test();\ndynamic_test();\n\n}\n", "example_test": "@example_test\n", "cuda_toolkit": "12.0"}
{"task_id": "CUDA/57", "date": "2025-03-31", "prompt": "Write a function `void copy_evens(const thrust::device_vector<int>& src,\nthrust::device_vector<int>& dst)` that copies the even integers of a src\nvector in GPU to a dst vector in GPU using a Thrust algorithm.\n", "cc_flags": "-arch=sm_90a --extended-lambda -arch=sm_89 --extended-lambda -arch=sm_80 --extended-lambda -arch=sm_70 --extended-lambda -arch=sm_60 --extended-lambda", "ld_flags": "", "declaration": "#include <thrust/copy.h>\n#include <thrust/device_vector.h>\n#include <cstdlib>\n#include <fstream>\n#include <iostream>\n\nvoid copy_evens(const thrust::device_vector<int> &src, thrust::device_vector<int> &dst);\n\n", "test": "int main() {\nauto dynamic_test = []() {\n    thrust::device_vector<int> x {0, 1, 2, 3, 4};\n    thrust::device_vector<int> y(x.size());\n    copy_evens(x, y);\n\n    thrust::device_vector<int> expected {0, 2, 4};\n\n    for (std::size_t i = 0; i < y.size(); i++)\n    {\n        if (y[i] != expected[i])\n        {\n            std::cerr << \"Test failed!\" << std::endl;\n            std::exit(1);\n        }\n    }\n};\n\nauto static_test = []() {\n    const char *path = std::getenv(\"COMPUTE_EVAL_SRC_FILE\");\n    if (path == nullptr)\n    {\n        std::cerr << \"Environment variable not found!\" << std::endl;\n        std::exit(1);\n    }\n\n    std::ifstream file(path);\n    if (!file.is_open())\n    {\n        std::cerr << \"File not found!\" << std::endl;\n        std::exit(1);\n    }\n\n    std::string line;\n\n    // Skip until the beginning of the completion block\n    while (std::getline(file, line))\n    {\n        if (line.find(\"completion-begin\") != std::string::npos &&\n            line.find(\"std::string::npos\") == std::string::npos)\n        {\n            break;\n        }\n    }\n\n    // Search for the thrust::copy_if call\n    bool found = false;\n    while (std::getline(file, line))\n    {\n        if (line.find(\"thrust::copy_if\") != std::string::npos)\n        {\n            found = true;\n            break;\n        }\n\n        if (line.find(\"completion-end\") != std::string::npos)\n        {\n            break;\n        }\n    }\n\n    if (!found)\n    {\n        std::cerr << \"Test failed!\" << std::endl;\n        std::exit(1);\n    }\n};\n\nstatic_test();\ndynamic_test();\n\n}\n", "example_test": "@example_test\n", "cuda_toolkit": "12.0"}
{"task_id": "CUDA/58", "date": "2025-03-31", "prompt": "Write a function `bool has_negatives(thrust::device_vector<int> const& vec)` that checks whether\nthere are any negatives in the input vector using a thrust algorithm. Do not use `thrust::all_of`.\n", "cc_flags": "-arch=sm_90a --extended-lambda -arch=sm_89 --extended-lambda -arch=sm_80 --extended-lambda -arch=sm_70 --extended-lambda -arch=sm_60 --extended-lambda", "ld_flags": "", "declaration": "#include <thrust/device_vector.h>\n#include <thrust/logical.h>\n#include <cstdlib>\n#include <fstream>\n#include <iostream>\n\nbool has_negatives(thrust::device_vector<int> const &vec);\n\n", "test": "int main() {\n\nauto dynamic_test = []() {\n    thrust::device_vector<int> x {42, 0, 4, -2, 1};\n\n    auto has = has_negatives(x);\n\n    if (has != true)\n    {\n        std::cerr << \"Error: expected true, got \" << has << std::endl;\n        std::exit(1);\n    }\n\n    x   = {42, 0, 4, 2, 1};\n    has = has_negatives(x);\n\n    if (has != false)\n    {\n        std::cerr << \"Error: expected false, got \" << has << std::endl;\n        std::exit(1);\n    }\n};\n\nauto static_test = []() {\n    const char *path = std::getenv(\"COMPUTE_EVAL_SRC_FILE\");\n    if (path == nullptr)\n    {\n        std::cerr << \"Environment variable not found!\" << std::endl;\n        std::exit(1);\n    }\n\n    std::ifstream file(path);\n    if (!file.is_open())\n    {\n        std::cerr << \"File not found!\" << std::endl;\n        std::exit(1);\n    }\n\n    std::string line;\n\n    // Skip until the beginning of the completion block\n    while (std::getline(file, line))\n    {\n        if (line.find(\"completion-begin\") != std::string::npos &&\n            line.find(\"std::string::npos\") == std::string::npos)\n        {\n            break;\n        }\n    }\n\n    // Search for the thrust::any_of call\n    bool found = false;\n    while (std::getline(file, line))\n    {\n        if (line.find(\"thrust::any_of\") != std::string::npos)\n        {\n            found = true;\n            break;\n        }\n\n        if (line.find(\"completion-end\") != std::string::npos)\n        {\n            break;\n        }\n    }\n\n    if (!found)\n    {\n        std::cerr << \"Test failed!\" << std::endl;\n        std::exit(1);\n    }\n};\n\nstatic_test();\ndynamic_test();\n\n}\n", "example_test": "@example_test\n", "cuda_toolkit": "12.0"}
{"task_id": "CUDA/59", "date": "2025-03-31", "prompt": "Write a function `thrust::device_vector<int> only_common(thrust::device_vector<int> const& vec1,\nthrust::device_vector<int> const& vec2)` that combines only the common elements of two input sorted\nvectors into a single sorted vector and returns it using one thrust algorithm.\n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_70 -arch=sm_60", "ld_flags": "", "declaration": "#include <thrust/device_vector.h>\n#include <thrust/set_operations.h>\n#include <cstdlib>\n#include <fstream>\n#include <iostream>\n\nthrust::device_vector<int> only_common(thrust::device_vector<int> const &vec1,\n                                       thrust::device_vector<int> const &vec2);\n", "test": "int main() {\n\nauto dynamic_test = []() {\n    thrust::device_vector<int> v1 {1, 2, 2, 2, 3, 10};\n    thrust::device_vector<int> v2 {-10, 0, 2, 2, 5, 10};\n\n    auto result = only_common(v1, v2);\n\n    thrust::device_vector<int> expected {2, 2, 10};\n\n    for (int i = 0; i < result.size(); i++)\n    {\n        if (result[i] != expected[i])\n        {\n            std::cerr << \"Error: error at index \" << i << \" got \" << result[i] << \" expected \"\n                      << expected[i] << std::endl;\n            std::exit(1);\n        }\n    }\n};\n\nauto static_test = []() {\n    const char *path = std::getenv(\"COMPUTE_EVAL_SRC_FILE\");\n    if (path == nullptr)\n    {\n        std::cerr << \"Environment variable not found!\" << std::endl;\n        std::exit(1);\n    }\n\n    std::ifstream file(path);\n    if (!file.is_open())\n    {\n        std::cerr << \"File not found!\" << std::endl;\n        std::exit(1);\n    }\n\n    std::string line;\n\n    // Skip until the beginning of the completion block\n    while (std::getline(file, line))\n    {\n        if (line.find(\"completion-begin\") != std::string::npos &&\n            line.find(\"std::string::npos\") == std::string::npos)\n        {\n            break;\n        }\n    }\n\n    // Search for the thrust::set_intersection call\n    bool found = false;\n    while (std::getline(file, line))\n    {\n        if (line.find(\"thrust::set_intersection\") != std::string::npos)\n        {\n            found = true;\n            break;\n        }\n\n        if (line.find(\"completion-end\") != std::string::npos)\n        {\n            break;\n        }\n    }\n\n    if (!found)\n    {\n        std::cerr << \"Test failed!\" << std::endl;\n        std::exit(1);\n    }\n};\n\nstatic_test();\ndynamic_test();\n\n}\n", "example_test": "@example_test\n", "cuda_toolkit": "12.0"}
{"task_id": "CUDA/60", "date": "2025-03-31", "prompt": "Write a function `thrust::pair<float, float> find_extrema(const thrust::device_vector<float>\n&vec)` that finds and returns the maximum and the minimum values (as a pair) of the input vector\nusing a thrust algorithm.\n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_70 -arch=sm_60", "ld_flags": "", "declaration": "#include <thrust/device_vector.h>\n#include <thrust/extrema.h>\n#include <cstdlib>\n#include <fstream>\n#include <iostream>\n\nthrust::pair<float, float> find_extrema(const thrust::device_vector<float> &vec);\n\n", "test": "int main() {\n\nauto dynamic_test = []() {\n    thrust::device_vector<float> vec {1.0f, 3.0f, 2.0f, 1.5f};\n\n    auto [min, max] = find_extrema(vec);\n    if (min != 1.0f || max != 3.0f)\n    {\n        std::cerr << \"Test failed!\" << std::endl;\n        std::exit(1);\n    }\n};\n\nauto static_test = []() {\n    const char *path = std::getenv(\"COMPUTE_EVAL_SRC_FILE\");\n    if (path == nullptr)\n    {\n        std::cerr << \"Environment variable not found!\" << std::endl;\n        std::exit(1);\n    }\n\n    std::ifstream file(path);\n    if (!file.is_open())\n    {\n        std::cerr << \"File not found!\" << std::endl;\n        std::exit(1);\n    }\n\n    std::string line;\n\n    // Skip until the beginning of the completion block\n    while (std::getline(file, line))\n    {\n        if (line.find(\"completion-begin\") != std::string::npos &&\n            line.find(\"std::string::npos\") == std::string::npos)\n        {\n            break;\n        }\n    }\n\n    // Search for the thrust::minmax_element call\n    bool found = false;\n    while (std::getline(file, line))\n    {\n        if (line.find(\"thrust::minmax_element\") != std::string::npos)\n        {\n            found = true;\n            break;\n        }\n\n        if (line.find(\"completion-end\") != std::string::npos)\n        {\n            break;\n        }\n    }\n\n    if (!found)\n    {\n        std::cerr << \"Test failed!\" << std::endl;\n        std::exit(1);\n    }\n};\n\nstatic_test();\ndynamic_test();\n\n}\n", "example_test": "@example_test\n", "cuda_toolkit": "12.0"}
{"task_id": "CUDA/61", "date": "2025-03-31", "prompt": "Write a function `thrust::device_vector<int> combine(thrust::device_vector<int> const& vec1,\nthrust::device_vector<int> const& vec2)` that combines every element of two input sorted vectors\ninto a single sorted vector and returns it using one thrust algorithm. If an element in exists\nin both inputs it shouldn't be duplicated.\n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_70 -arch=sm_60", "ld_flags": "", "declaration": "#include <thrust/device_vector.h>\n#include <thrust/set_operations.h>\n#include <cstdlib>\n#include <fstream>\n#include <iostream>\n\nthrust::device_vector<int> combine(thrust::device_vector<int> const &vec1,\n                                   thrust::device_vector<int> const &vec2);\n", "test": "int main() {\n\nauto dynamic_test = []() {\n    thrust::device_vector<int> v1 {1, 2, 2, 3, 10};\n    thrust::device_vector<int> v2 {-10, 0, 2, 3, 5};\n\n    auto result = combine(v1, v2);\n\n    thrust::device_vector<int> expected {-10, 0, 1, 2, 2, 3, 5, 10};\n\n    for (int i = 0; i < result.size(); i++)\n    {\n        if (result[i] != expected[i])\n        {\n            std::cerr << \"Error: error at index \" << i << \" got \" << result[i] << \" expected \"\n                      << expected[i] << std::endl;\n            std::exit(1);\n        }\n    }\n};\n\nauto static_test = []() {\n    const char *path = std::getenv(\"COMPUTE_EVAL_SRC_FILE\");\n    if (path == nullptr)\n    {\n        std::cerr << \"Environment variable not found!\" << std::endl;\n        std::exit(1);\n    }\n\n    std::ifstream file(path);\n    if (!file.is_open())\n    {\n        std::cerr << \"File not found!\" << std::endl;\n        std::exit(1);\n    }\n\n    std::string line;\n\n    // Skip until the beginning of the completion block\n    while (std::getline(file, line))\n    {\n        if (line.find(\"completion-begin\") != std::string::npos &&\n            line.find(\"std::string::npos\") == std::string::npos)\n        {\n            break;\n        }\n    }\n\n    // Search for the thrust::set_union call\n    bool found = false;\n    while (std::getline(file, line))\n    {\n        if (line.find(\"thrust::set_union\") != std::string::npos)\n        {\n            found = true;\n            break;\n        }\n\n        if (line.find(\"completion-end\") != std::string::npos)\n        {\n            break;\n        }\n    }\n\n    if (!found)\n    {\n        std::cerr << \"Test failed!\" << std::endl;\n        std::exit(1);\n    }\n};\n\nstatic_test();\ndynamic_test();\n\n}\n", "example_test": "@example_test\n", "cuda_toolkit": "12.0"}
{"task_id": "CUDA/62", "date": "2025-03-31", "prompt": "Write a function `bool no_positives(thrust::device_vector<int> const& vec)` that checks whether\nno values in a vector are positive using the proper logical thrust algorithm. Don't use\nthrust::all_of, thrust::any_of, thrust::find/(_if) or thrust::count/(_if).\n", "cc_flags": "-arch=sm_90a --extended-lambda -arch=sm_89 --extended-lambda -arch=sm_80 --extended-lambda -arch=sm_70 --extended-lambda -arch=sm_60 --extended-lambda", "ld_flags": "", "declaration": "#include <thrust/device_vector.h>\n#include <thrust/logical.h>\n#include <cstdlib>\n#include <fstream>\n#include <iostream>\n\nbool no_positives(thrust::device_vector<int> const &vec);\n\n", "test": "int main() {\n\nauto dynamic_test = []() {\n    thrust::device_vector<int> x = {-1, 2, 2, 5};\n    auto check                   = no_positives(x);\n\n    if (check != false)\n    {\n        std::cerr << \"Error: expected false, got \" << check << std::endl;\n        std::exit(1);\n    }\n\n    x     = {-1, -6, 0, -10};\n    check = no_positives(x);\n\n    if (check != true)\n    {\n        std::cerr << \"Error: expected true, got \" << check << std::endl;\n        std::exit(1);\n    }\n};\n\nauto static_test = []() {\n    const char *path = std::getenv(\"COMPUTE_EVAL_SRC_FILE\");\n    if (path == nullptr)\n    {\n        std::cerr << \"Environment variable not found!\" << std::endl;\n        std::exit(1);\n    }\n\n    std::ifstream file(path);\n    if (!file.is_open())\n    {\n        std::cerr << \"File not found!\" << std::endl;\n        std::exit(1);\n    }\n\n    std::string line;\n\n    // Skip until the beginning of the completion block\n    while (std::getline(file, line))\n    {\n        if (line.find(\"completion-begin\") != std::string::npos &&\n            line.find(\"std::string::npos\") == std::string::npos)\n        {\n            break;\n        }\n    }\n\n    // Search for the thrust::none_of call\n    bool found = false;\n    while (std::getline(file, line))\n    {\n        if (line.find(\"thrust::none_of\") != std::string::npos)\n        {\n            found = true;\n            break;\n        }\n\n        if (line.find(\"completion-end\") != std::string::npos)\n        {\n            break;\n        }\n    }\n\n    if (!found)\n    {\n        std::cerr << \"Test failed!\" << std::endl;\n        std::exit(1);\n    }\n};\n\nstatic_test();\ndynamic_test();\n\n}\n", "example_test": "@example_test\n", "cuda_toolkit": "12.0"}
{"task_id": "CUDA/63", "date": "2025-03-31", "prompt": "Write a function `thrust::device_vector<int> reduce_chunks(thrust::device_vector<int>& vec,\nthrust::device_vector<int> const& keys)` that adds all elements of the input vector vec that have\nthe same corresponding key value in the keys vector on GPU using one thrust algorithm. It should\nreturn a vector with the reduced values.\n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_70 -arch=sm_60", "ld_flags": "", "declaration": "#include <thrust/device_vector.h>\n#include <thrust/host_vector.h>\n#include <thrust/reduce.h>\n#include <thrust/unique.h>\n#include <cstdlib>\n#include <fstream>\n#include <iostream>\n\nthrust::device_vector<int> reduce_chunks(thrust::device_vector<int>& vec,\n                                         thrust::device_vector<int> const & keys);\n\n", "test": "int main() {\n\nauto dynamic_test = []() {\n    thrust::device_vector<int> vec {4, 2, 3, 4, 5, 10, 2, 1, 6, 8};\n    thrust::device_vector<int> keys {0, 1, 1, 1, 2, 2, 3, 3, 3, 3};\n\n    thrust::device_vector<int> res = reduce_chunks(vec, keys);\n    thrust::host_vector<int> res_host(res);\n    thrust::host_vector<int> ref {4, 9, 15, 17};\n\n    for (int i = 0; i < res.size(); i++)\n    {\n        if (res_host[i] != ref[i])\n        {\n            std::cerr << \"Error, expected \" << ref[i] << \" got \" << res[i] << \"in position \" << i\n                      << std::endl;\n            std::exit(1);\n        }\n    }\n};\n\nauto static_test = []() {\n    const char* path = std::getenv(\"COMPUTE_EVAL_SRC_FILE\");\n    if (path == nullptr)\n    {\n        std::cerr << \"Environment variable not found!\" << std::endl;\n        std::exit(1);\n    }\n\n    std::ifstream file(path);\n    if (!file.is_open())\n    {\n        std::cerr << \"File not found!\" << std::endl;\n        std::exit(1);\n    }\n\n    std::string line;\n\n    // Skip until the beginning of the completion block\n    while (std::getline(file, line))\n    {\n        if (line.find(\"completion-begin\") != std::string::npos &&\n            line.find(\"std::string::npos\") == std::string::npos)\n        {\n            break;\n        }\n    }\n\n    // Search for the thrust::reduce_by_key call\n    bool found = false;\n    while (std::getline(file, line))\n    {\n        if (line.find(\"thrust::reduce_by_key\") != std::string::npos)\n        {\n            found = true;\n            break;\n        }\n\n        if (line.find(\"completion-end\") != std::string::npos)\n        {\n            break;\n        }\n    }\n\n    if (!found)\n    {\n        std::cerr << \"Test failed!\" << std::endl;\n        std::exit(1);\n    }\n};\n\nstatic_test();\ndynamic_test();\n\n}\n", "example_test": "@example_test\n", "cuda_toolkit": "12.0"}
{"task_id": "CUDA/64", "date": "2025-03-31", "prompt": "Write a function `void delete_twos(thrust::device_vector<int>& vec)` that removes the elements of\na vector that are equal to 2 using a Thrust algorithm.\n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_70 -arch=sm_60", "ld_flags": "", "declaration": "#include <thrust/device_vector.h>\n#include <thrust/remove.h>\n#include <cstddef>\n#include <cstdlib>\n#include <fstream>\n#include <iostream>\n\nvoid delete_twos(thrust::device_vector<int>& vec);\n\n", "test": "int main() {\nauto dynamic_test = []() {\n    thrust::device_vector<int> x {2, 1, 2, 3, -2};\n    delete_twos(x);\n\n    thrust::device_vector<int> expected {1, 3, -2};\n\n    for (std::size_t i = 0; i < x.size(); i++)\n    {\n        if (x[i] != expected[i])\n        {\n            std::cerr << \"Test failed!\" << std::endl;\n            std::exit(1);\n        }\n    }\n};\n\nauto static_test = []() {\n    const char* path = std::getenv(\"COMPUTE_EVAL_SRC_FILE\");\n    if (path == nullptr)\n    {\n        std::cerr << \"Environment variable not found!\" << std::endl;\n        std::exit(1);\n    }\n\n    std::ifstream file(path);\n    if (!file.is_open())\n    {\n        std::cerr << \"File not found!\" << std::endl;\n        std::exit(1);\n    }\n\n    std::string line;\n\n    // Skip until the beginning of the completion block\n    while (std::getline(file, line))\n    {\n        if (line.find(\"completion-begin\") != std::string::npos &&\n            line.find(\"std::string::npos\") == std::string::npos)\n        {\n            break;\n        }\n    }\n\n    // Search for the thrust::remove call\n    bool found = false;\n    while (std::getline(file, line))\n    {\n        if (line.find(\"thrust::remove\") != std::string::npos)\n        {\n            found = true;\n            break;\n        }\n\n        if (line.find(\"completion-end\") != std::string::npos)\n        {\n            break;\n        }\n    }\n\n    if (!found)\n    {\n        std::cerr << \"Test failed!\" << std::endl;\n        std::exit(1);\n    }\n};\n\nstatic_test();\ndynamic_test();\n\n}\n", "example_test": "@example_test\n", "cuda_toolkit": "12.0"}
{"task_id": "CUDA/65", "date": "2025-03-31", "prompt": "Write a function `thrust::device_vector<int>::iterator\nfind_first_negative(thrust::device_vector<int>& vec)` that finds and returns an iterator to the\nfirst element of the input vector that is negative.\n", "cc_flags": "-arch=sm_90a --extended-lambda -arch=sm_89 --extended-lambda -arch=sm_80 --extended-lambda -arch=sm_70 --extended-lambda -arch=sm_60 --extended-lambda", "ld_flags": "", "declaration": "#include <thrust/device_vector.h>\n#include <thrust/find.h>\n#include <cstdlib>\n#include <fstream>\n#include <iostream>\n\nthrust::device_vector<int>::iterator find_first_negative(thrust::device_vector<int> &vec);\n\n", "test": "int main() {\n\nauto dynamic_test = []() {\n    thrust::device_vector<int> x {42, 0, 4, -2, 4};\n\n    auto it    = find_first_negative(x);\n    auto index = thrust::distance(x.begin(), it);\n\n    if (index != 3)\n    {\n        std::cerr << \"Error: expected 3, got \" << index << std::endl;\n        std::exit(1);\n    }\n};\n\nauto static_test = []() {\n    const char *path = std::getenv(\"COMPUTE_EVAL_SRC_FILE\");\n    if (path == nullptr)\n    {\n        std::cerr << \"Environment variable not found!\" << std::endl;\n        std::exit(1);\n    }\n\n    std::ifstream file(path);\n    if (!file.is_open())\n    {\n        std::cerr << \"File not found!\" << std::endl;\n        std::exit(1);\n    }\n\n    std::string line;\n\n    // Skip until the beginning of the completion block\n    while (std::getline(file, line))\n    {\n        if (line.find(\"completion-begin\") != std::string::npos &&\n            line.find(\"std::string::npos\") == std::string::npos)\n        {\n            break;\n        }\n    }\n\n    // Search for the thrust::find call\n    bool found = false;\n    while (std::getline(file, line))\n    {\n        if (line.find(\"thrust::find_if\") != std::string::npos)\n        {\n            found = true;\n            break;\n        }\n\n        if (line.find(\"completion-end\") != std::string::npos)\n        {\n            break;\n        }\n    }\n\n    if (!found)\n    {\n        std::cerr << \"Test failed!\" << std::endl;\n        std::exit(1);\n    }\n};\n\nstatic_test();\ndynamic_test();\n\n}\n", "example_test": "@example_test\n", "cuda_toolkit": "12.0"}
{"task_id": "CUDA/66", "date": "2025-03-31", "prompt": "Write a function `void all_42s(thrust::device_vector<int>& vec)` that flls the input vector all with\n42s using a thrust algorithm.\n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_70 -arch=sm_60", "ld_flags": "", "declaration": "#include <thrust/device_vector.h>\n#include <thrust/fill.h>\n#include <cstddef>\n#include <cstdlib>\n#include <fstream>\n#include <iostream>\n\nvoid all_42s(thrust::device_vector<int>& vec);\n", "test": "int main() {\nauto dynamic_test = []() {\n    thrust::device_vector<int> x {0, 1, 2, 3};\n    all_42s(x);\n\n    thrust::device_vector<int> expected {42, 42, 42, 42};\n\n    for (std::size_t i = 0; i < x.size(); i++)\n    {\n        if (x[i] != expected[i])\n        {\n            std::cerr << \"Test failed!\" << std::endl;\n            std::exit(1);\n        }\n    }\n};\n\nauto static_test = []() {\n    const char* path = std::getenv(\"COMPUTE_EVAL_SRC_FILE\");\n    if (path == nullptr)\n    {\n        std::cerr << \"Environment variable not found!\" << std::endl;\n        std::exit(1);\n    }\n\n    std::ifstream file(path);\n    if (!file.is_open())\n    {\n        std::cerr << \"File not found!\" << std::endl;\n        std::exit(1);\n    }\n\n    std::string line;\n\n    // Skip until the beginning of the completion block\n    while (std::getline(file, line))\n    {\n        if (line.find(\"completion-begin\") != std::string::npos &&\n            line.find(\"std::string::npos\") == std::string::npos)\n        {\n            break;\n        }\n    }\n\n    // Search for the thrust::fill call\n    bool found = false;\n    while (std::getline(file, line))\n    {\n        if (line.find(\"thrust::fill\") != std::string::npos)\n        {\n            found = true;\n            break;\n        }\n\n        if (line.find(\"completion-end\") != std::string::npos)\n        {\n            break;\n        }\n    }\n\n    if (!found)\n    {\n        std::cerr << \"Test failed!\" << std::endl;\n        std::exit(1);\n    }\n};\n\nstatic_test();\ndynamic_test();\n\n}\n", "example_test": "@example_test\n", "cuda_toolkit": "12.0"}
{"task_id": "CUDA/67", "date": "2025-03-31", "prompt": "Write a function `std::size_t find_divergence(thrust::device_vector<int>\nconst &vec1, thrust::device_vector<int> const &vec2)` that  detects the first index where the input\nvectors are not equal and returns the index using one thrust algorithm.\n", "cc_flags": "-arch=sm_90a --extended-lambda -arch=sm_89 --extended-lambda -arch=sm_80 --extended-lambda -arch=sm_70 --extended-lambda -arch=sm_60 --extended-lambda", "ld_flags": "", "declaration": "#include <thrust/device_vector.h>\n#include <thrust/host_vector.h>\n#include <thrust/mismatch.h>\n#include <cstdlib>\n#include <fstream>\n#include <iostream>\n\nstd::size_t find_divergence(thrust::device_vector<int> const &vec1,\n                            thrust::device_vector<int> const &vec2);\n\n", "test": "int main() {\n\nauto dynamic_test = []() {\n    thrust::device_vector<int> x {0, 1, 2, 3, 4, 5};\n    thrust::device_vector<int> y {0, 1, 2, 5, 4};\n\n    auto res = find_divergence(x, y);\n\n    std::size_t expected = 3;\n\n    if (res != expected)\n    {\n        std::cerr << \"Error: expected \" << expected << \", got \" << res << std::endl;\n        std::exit(1);\n    }\n};\n\nauto static_test = []() {\n    const char *path = std::getenv(\"COMPUTE_EVAL_SRC_FILE\");\n    if (path == nullptr)\n    {\n        std::cerr << \"Environment variable not found!\" << std::endl;\n        std::exit(1);\n    }\n\n    std::ifstream file(path);\n    if (!file.is_open())\n    {\n        std::cerr << \"File not found!\" << std::endl;\n        std::exit(1);\n    }\n\n    std::string line;\n\n    // Skip until the beginning of the completion block\n    while (std::getline(file, line))\n    {\n        if (line.find(\"completion-begin\") != std::string::npos &&\n            line.find(\"std::string::npos\") == std::string::npos)\n        {\n            break;\n        }\n    }\n\n    // Search for the thrust::mismatch call\n    bool found = false;\n    while (std::getline(file, line))\n    {\n        if (line.find(\"thrust::mismatch\") != std::string::npos)\n        {\n            found = true;\n            break;\n        }\n\n        if (line.find(\"completion-end\") != std::string::npos)\n        {\n            break;\n        }\n    }\n\n    if (!found)\n    {\n        std::cerr << \"Test failed!\" << std::endl;\n        std::exit(1);\n    }\n};\n\nstatic_test();\ndynamic_test();\n\n}\n", "example_test": "@example_test\n", "cuda_toolkit": "12.0"}
{"task_id": "CUDA/68", "date": "2025-03-31", "prompt": "Write a function `thrust::device_vector<int> neighbors_difference(thrust::device_vector<int> const&\nvec)` that computes the difference between every input element with its previous element using one\nthrust algorithm. For the first element just copy it as is.\n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_70 -arch=sm_60", "ld_flags": "", "declaration": "#include <thrust/adjacent_difference.h>\n#include <thrust/device_vector.h>\n#include <cstdlib>\n#include <fstream>\n#include <iostream>\n\nthrust::device_vector<int> neighbors_difference(thrust::device_vector<int> const &vec);\n", "test": "int main() {\n\nauto dynamic_test = []() {\n    thrust::device_vector<int> v1 {1, 2, 3, 4, 3, 2};\n\n    auto result = neighbors_difference(v1);\n\n    thrust::device_vector<int> expected {1, 1, 1, 1, -1, -1};\n\n    for (std::size_t i = 0; i < result.size(); i++)\n    {\n        if (result[i] != expected[i])\n        {\n            std::cerr << \"Error: error at index \" << i << \" got \" << result[i] << \" expected \"\n                      << expected[i] << std::endl;\n            std::exit(1);\n        }\n    }\n};\n\nauto static_test = []() {\n    const char *path = std::getenv(\"COMPUTE_EVAL_SRC_FILE\");\n    if (path == nullptr)\n    {\n        std::cerr << \"Environment variable not found!\" << std::endl;\n        std::exit(1);\n    }\n\n    std::ifstream file(path);\n    if (!file.is_open())\n    {\n        std::cerr << \"File not found!\" << std::endl;\n        std::exit(1);\n    }\n\n    std::string line;\n\n    // Skip until the beginning of the completion block\n    while (std::getline(file, line))\n    {\n        if (line.find(\"completion-begin\") != std::string::npos &&\n            line.find(\"std::string::npos\") == std::string::npos)\n        {\n            break;\n        }\n    }\n\n    // Search for the thrust::adjacent_difference call\n    bool found = false;\n    while (std::getline(file, line))\n    {\n        if (line.find(\"thrust::adjacent_difference\") != std::string::npos)\n        {\n            found = true;\n            break;\n        }\n\n        if (line.find(\"completion-end\") != std::string::npos)\n        {\n            break;\n        }\n    }\n\n    if (!found)\n    {\n        std::cerr << \"Test failed!\" << std::endl;\n        std::exit(1);\n    }\n};\n\nstatic_test();\ndynamic_test();\n\n}\n", "example_test": "@example_test\n", "cuda_toolkit": "12.0"}
{"task_id": "CUDA/69", "date": "2025-03-31", "prompt": "Write a function `void square_indices(thrust::device_vector<int> &vec);` that fills the input vector\nwith the squares of the indices using one thrust algorithm.\n", "cc_flags": "-arch=sm_90a --extended-lambda -arch=sm_89 --extended-lambda -arch=sm_80 --extended-lambda -arch=sm_70 --extended-lambda -arch=sm_60 --extended-lambda", "ld_flags": "", "declaration": "#include <thrust/device_vector.h>\n#include <thrust/host_vector.h>\n#include <thrust/tabulate.h>\n#include <cstdlib>\n#include <fstream>\n#include <iostream>\n\nvoid square_indices(thrust::device_vector<int> &vec);\n\n", "test": "int main() {\n\nauto dynamic_test = []() {\n    thrust::device_vector<int> x(5);\n\n    square_indices(x);\n\n    thrust::host_vector<int> expected {0, 1, 4, 9, 16};\n    thrust::host_vector<int> h_x(x);\n\n    for (std::size_t i = 0; i < x.size(); i++)\n    {\n        if (h_x[i] != expected[i])\n        {\n            std::cerr << \"Error at index \" << i << \": expected \" << expected[i] << \", got \"\n                      << h_x[i] << std::endl;\n            std::exit(1);\n        }\n    }\n};\n\nauto static_test = []() {\n    const char *path = std::getenv(\"COMPUTE_EVAL_SRC_FILE\");\n    if (path == nullptr)\n    {\n        std::cerr << \"Environment variable not found!\" << std::endl;\n        std::exit(1);\n    }\n\n    std::ifstream file(path);\n    if (!file.is_open())\n    {\n        std::cerr << \"File not found!\" << std::endl;\n        std::exit(1);\n    }\n\n    std::string line;\n\n    // Skip until the beginning of the completion block\n    while (std::getline(file, line))\n    {\n        if (line.find(\"completion-begin\") != std::string::npos &&\n            line.find(\"std::string::npos\") == std::string::npos)\n        {\n            break;\n        }\n    }\n\n    // Search for the thrust::tabulate call\n    bool found = false;\n    while (std::getline(file, line))\n    {\n        if (line.find(\"thrust::tabulate\") != std::string::npos)\n        {\n            found = true;\n            break;\n        }\n\n        if (line.find(\"completion-end\") != std::string::npos)\n        {\n            break;\n        }\n    }\n\n    if (!found)\n    {\n        std::cerr << \"Test failed!\" << std::endl;\n        std::exit(1);\n    }\n};\n\nstatic_test();\ndynamic_test();\n\n}\n", "example_test": "@example_test\n", "cuda_toolkit": "12.0"}
{"task_id": "CUDA/70", "date": "2025-03-31", "prompt": "Write a function `void stable_sort_pairs(const thrust::device_vector<thrust::pair<int, char>> &vec)`\nthat sorts the input vector on GPU in increasing order according to the first element of the pair by\nmaintaining the relative order of the elements using a single thrust algorithm.\n", "cc_flags": "-arch=sm_90a --extended-lambda -arch=sm_89 --extended-lambda -arch=sm_80 --extended-lambda -arch=sm_70 --extended-lambda -arch=sm_60 --extended-lambda", "ld_flags": "", "declaration": "#include <thrust/device_vector.h>\n#include <thrust/execution_policy.h>\n#include <thrust/host_vector.h>\n#include <thrust/pair.h>\n#include <thrust/sort.h>\n#include <thrust/tuple.h>\n#include <cstdlib>\n#include <fstream>\n#include <iostream>\n\nvoid stable_sort_pairs(const thrust::device_vector<thrust::pair<int, char>>& vec);\n\n", "test": "int main() {\n\nauto dynamic_test = []() {\n    thrust::device_vector<thrust::pair<int, char>> in = {{4, 'a'}, {1, 'b'}, {0, 'c'}, {1, 'd'}};\n\n    stable_sort_pairs(in);\n\n    thrust::host_vector<thrust::pair<int, char>> ref(in);\n    if (ref[0] != thrust::make_pair(0, 'c') || ref[1] != thrust::make_pair(1, 'b') ||\n        ref[2] != thrust::make_pair(1, 'd') || ref[3] != thrust::make_pair(4, 'a'))\n    {\n        std::cerr << \"Test failed!\" << std::endl;\n        std::exit(1);\n    }\n};\n\nauto static_test = []() {\n    const char* path = std::getenv(\"COMPUTE_EVAL_SRC_FILE\");\n    if (path == nullptr)\n    {\n        std::cerr << \"Environment variable not found!\" << std::endl;\n        std::exit(1);\n    }\n\n    std::ifstream file(path);\n    if (!file.is_open())\n    {\n        std::cerr << \"File not found!\" << std::endl;\n        std::exit(1);\n    }\n\n    std::string line;\n\n    // Skip until the beginning of the completion block\n    while (std::getline(file, line))\n    {\n        if (line.find(\"completion-begin\") != std::string::npos &&\n            line.find(\"std::string::npos\") == std::string::npos)\n        {\n            break;\n        }\n    }\n\n    // Search for the thrust::stable_sort call\n    bool found = false;\n    while (std::getline(file, line))\n    {\n        if (line.find(\"thrust::stable_sort\") != std::string::npos)\n        {\n            found = true;\n            break;\n        }\n\n        if (line.find(\"completion-end\") != std::string::npos)\n        {\n            break;\n        }\n    }\n\n    if (!found)\n    {\n        std::cerr << \"Test failed!\" << std::endl;\n        std::exit(1);\n    }\n};\n\nstatic_test();\ndynamic_test();\n\n}\n", "example_test": "@example_test\n", "cuda_toolkit": "12.0"}
{"task_id": "CUDA/71", "date": "2025-03-31", "prompt": "Write a function `bool is_divided(thrust::device_vector<int> const& vec1)` that accepts a device\nvector and checks whether it is divided properly such that all even numbers appear before all odd\nnumbers using a single thrust algorithm.\n", "cc_flags": "-arch=sm_90a --extended-lambda -arch=sm_89 --extended-lambda -arch=sm_80 --extended-lambda -arch=sm_70 --extended-lambda -arch=sm_60 --extended-lambda", "ld_flags": "", "declaration": "#include <thrust/device_vector.h>\n#include <thrust/partition.h>\n#include <cstdlib>\n#include <fstream>\n#include <iostream>\n\nbool is_divided(thrust::device_vector<int> const &vec1);\n\n", "test": "int main() {\n\nauto dynamic_test = []() {\n    thrust::device_vector<int> x {42, 0, 4, 2, 4, 1, 3};\n    if (is_divided(x) == false)\n    {\n        std::cerr << \"Error: is_divided failed, expected true!\" << std::endl;\n        std::exit(1);\n    }\n\n    x = {42, 0, 3, 2, 4, 1};\n    if (is_divided(x) == true)\n    {\n        std::cerr << \"Error: is_divided failed, expected false!\" << std::endl;\n        std::exit(1);\n    }\n};\n\nauto static_test = []() {\n    const char *path = std::getenv(\"COMPUTE_EVAL_SRC_FILE\");\n    if (path == nullptr)\n    {\n        std::cerr << \"Environment variable not found!\" << std::endl;\n        std::exit(1);\n    }\n\n    std::ifstream file(path);\n    if (!file.is_open())\n    {\n        std::cerr << \"File not found!\" << std::endl;\n        std::exit(1);\n    }\n\n    std::string line;\n\n    // Skip until the beginning of the completion block\n    while (std::getline(file, line))\n    {\n        if (line.find(\"completion-begin\") != std::string::npos &&\n            line.find(\"std::string::npos\") == std::string::npos)\n        {\n            break;\n        }\n    }\n\n    // Search for the thrust::is_partitioned call\n    bool found = false;\n    while (std::getline(file, line))\n    {\n        if (line.find(\"thrust::is_partitioned\") != std::string::npos)\n        {\n            found = true;\n            break;\n        }\n\n        if (line.find(\"completion-end\") != std::string::npos)\n        {\n            break;\n        }\n    }\n\n    if (!found)\n    {\n        std::cerr << \"Test failed!\" << std::endl;\n        std::exit(1);\n    }\n};\n\nstatic_test();\ndynamic_test();\n\n}\n", "example_test": "@example_test\n", "cuda_toolkit": "12.0"}
{"task_id": "CUDA/72", "date": "2025-03-31", "prompt": "Write a function `bool check_equality(thrust::device_vector<int>&\nvec1, thrust::device_vector<int>& vec2)` that checks whether two vectors are equal on device using a\nthrust algorithm.\n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_70 -arch=sm_60", "ld_flags": "", "declaration": "#include <thrust/device_vector.h>\n#include <thrust/equal.h>\n#include <cstdlib>\n#include <fstream>\n#include <iostream>\n\nbool check_equality(thrust::device_vector<int> &vec1, thrust::device_vector<int> &vec2);\n", "test": "int main() {\n\nauto dynamic_test = []() {\n    thrust::device_vector<int> vec1 {42, 0, 4, 2, 4};\n    thrust::device_vector<int> vec2 {42, 0, 4, 2, 4};\n\n    auto same = check_equality(vec1, vec2);\n\n    if (same != true)\n    {\n        std::cerr << \"Error: expected true, got false.\" << std::endl;\n        std::exit(1);\n    }\n\n    vec2 = {42, 0, 4, 2, 42};\n    same = check_equality(vec1, vec2);\n\n    if (same != false)\n    {\n        std::cerr << \"Error: expected false, got true.\" << std::endl;\n        std::exit(1);\n    }\n};\n\nauto static_test = []() {\n    const char *path = std::getenv(\"COMPUTE_EVAL_SRC_FILE\");\n    if (path == nullptr)\n    {\n        std::cerr << \"Environment variable not found!\" << std::endl;\n        std::exit(1);\n    }\n\n    std::ifstream file(path);\n    if (!file.is_open())\n    {\n        std::cerr << \"File not found!\" << std::endl;\n        std::exit(1);\n    }\n\n    std::string line;\n\n    // Skip until the beginning of the completion block\n    while (std::getline(file, line))\n    {\n        if (line.find(\"completion-begin\") != std::string::npos &&\n            line.find(\"std::string::npos\") == std::string::npos)\n        {\n            break;\n        }\n    }\n\n    // Search for the thrust::equal call\n    bool found = false;\n    while (std::getline(file, line))\n    {\n        if (line.find(\"thrust::equal\") != std::string::npos)\n        {\n            found = true;\n            break;\n        }\n\n        if (line.find(\"completion-end\") != std::string::npos)\n        {\n            break;\n        }\n    }\n\n    if (!found)\n    {\n        std::cerr << \"Test failed!\" << std::endl;\n        std::exit(1);\n    }\n};\n\nstatic_test();\ndynamic_test();\n\n}\n", "example_test": "@example_test\n", "cuda_toolkit": "12.0"}
{"task_id": "CUDA/73", "date": "2025-03-31", "prompt": "Write a function `bool is_arranged_in_order(const thrust::device_vector<int>& vec)` that checks if\ndevice input vector elements are in order using a thrust algorithm.\n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_70 -arch=sm_60", "ld_flags": "", "declaration": "#include <thrust/device_vector.h>\n#include <thrust/execution_policy.h>\n#include <thrust/sort.h>\n#include <cstdlib>\n#include <fstream>\n#include <iostream>\n\nbool is_arranged_in_order(const thrust::device_vector<int> &vec);\n\n", "test": "int main() {\n\nauto dynamic_test = []() {\n    const thrust::device_vector<int> in1 {3, 1, 4, 0};\n    bool check = is_arranged_in_order(in1);\n\n    if (check != false)\n    {\n        std::cerr << \"Test failed!\" << std::endl;\n        std::exit(1);\n    }\n\n    const thrust::device_vector<int> in2 = {1, 2, 3, 4};\n    check                                = is_arranged_in_order(in2);\n\n    if (check != true)\n    {\n        std::cerr << \"Test failed!\" << std::endl;\n        std::exit(1);\n    }\n};\n\nauto static_test = []() {\n    const char *path = std::getenv(\"COMPUTE_EVAL_SRC_FILE\");\n    if (path == nullptr)\n    {\n        std::cerr << \"Environment variable not found!\" << std::endl;\n        std::exit(1);\n    }\n\n    std::ifstream file(path);\n    if (!file.is_open())\n    {\n        std::cerr << \"File not found!\" << std::endl;\n        std::exit(1);\n    }\n\n    std::string line;\n\n    // Skip until the beginning of the completion block\n    while (std::getline(file, line))\n    {\n        if (line.find(\"completion-begin\") != std::string::npos &&\n            line.find(\"std::string::npos\") == std::string::npos)\n        {\n            break;\n        }\n    }\n\n    // Search for the thrust::is_sorted call\n    bool found = false;\n    while (std::getline(file, line))\n    {\n        if (line.find(\"thrust::is_sorted\") != std::string::npos)\n        {\n            found = true;\n            break;\n        }\n\n        if (line.find(\"completion-end\") != std::string::npos)\n        {\n            break;\n        }\n    }\n\n    if (!found)\n    {\n        std::cerr << \"Test failed!\" << std::endl;\n        std::exit(1);\n    }\n};\n\nstatic_test();\ndynamic_test();\n\n}\n", "example_test": "@example_test\n", "cuda_toolkit": "12.0"}
{"task_id": "CUDA/74", "date": "2025-03-31", "prompt": "Write a function `thrust::device_vector<int> vector_difference(thrust::device_vector<int> const&\nvec1, thrust::device_vector<int> const& vec2)` that removes all the elements of the sorted vector\nvec2 from the sorted vector vec1 using one thrust algorithm. Returns the difference vector as a\nresult.\n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_70 -arch=sm_60", "ld_flags": "", "declaration": "#include <thrust/device_vector.h>\n#include <thrust/set_operations.h>\n#include <cstdlib>\n#include <fstream>\n#include <iostream>\n\nthrust::device_vector<int> vector_difference(thrust::device_vector<int> const &vec1,\n                                             thrust::device_vector<int> const &vec2);\n", "test": "int main() {\n\nauto dynamic_test = []() {\n    thrust::device_vector<int> v1 {1, 2, 2, 2, 3, 10};\n    thrust::device_vector<int> v2 {-10, 0, 2, 2, 5, 10};\n\n    auto result = vector_difference(v1, v2);\n\n    thrust::device_vector<int> expected {1, 2, 3};\n\n    for (int i = 0; i < result.size(); i++)\n    {\n        if (result[i] != expected[i])\n        {\n            std::cerr << \"Error: error at index \" << i << \" got \" << result[i] << \" expected \"\n                      << expected[i] << std::endl;\n            std::exit(1);\n        }\n    }\n};\n\nauto static_test = []() {\n    const char *path = std::getenv(\"COMPUTE_EVAL_SRC_FILE\");\n    if (path == nullptr)\n    {\n        std::cerr << \"Environment variable not found!\" << std::endl;\n        std::exit(1);\n    }\n\n    std::ifstream file(path);\n    if (!file.is_open())\n    {\n        std::cerr << \"File not found!\" << std::endl;\n        std::exit(1);\n    }\n\n    std::string line;\n\n    // Skip until the beginning of the completion block\n    while (std::getline(file, line))\n    {\n        if (line.find(\"completion-begin\") != std::string::npos &&\n            line.find(\"std::string::npos\") == std::string::npos)\n        {\n            break;\n        }\n    }\n\n    // Search for the thrust::set_difference call\n    bool found = false;\n    while (std::getline(file, line))\n    {\n        if (line.find(\"thrust::set_difference\") != std::string::npos)\n        {\n            found = true;\n            break;\n        }\n\n        if (line.find(\"completion-end\") != std::string::npos)\n        {\n            break;\n        }\n    }\n\n    if (!found)\n    {\n        std::cerr << \"Test failed!\" << std::endl;\n        std::exit(1);\n    }\n};\n\nstatic_test();\ndynamic_test();\n\n}\n", "example_test": "@example_test\n", "cuda_toolkit": "12.0"}
{"task_id": "CUDA/75", "date": "2025-03-31", "prompt": "Write a function `int how_many_threes(thrust::device_vector<int> const& vec)` that counts how many\noccurances of the number three are there in the input vector using a thrust algorithm.\n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_70 -arch=sm_60", "ld_flags": "", "declaration": "#include <thrust/count.h>\n#include <thrust/device_vector.h>\n#include <cstdlib>\n#include <fstream>\n#include <iostream>\n\nint how_many_threes(thrust::device_vector<int> const &vec);\n\n", "test": "int main() {\n\nauto dynamic_test = []() {\n    thrust::device_vector<int> x {1, 3, 2, 10, 3};\n\n    int threes = how_many_threes(x);\n\n    if (threes != 2)\n    {\n        std::cerr << \"Error: expected 2, got \" << threes << std::endl;\n        std::exit(1);\n    }\n};\n\nauto static_test = []() {\n    const char *path = std::getenv(\"COMPUTE_EVAL_SRC_FILE\");\n    if (path == nullptr)\n    {\n        std::cerr << \"Environment variable not found!\" << std::endl;\n        std::exit(1);\n    }\n\n    std::ifstream file(path);\n    if (!file.is_open())\n    {\n        std::cerr << \"File not found!\" << std::endl;\n        std::exit(1);\n    }\n\n    std::string line;\n\n    // Skip until the beginning of the completion block\n    while (std::getline(file, line))\n    {\n        if (line.find(\"completion-begin\") != std::string::npos &&\n            line.find(\"std::string::npos\") == std::string::npos)\n        {\n            break;\n        }\n    }\n\n    // Search for the thrust::count call\n    bool found = false;\n    while (std::getline(file, line))\n    {\n        if (line.find(\"thrust::count\") != std::string::npos)\n        {\n            found = true;\n            break;\n        }\n\n        if (line.find(\"completion-end\") != std::string::npos)\n        {\n            break;\n        }\n    }\n\n    if (!found)\n    {\n        std::cerr << \"Test failed!\" << std::endl;\n        std::exit(1);\n    }\n};\n\nstatic_test();\ndynamic_test();\n\n}\n", "example_test": "@example_test\n", "cuda_toolkit": "12.0"}
{"task_id": "CUDA/76", "date": "2025-03-31", "prompt": "Write a function `int how_many_negatives(thrust::device_vector<int> const& vec)` that counts how\nmany negative numbers are there in the input vector using a thrust algorithm.\n", "cc_flags": "-arch=sm_90a --extended-lambda -arch=sm_89 --extended-lambda -arch=sm_80 --extended-lambda -arch=sm_70 --extended-lambda -arch=sm_60 --extended-lambda", "ld_flags": "", "declaration": "#include <thrust/count.h>\n#include <thrust/device_vector.h>\n#include <cstdlib>\n#include <fstream>\n#include <iostream>\n\nint how_many_negatives(thrust::device_vector<int> const &vec);\n\n", "test": "int main() {\n\nauto dynamic_test = []() {\n    thrust::device_vector<int> x {1, 3, -2, -10, 0};\n\n    int neatives = how_many_negatives(x);\n\n    if (neatives != 2)\n    {\n        std::cerr << \"Error: expected 2, got \" << neatives << std::endl;\n        std::exit(1);\n    }\n};\n\nauto static_test = []() {\n    const char *path = std::getenv(\"COMPUTE_EVAL_SRC_FILE\");\n    if (path == nullptr)\n    {\n        std::cerr << \"Environment variable not found!\" << std::endl;\n        std::exit(1);\n    }\n\n    std::ifstream file(path);\n    if (!file.is_open())\n    {\n        std::cerr << \"File not found!\" << std::endl;\n        std::exit(1);\n    }\n\n    std::string line;\n\n    // Skip until the beginning of the completion block\n    while (std::getline(file, line))\n    {\n        if (line.find(\"completion-begin\") != std::string::npos &&\n            line.find(\"std::string::npos\") == std::string::npos)\n        {\n            break;\n        }\n    }\n\n    // Search for the thrust::count_if call\n    bool found = false;\n    while (std::getline(file, line))\n    {\n        if (line.find(\"thrust::count_if\") != std::string::npos)\n        {\n            found = true;\n            break;\n        }\n\n        if (line.find(\"completion-end\") != std::string::npos)\n        {\n            break;\n        }\n    }\n\n    if (!found)\n    {\n        std::cerr << \"Test failed!\" << std::endl;\n        std::exit(1);\n    }\n};\n\nstatic_test();\ndynamic_test();\n\n}\n", "example_test": "@example_test\n", "cuda_toolkit": "12.0"}
{"task_id": "CUDA/77", "date": "2025-03-31", "prompt": "Write a function `void copy_first_n(const thrust::device_vector<int>& src,\nthrust::device_vector<int>& dst, int n)` that copies the first n elements of a src vector in GPU to\na dst vector in GPU using a thrust algorithm that efficiently transfers a specific number of\nelements. The function should utilize an appropriate thrust method for copying a fixed number of\nelements.\n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_70 -arch=sm_60", "ld_flags": "", "declaration": "#include <thrust/copy.h>\n#include <thrust/device_vector.h>\n#include <cstdlib>\n#include <fstream>\n#include <iostream>\n\nvoid copy_first_n(const thrust::device_vector<int> &src, thrust::device_vector<int> &dst, int n);\n\n", "test": "int main() {\nauto dynamic_test = []() {\n    thrust::device_vector<int> x {0, 1, 2, 3, 4};\n    thrust::device_vector<int> y(2);\n    copy_first_n(x, y, 2);\n\n    thrust::device_vector<int> expected {0, 1};\n\n    for (std::size_t i = 0; i < y.size(); i++)\n    {\n        if (y[i] != expected[i])\n        {\n            std::cerr << \"Test failed!\" << std::endl;\n            std::exit(1);\n        }\n    }\n};\n\nauto static_test = []() {\n    const char *path = std::getenv(\"COMPUTE_EVAL_SRC_FILE\");\n    if (path == nullptr)\n    {\n        std::cerr << \"Environment variable not found!\" << std::endl;\n        std::exit(1);\n    }\n\n    std::ifstream file(path);\n    if (!file.is_open())\n    {\n        std::cerr << \"File not found!\" << std::endl;\n        std::exit(1);\n    }\n\n    std::string line;\n\n    // Skip until the beginning of the completion block\n    while (std::getline(file, line))\n    {\n        if (line.find(\"completion-begin\") != std::string::npos &&\n            line.find(\"std::string::npos\") == std::string::npos)\n        {\n            break;\n        }\n    }\n\n    // Search for the thrust::copy_n call\n    bool found = false;\n    while (std::getline(file, line))\n    {\n        if (line.find(\"thrust::copy_n\") != std::string::npos)\n        {\n            found = true;\n            break;\n        }\n\n        if (line.find(\"completion-end\") != std::string::npos)\n        {\n            break;\n        }\n    }\n\n    if (!found)\n    {\n        std::cerr << \"Test failed!\" << std::endl;\n        std::exit(1);\n    }\n};\n\nstatic_test();\ndynamic_test();\n\n}\n", "example_test": "@example_test\n", "cuda_toolkit": "12.0"}
{"task_id": "CUDA/78", "date": "2025-03-31", "prompt": "Write a function `bool all_positives(thrust::device_vector<int> const& vec)` that checks whether\nall values in a vector are positive using a Thrust algorithm.\n", "cc_flags": "-arch=sm_90a --extended-lambda -arch=sm_89 --extended-lambda -arch=sm_80 --extended-lambda -arch=sm_70 --extended-lambda -arch=sm_60 --extended-lambda", "ld_flags": "", "declaration": "#include <thrust/device_vector.h>\n#include <thrust/logical.h>\n#include <cstdlib>\n#include <fstream>\n#include <iostream>\n\nbool all_positives(thrust::device_vector<int> const &vec);\n\n", "test": "int main() {\n\nauto dynamic_test = []() {\n    thrust::device_vector<int> x {1, 6, 2, 10};\n\n    auto check = all_positives(x);\n\n    if (check != true)\n    {\n        std::cerr << \"Error: expected true, got \" << check << std::endl;\n        std::exit(1);\n    }\n\n    x     = {-1, 2, 2, 5};\n    check = all_positives(x);\n\n    if (check != false)\n    {\n        std::cerr << \"Error: expected false, got \" << check << std::endl;\n        std::exit(1);\n    }\n\n    x     = {1, 2, 0, 5};\n    check = all_positives(x);\n\n    if (check != false)\n    {\n        std::cerr << \"Error: expected false, got \" << check << std::endl;\n        std::exit(1);\n    }\n};\n\nauto static_test = []() {\n    const char *path = std::getenv(\"COMPUTE_EVAL_SRC_FILE\");\n    if (path == nullptr)\n    {\n        std::cerr << \"Environment variable not found!\" << std::endl;\n        std::exit(1);\n    }\n\n    std::ifstream file(path);\n    if (!file.is_open())\n    {\n        std::cerr << \"File not found!\" << std::endl;\n        std::exit(1);\n    }\n\n    std::string line;\n\n    // Skip until the beginning of the completion block\n    while (std::getline(file, line))\n    {\n        if (line.find(\"completion-begin\") != std::string::npos &&\n            line.find(\"std::string::npos\") == std::string::npos)\n        {\n            break;\n        }\n    }\n\n    // Search for the thrust::all_of call\n    bool found = false;\n    while (std::getline(file, line))\n    {\n        if (line.find(\"thrust::all_of\") != std::string::npos)\n        {\n            found = true;\n            break;\n        }\n\n        if (line.find(\"completion-end\") != std::string::npos)\n        {\n            break;\n        }\n    }\n\n    if (!found)\n    {\n        std::cerr << \"Test failed!\" << std::endl;\n        std::exit(1);\n    }\n};\n\nstatic_test();\ndynamic_test();\n\n}\n", "example_test": "@example_test\n", "cuda_toolkit": "12.0"}
{"task_id": "CUDA/79", "date": "2025-03-31", "prompt": "Write a function `void mix_and_scramble(thrust::device_vector<int>& vec)` that\ntakes an input vector and reorders the elements in a random way using one thrust algorithm.\n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_70 -arch=sm_60", "ld_flags": "", "declaration": "#include <thrust/device_vector.h>\n#include <thrust/shuffle.h>\n#include <thrust/sort.h>\n#include <cstdlib>\n#include <fstream>\n#include <iostream>\n\nvoid mix_and_scramble(thrust::device_vector<int> &vec);\n\n", "test": "int main() {\n\nauto dynamic_test = []() {\n    thrust::device_vector<int> x {1, 2, 3, 4, 5};\n    thrust::device_vector<int> ref {1, 2, 3, 4, 5};\n\n    mix_and_scramble(x);\n\n    if (x == ref)\n    {\n        std::cerr << \"Error: result vector is the same before and after shuffle!\" << std::endl;\n        std::exit(1);\n    }\n\n    thrust::sort(x.begin(), x.end());\n\n    if (x != ref)\n    {\n        std::cerr << \"Error: elements are not the same as the original.\" << std::endl;\n        std::exit(1);\n    }\n};\n\nauto static_test = []() {\n    const char *path = std::getenv(\"COMPUTE_EVAL_SRC_FILE\");\n    if (path == nullptr)\n    {\n        std::cerr << \"Environment variable not found!\" << std::endl;\n        std::exit(1);\n    }\n\n    std::ifstream file(path);\n    if (!file.is_open())\n    {\n        std::cerr << \"File not found!\" << std::endl;\n        std::exit(1);\n    }\n\n    std::string line;\n\n    // Skip until the beginning of the completion block\n    while (std::getline(file, line))\n    {\n        if (line.find(\"completion-begin\") != std::string::npos &&\n            line.find(\"std::string::npos\") == std::string::npos)\n        {\n            break;\n        }\n    }\n\n    // Search for the thrust::shuffle call\n    bool found = false;\n    while (std::getline(file, line))\n    {\n        if (line.find(\"thrust::shuffle\") != std::string::npos)\n        {\n            found = true;\n            break;\n        }\n\n        if (line.find(\"completion-end\") != std::string::npos)\n        {\n            break;\n        }\n    }\n\n    if (!found)\n    {\n        std::cerr << \"Test failed!\" << std::endl;\n        std::exit(1);\n    }\n};\n\nstatic_test();\ndynamic_test();\n\n}\n", "example_test": "@example_test\n", "cuda_toolkit": "12.0"}
{"task_id": "CUDA/80", "date": "2025-03-31", "prompt": "Write a CUDA kernel to compute the dot product of two vectors using shared memory.\n \nThe signature of the function is __global__ void k_dotProduct(const int *inputVectorA, const int *inputVectorB, int *resultDotProduct, const int n).\n\n>>> k_dotProduct({1, 2, 3, 4}, {1, 0, 0, 1}, resultDotProduct, 4) -> resultDotProduct: 5\n>>> k_dotProduct({1, 2, 3, 4, 5, 6, 7, 8, 9}, {1, 0, 0, 1, 0, 0, 1, 0, 0}, resultDotProduct, 9) -> resultDotProduct: 12 \n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_70 -arch=sm_60", "ld_flags": "", "declaration": "#include <cuda_runtime.h>\n#include <algorithm>\n#include <cstdio>\n#define CUDA_CHECK(call)                                        \\\ndo {                                                            \\\n        cudaError_t error = call;                               \\\n        if (error != cudaSuccess) {                             \\\n            fprintf(stderr, \"CUDA error at %s:%d - %s\\n\",       \\\n                    __FILE__, __LINE__,                         \\\n                    cudaGetErrorString(error));                 \\\n            exit(EXIT_FAILURE);                                 \\\n        }                                                       \\\n} while(0)\n#undef NDEBUG\n#include <assert.h>\n\n__global__ void k_dotProduct(const int *inputVectorA, const int *inputVectorB, int *resultDotProduct, const int n);\n\nvoid launch() {\n    const int testCaseCount = 9; // Number of test cases\n    int vectorSize[testCaseCount] = {4, 4, 4, 4, 4, 4, 10, 4, 9}; // Sizes of the vectors in each test case\n    const int expectedDotProduct[testCaseCount] = {20, 10,  70, 100, 30, 140, 10, 5, 12}; // Expected results for each test\n    const int maxVectorSize = *std::max_element(vectorSize, vectorSize + testCaseCount);\n    const int BLOCK_SIZE = 512; // number of threads per block\n\n    // Input vectors for the tests\n    int inputVectorA_h[testCaseCount][maxVectorSize] =  {\n        {2, 4, 6, 8},                   // test case 1\n        {1, 3, 5, 7},                   // test case 2\n        {9, 8, 7, 6},                   // test case 3\n        {5, 10, 15, 20},                // test case 4\n        {3, 6, 9, 12},                  // test case 5\n        {7, 14, 21, 28},                // test case 6\n        {1, 1, 1, 1, 1, 1, 1, 1, 1, 1}, // test case 7\n        {1, 2, 3, 4},                   // test case 8\n        {1, 2, 3, 4, 5, 6, 7, 8, 9}};   // test case 9\n\n    int inputVectorB_h[testCaseCount][maxVectorSize] =  {\n        {1, 1, 1, 1},                   // test case 1\n        {0, 1, 0, 1},                   // test case 2\n        {1, 2, 3, 4},                   // test case 3\n        {2, 2, 2, 2},                   // test case 4\n        {3, 2, 1, 0},                   // test case 5\n        {4, 3, 2, 1},                   // test case 6\n        {1, 1, 1, 1, 1, 1, 1, 1, 1, 1}, // test case 7\n        {1, 0, 0, 1},                   // test case 8\n        {1, 0, 0, 1, 0, 0, 1, 0, 0}};   // test case 9\n\n    // Use a CUDA stream for asynchronous operations\n    cudaStream_t stream;\n    CUDA_CHECK(cudaStreamCreate(&stream));\n\n    int dotProduct_h = 0; // result on the host\n    int *inputVectorA_d, *inputVectorB_d, *dotProduct_d;  // Pointers for device memory (GPU)\n\n    // Allocate the memory on the device\n    CUDA_CHECK(cudaMallocAsync(&inputVectorA_d, maxVectorSize * sizeof(int), stream));\n    CUDA_CHECK(cudaMallocAsync(&inputVectorB_d, maxVectorSize * sizeof(int), stream));\n    CUDA_CHECK(cudaMallocAsync(&dotProduct_d, sizeof(int), stream));\n\n    // Loop to execute each test case\n    for (int i = 0; i < testCaseCount; ++i) {\n        // Copy input data to the device\n        CUDA_CHECK(cudaMemcpyAsync(inputVectorA_d, inputVectorA_h[i], vectorSize[i] * sizeof(int), cudaMemcpyHostToDevice, stream));\n        CUDA_CHECK(cudaMemcpyAsync(inputVectorB_d, inputVectorB_h[i], vectorSize[i] * sizeof(int), cudaMemcpyHostToDevice, stream));\n        CUDA_CHECK(cudaMemsetAsync(dotProduct_d, 0, sizeof(int), stream));  // Initialize the result on the device\n\n        // Determine the number of threads and blocks\n        int blocks  = (vectorSize[i] + BLOCK_SIZE - 1) / BLOCK_SIZE;\n\n        // Execute the kernel\n        // Grid:  (ceil(N/ 512), 1, 1) \n        // Block: (512, 1, 1)\n        void *args[] = {&inputVectorA_d, &inputVectorB_d, &dotProduct_d, &vectorSize[i]};\n        CUDA_CHECK(cudaLaunchKernel((void*)k_dotProduct, blocks, BLOCK_SIZE, args, BLOCK_SIZE * sizeof(int), stream));\n\n        // Copy the result back to the host (CPU)\n        CUDA_CHECK(cudaMemcpyAsync(&dotProduct_h, dotProduct_d, sizeof(int), cudaMemcpyDeviceToHost, stream));\n\n        // Check tasks in the stream has completed\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n\n        // Verify if the calculated dot product matches the expected result\n        assert(dotProduct_h == expectedDotProduct[i]);\n    }\n\n    // Clean up\n    CUDA_CHECK(cudaFreeAsync(inputVectorA_d, stream));\n    CUDA_CHECK(cudaFreeAsync(inputVectorB_d, stream));\n    CUDA_CHECK(cudaFreeAsync(dotProduct_d, stream));\n    CUDA_CHECK(cudaStreamDestroy(stream));    \n}\n\n__global__ void k_dotProduct(const int *inputVectorA, const int *inputVectorB, int *resultDotProduct, const int n) {\n", "test": "int main() {\n    launch();\n}\n", "example_test": "    @example_test\n", "cuda_toolkit": "12.2"}
{"task_id": "CUDA/81", "date": "2025-03-31", "prompt": "Write a CUDA kernel to transpose a NxN square matrix in-place using statically allocated shared memory. Assume that the block size is pre-defined as a constant BLOCK_SIZE. The signature of the function is __global__ void k_transposeMatrix(int* matrix, const int height, const int width).\n\nThe matrix transpose needs to be computed in-place without creating a copy of the original matrix.\n\n>>> k_transposeMatrix({{1, 2, 3}, {4, 5, 6}, {7, 8, 9}}, 3, 3) -> {{1, 4, 7}, {2, 5, 8}, {3, 6, 9}}\n>>> k_transposeMatrix({{1, 2}, {3, 4}}, 2, 2) -> {{1, 3}, {2, 4}}\n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_70 -arch=sm_60", "ld_flags": "", "declaration": "#include <cuda_runtime.h>\n#include <cstdio>\n#define CUDA_CHECK(call)                                        \\\ndo {                                                            \\\n        cudaError_t error = call;                               \\\n        if (error != cudaSuccess) {                             \\\n            fprintf(stderr, \"CUDA error at %s:%d - %s\\n\",       \\\n                    __FILE__, __LINE__,                         \\\n                    cudaGetErrorString(error));                 \\\n            exit(EXIT_FAILURE);                                 \\\n        }                                                       \\\n} while(0)\n\nconst int BLOCK_SIZE = 16;\nconst int TILE_DIM = 4;\n\n#undef NDEBUG\n#include <assert.h>\n\n__global__ void k_transposeMatrix(int* matrix, const int height, const int width);\n\nvoid launch() {\n    int *matrix_d;\n    int *d_transpose_matrix;\n\n    // Use a CUDA stream for asynchronous operations\n    cudaStream_t stream;\n    CUDA_CHECK(cudaStreamCreate(&stream));\n    CUDA_CHECK(cudaMallocAsync(&matrix_d, TILE_DIM * TILE_DIM * sizeof(int), stream));\n    CUDA_CHECK(cudaMallocAsync(&d_transpose_matrix, TILE_DIM * TILE_DIM * sizeof(int), stream));\n\n    // Test 1 - 3x3 matrix\n    {\n        int height = 3;\n        int width = 3;\n        int matrix_h[height * width] = {1, 2, 3, 4, 5, 6, 7, 8, 9};\n        int transposeMatrix_h[height * width] = {0};\n        int expectedOutput[height * width] = {1, 4, 7, 2, 5, 8, 3, 6, 9};\n\n        CUDA_CHECK(cudaMemcpyAsync(matrix_d, matrix_h, height * width * sizeof(int), cudaMemcpyHostToDevice, stream));\n\n        dim3 dimBlock(BLOCK_SIZE, BLOCK_SIZE);\n        dim3 dimGrid((height + BLOCK_SIZE - 1)/BLOCK_SIZE, (width + BLOCK_SIZE - 1)/BLOCK_SIZE);\n\n        void *args[] = {&matrix_d, &height, &width};\n        CUDA_CHECK(cudaLaunchKernel((void*)k_transposeMatrix, dimGrid, dimBlock, args, TILE_DIM * TILE_DIM * sizeof(int), stream));\n\n        CUDA_CHECK(cudaMemcpyAsync(transposeMatrix_h, matrix_d, height * width * sizeof(int), cudaMemcpyDeviceToHost, stream));\n\n        // Check tasks in the stream has completed\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n\n        for (int i=0; i < height * width; i++) {\n            assert(transposeMatrix_h[i] == expectedOutput[i]);\n        }\n    }\n\n    // Test 2 - 4x4 matrix\n    {\n        int height = 4;\n        int width = 4;\n        int matrix_h[height * width] = {1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16};\n        int transposeMatrix_h[height * width] = {0};\n        int expectedOutput[height * width] = {1, 5, 9, 13, 2, 6, 10, 14, 3, 7, 11, 15, 4, 8, 12, 16};\n\n        CUDA_CHECK(cudaMemcpyAsync(matrix_d, matrix_h, height * width * sizeof(int), cudaMemcpyHostToDevice, stream));\n\n        dim3 dimBlock(BLOCK_SIZE, BLOCK_SIZE);\n        dim3 dimGrid((height + BLOCK_SIZE - 1)/BLOCK_SIZE, (width + BLOCK_SIZE - 1)/BLOCK_SIZE);\n\n        void *args[] = {&matrix_d, &height, &width};\n        CUDA_CHECK(cudaLaunchKernel((void*)k_transposeMatrix, dimGrid, dimBlock, args, TILE_DIM * TILE_DIM * sizeof(int), stream));\n\n        CUDA_CHECK(cudaMemcpyAsync(transposeMatrix_h, matrix_d, height * width * sizeof(int), cudaMemcpyDeviceToHost, stream));\n\n        // Check tasks in the stream has completed\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n\n        for (int i=0; i < height * width; i++) {\n            assert(transposeMatrix_h[i] == expectedOutput[i]);\n        }\n    }\n\n    // Test 3 - 3x3 matrix\n    {\n        int height = 3;\n        int width = 3;\n        int matrix_h[height * width] = {1, 2, 3, 4, 5, 6, 7, 8, 9};\n        int transposeMatrix_h[height * width] = {0};\n        int expectedOutput[height * width] = {1, 4, 7, 2, 5, 8, 3, 6, 9};\n\n        CUDA_CHECK(cudaMemcpyAsync(matrix_d, matrix_h, height * width * sizeof(int), cudaMemcpyHostToDevice, stream));\n\n        dim3 dimBlock(BLOCK_SIZE, BLOCK_SIZE);\n        dim3 dimGrid((height + BLOCK_SIZE - 1)/BLOCK_SIZE, (width + BLOCK_SIZE - 1)/BLOCK_SIZE);\n\n        void *args[] = {&matrix_d, &height, &width};\n        CUDA_CHECK(cudaLaunchKernel((void*)k_transposeMatrix, dimGrid, dimBlock, args, TILE_DIM * TILE_DIM * sizeof(int), stream));\n\n        CUDA_CHECK(cudaMemcpyAsync(transposeMatrix_h, matrix_d, height * width * sizeof(int), cudaMemcpyDeviceToHost, stream));\n\n        // Check tasks in the stream has completed\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n\n        for (int i=0; i < height * width; i++) {\n            assert(transposeMatrix_h[i] == expectedOutput[i]);\n        }\n    }\n\n    // Test 4 - 2x2 matrix\n    {\n        int height = 2;\n        int width = 2;\n        int matrix_h[height * width] = {1, 2, 3, 4};\n        int transposeMatrix_h[height * width] = {0};\n        int expectedOutput[height * width] = {1, 3, 2, 4};\n\n        CUDA_CHECK(cudaMemcpyAsync(matrix_d, matrix_h, height * width * sizeof(int), cudaMemcpyHostToDevice, stream));\n\n        dim3 dimBlock(BLOCK_SIZE, BLOCK_SIZE);\n        dim3 dimGrid((height + BLOCK_SIZE - 1)/BLOCK_SIZE, (width + BLOCK_SIZE - 1)/BLOCK_SIZE);\n\n        void *args[] = {&matrix_d, &height, &width};\n        CUDA_CHECK(cudaLaunchKernel((void*)k_transposeMatrix, dimGrid, dimBlock, args, TILE_DIM * TILE_DIM * sizeof(int), stream));\n\n        CUDA_CHECK(cudaMemcpyAsync(transposeMatrix_h, matrix_d, height * width * sizeof(int), cudaMemcpyDeviceToHost, stream));\n\n        // Check tasks in the stream has completed\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n\n        for (int i=0; i < height * width; i++) {\n            assert(transposeMatrix_h[i] == expectedOutput[i]);\n        }\n    }\n\n    // Test 5 - 1x1 matrix\n    {\n        int height = 1;\n        int width = 1;\n        int matrix_h[height * width] = {1};\n        int transposeMatrix_h[height * width] = {0};\n        int expectedOutput[height * width] = {1};\n\n        CUDA_CHECK(cudaMemcpyAsync(matrix_d, matrix_h, height * width * sizeof(int), cudaMemcpyHostToDevice, stream));\n\n        dim3 dimBlock(BLOCK_SIZE, BLOCK_SIZE);\n        dim3 dimGrid((height + BLOCK_SIZE - 1)/BLOCK_SIZE, (width + BLOCK_SIZE - 1)/BLOCK_SIZE);\n\n        void *args[] = {&matrix_d, &height, &width};\n        CUDA_CHECK(cudaLaunchKernel((void*)k_transposeMatrix, dimGrid, dimBlock, args, TILE_DIM * TILE_DIM * sizeof(int), stream));\n\n        CUDA_CHECK(cudaMemcpyAsync(transposeMatrix_h, matrix_d, height * width * sizeof(int), cudaMemcpyDeviceToHost, stream));\n\n        // Check tasks in the stream has completed\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n\n        for (int i=0; i < height * width; i++) {\n            assert(transposeMatrix_h[i] == expectedOutput[i]);\n        }\n    }\n\n    // Test 6 - 9x9 matrix\n    {\n        int height = 3;\n        int width = 3;\n        int matrix_h[height * width] = {0, 0, 0, 0, 0, 0, 0, 0, 0};\n        int transposeMatrix_h[height * width] = {0};\n        int expectedOutput[height * width] = {0, 0, 0, 0, 0, 0, 0, 0, 0};\n\n        CUDA_CHECK(cudaMemcpyAsync(matrix_d, matrix_h, height * width * sizeof(int), cudaMemcpyHostToDevice, stream));\n\n        dim3 dimBlock(BLOCK_SIZE, BLOCK_SIZE);\n        dim3 dimGrid((height + BLOCK_SIZE - 1)/BLOCK_SIZE, (width + BLOCK_SIZE - 1)/BLOCK_SIZE);\n\n        void *args[] = {&matrix_d, &height, &width};\n        CUDA_CHECK(cudaLaunchKernel((void*)k_transposeMatrix, dimGrid, dimBlock, args, TILE_DIM * TILE_DIM * sizeof(int), stream));\n\n        CUDA_CHECK(cudaMemcpyAsync(transposeMatrix_h, matrix_d, height * width * sizeof(int), cudaMemcpyDeviceToHost, stream));\n\n        // Check tasks in the stream has completed\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n\n        for (int i=0; i < height * width; i++) {\n            assert(transposeMatrix_h[i] == expectedOutput[i]);\n        }\n    }\n\n    // Test 7 - 16x16 matrix\n    {\n        int height = 2;\n        int width = 2;\n        int matrix_h[height * width] = {1, 1, 1, 1};\n        int transposeMatrix_h[height * width] = {0};\n        int expectedOutput[height * width] = {1, 1, 1, 1};\n\n        CUDA_CHECK(cudaMemcpyAsync(matrix_d, matrix_h, height * width * sizeof(int), cudaMemcpyHostToDevice, stream));\n\n        dim3 dimBlock(BLOCK_SIZE, BLOCK_SIZE);\n        dim3 dimGrid((height + BLOCK_SIZE - 1)/BLOCK_SIZE, (width + BLOCK_SIZE - 1)/BLOCK_SIZE);\n\n        void *args[] = {&matrix_d, &height, &width};\n        CUDA_CHECK(cudaLaunchKernel((void*)k_transposeMatrix, dimGrid, dimBlock, args, TILE_DIM * TILE_DIM * sizeof(int), stream));\n\n        CUDA_CHECK(cudaMemcpyAsync(transposeMatrix_h, matrix_d, height * width * sizeof(int), cudaMemcpyDeviceToHost, stream));\n\n        // Check tasks in the stream has completed\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n\n        for (int i=0; i < height * width; i++) {\n            assert(transposeMatrix_h[i] == expectedOutput[i]);\n        }\n    }\n\n    // Clean up\n    CUDA_CHECK(cudaFreeAsync(matrix_d, stream));\n    CUDA_CHECK(cudaFreeAsync(d_transpose_matrix, stream));\n    CUDA_CHECK(cudaStreamDestroy(stream));\n}\n\n__global__ void k_transposeMatrix(int* matrix, const int height, const int width) {\n", "test": "int main() {\n    launch();\n}\n", "example_test": "    @example_test\n", "cuda_toolkit": "12.2"}
{"task_id": "CUDA/82", "date": "2025-03-31", "prompt": "Write a CUDA kernel to find minimum and maximum values in a vector. The kernel needs to use warp shuffles, reductions and atomics in finding minimum and maximum values in the vector.\n\nThe signature of the kernel is __global__ void k_findMinMax(int* data, int* minResult, int* maxResult, int n).\n\n>>> k_findMinMax({2, 1, 5, 4}) -> min: 1 and max: 5\n>>> k_findMinMax({9, 3, 3, 5, 2, 8, 3, 10, 21}) -> min: 2 and max: 21 \n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_70 -arch=sm_60", "ld_flags": "", "declaration": "#include <iostream>\n#include <limits.h>\n#include <cuda_runtime.h>\n#include <algorithm>\n#define CUDA_CHECK(call)                                                 \\\ndo {                                                                     \\\n    cudaError_t error = call;                                           \\\n    if (error != cudaSuccess) {                                         \\\n        fprintf(stderr, \"CUDA error at %s:%d - %s\\n\", __FILE__, __LINE__, cudaGetErrorString(error)); \\\n        exit(EXIT_FAILURE);                                             \\\n    }                                                                   \\\n} while (0)\n// Kernel to find both the minimum and maximum values in a vector\n#undef NDEBUG\n#include <assert.h>\n\n__global__ void k_findMinMax(int* data, int* minResult, int* maxResult, int n);\n\nint launch() {\n    const int testCaseCount = 7; // Number of test cases\n    const int vectorSize[testCaseCount] = {4, 4, 8, 16, 32, 64, 100}; // Sizes of the vectors in each test case\n    const int expectedMin[testCaseCount] = {1, 3, 0, 1, 1, 1, 1}; // Expected results for each test\n    const int expectedMax[testCaseCount] = {8, 9, 11, 20, 99, 99, 100}; // Expected results for each test\n    int maxVectorSize = *std::max_element(vectorSize, vectorSize + testCaseCount);\n\n    // Input vectors for the tests\n    int inputVector[testCaseCount][maxVectorSize] =  {   \n        {2, 5, 1, 8},                                                     // test case 1\n        {3, 9, 5, 7},                                                     // test case 2\n        {9, 11, 6, 9, 0, 8, 7, 6},                                        // test case 3\n        {2, 5, 1, 8, 5, 10, 15, 20, 3, 9, 5, 7, 3, 9, 10, 12},            // test case 4\n        {32, 4, 98, 7, 18, 15, 3, 8, 99, 12, 11, 1, 24, 97, 6, 13, \n         30, 9, 14, 20, 2, 5, 27, 10, 21, 22, 17, 26, 16, 28, 29, 31},    // test case 5\n        {32, 4, 98, 7, 18, 15, 3, 8, 99, 12, 11, 1, 24, 97, 6, 13, \n         30, 9, 14, 20, 2, 5, 27, 10, 21, 22, 17, 26, 16, 28, 29, 31,\n         33, 38, 93, 40, 95, 41, 34, 36, 94, 39, 43, 35, 44, 48, 37, 42,\n         49, 54, 77, 56, 79, 57, 50, 52, 78, 55, 59, 51, 60, 64, 53, 58}, // test case 6\n        {32, 4, 98, 7, 18, 15, 3, 8, 99, 12, 11, 1, 24, 97, 6, 13,\n         30, 9, 14, 20, 2, 5, 27, 10, 21, 22, 17, 26, 16, 28, 29, 31,\n         33, 38, 93, 40, 95, 41, 34, 36, 94, 39, 43, 35, 44, 48, 37, 42,\n         49, 54, 77, 56, 79, 57, 50, 52, 78, 55, 59, 51, 60, 64, 53, 58,\n         65, 70, 61, 72, 63, 73, 66, 68, 62, 71, 75, 67, 76, 80, 69, 74,\n         81, 86, 45, 88, 47, 89, 82, 84, 46, 87, 91, 83, 92, 96, 85, 90,\n         25, 23, 19, 100}                                                 // test case 7\n         };\n\n    // Loop to execute each test case\n    for (int i = 0; i < testCaseCount; ++i) {\n        // Allocate memory on the device\n        int* d_data;\n        int* d_minResult;\n        int* d_maxResult;\n        CUDA_CHECK(cudaMalloc(&d_data, vectorSize[i] * sizeof(int)));\n        CUDA_CHECK(cudaMalloc(&d_minResult, sizeof(int)));\n        CUDA_CHECK(cudaMalloc(&d_maxResult, sizeof(int)));\n        \n        // Initialize result values on the host\n        int minResult = INT_MAX;\n        int maxResult = INT_MIN;        \n        \n        // Copy the data to the device\n        CUDA_CHECK(cudaMemcpy(d_data, inputVector[i], vectorSize[i] * sizeof(int), cudaMemcpyHostToDevice));\n        CUDA_CHECK(cudaMemcpy(d_minResult, &minResult, sizeof(int), cudaMemcpyHostToDevice));\n        CUDA_CHECK(cudaMemcpy(d_maxResult, &maxResult, sizeof(int), cudaMemcpyHostToDevice));\n        \n        // Launch the kernel with enough threads\n        int blockSize = 512;\n        int numBlocks = (vectorSize[i] + blockSize - 1) / blockSize;\n        //Grid: (ceil(vectorSize / 512), 1, 1)\n        //Block: (512, 1, 1)\n        k_findMinMax<<<numBlocks, blockSize>>>(d_data, d_minResult, d_maxResult, vectorSize[i]);\n        \n        // Synchronize the device to ensure the kernel has completed\n        CUDA_CHECK(cudaDeviceSynchronize());\n        \n        // Copy the results back to the CPU\n        CUDA_CHECK(cudaMemcpy(&minResult, d_minResult, sizeof(int), cudaMemcpyDeviceToHost));\n        CUDA_CHECK(cudaMemcpy(&maxResult, d_maxResult, sizeof(int), cudaMemcpyDeviceToHost));\n\n        assert(minResult == expectedMin[i]);\n        assert(maxResult == expectedMax[i]);\n\n        // Free GPU memory\n        cudaFree(d_data);\n        cudaFree(d_minResult);\n        cudaFree(d_maxResult);\n    }\n    return 0;\n}\n\n__global__ void k_findMinMax(int* data, int* minResult, int* maxResult, int n) {\n", "test": "int main() {\n    launch();\n}\n", "example_test": "    @example_test\n", "cuda_toolkit": "12.2"}
{"task_id": "CUDA/83", "date": "2025-03-31", "prompt": "Write a function that uses the cuBLAS library to compute the Euclidean distances between two vectors.\n\nThe signature of the function is float calculateEuclideanDistance(float* inputVectorA_d, float* inputVectorB_d, int n, cudaStream_t stream, cublasHandle_t handle), where inputVectorA_d and inputVectorB_d are device pointers to the input vectors, n is the number of elements in the vectors, the stream is the CUDA stream for asynchronous execution, and the handle is the cuBLAS handle for managing cuBLAS operations.\n\n>>> calculateEuclideanDistance({41.48, 79.25, 93.81, 75.60, 72.91, 39.09, 34.96, 88.32, 32.21, 95.47}, {7.21, 1.02, 95.87, 61.54, 99.16, 25.89, 85.60, 87.90, 12.21, 22.57}, 10) -> 128.991\n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_70 -arch=sm_60", "ld_flags": "-lcublas", "declaration": "#include <cstdio>\n#include <algorithm>\n#include <cuda_runtime.h>\n#include <cublas_v2.h>\n#undef NDEBUG\n#include <assert.h>\n\n#define CUDA_CHECK(call) \\\ndo { \\\n       cudaError_t error = call; \\\n       if (error != cudaSuccess) { \\\n           fprintf(stderr, \"CUDA error at %s:%d %s\\n\", \\\n                   __FILE__, __LINE__, \\\n                   cudaGetErrorString(error)); \\\n           exit(EXIT_FAILURE); \\\n       } \\\n} while(0)\n\nfloat calculateEuclideanDistance(float* inputVectorA_d, float* inputVectorB_d, int n, cudaStream_t stream, cublasHandle_t handle);\n\nvoid launch() {\n    const int testCaseCount = 9; // Number of test cases\n    const int vectorSize[testCaseCount] = {10, 10, 10, 10, 10, 10, 10, 10, 2}; // Sizes of the vectors in each test case\n    const float expectedEuclideanDistance[testCaseCount] = {89.5842f,91.4034f,95.1649f,134.572f,130.933f,104.339f,142.695f, 128.991f, 7.99826f}; // Expected results for each test\n    int maxVectorSize = *std::max_element(vectorSize, vectorSize + testCaseCount);\n    float precisionTolerance=1e-3;\n    float *inputVectorA_d, *inputVectorB_d;\n\n    float inputVectorA_h[testCaseCount][maxVectorSize] = {\n        {10.50f, 82.88f, 77.71f, 54.94f, 88.26f, 57.97f, 33.54f, 40.78f, 21.73f, 42.08f}, // Test case 1\n        {21.01f, 46.84f, 47.99f, 18.44f, 12.15f, 17.98f, 10.74f, 37.09f, 56.35f, 35.77f}, // Test case 2\n        {59.50f, 35.18f, 59.55f, 94.73f, 64.39f, 82.98f, 43.86f, 60.24f, 71.31f, 45.59f}, // Test case 3\n        {13.12f, 66.54f, 13.45f, 91.62f, 45.72f, 86.90f, 69.65f, 4.61f, 90.95f, 56.26f}, // Test case 4\n        {42.22f, 66.05f, 49.51f, 84.67f, 85.78f, 49.76f, 10.12f, 91.17f, 8.28f, 33.39f}, // Test case 5\n        {92.24f, 83.72f, 31.96f, 31.48f, 43.90f, 82.75f, 19.45f, 74.00f, 72.62f, 46.73f}, // Test case 6\n        {26.32f, 80.19f, 61.36f, 76.85f, 91.31f, 82.48f, 32.80f, 65.68f, 22.03f, 63.05f}, // Test case 7\n        {41.48f, 79.25f, 93.81f, 75.60f, 72.91f, 39.09f, 34.96f, 88.32f, 32.21f, 95.47f}, // Test case 8\n        {1.45, 7.56} // Test case 9\n    };\n\n    float inputVectorB_h[testCaseCount][maxVectorSize] = {\n        {18.43f, 47.28f, 60.18f, 30.84f, 95.26f, 35.39f, 42.01f, 57.82f, 83.87f, 10.07f}, // Test case 1\n        {27.45f, 89.76f, 93.14f, 20.94f, 2.15f, 51.48f, 56.54f, 4.93f, 49.58f, 40.89f}, // Test case 2\n        {50.50f, 21.56f, 72.17f, 95.49f, 25.66f, 22.71f, 99.55f, 61.44f, 59.20f, 29.84f}, // Test case 3\n        {43.07f, 66.37f, 23.35f, 27.40f, 10.15f, 10.16f, 87.45f, 32.45f, 27.87f, 83.92f}, // Test case 4\n        {48.77f, 58.12f, 97.22f, 73.13f, 96.90f, 97.11f, 67.14f, 19.07f, 68.33f, 19.01f}, // Test case 5\n        {7.78f, 85.31f, 64.76f, 24.15f, 17.03f, 40.79f, 16.89f, 64.71f, 67.48f, 42.35f}, // Test case 6\n        {97.74f, 61.81f, 7.85f, 44.32f, 96.69f, 9.15f, 64.12f, 30.51f, 34.74f, 6.34f}, // Test case 7\n        {7.21f, 1.02f, 95.87f, 61.54f, 99.16f, 25.89f, 85.60f, 87.90f, 12.21f, 22.57f}, // Test case 8\n        {7.81f, 12.41f} // Test case 9\n    };\n\n    // Use a CUDA stream for asynchronous operations\n    cudaStream_t stream;\n    CUDA_CHECK(cudaStreamCreate(&stream));\n\n    // Initialize cuBLAS\n    cublasHandle_t handle;\n    cublasCreate(&handle);\n    cublasSetStream(handle, stream);\n\n    // Allocate device memory on the GPU for the vectors\n    CUDA_CHECK(cudaMallocAsync(&inputVectorA_d, maxVectorSize * sizeof(float), stream));\n    CUDA_CHECK(cudaMallocAsync(&inputVectorB_d, maxVectorSize * sizeof(float), stream));\n\n    // Loop to execute each test case\n    for (int i = 0; i < testCaseCount; ++i) {\n        // Copy data from the host (CPU) to the device (GPU)\n        CUDA_CHECK(cudaMemcpyAsync(inputVectorA_d, inputVectorA_h[i], vectorSize[i] * sizeof(float), cudaMemcpyHostToDevice, stream));\n        CUDA_CHECK(cudaMemcpyAsync(inputVectorB_d, inputVectorB_h[i], vectorSize[i] * sizeof(float), cudaMemcpyHostToDevice, stream));\n\n        float euclideanDistance = calculateEuclideanDistance(inputVectorA_d, inputVectorB_d, vectorSize[i], stream, handle);\n\n        // Check tasks in the stream has completed\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n\n        assert(fabs(euclideanDistance - expectedEuclideanDistance[i]) < precisionTolerance);\n    }\n\n    // Clean up\n    cublasDestroy(handle);\n    CUDA_CHECK(cudaFreeAsync(inputVectorA_d, stream));\n    CUDA_CHECK(cudaFreeAsync(inputVectorB_d, stream));\n    CUDA_CHECK(cudaStreamDestroy(stream));\n}\n\nfloat calculateEuclideanDistance(float* inputVectorA_d, float* inputVectorB_d, int n, cudaStream_t stream, cublasHandle_t handle) {\n", "test": "int main() {\n    launch();\n}\n", "example_test": "    @example_test\n", "cuda_toolkit": "12.2"}
{"task_id": "CUDA/84", "date": "2025-03-31", "prompt": "Write a CUDA kernel to perform a Linear Translation using unified memory, where each thread updates the coordinates (x, y, z) by applying translation offsets.\n\nThe signature of function is __global__ void k_translatePoints(float* x_coords, float* y_coords, float* z_coords, float tx, float ty, float tz, int size).\n\n>>> k_translatePoints({0,1,2,3,4}, {0,1,2,3,4}, {0,1,2,3,4}, 1, 1, 1, 5) -> x_coords: {1,2,3,4,5}, y_coords: {1,2,3,4,5}, z_coords: {1,2,3,4,5})\n>>> k_translatePoints({0,1,2,3,4,5,6,7,8,9}, {0,1,2,3,4,5,6,7,8,9}, {0,1,2,3,4,5,6,7,8,9}, 0.1, 0.2, 0.3, 10) -> x_coords: {0.1,1.1,2.1,3.1,4.1,5.1,6.1,7.1,8.1,9.1}, y_coords: {0.2,1.2,2.2,3.2,4.2,5.2,6.2,7.2,8.2,9.2}, z_coords: {0.3,1.3,2.3,3.3,4.3,5.3,6.3,7.3,8.3,9.3} \n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_70 -arch=sm_60", "ld_flags": "", "declaration": "#include <cuda_runtime.h>\n#undef NDEBUG\n#include <assert.h>\n\n__global__ void k_translatePoints(float* x_coords, float* y_coords, float* z_coords, float tx, float ty, float tz, int size);\n\nvoid launch() {\n    // Define 7 test cases\n    const int num_tests = 7;\n\n    // Arrays to hold input sizes, translation vectors, and tolerance for each test case\n    int sizes[num_tests] = { 5, 1000, 10, 5, 1000, 1, 10 };\n    float translations[num_tests][3] = {\n        {1.0f, 1.0f, 1.0f},  // Translation vector for Test Case 1\n        {2.0f, 2.0f, 2.0f},  // Test Case 2\n        {0.1f, 0.2f, 0.3f},  // Test Case 3\n        {-1.0f, -2.0f, -3.0f},  // Test Case 4\n        {0.0f, 0.0f, 0.0f},  // Test Case 5 (no translation)\n        {5.0f, 5.0f, 5.0f},  // Test Case 6\n        {0.5f, 0.5f, 0.5f}   // Test Case 7\n    };\n    float tolerances[num_tests] = { 0.1f, 0.1f, 0.01f, 0.2f, 0.01f, 0.1f, 0.05f }; // Tolerances for each test case\n\n    for (int t = 0; t < num_tests; t++) {\n        int size = sizes[t];\n        float tx = translations[t][0];\n        float ty = translations[t][1];\n        float tz = translations[t][2];\n        float tolerance = tolerances[t];\n\n        // Allocate memory for the x, y, and z coordinate arrays using managed memory\n        float* x_coords, * y_coords, * z_coords;\n        cudaMallocManaged(&x_coords, size * sizeof(float));\n        cudaMallocManaged(&y_coords, size * sizeof(float));\n        cudaMallocManaged(&z_coords, size * sizeof(float));\n\n        // Allocate memory for the expected results\n        float* expected_x = new float[size];\n        float* expected_y = new float[size];\n        float* expected_z = new float[size];\n\n        // Initialize points and expected results\n        for (int i = 0; i < size; i++) {\n            x_coords[i] = float(i); // Initial x-coordinate\n            y_coords[i] = float(i); // Initial y-coordinate\n            z_coords[i] = float(i); // Initial z-coordinate\n            expected_x[i] = float(i) + tx;  // Expected x-coordinate\n            expected_y[i] = float(i) + ty;  // Expected y-coordinate\n            expected_z[i] = float(i) + tz;  // Expected z-coordinate\n        }\n\n        // Launch translation kernel\n        k_translatePoints<<<(size + 255) / 256, 256>>>(x_coords, y_coords, z_coords, tx, ty, tz, size);\n        cudaDeviceSynchronize();\n\n        // Validate the results with assertions and a tolerance\n        for (int i = 0; i < size; i++) {\n            // Check if the result is within the expected tolerance for x, y, and z coordinates\n            assert(std::abs(x_coords[i] - expected_x[i]) <= tolerance);\n            assert(std::abs(y_coords[i] - expected_y[i]) <= tolerance);\n            assert(std::abs(z_coords[i] - expected_z[i]) <= tolerance);\n        }\n\n        // Free managed memory\n        cudaFree(x_coords);\n        cudaFree(y_coords);\n        cudaFree(z_coords);\n        delete[] expected_x;\n        delete[] expected_y;\n        delete[] expected_z;\n    }\n}\n\n__global__ void k_translatePoints(float* x_coords, float* y_coords, float* z_coords, float tx, float ty, float tz, int size) {\n", "test": "int main() {\n    launch();\n}\n", "example_test": "    @example_test\n", "cuda_toolkit": "12.2"}
{"task_id": "CUDA/85", "date": "2025-03-31", "prompt": "Create a CUDA kernel for RGB to grayscale conversion, where each thread processes a single pixel using a weighted sum of RGB channels.\n\nThe signature of the functions is __global__ void k_rgbToGrayscaleKernel(unsigned char* rgbInput_d, float* weights_d, unsigned char* grayscaleOutput_d, int width, int height), where rgbInput_d is input pixels of RGB, weights_d is the weights for RGB conversion, grayscaleOutput_d is converted grayscale output, width & height are the dimension of the image.\n\n>>> k_rgbToGrayscaleKernel({{255, 0, 0}, {0, 255, 0}, {0, 0, 255}, {255, 255, 0}, {255, 255, 255}}, {0.299, 0.587, 0.114}, grayscaleOutput_d, 5, 1)-> grayscaleOutput_d: ({76, 149, 29, 225, 255})\n>>> k_rgbToGrayscaleKernel({{123, 231, 12}, {45, 67, 89}, {190, 12, 220}, {12, 180, 45}, {255, 123, 89}}, {0.299, 0.587, 0.114}, grayscaleOutput_d, 5, 1)-> grayscaleOutput_d: ({173, 62, 88, 114, 158}) \n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_70 -arch=sm_60", "ld_flags": "", "declaration": "#include <cuda_runtime.h>\n#include <cstdio>\n#undef NDEBUG\n#include <assert.h>\n\n#define CUDA_CHECK(call)                                                           \\\ndo {                                                                               \\\n        cudaError_t error = call;                                                  \\\n        if (error != cudaSuccess) {                                                \\\n            fprintf(stderr, \"CUDA Error: %s at %s:%d\\n\", cudaGetErrorString(error),\\\n                    __FILE__, __LINE__);                                           \\\n            exit(error);                                                           \\\n        }                                                                          \\\n} while (0)\n\n__global__ void k_rgbToGrayscaleKernel(unsigned char* rgbInput_d, float* weights_d, unsigned char* grayscaleOutput_d, int width, int height);\n\nvoid launch() {\n    const int BLOCK_SIZE = 16;\n    // Input RGB values for 7 test cases\n    unsigned char testInputRGB[7][8][3] = {\n        { {255, 0, 0}, {0, 255, 0}, {0, 0, 255}, {255, 255, 0}, {255, 255, 255} },        // Test case 1\n        { {123, 231, 12}, {45, 67, 89}, {190, 12, 220}, {12, 180, 45}, {255, 123, 89} },  // Test case 2\n        { {0, 0, 0}, {128, 128, 128}, {64, 64, 64}, {255, 255, 255}, {1, 2, 3} },         // Test case 3\n        { {12, 34, 56}, {78, 90, 123}, {200, 150, 100}, {255, 0, 255}, {150, 75, 0} },    // Test case 4\n        { {255, 128, 0}, {0, 128, 255}, {128, 255, 128}, {64, 128, 192}, {192, 128, 64} },// Test case 5\n        { {50, 150, 200}, {200, 50, 150}, {150, 200, 50}, {100, 100, 100}, {0, 0, 0} },   // Test case 6\n        { {100, 200, 50}, {50, 100, 200}, {200, 50, 100}, {123, 45, 67}, {12, 180, 45} }  // Test case 7\n    };\n\n    // Expected grayscale output for each test case\n    unsigned char expectedOutputGray[7][8] = {\n        {76, 149, 29, 225, 255},   // Test case 1\n        {173, 62, 88, 114, 158},   // Test case 2\n        {0, 128, 64, 255, 1},      // Test case 3\n        {29, 90, 159, 105, 88},    // Test case 4\n        {151, 104, 202, 116, 139}, // Test case 5\n        {125, 106, 167, 100, 0},   // Test case 6\n        {153, 96, 100, 70, 114}    // Test case 7\n    };\n\n    float grayscaleInput[3] = {0.299, 0.587, 0.114};\n    int width = 5;  // 5 RGB values in each test case\n    int height = 1; // Single row of RGB values in each test case\n    int channels = 3; // RGB has 3 channels\n    float* weights_d;\n\n    // Use a CUDA stream for asynchronous operations\n    cudaStream_t stream;\n    CUDA_CHECK(cudaStreamCreate(&stream));\n\n    CUDA_CHECK(cudaMallocAsync(&weights_d, 3 * sizeof(float), stream));\n    CUDA_CHECK(cudaMemcpyAsync(weights_d, grayscaleInput, 3 * sizeof(float), cudaMemcpyHostToDevice, stream));\n\n    // Allocate device memory for input and output\n    unsigned char* rgbInput_d;\n    unsigned char* grayscaleOutput_d;\n    CUDA_CHECK(cudaMallocAsync(&rgbInput_d, width * height * channels * sizeof(unsigned char), stream));\n    CUDA_CHECK(cudaMallocAsync(&grayscaleOutput_d, width * height * sizeof(unsigned char), stream));\n    // Allocate host memory for output\n    unsigned char grayscaleOutput_h[5];\n\n    // Iterate over test cases\n    for (int i = 0; i < 7; ++i) {\n        // Copy input RGB values to device\n        CUDA_CHECK(cudaMemcpyAsync(rgbInput_d, testInputRGB[i], width * height * channels * sizeof(unsigned char), cudaMemcpyHostToDevice, stream));\n\n        // Define block and grid sizes\n        dim3 block(BLOCK_SIZE, BLOCK_SIZE);\n        dim3 grid((width + block.x - 1) / block.x, (height + block.y - 1) / block.y);\n\n        // Grid: (ceil(width / 16), ceil(width / 16), 1)\n        // Block: (16, 16, 1)\n        void *args[] = {&rgbInput_d, &weights_d, &grayscaleOutput_d, &width, &height};\n        CUDA_CHECK(cudaLaunchKernel((void*)k_rgbToGrayscaleKernel, grid, block, args, BLOCK_SIZE * BLOCK_SIZE * sizeof(int), stream));\n\n        // Copy result back to host\n        CUDA_CHECK(cudaMemcpyAsync(grayscaleOutput_h, grayscaleOutput_d, width * height * sizeof(unsigned char), cudaMemcpyDeviceToHost, stream));\n\n        // Check tasks in the stream has completed\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n\n        // Compare the result with the expected output\n        for (int j = 0; j < 5; ++j) {\n            assert(grayscaleOutput_h[j] == expectedOutputGray[i][j]);\n        }\n    }\n\n    // Free device memory\n    CUDA_CHECK(cudaFreeAsync(rgbInput_d, stream));\n    CUDA_CHECK(cudaFreeAsync(grayscaleOutput_d, stream));\n    CUDA_CHECK(cudaFreeAsync(weights_d, stream));\n    CUDA_CHECK(cudaStreamDestroy(stream)); \n}\n\n__global__ void k_rgbToGrayscaleKernel(unsigned char* rgbInput_d, float* weights_d, unsigned char* grayscaleOutput_d, int width, int height) {\n", "test": "int main() {\n    launch();\n}\n", "example_test": "    @example_test\n", "cuda_toolkit": "12.2"}
{"task_id": "CUDA/86", "date": "2025-03-31", "prompt": "Write a CUDA kernel k_sumSpectralBands using managed memory to perform summation across spectral bands for each pixel in a 3D hyperspectral data cube. The kernel should reduce the 3D data cube (height \u00d7 width \u00d7 bands) to a 2D output (height \u00d7 width) by summing along the spectral bands, optimizing for real-time processing of large datasets.\n\nThe signature of the function is __global__ void k_sumSpectralBands(float* inputData_d, float* outputData_d, int x_dim, int y_dim, int z_dim).\n\n>>> k_sumSpectralBands({10, 20, 30, 15, 25, 35, 11, 21, 31, 9, 19, 29}) -> ({60, 75, 63, 57})\n>>> k_sumSpectralBands({5, 15, 25, 10, 20, 30, 7, 17, 27, 12, 22, 32}) -> ({45, 60, 51, 66}) \n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_70 -arch=sm_60", "ld_flags": "", "declaration": "#include <cuda_runtime.h>\n\n#define X_DIM 4   // Number of rows (spatial)\n#define Y_DIM 4   // Number of columns (spatial)\n#define Z_DIM 3   // Number of spectral bands (depth)\n\n#undef NDEBUG\n#include <assert.h>\n\n__global__ void k_sumSpectralBands(float* inputData_d, float* outputData_d, int x_dim, int y_dim, int z_dim);\n\nvoid launch() {\n    // Test Case 1\n    {\n        // Define the dimensions of the hyperspectral data cube\n        int x_dim = X_DIM;\n        int y_dim = Y_DIM;\n        int z_dim = Z_DIM;\n\n        // Predefined input data for testing (non-sequential values)\n        float inputData_h[X_DIM * Y_DIM * Z_DIM] = {\n            10, 20, 30,    15, 25, 35,   11, 21, 31,   9, 19, 29,     // First row of Z bands\n            12, 22, 32,    17, 27, 37,   13, 23, 33,   8, 18, 28,     // Second row of Z bands\n            14, 24, 34,    19, 29, 39,   16, 26, 36,   7, 17, 27,     // Third row of Z bands\n            18, 28, 38,    10, 30, 40,   20, 30, 50,   6, 16, 26      // Fourth row of Z bands\n        };\n\n        float expectedOutput_h[X_DIM * Y_DIM] = {\n            60, 75, 63, 57,\n            66, 81, 69, 54,\n            72, 87, 78, 51,\n            84, 80, 100, 48\n        };\n\n        // Allocate managed memory for the 2D output array on the device\n        float* outputData_d;\n        cudaMallocManaged(&outputData_d, x_dim * y_dim * sizeof(float));\n\n        // Allocate managed memory for the input data on the device and copy from predefined inputData_h\n        float* inputData_d;\n        cudaMallocManaged(&inputData_d, x_dim * y_dim * z_dim * sizeof(float));\n        cudaMemcpy(inputData_d, inputData_h, x_dim * y_dim * z_dim * sizeof(float), cudaMemcpyHostToDevice);\n\n        // Define block size and grid size\n        dim3 blockSize(4, 4); // Each block has 4x4 threads\n        dim3 gridSize((x_dim + blockSize.x - 1) / blockSize.x, (y_dim + blockSize.y - 1) / blockSize.y);\n\n        // Block: (4, 4, 1)\n        // Grid: ((x_dim + blockSize.x - 1) / blockSize.x, (y_dim + blockSize.y - 1) / blockSize.y, 1)\n        k_sumSpectralBands << <gridSize, blockSize >> > (inputData_d, outputData_d, x_dim, y_dim, z_dim);\n\n        // Wait for the GPU to finish before accessing the results\n        cudaDeviceSynchronize();\n\n        for (int i = 0; i < x_dim; ++i) {\n            for (int j = 0; j < y_dim; ++j) {\n                int idx = i * y_dim + j;\n                assert(outputData_d[idx] == expectedOutput_h[idx]);\n            }\n        }\n\n        // Free the allocated memory\n        cudaFree(inputData_d);\n        cudaFree(outputData_d);\n    }\n\n    // Test Case 2\n    {\n        // Define the dimensions of the hyperspectral data cube\n        int x_dim = X_DIM;\n        int y_dim = Y_DIM;\n        int z_dim = Z_DIM;\n\n        // Predefined input data for testing (non-sequential values)\n        float inputData_h[X_DIM * Y_DIM * Z_DIM] = {\n            5, 15, 25,    10, 20, 30,   7, 17, 27,    12, 22, 32,\n            9, 19, 29,    14, 24, 34,   6, 16, 26,    8, 18, 28,\n            11, 21, 31,   13, 23, 33,   15, 25, 35,   9, 19, 29,\n            10, 20, 30,   18, 28, 38,   12, 22, 32,   7, 17, 27\n        };\n\n        float expectedOutput_h[X_DIM * Y_DIM] = {\n            45, 60, 51, 66,\n            57, 72, 48, 54,\n            63, 69, 75, 57,\n            60, 84, 66, 51\n        };\n\n        // Allocate managed memory for the 2D output array on the device\n        float* outputData_d;\n        cudaMallocManaged(&outputData_d, x_dim * y_dim * sizeof(float));\n\n        // Allocate managed memory for the input data on the device and copy from predefined inputData_h\n        float* inputData_d;\n        cudaMallocManaged(&inputData_d, x_dim * y_dim * z_dim * sizeof(float));\n        cudaMemcpy(inputData_d, inputData_h, x_dim * y_dim * z_dim * sizeof(float), cudaMemcpyHostToDevice);\n\n        // Define block size and grid size\n        dim3 blockSize(4, 4); // Each block has 4x4 threads\n        dim3 gridSize((x_dim + blockSize.x - 1) / blockSize.x, (y_dim + blockSize.y - 1) / blockSize.y);\n\n        // Block: (4, 4, 1)\n        // Grid: ((x_dim + blockSize.x - 1) / blockSize.x, (y_dim + blockSize.y - 1) / blockSize.y, 1)\n        k_sumSpectralBands << <gridSize, blockSize >> > (inputData_d, outputData_d, x_dim, y_dim, z_dim);\n\n        // Wait for the GPU to finish before accessing the results\n        cudaDeviceSynchronize();\n\n        for (int i = 0; i < x_dim; ++i) {\n            for (int j = 0; j < y_dim; ++j) {\n                int idx = i * y_dim + j;\n                assert(outputData_d[idx] == expectedOutput_h[idx]);\n            }\n        }\n\n        // Free the allocated memory\n        cudaFree(inputData_d);\n        cudaFree(outputData_d);\n    }\n\n    // Test Case 3\n    {\n        // Define the dimensions of the hyperspectral data cube\n        int x_dim = X_DIM;\n        int y_dim = Y_DIM;\n        int z_dim = Z_DIM;\n\n        // Predefined input data for testing (non-sequential values)\n        float inputData_h[X_DIM * Y_DIM * Z_DIM] = {\n            13, 23, 33,   19, 29, 39,   14, 24, 34,   16, 26, 36,\n            8, 18, 28,    10, 20, 30,   5, 15, 25,    6, 16, 26,\n            17, 27, 37,   21, 31, 41,   11, 21, 31,   15, 25, 35,\n            12, 22, 32,   9, 19, 29,    14, 24, 34,   18, 28, 38\n        };\n\n        float expectedOutput_h[X_DIM * Y_DIM] = {\n            69, 87, 72, 78,\n            54, 60, 45, 48,\n            81, 93, 63, 75,\n            66, 57, 72, 84\n        };\n\n        // Allocate managed memory for the 2D output array on the device\n        float* outputData_d;\n        cudaMallocManaged(&outputData_d, x_dim * y_dim * sizeof(float));\n\n        // Allocate managed memory for the input data on the device and copy from predefined inputData_h\n        float* inputData_d;\n        cudaMallocManaged(&inputData_d, x_dim * y_dim * z_dim * sizeof(float));\n        cudaMemcpy(inputData_d, inputData_h, x_dim * y_dim * z_dim * sizeof(float), cudaMemcpyHostToDevice);\n\n        // Define block size and grid size\n        dim3 blockSize(4, 4); // Each block has 4x4 threads\n        dim3 gridSize((x_dim + blockSize.x - 1) / blockSize.x, (y_dim + blockSize.y - 1) / blockSize.y);\n\n        // Block: (4, 4, 1)\n        // Grid: ((x_dim + blockSize.x - 1) / blockSize.x, (y_dim + blockSize.y - 1) / blockSize.y, 1)\n        k_sumSpectralBands << <gridSize, blockSize >> > (inputData_d, outputData_d, x_dim, y_dim, z_dim);\n\n        // Wait for the GPU to finish before accessing the results\n        cudaDeviceSynchronize();\n\n        for (int i = 0; i < x_dim; ++i) {\n            for (int j = 0; j < y_dim; ++j) {\n                int idx = i * y_dim + j;\n                assert(outputData_d[idx] == expectedOutput_h[idx]);\n            }\n        }\n\n        // Free the allocated memory\n        cudaFree(inputData_d);\n        cudaFree(outputData_d);\n    }\n\n    // Test Case 4\n    {\n        // Define the dimensions of the hyperspectral data cube\n        int x_dim = X_DIM;\n        int y_dim = Y_DIM;\n        int z_dim = Z_DIM;\n\n        // Predefined input data for testing (non-sequential values)\n        float inputData_h[X_DIM * Y_DIM * Z_DIM] = {\n            20, 30, 40,   22, 32, 42,   16, 26, 36,   18, 28, 38,\n            11, 21, 31,   13, 23, 33,   9, 19, 29,    10, 20, 30,\n            7, 17, 27,    12, 22, 32,   5, 15, 25,    8, 18, 28,\n            17, 27, 37,   15, 25, 35,   14, 24, 34,   19, 29, 39\n        };\n\n        float expectedOutput_h[X_DIM * Y_DIM] = {\n            90, 96, 78, 84,\n            63, 69, 57, 60,\n            51, 66, 45, 54,\n            81, 75, 72, 87\n        };\n\n        // Allocate managed memory for the 2D output array on the device\n        float* outputData_d;\n        cudaMallocManaged(&outputData_d, x_dim * y_dim * sizeof(float));\n\n        // Allocate managed memory for the input data on the device and copy from predefined inputData_h\n        float* inputData_d;\n        cudaMallocManaged(&inputData_d, x_dim * y_dim * z_dim * sizeof(float));\n        cudaMemcpy(inputData_d, inputData_h, x_dim * y_dim * z_dim * sizeof(float), cudaMemcpyHostToDevice);\n\n        // Define block size and grid size\n        dim3 blockSize(4, 4); // Each block has 4x4 threads\n        dim3 gridSize((x_dim + blockSize.x - 1) / blockSize.x, (y_dim + blockSize.y - 1) / blockSize.y);\n\n        // Block: (4, 4, 1)\n        // Grid: ((x_dim + blockSize.x - 1) / blockSize.x, (y_dim + blockSize.y - 1) / blockSize.y, 1)\n        k_sumSpectralBands << <gridSize, blockSize >> > (inputData_d, outputData_d, x_dim, y_dim, z_dim);\n\n        // Wait for the GPU to finish before accessing the results\n        cudaDeviceSynchronize();\n\n        for (int i = 0; i < x_dim; ++i) {\n            for (int j = 0; j < y_dim; ++j) {\n                int idx = i * y_dim + j;\n                assert(outputData_d[idx] == expectedOutput_h[idx]);\n            }\n        }\n\n        // Free the allocated memory\n        cudaFree(inputData_d);\n        cudaFree(outputData_d);\n    }\n\n    // Test Case 5\n    {\n        // Define the dimensions of the hyperspectral data cube\n        int x_dim = X_DIM;\n        int y_dim = Y_DIM;\n        int z_dim = Z_DIM;\n\n        // Predefined input data for testing (non-sequential values)\n        float inputData_h[X_DIM * Y_DIM * Z_DIM] = {\n            18, 28, 38,   16, 26, 36,   14, 24, 34,   12, 22, 32,\n            10, 20, 30,   13, 23, 33,   7, 17, 27,    9, 19, 29,\n            11, 21, 31,   8, 18, 28,    15, 25, 35,   6, 16, 26,\n            20, 30, 40,   5, 15, 25,    19, 29, 39,   17, 27, 37\n        };\n\n        float expectedOutput_h[X_DIM * Y_DIM] = {\n            84, 78, 72, 66,\n            60, 69, 51, 57,\n            63, 54, 75, 48,\n            90, 45, 87, 81\n        };\n\n        // Allocate managed memory for the 2D output array on the device\n        float* outputData_d;\n        cudaMallocManaged(&outputData_d, x_dim * y_dim * sizeof(float));\n\n        // Allocate managed memory for the input data on the device and copy from predefined inputData_h\n        float* inputData_d;\n        cudaMallocManaged(&inputData_d, x_dim * y_dim * z_dim * sizeof(float));\n        cudaMemcpy(inputData_d, inputData_h, x_dim * y_dim * z_dim * sizeof(float), cudaMemcpyHostToDevice);\n\n        // Define block size and grid size\n        dim3 blockSize(4, 4); // Each block has 4x4 threads\n        dim3 gridSize((x_dim + blockSize.x - 1) / blockSize.x, (y_dim + blockSize.y - 1) / blockSize.y);\n\n        // Block: (4, 4, 1)\n        // Grid: ((x_dim + blockSize.x - 1) / blockSize.x, (y_dim + blockSize.y - 1) / blockSize.y, 1)\n        k_sumSpectralBands << <gridSize, blockSize >> > (inputData_d, outputData_d, x_dim, y_dim, z_dim);\n\n        // Wait for the GPU to finish before accessing the results\n        cudaDeviceSynchronize();\n\n        for (int i = 0; i < x_dim; ++i) {\n            for (int j = 0; j < y_dim; ++j) {\n                int idx = i * y_dim + j;\n                assert(outputData_d[idx] == expectedOutput_h[idx]);\n            }\n        }\n\n        // Free the allocated memory\n        cudaFree(inputData_d);\n        cudaFree(outputData_d);\n    }\n\n    // Test Case 6\n    {\n        // Define the dimensions of the hyperspectral data cube\n        int x_dim = X_DIM;\n        int y_dim = Y_DIM;\n        int z_dim = Z_DIM;\n\n        // Predefined input data for testing (non-sequential values)\n        float inputData_h[X_DIM * Y_DIM * Z_DIM] = {\n            12, 22, 32,   14, 24, 34,   19, 29, 39,   15, 25, 35,\n            7, 17, 27,    8, 18, 28,    13, 23, 33,   10, 20, 30,\n            16, 26, 36,   11, 21, 31,   14, 24, 34,   9, 19, 29,\n            5, 15, 25,    20, 30, 40,   18, 28, 38,   6, 16, 26\n        };\n\n        float expectedOutput_h[X_DIM * Y_DIM] = {\n            66, 72, 87, 75,\n            51, 54, 69, 60,\n            78, 63, 72, 57,\n            45, 90, 84, 48\n        };\n\n        // Allocate managed memory for the 2D output array on the device\n        float* outputData_d;\n        cudaMallocManaged(&outputData_d, x_dim * y_dim * sizeof(float));\n\n        // Allocate managed memory for the input data on the device and copy from predefined inputData_h\n        float* inputData_d;\n        cudaMallocManaged(&inputData_d, x_dim * y_dim * z_dim * sizeof(float));\n        cudaMemcpy(inputData_d, inputData_h, x_dim * y_dim * z_dim * sizeof(float), cudaMemcpyHostToDevice);\n\n        // Define block size and grid size\n        dim3 blockSize(4, 4); // Each block has 4x4 threads\n        dim3 gridSize((x_dim + blockSize.x - 1) / blockSize.x, (y_dim + blockSize.y - 1) / blockSize.y);\n\n        // Block: (4, 4, 1)\n        // Grid: ((x_dim + blockSize.x - 1) / blockSize.x, (y_dim + blockSize.y - 1) / blockSize.y, 1)\n        k_sumSpectralBands << <gridSize, blockSize >> > (inputData_d, outputData_d, x_dim, y_dim, z_dim);\n\n        // Wait for the GPU to finish before accessing the results\n        cudaDeviceSynchronize();\n\n        for (int i = 0; i < x_dim; ++i) {\n            for (int j = 0; j < y_dim; ++j) {\n                int idx = i * y_dim + j;\n                assert(outputData_d[idx] == expectedOutput_h[idx]);\n            }\n        }\n\n        // Free the allocated memory\n        cudaFree(inputData_d);\n        cudaFree(outputData_d);\n    }\n\n    // Test Case 7\n    {\n        // Define the dimensions of the hyperspectral data cube\n        int x_dim = X_DIM;\n        int y_dim = Y_DIM;\n        int z_dim = Z_DIM;\n\n        // Predefined input data for testing (non-sequential values)\n        float inputData_h[X_DIM * Y_DIM * Z_DIM] = {\n            9, 19, 29,    8, 18, 28,    14, 24, 34,   10, 20, 30,\n            12, 22, 32,   15, 25, 35,   11, 21, 31,   5, 15, 25,\n            17, 27, 37,   16, 26, 36,   18, 28, 38,   19, 29, 39,\n            13, 23, 33,   7, 17, 27,    6, 16, 26,    20, 30, 40\n        };\n\n        float expectedOutput_h[X_DIM * Y_DIM] = {\n            57, 54, 72, 60,\n            66, 75, 63, 45,\n            81, 78, 84, 87,\n            69, 51, 48, 90\n        };\n\n        // Allocate managed memory for the 2D output array on the device\n        float* outputData_d;\n        cudaMallocManaged(&outputData_d, x_dim * y_dim * sizeof(float));\n\n        // Allocate managed memory for the input data on the device and copy from predefined inputData_h\n        float* inputData_d;\n        cudaMallocManaged(&inputData_d, x_dim * y_dim * z_dim * sizeof(float));\n        cudaMemcpy(inputData_d, inputData_h, x_dim * y_dim * z_dim * sizeof(float), cudaMemcpyHostToDevice);\n\n        // Define block size and grid size\n        dim3 blockSize(4, 4); // Each block has 4x4 threads\n        dim3 gridSize((x_dim + blockSize.x - 1) / blockSize.x, (y_dim + blockSize.y - 1) / blockSize.y);\n\n        // Block: (4, 4, 1)\n        // Grid: ((x_dim + blockSize.x - 1) / blockSize.x, (y_dim + blockSize.y - 1) / blockSize.y, 1)\n        k_sumSpectralBands << <gridSize, blockSize >> > (inputData_d, outputData_d, x_dim, y_dim, z_dim);\n\n        // Wait for the GPU to finish before accessing the results\n        cudaDeviceSynchronize();\n\n        for (int i = 0; i < x_dim; ++i) {\n            for (int j = 0; j < y_dim; ++j) {\n                int idx = i * y_dim + j;\n                assert(outputData_d[idx] == expectedOutput_h[idx]);\n            }\n        }\n\n        // Free the allocated memory\n        cudaFree(inputData_d);\n        cudaFree(outputData_d);\n    }\n}\n\n__global__ void k_sumSpectralBands(float* inputData_d, float* outputData_d, int x_dim, int y_dim, int z_dim) {\n", "test": "int main() {\n    launch();\n}\n", "example_test": "    @example_test\n", "cuda_toolkit": "12.2"}
{"task_id": "CUDA/87", "date": "2025-03-31", "prompt": "Write a CUDA kernel to apply a 3x3 sharpening filter. Each thread computes one pixel for efficient access to neighboring pixels and handles zero-padding at image boundaries.\n\nSharpening Kernel = [0  -1  0\n                     -1  5  -1\n                     0  -1  0]  \n\nThe signature of the function is __global__ void k_sharpenImage(const unsigned char* inputImage, unsigned char* outputImage, int width, int height).\n\n>>> k_sharpenImage({10,20,30,40,50,60,70,80,90,100,110,120,130,140,150,160,170,180,190,200,210,220,230,240,250}, outputImage, 5, 5) -> outputImage: {0,0,10,30,110,110,70,80,90,210,210,120,130,140,255,255,170,180,190,255,255,255,255,255,255}\n>>> k_sharpenImage({255,254,253,252,251,250,249,248,247,246,245,244,243,242,241,240,239,238,237,236,235,234,233,232,2310},outputImage, 5, 5) -> outputImage: {255,255,255,255,255,255,249,248,247,255,255,244,243,242,255,255,239,238,237,255,255,255,255,255,255} \n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_70 -arch=sm_60", "ld_flags": "", "declaration": "#include <cuda_runtime.h>\n#include <cstdio>\n\n#define CUDA_CHECK(call)                                                          \\\n    {                                                                             \\\n        cudaError_t err = call;                                                   \\\n        if (err != cudaSuccess) {                                                 \\\n            fprintf(stderr, \"CUDA error in file '%s' in line %d: %s.\\n\",          \\\n                    __FILE__, __LINE__, cudaGetErrorString(err));                 \\\n            exit(EXIT_FAILURE);                                                   \\\n        }                                                                         \\\n    }\n\n#undef NDEBUG\n#include <assert.h>\n\n__global__ void k_sharpenImage(const unsigned char* inputImage, unsigned char* outputImage, int width, int height);\n\nvoid launch() {\n    const int BLOCK_SIZE = 16;\n    int W = 5;\n    int H = 5;\n\n    // Use a CUDA stream for asynchronous operations\n    cudaStream_t stream;\n    CUDA_CHECK(cudaStreamCreate(&stream));\n\n    // Allocate host memory for output image\n    unsigned char outputImage_h [W * H];\n\n    // Allocate device memory\n    unsigned char* inputImage_d, * outputImage_d;\n    CUDA_CHECK(cudaMallocAsync(&inputImage_d, W * H * sizeof(unsigned char), stream));\n    CUDA_CHECK(cudaMallocAsync(&outputImage_d, W * H * sizeof(unsigned char), stream));\n\n    //Test Case 1\n    {\n        unsigned char inputImage_h [W * H] = {\n            10, 20, 30, 40, 50,\n            60, 70, 80, 90, 100,\n            110, 120, 130, 140, 150,\n            160, 170, 180, 190, 200,\n            210, 220, 230, 240, 250\n        };\n\n        unsigned char expectedOutput_h [W * H] = {\n            0, 0, 10, 30, 110,\n            110, 70, 80, 90, 210,\n            210, 120, 130, 140, 255,\n            255, 170, 180, 190, 255,\n            255, 255, 255, 255, 255\n        };\n\n        CUDA_CHECK(cudaMemcpyAsync(inputImage_d, inputImage_h, W * H * sizeof(unsigned char), cudaMemcpyHostToDevice, stream));\n\n        // Define block and grid sizes\n        dim3 blockDim(BLOCK_SIZE, BLOCK_SIZE);\n        dim3 gridDim((W + blockDim.x - 1) / blockDim.x, (H + blockDim.y - 1) / blockDim.y);\n\n        // Grid: (ceil(W / 16), ceil(H / 16), 1)        \n        // Block: (16, 16, 1)\n        void *args[] = {&inputImage_d, &outputImage_d, &W, &H};\n        CUDA_CHECK(cudaLaunchKernel((void*)k_sharpenImage, gridDim, blockDim, args, BLOCK_SIZE * BLOCK_SIZE * sizeof(int), stream));\n\n        CUDA_CHECK(cudaMemcpyAsync(outputImage_h, outputImage_d, W * H * sizeof(unsigned char), cudaMemcpyDeviceToHost, stream));\n\n        // Check tasks in the stream has completed\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n\n        for (int y = 0; y < H; y++) {\n            for (int x = 0; x < W; x++) {\n                assert(outputImage_h[y * W + x] == expectedOutput_h[y * W + x]);\n            }\n        }\n    }\n\n    //Test Case 2\n    {\n        unsigned char inputImage_h [W * H] = {\n            255, 254, 253, 252, 251,\n            250, 249, 248, 247, 246,\n            245, 244, 243, 242, 241,\n            240, 239, 238, 237, 236,\n            235, 234, 233, 232, 231\n        };\n\n        unsigned char expectedOutput_h [W * H] = {\n            255, 255, 255, 255, 255,\n            255, 249, 248, 247, 255,\n            255, 244, 243, 242, 255,\n            255, 239, 238, 237, 255,\n            255, 255, 255, 255, 255\n        };\n\n        CUDA_CHECK(cudaMemcpyAsync(inputImage_d, inputImage_h, W * H * sizeof(unsigned char), cudaMemcpyHostToDevice, stream));\n\n        // Define block and grid sizes\n        dim3 blockDim(BLOCK_SIZE, BLOCK_SIZE);\n        dim3 gridDim((W + blockDim.x - 1) / blockDim.x, (H + blockDim.y - 1) / blockDim.y);\n\n        // Grid: (ceil(W / 16), ceil(H / 16), 1)        \n        // Block: (16, 16, 1)\n        void *args[] = {&inputImage_d, &outputImage_d, &W, &H};\n        CUDA_CHECK(cudaLaunchKernel((void*)k_sharpenImage, gridDim, blockDim, args, BLOCK_SIZE * BLOCK_SIZE * sizeof(int), stream));\n\n        CUDA_CHECK(cudaMemcpyAsync(outputImage_h, outputImage_d, W * H * sizeof(unsigned char), cudaMemcpyDeviceToHost, stream));\n\n        // Check tasks in the stream has completed\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n\n        for (int y = 0; y < H; y++) {\n            for (int x = 0; x < W; x++) {\n                assert(outputImage_h[y * W + x] == expectedOutput_h[y * W + x]);\n            }\n        }\n    }\n\n    //Test Case 3\n    {\n        unsigned char inputImage_h [W * H] = {\n            0, 10, 20, 30, 40,\n            50, 60, 70, 80, 90,\n            100, 110, 120, 130, 140,\n            150, 160, 170, 180, 190,\n            200, 210, 220, 230, 240\n        };\n\n        unsigned char expectedOutput_h [W * H] = {\n            0, 0, 0, 10, 80,\n            90, 60, 70, 80, 190,\n            190, 110, 120, 130, 255,\n            255, 160, 170, 180, 255,\n            255, 255, 255, 255, 255\n        };\n\n        CUDA_CHECK(cudaMemcpyAsync(inputImage_d, inputImage_h, W * H * sizeof(unsigned char), cudaMemcpyHostToDevice, stream));\n\n        // Define block and grid sizes\n        dim3 blockDim(BLOCK_SIZE, BLOCK_SIZE);\n        dim3 gridDim((W + blockDim.x - 1) / blockDim.x, (H + blockDim.y - 1) / blockDim.y);\n\n        // Grid: (ceil(W / 16), ceil(H / 16), 1)        \n        // Block: (16, 16, 1)\n        void *args[] = {&inputImage_d, &outputImage_d, &W, &H};\n        CUDA_CHECK(cudaLaunchKernel((void*)k_sharpenImage, gridDim, blockDim, args, BLOCK_SIZE * BLOCK_SIZE * sizeof(int), stream));\n\n        CUDA_CHECK(cudaMemcpyAsync(outputImage_h, outputImage_d, W * H * sizeof(unsigned char), cudaMemcpyDeviceToHost, stream));\n\n        // Check tasks in the stream has completed\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n\n        for (int y = 0; y < H; y++) {\n            for (int x = 0; x < W; x++) {\n                assert(outputImage_h[y * W + x] == expectedOutput_h[y * W + x]);\n            }\n        }\n    }\n\n    //Test Case 4\n    {\n        unsigned char inputImage_h [W * H] = {\n            100, 90, 80, 70, 60,\n            50, 40, 30, 20, 10,\n            0, 10, 20, 30, 40,\n            50, 60, 70, 80, 90,\n            100, 110, 120, 130, 140\n        };\n\n        unsigned char expectedOutput_h [W * H] = {\n            255, 230, 210, 190, 220,\n            110, 20, 0, 0, 0,\n            0, 0, 0, 0, 70,\n            90, 60, 70, 80, 190,\n            255, 255, 255, 255, 255\n        };\n\n        CUDA_CHECK(cudaMemcpyAsync(inputImage_d, inputImage_h, W * H * sizeof(unsigned char), cudaMemcpyHostToDevice, stream));\n\n        // Define block and grid sizes\n        dim3 blockDim(BLOCK_SIZE, BLOCK_SIZE);\n        dim3 gridDim((W + blockDim.x - 1) / blockDim.x, (H + blockDim.y - 1) / blockDim.y);\n\n        // Grid: (ceil(W / 16), ceil(H / 16), 1)        \n        // Block: (16, 16, 1)\n        void *args[] = {&inputImage_d, &outputImage_d, &W, &H};\n        CUDA_CHECK(cudaLaunchKernel((void*)k_sharpenImage, gridDim, blockDim, args, BLOCK_SIZE * BLOCK_SIZE * sizeof(int), stream));\n\n        CUDA_CHECK(cudaMemcpyAsync(outputImage_h, outputImage_d, W * H * sizeof(unsigned char), cudaMemcpyDeviceToHost, stream));\n\n        // Check tasks in the stream has completed\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n\n        for (int y = 0; y < H; y++) {\n            for (int x = 0; x < W; x++) {\n                assert(outputImage_h[y * W + x] == expectedOutput_h[y * W + x]);\n            }\n        }\n    }\n\n    //Test Case 5\n    {\n        unsigned char inputImage_h [W * H] = {\n            5, 10, 15, 20, 25,\n            30, 35, 40, 45, 50,\n            55, 60, 65, 70, 75,\n            80, 85, 90, 95, 100,\n            105, 110, 115, 120, 125\n        };\n\n        unsigned char expectedOutput_h [W * H] = {\n            0, 0, 5, 15, 55,\n            55, 35, 40, 45, 105,\n            105, 60, 65, 70, 155,\n            155, 85, 90, 95, 205,\n            255, 245, 255, 255, 255\n        };\n\n        CUDA_CHECK(cudaMemcpyAsync(inputImage_d, inputImage_h, W * H * sizeof(unsigned char), cudaMemcpyHostToDevice, stream));\n\n        // Define block and grid sizes\n        dim3 blockDim(BLOCK_SIZE, BLOCK_SIZE);\n        dim3 gridDim((W + blockDim.x - 1) / blockDim.x, (H + blockDim.y - 1) / blockDim.y);\n\n        // Grid: (ceil(W / 16), ceil(H / 16), 1)        \n        // Block: (16, 16, 1)\n        void *args[] = {&inputImage_d, &outputImage_d, &W, &H};\n        CUDA_CHECK(cudaLaunchKernel((void*)k_sharpenImage, gridDim, blockDim, args, BLOCK_SIZE * BLOCK_SIZE * sizeof(int), stream));\n\n        CUDA_CHECK(cudaMemcpyAsync(outputImage_h, outputImage_d, W * H * sizeof(unsigned char), cudaMemcpyDeviceToHost, stream));\n\n        // Check tasks in the stream has completed\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n\n        for (int y = 0; y < H; y++) {\n            for (int x = 0; x < W; x++) {\n                assert(outputImage_h[y * W + x] == expectedOutput_h[y * W + x]);\n            }\n        }\n    }\n\n    //Test Case 6\n    {\n        unsigned char inputImage_h [W * H] = {\n            0, 0, 0, 0, 0,\n            0, 255, 255, 255, 0,\n            0, 255, 0, 255, 0,\n            0, 255, 255, 255, 0,\n            0, 0, 0, 0, 0\n        };\n\n        unsigned char expectedOutput_h [W * H] = {\n            0, 0, 0, 0, 0,\n            0, 255, 255, 255, 0,\n            0, 255, 0, 255, 0,\n            0, 255, 255, 255, 0,\n            0, 0, 0, 0, 0\n        };\n\n        CUDA_CHECK(cudaMemcpyAsync(inputImage_d, inputImage_h, W * H * sizeof(unsigned char), cudaMemcpyHostToDevice, stream));\n\n        // Define block and grid sizes\n        dim3 blockDim(BLOCK_SIZE, BLOCK_SIZE);\n        dim3 gridDim((W + blockDim.x - 1) / blockDim.x, (H + blockDim.y - 1) / blockDim.y);\n\n        // Grid: (ceil(W / 16), ceil(H / 16), 1)        \n        // Block: (16, 16, 1)\n        void *args[] = {&inputImage_d, &outputImage_d, &W, &H};\n        CUDA_CHECK(cudaLaunchKernel((void*)k_sharpenImage, gridDim, blockDim, args, BLOCK_SIZE * BLOCK_SIZE * sizeof(int), stream));\n\n        CUDA_CHECK(cudaMemcpyAsync(outputImage_h, outputImage_d, W * H * sizeof(unsigned char), cudaMemcpyDeviceToHost, stream));\n\n        // Check tasks in the stream has completed\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n\n        for (int y = 0; y < H; y++) {\n            for (int x = 0; x < W; x++) {\n                assert(outputImage_h[y * W + x] == expectedOutput_h[y * W + x]);\n            }\n        }\n    }\n\n    //Test Case 7\n    {\n        unsigned char inputImage_h [W * H] = {\n            255, 0, 255, 0, 255,\n            0, 255, 0, 255, 0,\n            255, 0, 255, 0, 255,\n            0, 255, 0, 255, 0,\n            255, 0, 255, 0, 255\n        };\n\n        unsigned char expectedOutput_h [W * H] = {\n            255, 0, 255, 0, 255,\n            0, 255, 0, 255, 0,\n            255, 0, 255, 0, 255,\n            0, 255, 0, 255, 0,\n            255, 0, 255, 0, 255\n        };\n\n        CUDA_CHECK(cudaMemcpyAsync(inputImage_d, inputImage_h, W * H * sizeof(unsigned char), cudaMemcpyHostToDevice, stream));\n\n        // Define block and grid sizes\n        dim3 blockDim(BLOCK_SIZE, BLOCK_SIZE);\n        dim3 gridDim((W + blockDim.x - 1) / blockDim.x, (H + blockDim.y - 1) / blockDim.y);\n\n        // Grid: (ceil(W / 16), ceil(H / 16), 1)        \n        // Block: (16, 16, 1)\n        void *args[] = {&inputImage_d, &outputImage_d, &W, &H};\n        CUDA_CHECK(cudaLaunchKernel((void*)k_sharpenImage, gridDim, blockDim, args, BLOCK_SIZE * BLOCK_SIZE * sizeof(int), stream));\n\n        CUDA_CHECK(cudaMemcpyAsync(outputImage_h, outputImage_d, W * H * sizeof(unsigned char), cudaMemcpyDeviceToHost, stream));\n\n        // Check tasks in the stream has completed\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n\n        for (int y = 0; y < H; y++) {\n            for (int x = 0; x < W; x++) {\n                assert(outputImage_h[y * W + x] == expectedOutput_h[y * W + x]);\n            }\n        }\n    }\n\n    // Cleanup\n    CUDA_CHECK(cudaFreeAsync(inputImage_d, stream));\n    CUDA_CHECK(cudaFreeAsync(outputImage_d, stream));\n    CUDA_CHECK(cudaStreamDestroy(stream)); \n}\n\n__global__ void k_sharpenImage(const unsigned char* inputImage, unsigned char* outputImage, int width, int height) {\n", "test": "int main() {\n    launch();\n}\n", "example_test": "    @example_test\n", "cuda_toolkit": "12.2"}
{"task_id": "CUDA/88", "date": "2025-03-31", "prompt": "Write a CUDA kernel for 1D signal convolution filter with smoothing and boundary condition handling.\n\nThe signature of the function is __global__ void k_convolve1D(const float* signal, const float* filter, float* output, int signalLen, int filterLen).\n\n>>> k_convolve1D({3.0f, 1.0f, 4.0f, 1.0f, 5.0f, 9.0f, 2.0f, 6.0f, 5.0f, 3.0f}, {0.25, 0.5, 0.25}, output, 10, 3)-> output: ({0.75, 1.75, 2.25, 2.50, 2.75, 5.00, 6.25, 4.75, 4.75, 4.75})\n>>> k_convolve1D({1, 2, 3, 4, 5, 6, 7, 8, 9, 10}, {0.25, 0.5, 0.25}, output, 10, 3)-> output: ({0.25, 1.00, 2.00, 3.00, 4.00, 5.00, 6.00, 7.00, 8.00, 9.00}) \n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_70 -arch=sm_60", "ld_flags": "", "declaration": "#include <cuda_runtime.h>\n#include <cstdio>\n\n#define CUDA_CHECK(call) {                                                        \\\n        cudaError_t err = call;                                                   \\\n        if (err != cudaSuccess) {                                                 \\\n            fprintf(stderr, \"CUDA error in file '%s' in line %d: %s.\\n\",          \\\n                    __FILE__, __LINE__, cudaGetErrorString(err));                 \\\n            exit(EXIT_FAILURE);                                                   \\\n        }                                                                         \\\n}\n\n#undef NDEBUG\n#include <assert.h>\n\n#define TOLERANCE 1E-2\n\n__global__ void k_convolve1D(const float* signal, const float* filter, float* output, int signalLen, int filterLen);\n\nvoid launch() {\n    // Use a CUDA stream for asynchronous operations\n    cudaStream_t stream;\n    CUDA_CHECK(cudaStreamCreate(&stream));\n\n    int signalLen = 10;\n    int filterLen = 3;\n    // Allocate device memory\n    float* signal_d, * filter_d, * output_d;\n    // Allocate and check device memory\n    CUDA_CHECK(cudaMallocAsync(&signal_d, signalLen * sizeof(float), stream));\n    CUDA_CHECK(cudaMallocAsync(&filter_d, filterLen * sizeof(float), stream));\n    CUDA_CHECK(cudaMallocAsync(&output_d, signalLen * sizeof(float), stream));\n\n    //Test Case 1\n    {\n        // Non-sequential input signal and kernel\n        float signal_h[10] = {3.0f, 1.0f, 4.0f, 1.0f, 5.0f, 9.0f, 2.0f, 6.0f, 5.0f, 3.0f};\n        float filter_h[3] = { 0.25, 0.5, 0.25 };\n        float output_h[10] = { 0 };\n\n        float expectedOutput_h[10] = { 0.75, 1.75, 2.25, 2.50, 2.75, 5.00, 6.25, 4.75, 4.75, 4.75 };\n    \n        // Copy data to device\n        CUDA_CHECK(cudaMemcpyAsync(signal_d, signal_h, signalLen * sizeof(float), cudaMemcpyHostToDevice, stream));\n        CUDA_CHECK(cudaMemcpyAsync(filter_d, filter_h, filterLen * sizeof(float), cudaMemcpyHostToDevice, stream));\n\n        // Define block size and grid size\n        int blockSize = 16;\n        int gridSize = (signalLen + blockSize - 1) / blockSize;\n\n        // Block: (16, 1, 1)\n        // Grid: (ceil(signalLen / 16), 1, 1)\n        void *args[] = {&signal_d, &filter_d, &output_d, &signalLen, &filterLen};\n        CUDA_CHECK(cudaLaunchKernel((void*)k_convolve1D, gridSize, blockSize, args, blockSize * sizeof(int), stream));\n\n        // Copy results back to host\n        CUDA_CHECK(cudaMemcpyAsync(output_h, output_d, signalLen * sizeof(float), cudaMemcpyDeviceToHost, stream));\n    \n        // Check tasks in the stream has completed\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n\n        // Validate output\n        for (int i = 0; i < signalLen; ++i) {\n            assert(abs(output_h[i] - expectedOutput_h[i]) < TOLERANCE);\n        }\n    }\n\n    //Test Case 2\n    {\n        // Non-sequential input signal and kernel\n        float signal_h[10] = {1.0f, 2.0f, 3.0f, 4.0f, 5.0f, 6.0f, 7.0f, 8.0f, 9.0f, 10.0f};\n        float filter_h[3] = { 0.25, 0.5, 0.25 };\n        float output_h[10] = { 0 };\n        float expectedOutput_h[10] = { 0.25, 1.00, 2.00, 3.00, 4.00, 5.00, 6.00, 7.00, 8.00, 9.00 };\n\n        // Copy data to device\n        CUDA_CHECK(cudaMemcpyAsync(signal_d, signal_h, signalLen * sizeof(float), cudaMemcpyHostToDevice, stream));\n        CUDA_CHECK(cudaMemcpyAsync(filter_d, filter_h, filterLen * sizeof(float), cudaMemcpyHostToDevice, stream));\n\n        // Define block size and grid size\n        int blockSize = 16;\n        int gridSize = (signalLen + blockSize - 1) / blockSize;\n\n        // Block: (16, 1, 1)\n        // Grid: (ceil(signalLen / 16), 1, 1)\n        void *args[] = {&signal_d, &filter_d, &output_d, &signalLen, &filterLen};\n        CUDA_CHECK(cudaLaunchKernel((void*)k_convolve1D, gridSize, blockSize, args, blockSize * sizeof(int), stream));\n\n        // Copy results back to host\n        CUDA_CHECK(cudaMemcpyAsync(output_h, output_d, signalLen * sizeof(float), cudaMemcpyDeviceToHost, stream));\n\n        // Check tasks in the stream has completed\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n\n        // Validate output\n        for (int i = 0; i < signalLen; ++i) {\n            assert(abs(output_h[i] - expectedOutput_h[i]) < TOLERANCE);\n        }\n    }\n\n    //Test Case 3\n    {\n        // Non-sequential input signal and kernel\n        float signal_h[10] = {10.0f, 9.0f, 8.0f, 7.0f, 6.0f, 5.0f, 4.0f, 3.0f, 2.0f, 1.0f};\n        float filter_h[3] = { 0.25, 0.5, 0.25 };\n        float output_h[10] = { 0 };\n        float expectedOutput_h[10] = { 2.50, 7.25, 9.00, 8.00, 7.00, 6.00, 5.00, 4.00, 3.00, 2.00 };\n\n        // Copy data to device\n        CUDA_CHECK(cudaMemcpyAsync(signal_d, signal_h, signalLen * sizeof(float), cudaMemcpyHostToDevice, stream));\n        CUDA_CHECK(cudaMemcpyAsync(filter_d, filter_h, filterLen * sizeof(float), cudaMemcpyHostToDevice, stream));\n\n        // Define block size and grid size\n        int blockSize = 16;\n        int gridSize = (signalLen + blockSize - 1) / blockSize;\n\n        // Block: (16, 1, 1)\n        // Grid: (ceil(signalLen / 16), 1, 1)\n        void *args[] = {&signal_d, &filter_d, &output_d, &signalLen, &filterLen};\n        CUDA_CHECK(cudaLaunchKernel((void*)k_convolve1D, gridSize, blockSize, args, blockSize * sizeof(int), stream));\n\n        // Copy results back to host\n        CUDA_CHECK(cudaMemcpyAsync(output_h, output_d, signalLen * sizeof(float), cudaMemcpyDeviceToHost, stream));\n\n        // Check tasks in the stream has completed\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n\n        // Validate output\n        for (int i = 0; i < signalLen; ++i) {\n            assert(abs(output_h[i] - expectedOutput_h[i]) < TOLERANCE);\n        }\n    }\n\n    //Test Case 4\n    {\n        // Non-sequential input signal and kernel\n        float signal_h[10] = {5.0f, 1.0f, 5.0f, 1.0f, 5.0f, 1.0f, 5.0f, 1.0f, 5.0f, 1.0f};\n        float filter_h[3] = { 0.25, 0.5, 0.25 };\n        float output_h[10] = { 0 };\n        float expectedOutput_h[10] = { 1.25, 2.75, 3.00, 3.00, 3.00, 3.00, 3.00, 3.00, 3.00, 3.00 };\n\n        // Copy data to device\n        CUDA_CHECK(cudaMemcpyAsync(signal_d, signal_h, signalLen * sizeof(float), cudaMemcpyHostToDevice, stream));\n        CUDA_CHECK(cudaMemcpyAsync(filter_d, filter_h, filterLen * sizeof(float), cudaMemcpyHostToDevice, stream));\n\n        // Define block size and grid size\n        int blockSize = 16;\n        int gridSize = (signalLen + blockSize - 1) / blockSize;\n\n        // Block: (16, 1, 1)\n        // Grid: (ceil(signalLen / 16), 1, 1)\n        void *args[] = {&signal_d, &filter_d, &output_d, &signalLen, &filterLen};\n        CUDA_CHECK(cudaLaunchKernel((void*)k_convolve1D, gridSize, blockSize, args, blockSize * sizeof(int), stream));\n\n        // Copy results back to host\n        CUDA_CHECK(cudaMemcpyAsync(output_h, output_d, signalLen * sizeof(float), cudaMemcpyDeviceToHost, stream));\n    \n        // Check tasks in the stream has completed\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n\n        // Validate output\n        for (int i = 0; i < signalLen; ++i) {\n            assert(abs(output_h[i] - expectedOutput_h[i]) < TOLERANCE);\n        }\n    }\n\n    //Test Case 5\n    {\n        // Non-sequential input signal and kernel\n        float signal_h[10] = {7.0f, 3.0f, 9.0f, 2.0f, 8.0f, 1.0f, 6.0f, 4.0f, 10.0f, 5.0f};\n        float filter_h[3] = { 0.25, 0.5, 0.25 };\n        float output_h[10] = { 0 };\n\n        float expectedOutput_h[10] = { 1.75, 4.25, 5.50, 5.75, 5.25, 4.75, 4.00, 4.25, 6.00, 7.25 };\n\n        // Copy data to device\n        CUDA_CHECK(cudaMemcpyAsync(signal_d, signal_h, signalLen * sizeof(float), cudaMemcpyHostToDevice, stream));\n        CUDA_CHECK(cudaMemcpyAsync(filter_d, filter_h, filterLen * sizeof(float), cudaMemcpyHostToDevice, stream));\n\n        // Define block size and grid size\n        int blockSize = 16;\n        int gridSize = (signalLen + blockSize - 1) / blockSize;\n\n        // Block: (16, 1, 1)\n        // Grid: (ceil(signalLen / 16), 1, 1)\n        void *args[] = {&signal_d, &filter_d, &output_d, &signalLen, &filterLen};\n        CUDA_CHECK(cudaLaunchKernel((void*)k_convolve1D, gridSize, blockSize, args, blockSize * sizeof(int), stream));\n\n        // Copy results back to host\n        CUDA_CHECK(cudaMemcpyAsync(output_h, output_d, signalLen * sizeof(float), cudaMemcpyDeviceToHost, stream));\n\n        // Check tasks in the stream has completed\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n\n        // Validate output\n        for (int i = 0; i < signalLen; ++i) {\n            assert(abs(output_h[i] - expectedOutput_h[i]) < TOLERANCE);\n        }\n    }\n\n    //Test Case 6\n    {\n        // Non-sequential input signal and kernel\n        float signal_h[10] = {2.0f, 2.0f, 2.0f, 2.0f, 2.0f, 2.0f, 2.0f, 2.0f, 2.0f, 2.0f};\n        float filter_h[3] = { 0.25, 0.5, 0.25 };\n        float output_h[10] = { 0 };\n\n        float expectedOutput_h[10] = { 0.50, 1.50, 2.00, 2.00, 2.00, 2.00, 2.00, 2.00, 2.00, 2.00 };\n\n        // Copy data to device\n        CUDA_CHECK(cudaMemcpyAsync(signal_d, signal_h, signalLen * sizeof(float), cudaMemcpyHostToDevice, stream));\n        CUDA_CHECK(cudaMemcpyAsync(filter_d, filter_h, filterLen * sizeof(float), cudaMemcpyHostToDevice, stream));\n\n        // Define block size and grid size\n        int blockSize = 16;\n        int gridSize = (signalLen + blockSize - 1) / blockSize;\n\n        // Block: (16, 1, 1)\n        // Grid: (ceil(signalLen / 16), 1, 1)\n        void *args[] = {&signal_d, &filter_d, &output_d, &signalLen, &filterLen};\n        CUDA_CHECK(cudaLaunchKernel((void*)k_convolve1D, gridSize, blockSize, args, blockSize * sizeof(int), stream));\n\n        // Copy results back to host\n        CUDA_CHECK(cudaMemcpyAsync(output_h, output_d, signalLen * sizeof(float), cudaMemcpyDeviceToHost, stream));\n    \n        // Check tasks in the stream has completed\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n\n        // Validate output\n        for (int i = 0; i < signalLen; ++i) {\n            assert(abs(output_h[i] - expectedOutput_h[i]) < TOLERANCE);\n        }\n    }\n\n    //Test Case 7\n    {\n        // Non-sequential input signal and kernel\n        float signal_h[10] = {-3.0f, 1.0f, -4.0f, 1.0f, -5.0f, 9.0f, -2.0f, 6.0f, -5.0f, 3.0f};\n        float filter_h[3] = { 0.25, 0.5, 0.25 };\n        float output_h[10] = { 0 };\n\n        float expectedOutput_h[10] = { -0.75, -1.25, -1.25, -1.50, -1.75, 0.00, 2.75, 2.75, 1.25, -0.25 };\n\n        // Copy data to device\n        CUDA_CHECK(cudaMemcpyAsync(signal_d, signal_h, signalLen * sizeof(float), cudaMemcpyHostToDevice, stream));\n        CUDA_CHECK(cudaMemcpyAsync(filter_d, filter_h, filterLen * sizeof(float), cudaMemcpyHostToDevice, stream));\n\n        // Define block size and grid size\n        int blockSize = 16;\n        int gridSize = (signalLen + blockSize - 1) / blockSize;\n\n        // Block: (16, 1, 1)\n        // Grid: (ceil(signalLen / 16), 1, 1)\n        void *args[] = {&signal_d, &filter_d, &output_d, &signalLen, &filterLen};\n        CUDA_CHECK(cudaLaunchKernel((void*)k_convolve1D, gridSize, blockSize, args, blockSize * sizeof(int), stream));\n\n        // Copy results back to host\n        CUDA_CHECK(cudaMemcpyAsync(output_h, output_d, signalLen * sizeof(float), cudaMemcpyDeviceToHost, stream));\n\n        // Check tasks in the stream has completed\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n\n        // Validate output\n        for (int i = 0; i < signalLen; ++i) {\n            assert(abs(output_h[i] - expectedOutput_h[i]) < TOLERANCE);\n        }\n    }\n\n    // Free device memory\n    CUDA_CHECK(cudaFreeAsync(signal_d, stream));\n    CUDA_CHECK(cudaFreeAsync(filter_d, stream));\n    CUDA_CHECK(cudaFreeAsync(output_d, stream));\n    CUDA_CHECK(cudaStreamDestroy(stream));\n}\n\n__global__ void k_convolve1D(const float* signal, const float* filter, float* output, int signalLen, int filterLen) {\n", "test": "int main() {\n    launch();\n}\n", "example_test": "    @example_test\n", "cuda_toolkit": "12.2"}
{"task_id": "CUDA/89", "date": "2025-03-31", "prompt": "Write a CUDA kernel to find the L2 norm of a vector that utilizes shared memory, atomic operations, and reduction.\n\nThe signature of the function is __global__ void k_l2Norm(float *input, float *result, int n, bool square), where input is a vector for which L2 norm need to be calculated, result is a pointer where the output is stored, n is the total number of elements in the vector, and square controls whether the elements are squared before summing or summed directly.\n\n\n>>> k_l2Norm({2, 5, 1, 8}, result, 4, true) -> result: 9.695360\n>>> k_l2Norm({3, 9, 5, 7}, result, 4, true) -> result: 12.806249\n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_70 -arch=sm_60", "ld_flags": "", "declaration": "#include <cuda_runtime.h>\n#include <algorithm>\n#include <cstdio>\n#include <cmath>\n\n#define EPSILON 1e-5  // Tolerance for floating-point comparison\n#define CUDA_CHECK(call)                                                                               \\\ndo {                                                                                                  \\\n    cudaError_t error = call;                                                                         \\\n    if (error != cudaSuccess) {                                                                       \\\n        fprintf(stderr, \"CUDA error at %s:%d - %s\\n\", __FILE__, __LINE__, cudaGetErrorString(error)); \\\n        exit(EXIT_FAILURE);                                                                           \\\n    }                                                                                                 \\\n} while (0)\n\n#undef NDEBUG\n#include <assert.h>\n\n//Kernel to find the L2 norm of a vector\n__global__ void k_l2Norm(float *input, float *result, int n, bool square);\n\nvoid launch() {\n    const int testCaseCount = 8; // Number of test cases\n    int vectorSize[testCaseCount] = {4, 4, 8, 16, 32, 64, 100, 100000}; // Sizes of the vectors in each test case\n    const float expectedOutput[testCaseCount] = {9.695360, 12.806249, 21.633308, 36.633320, 196.822250, 378.970978, 581.678589, 316.22776601683796}; // Expected results for each test\n    int maxVectorSize = *std::max_element(vectorSize, vectorSize + testCaseCount);    \n\n    // Input vectors for the tests\n    float inputVector[testCaseCount][maxVectorSize] =  {\n        {2, 5, 1, 8},                                                     // test case 1\n        {3, 9, 5, 7},                                                     // test case 2\n        {9, 11, 6, 9, 0, 8, 7, 6},                                        // test case 3\n        {2, 5, 1, 8, 5, 10, 15, 20, 3, 9, 5, 7, 3, 9, 10, 12},            // test case 4\n        {32, 4, 98, 7, 18, 15, 3, 8, 99, 12, 11, 1, 24, 97, 6, 13,\n         30, 9, 14, 20, 2, 5, 27, 10, 21, 22, 17, 26, 16, 28, 29, 31},    // test case 5\n        {32, 4, 98, 7, 18, 15, 3, 8, 99, 12, 11, 1, 24, 97, 6, 13,\n         30, 9, 14, 20, 2, 5, 27, 10, 21, 22, 17, 26, 16, 28, 29, 31,\n         33, 38, 93, 40, 95, 41, 34, 36, 94, 39, 43, 35, 44, 48, 37, 42,\n         49, 54, 77, 56, 79, 57, 50, 52, 78, 55, 59, 51, 60, 64, 53, 58}, // test case 6\n        {32, 4, 98, 7, 18, 15, 3, 8, 99, 12, 11, 1, 24, 97, 6, 13,\n         30, 9, 14, 20, 2, 5, 27, 10, 21, 22, 17, 26, 16, 28, 29, 31,\n         33, 38, 93, 40, 95, 41, 34, 36, 94, 39, 43, 35, 44, 48, 37, 42,\n         49, 54, 77, 56, 79, 57, 50, 52, 78, 55, 59, 51, 60, 64, 53, 58,\n         65, 70, 61, 72, 63, 73, 66, 68, 62, 71, 75, 67, 76, 80, 69, 74,\n         81, 86, 45, 88, 47, 89, 82, 84, 46, 87, 91, 83, 92, 96, 85, 90,\n         25, 23, 19, 100},                                                 // test case 7\n         {1}\n         };\n\n    // set all elements of the test case 8 to 1\n    for (int j = 0; j < 100000; ++j) {\n        inputVector[7][j]=1;\n    }\n\n    // Use a CUDA stream for asynchronous operations\n    cudaStream_t stream;\n    CUDA_CHECK(cudaStreamCreate(&stream));\n\n    int threadsPerBlock = 256, blocksPerGrid=0;\n    bool square;\n    float *input_d, *result_d, l2norm=0;\n\n    // Allocate memory on device\n    CUDA_CHECK(cudaMallocAsync(&input_d, maxVectorSize * sizeof(float), stream));\n    int maxBlocksPerGrid = (maxVectorSize + threadsPerBlock - 1) / threadsPerBlock;\n    CUDA_CHECK(cudaMallocAsync(&result_d, maxBlocksPerGrid * sizeof(float), stream));\n\n    // Loop to execute each test case\n    for (int i = 0; i < testCaseCount; ++i) {\n        blocksPerGrid = (vectorSize[i] + threadsPerBlock - 1) / threadsPerBlock;\n        float result_h[blocksPerGrid] = {0};\n\n        // Copy input data to device\n        CUDA_CHECK(cudaMemcpyAsync(input_d, inputVector[i], vectorSize[i] * sizeof(float), cudaMemcpyHostToDevice, stream));\n        CUDA_CHECK(cudaMemsetAsync(result_d, 0.0f, blocksPerGrid * sizeof(float), stream));\n        \n        square=true; // this is to calculate the square of each element\n        void *argsL2Norm[] = {&input_d, &result_d, &vectorSize[i], &square};\n        CUDA_CHECK(cudaLaunchKernel((void*)k_l2Norm, blocksPerGrid, threadsPerBlock, argsL2Norm, threadsPerBlock * sizeof(float), stream));\n\n        square=false; // this is to sum the elements of the vector\n        while(blocksPerGrid>1) {\n          void *argsL2Norm[] = {&result_d, &result_d, &blocksPerGrid, &square};\n          CUDA_CHECK(cudaLaunchKernel((void*)k_l2Norm, blocksPerGrid, threadsPerBlock, argsL2Norm, threadsPerBlock * sizeof(float), stream));\n\n          blocksPerGrid = (blocksPerGrid + threadsPerBlock - 1) / threadsPerBlock;\n        }\n\n        CUDA_CHECK(cudaMemcpyAsync(result_h, result_d, blocksPerGrid * sizeof(float), cudaMemcpyDeviceToHost, stream));\n\n        // Check tasks in the stream has completed\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n\n        l2norm = sqrt(result_h[0]);\n\n        assert(fabs(l2norm - expectedOutput[i]) <= EPSILON);\n    }\n\n    // Free device memory\n    CUDA_CHECK(cudaFreeAsync(input_d, stream));\n    CUDA_CHECK(cudaFreeAsync(result_d, stream));\n    CUDA_CHECK(cudaStreamDestroy(stream));\n}\n\n__global__ void k_l2Norm(float *input, float *result, int n, bool square) {\n", "test": "int main() {\n    launch();\n}\n", "example_test": "    @example_test\n", "cuda_toolkit": "12.2"}
{"task_id": "CUDA/90", "date": "2025-03-31", "prompt": "By leveraging CUDA device memory, write a CUDA kernel to find the distance of two sets of geographical coordinates, A and B. Here, $A=((lat_{a0}, long_{a0}), (lat_{a1}, long_{a1}), (lat_{a2}, long_{a2}), \\cdots (lat_a{n-1}, long_a{n-1}))$ and $B=((lat_{b0}, long_{b0}), (lat_{b1}, long_{b1}), (lat_{b2}, long_{b2}), \\cdots , (lat_b{n-1}, long_b{n-1}))$.\nThe distance between each pair of A and B should be in kilometers, such as $Output = (dist(a_0, b_0), dist(a_1,b_1), dist(a_2,b_2) \\cdots )$ in km, here each $a_i = (lat_{ai}, long_{ai})$, and each $b_i = (lat_{bi}, long_{bi})$.\n\nThe signature of the kernel is __global__ void k_GeoDistance(double *lat1, double *lon1, double *lat2, double *lon2, double *result, int n) where lat1 and lon1  are arrays containing the latitudes and longitudes of the first set of coordinates, lat1 and lon1  are arrays containing the latitudes and longitudes of the second set of coordinates, result is an array where the calculated distances will be stored, n is the number of coordinate pairs to process.\n\n>>> k_MatrixMul(A{1,2,3}{4,5,6}, B{7,8}{9,10}{11,12}) --> Output{58,64}{139,154}\n>>> k_MatrixMul(A{1,0,2}{-1,3,1}{2,-2,0}, B{3,1,2}{2,1,1}{1,0,1}) --> Output{5,1,4}{4,2,4}{4,0,4} \n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_70 -arch=sm_60", "ld_flags": "", "declaration": "#include <stdio.h>\n#include <math.h>\n#define EPSILON (1e-2)  // Tolerance for floating-point comparison\n#define R 6371 // Earth's radius in kilometers\n#undef NDEBUG\n#include <assert.h>\n#define FACTOR (M_PI / 180.0)\n\n#define CUDA_CHECK(call)                                                 \\\ndo {                                                                     \\\n    cudaError_t error = call;                                           \\\n    if (error != cudaSuccess) {                                         \\\n        fprintf(stderr, \"CUDA error at %s:%d - %s\\n\", __FILE__, __LINE__, cudaGetErrorString(error)); \\\n        exit(EXIT_FAILURE);                                             \\\n    }                                                                   \\\n} while (0)\n\n\n__global__ void k_GeoDistance(double *lat1, double *lon1, double *lat2, double *lon2, double *result, int n);\n\nvoid launch() {\n\n    int MAX_NUM_POINTS = 10;\n    double *d_lat1, *d_lon1, *d_lat2, *d_lon2, *d_result;\n    \n    // Use a CUDA stream for asynchronous operations\n    cudaStream_t stream;\n    CUDA_CHECK(cudaStreamCreate(&stream));\n\n    // Allocate memory on the device\n    CUDA_CHECK(cudaMallocAsync(&d_lat1, MAX_NUM_POINTS * sizeof(double), stream));\n    CUDA_CHECK(cudaMallocAsync(&d_lon1, MAX_NUM_POINTS * sizeof(double), stream));\n    CUDA_CHECK(cudaMallocAsync(&d_lat2, MAX_NUM_POINTS * sizeof(double), stream));\n    CUDA_CHECK(cudaMallocAsync(&d_lon2, MAX_NUM_POINTS * sizeof(double), stream));\n    CUDA_CHECK(cudaMallocAsync(&d_result, MAX_NUM_POINTS * sizeof(double), stream));\n    \n    //Test case: 1\n    {\n        int NUM_POINTS = 2;\n        double lat1_h[NUM_POINTS] = {34.052235, 48.856613};\n        double lon1_h[NUM_POINTS] = {-118.243683, 2.352222};\n        double lat2_h[NUM_POINTS] = {35.689487, 19.076090};\n        double lon2_h[NUM_POINTS] = {139.691711, 72.877426};\n        double result_h[NUM_POINTS];\n        double expectedOutput[NUM_POINTS] = {8815.47, 7009.30};\n\n        // Copy data from host to device\n        CUDA_CHECK(cudaMemcpyAsync(d_lat1, lat1_h, NUM_POINTS * sizeof(double), cudaMemcpyHostToDevice, stream));\n        CUDA_CHECK(cudaMemcpyAsync(d_lon1, lon1_h, NUM_POINTS * sizeof(double), cudaMemcpyHostToDevice, stream));\n        CUDA_CHECK(cudaMemcpyAsync(d_lat2, lat2_h, NUM_POINTS * sizeof(double), cudaMemcpyHostToDevice, stream));\n        CUDA_CHECK(cudaMemcpyAsync(d_lon2, lon2_h, NUM_POINTS * sizeof(double), cudaMemcpyHostToDevice, stream));\n\n        // Launch the kernel\n        int threadsPerBlock = 256;\n        int blocksPerGrid = (NUM_POINTS + threadsPerBlock - 1) / threadsPerBlock;\n        // Grid: (ceil(NUM_POINTS / 256), 1, 1)\n        // Block: (256, 1, 1)\n        void *args[] = {&d_lat1, &d_lon1, &d_lat2, &d_lon2, &d_result, &NUM_POINTS};\n        cudaLaunchKernel((void*)k_GeoDistance, blocksPerGrid, threadsPerBlock, args, 0, stream);\n\n        // Copy result back to host\n        CUDA_CHECK(cudaMemcpyAsync(result_h, d_result, NUM_POINTS * sizeof(double), cudaMemcpyDeviceToHost, stream));\n\n        // Check tasks in the stream has completed\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n\n        for (int i = 0; i < NUM_POINTS; ++i) {\n            assert(fabs(result_h[i] - expectedOutput[i]) <= EPSILON);\n        }\n    }\n\n    //Test case: 2\n    {\n        int NUM_POINTS = 3;\n        double lat1_h[NUM_POINTS] = {51.507351, 40.712776, 35.689487};\n        double lon1_h[NUM_POINTS] = {-0.127758, -74.006058, 139.691711};\n        double lat2_h[NUM_POINTS] = {40.712776, 51.507351, 34.052235};\n        double lon2_h[NUM_POINTS] = {-74.006058, -0.127758, -118.243683};\n        double result_h[NUM_POINTS];\n        double expectedOutput[NUM_POINTS] = {5570.23, 5570.23, 8815.47};\n\n        // Copy data from host to device\n        CUDA_CHECK(cudaMemcpyAsync(d_lat1, lat1_h, NUM_POINTS * sizeof(double), cudaMemcpyHostToDevice, stream));\n        CUDA_CHECK(cudaMemcpyAsync(d_lon1, lon1_h, NUM_POINTS * sizeof(double), cudaMemcpyHostToDevice, stream));\n        CUDA_CHECK(cudaMemcpyAsync(d_lat2, lat2_h, NUM_POINTS * sizeof(double), cudaMemcpyHostToDevice, stream));\n        CUDA_CHECK(cudaMemcpyAsync(d_lon2, lon2_h, NUM_POINTS * sizeof(double), cudaMemcpyHostToDevice, stream));\n\n        // Launch the kernel\n        int threadsPerBlock = 256;\n        int blocksPerGrid = (NUM_POINTS + threadsPerBlock - 1) / threadsPerBlock;\n        // Grid: (ceil(NUM_POINTS / 256), 1, 1)\n        // Block: (256, 1, 1)\n        void *args[] = {&d_lat1, &d_lon1, &d_lat2, &d_lon2, &d_result, &NUM_POINTS};\n        cudaLaunchKernel((void*)k_GeoDistance, blocksPerGrid, threadsPerBlock, args, 0, stream);\n\n        // Copy result back to host\n        CUDA_CHECK(cudaMemcpyAsync(result_h, d_result, NUM_POINTS * sizeof(double), cudaMemcpyDeviceToHost, stream));\n\n        // Check tasks in the stream has completed\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n\n        for (int i = 0; i < NUM_POINTS; ++i) {\n            assert(fabs(result_h[i] - expectedOutput[i]) <= EPSILON);\n        }\n    }\n\n    //Test case: 3\n    {\n        int NUM_POINTS = 5;\n        double lat1_h[NUM_POINTS] = {34.052235, 48.856613, 51.507351, 40.712776, 35.689487};\n        double lon1_h[NUM_POINTS] = {-118.243683, 2.352222, -0.127758, -74.006058, 139.691711};\n        double lat2_h[NUM_POINTS] = {35.689487, 19.076090, 40.712776, 51.507351, 34.052235};\n        double lon2_h[NUM_POINTS] = {139.691711, 72.877426, -74.006058, -0.127758, -118.243683};\n        double result_h[NUM_POINTS];\n        double expectedOutput[NUM_POINTS] = {8815.47, 7009.30, 5570.23, 5570.23, 8815.47};\n\n        // Copy data from host to device\n        CUDA_CHECK(cudaMemcpyAsync(d_lat1, lat1_h, NUM_POINTS * sizeof(double), cudaMemcpyHostToDevice, stream));\n        CUDA_CHECK(cudaMemcpyAsync(d_lon1, lon1_h, NUM_POINTS * sizeof(double), cudaMemcpyHostToDevice, stream));\n        CUDA_CHECK(cudaMemcpyAsync(d_lat2, lat2_h, NUM_POINTS * sizeof(double), cudaMemcpyHostToDevice, stream));\n        CUDA_CHECK(cudaMemcpyAsync(d_lon2, lon2_h, NUM_POINTS * sizeof(double), cudaMemcpyHostToDevice, stream));\n\n        // Launch the kernel\n        int threadsPerBlock = 256;\n        int blocksPerGrid = (NUM_POINTS + threadsPerBlock - 1) / threadsPerBlock;\n        // Grid: (ceil(NUM_POINTS / 256), 1, 1)\n        // Block: (256, 1, 1)\n        void *args[] = {&d_lat1, &d_lon1, &d_lat2, &d_lon2, &d_result, &NUM_POINTS};\n        cudaLaunchKernel((void*)k_GeoDistance, blocksPerGrid, threadsPerBlock, args, 0, stream);\n\n        // Copy result back to host\n        CUDA_CHECK(cudaMemcpyAsync(result_h, d_result, NUM_POINTS * sizeof(double), cudaMemcpyDeviceToHost, stream));\n\n        // Check tasks in the stream has completed\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n\n        for (int i = 0; i < NUM_POINTS; ++i) {\n            assert(fabs(result_h[i] - expectedOutput[i]) <= EPSILON);\n        }\n    }\n\n    //Test case: 4\n    {\n        int NUM_POINTS = 5;\n        double lat1_h[NUM_POINTS] = {33.052235, 48.856613, 50.507351, 39.712776, 35.689487};\n        double lon1_h[NUM_POINTS] = {-118.243683, 2.352222, -0.127758, -74.006058, 138.691711};\n        double lat2_h[NUM_POINTS] = {35.689487, 18.076090, 40.712776, 51.507351, 34.052235};\n        double lon2_h[NUM_POINTS] = {139.691711, 72.877426, -74.006058, -0.127758, -118.243683};\n        double result_h[NUM_POINTS];\n        double expectedOutput[NUM_POINTS] = {8881.05, 7089.39, 5605.93, 5640.37, 8889.72};\n\n        // Copy data from host to device\n        CUDA_CHECK(cudaMemcpyAsync(d_lat1, lat1_h, NUM_POINTS * sizeof(double), cudaMemcpyHostToDevice, stream));\n        CUDA_CHECK(cudaMemcpyAsync(d_lon1, lon1_h, NUM_POINTS * sizeof(double), cudaMemcpyHostToDevice, stream));\n        CUDA_CHECK(cudaMemcpyAsync(d_lat2, lat2_h, NUM_POINTS * sizeof(double), cudaMemcpyHostToDevice, stream));\n        CUDA_CHECK(cudaMemcpyAsync(d_lon2, lon2_h, NUM_POINTS * sizeof(double), cudaMemcpyHostToDevice, stream));\n\n        // Launch the kernel\n        int threadsPerBlock = 256;\n        int blocksPerGrid = (NUM_POINTS + threadsPerBlock - 1) / threadsPerBlock;\n        // Grid: (ceil(NUM_POINTS / 256), 1, 1)\n        // Block: (256, 1, 1)\n        void *args[] = {&d_lat1, &d_lon1, &d_lat2, &d_lon2, &d_result, &NUM_POINTS};\n        cudaLaunchKernel((void*)k_GeoDistance, blocksPerGrid, threadsPerBlock, args, 0, stream);\n\n        // Copy result back to host\n        CUDA_CHECK(cudaMemcpyAsync(result_h, d_result, NUM_POINTS * sizeof(double), cudaMemcpyDeviceToHost, stream));\n\n        // Check tasks in the stream has completed\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n\n        for (int i = 0; i < NUM_POINTS; ++i) {\n            assert(fabs(result_h[i] - expectedOutput[i]) <= EPSILON);\n        }\n    }\n\n    //Test case: 5\n    {\n        int NUM_POINTS = 6;\n        double lat1_h[NUM_POINTS] = {-33.868820, 37.774929, 25.276987, 55.755826, 19.076090, 12.971619};\n        double lon1_h[NUM_POINTS] = {151.209290, -122.419418, 55.296249, 37.617300, 72.877426, 77.594566};\n        double lat2_h[NUM_POINTS] = {55.755826, 48.856613, 25.276987, 37.774929, -33.868820, 28.704059};\n        double lon2_h[NUM_POINTS] = {37.617300, 2.352222, 55.296249, -122.419418, 151.209290, 77.102491};\n        double result_h[NUM_POINTS];\n        double expectedOutput[NUM_POINTS] = {14496.16, 8953.39, 0.00, 9444.18, 10156.85, 1750.11};\n\n        // Copy data from host to device\n        CUDA_CHECK(cudaMemcpyAsync(d_lat1, lat1_h, NUM_POINTS * sizeof(double), cudaMemcpyHostToDevice, stream));\n        CUDA_CHECK(cudaMemcpyAsync(d_lon1, lon1_h, NUM_POINTS * sizeof(double), cudaMemcpyHostToDevice, stream));\n        CUDA_CHECK(cudaMemcpyAsync(d_lat2, lat2_h, NUM_POINTS * sizeof(double), cudaMemcpyHostToDevice, stream));\n        CUDA_CHECK(cudaMemcpyAsync(d_lon2, lon2_h, NUM_POINTS * sizeof(double), cudaMemcpyHostToDevice, stream));\n\n        // Launch the kernel\n        int threadsPerBlock = 256;\n        int blocksPerGrid = (NUM_POINTS + threadsPerBlock - 1) / threadsPerBlock;\n        // Grid: (ceil(NUM_POINTS / 256), 1, 1)\n        // Block: (256, 1, 1)\n        void *args[] = {&d_lat1, &d_lon1, &d_lat2, &d_lon2, &d_result, &NUM_POINTS};\n        cudaLaunchKernel((void*)k_GeoDistance, blocksPerGrid, threadsPerBlock, args, 0, stream);\n\n        // Copy result back to host\n        CUDA_CHECK(cudaMemcpyAsync(result_h, d_result, NUM_POINTS * sizeof(double), cudaMemcpyDeviceToHost, stream));\n\n        // Check tasks in the stream has completed\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n\n        for (int i = 0; i < NUM_POINTS; ++i) {\n            assert(fabs(result_h[i] - expectedOutput[i]) <= EPSILON);\n        }\n    }\n\n    //Test case: 6\n    {\n        int NUM_POINTS = 6;\n        double lat1_h[NUM_POINTS] = {-34.868820, 38.774929, 26.276987, 54.755826, 18.076090, 11.971619};\n        double lon1_h[NUM_POINTS] = {150.209290, -121.419418, 54.296249, 37.617300, 72.877426, 77.594566};\n        double lat2_h[NUM_POINTS] = {54.755826, 48.856613, 25.276987, 37.774929, -33.868820, 28.704059};\n        double lon2_h[NUM_POINTS] = {37.617300, 2.352222, 55.296249, -122.419418, 151.209290, 77.102491};\n        double result_h[NUM_POINTS];\n        double expectedOutput[NUM_POINTS] = {14505.46, 8812.48, 149.63, 9551.22, 10092.15, 1861.26};\n\n        // Copy data from host to device\n        CUDA_CHECK(cudaMemcpyAsync(d_lat1, lat1_h, NUM_POINTS * sizeof(double), cudaMemcpyHostToDevice, stream));\n        CUDA_CHECK(cudaMemcpyAsync(d_lon1, lon1_h, NUM_POINTS * sizeof(double), cudaMemcpyHostToDevice, stream));\n        CUDA_CHECK(cudaMemcpyAsync(d_lat2, lat2_h, NUM_POINTS * sizeof(double), cudaMemcpyHostToDevice, stream));\n        CUDA_CHECK(cudaMemcpyAsync(d_lon2, lon2_h, NUM_POINTS * sizeof(double), cudaMemcpyHostToDevice, stream));\n\n        // Launch the kernel\n        int threadsPerBlock = 256;\n        int blocksPerGrid = (NUM_POINTS + threadsPerBlock - 1) / threadsPerBlock;\n        // Grid: (ceil(NUM_POINTS / 256), 1, 1)\n        // Block: (256, 1, 1)\n        void *args[] = {&d_lat1, &d_lon1, &d_lat2, &d_lon2, &d_result, &NUM_POINTS};\n        cudaLaunchKernel((void*)k_GeoDistance, blocksPerGrid, threadsPerBlock, args, 0, stream);\n\n        // Copy result back to host\n        CUDA_CHECK(cudaMemcpyAsync(result_h, d_result, NUM_POINTS * sizeof(double), cudaMemcpyDeviceToHost, stream));\n\n        // Check tasks in the stream has completed\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n\n        for (int i = 0; i < NUM_POINTS; ++i) {\n            assert(fabs(result_h[i] - expectedOutput[i]) <= EPSILON);\n        }\n    }\n\n    //Test case: 7\n    {\n        int NUM_POINTS = 10;\n        double lat1_h[NUM_POINTS] = {34.052235, 48.856613, 51.507351, 40.712776, 35.689487, -33.868820, 37.774929, 25.276987, 55.755826, 19.076090};\n        double lon1_h[NUM_POINTS] = {-118.243683, 2.352222, -0.127758, -74.006058, 139.691711, 151.209290, -122.419418, 55.296249, 37.617300, 72.877426};\n        double lat2_h[NUM_POINTS] = {35.689487, 19.076090, 40.712776, 51.507351, 34.052235, 55.755826, 48.856613, 25.276987, 37.774929, -33.868820};\n        double lon2_h[NUM_POINTS] = {139.691711, 72.877426, -74.006058, -0.127758, -118.243683, 37.617300, 2.352222, 55.296249, -122.419418, 151.209290};\n        double result_h[NUM_POINTS];\n        double expectedOutput[NUM_POINTS] = {8815.47, 7009.30, 5570.23, 5570.23, 8815.47, 14496.16, 8953.39, 0.00, 9444.18, 10156.85};\n\n        // Copy data from host to device\n        CUDA_CHECK(cudaMemcpyAsync(d_lat1, lat1_h, NUM_POINTS * sizeof(double), cudaMemcpyHostToDevice, stream));\n        CUDA_CHECK(cudaMemcpyAsync(d_lon1, lon1_h, NUM_POINTS * sizeof(double), cudaMemcpyHostToDevice, stream));\n        CUDA_CHECK(cudaMemcpyAsync(d_lat2, lat2_h, NUM_POINTS * sizeof(double), cudaMemcpyHostToDevice, stream));\n        CUDA_CHECK(cudaMemcpyAsync(d_lon2, lon2_h, NUM_POINTS * sizeof(double), cudaMemcpyHostToDevice, stream));\n\n        // Launch the kernel\n        int threadsPerBlock = 256;\n        int blocksPerGrid = (NUM_POINTS + threadsPerBlock - 1) / threadsPerBlock;\n        // Grid: (ceil(NUM_POINTS / 256), 1, 1)\n        // Block: (256, 1, 1)\n        void *args[] = {&d_lat1, &d_lon1, &d_lat2, &d_lon2, &d_result, &NUM_POINTS};\n        cudaLaunchKernel((void*)k_GeoDistance, blocksPerGrid, threadsPerBlock, args, 0, stream);\n\n        // Copy result back to host\n        CUDA_CHECK(cudaMemcpyAsync(result_h, d_result, NUM_POINTS * sizeof(double), cudaMemcpyDeviceToHost, stream));\n\n        // Check tasks in the stream has completed\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n\n        for (int i = 0; i < NUM_POINTS; ++i) {\n            assert(fabs(result_h[i] - expectedOutput[i]) <= EPSILON);\n        }\n    }\n\n    // Clean up\n    CUDA_CHECK(cudaFreeAsync(d_lat1, stream));\n    CUDA_CHECK(cudaFreeAsync(d_lon1, stream));\n    CUDA_CHECK(cudaFreeAsync(d_lat2, stream));\n    CUDA_CHECK(cudaFreeAsync(d_lon2, stream));\n    CUDA_CHECK(cudaStreamDestroy(stream));    \n}\n\n__global__ void k_GeoDistance(double *lat1, double *lon1, double *lat2, double *lon2, double *result, int n) {\n", "test": "int main() {\n    launch();\n}\n", "example_test": "    @example_test\n", "cuda_toolkit": "12.2"}
{"task_id": "CUDA/91", "date": "2025-03-31", "prompt": "Write a CUDA kernel to calculate the signal power, where each thread computes the power of an element in an input signal by squaring its amplitude.\n\nThe signature of the function is __global__ void k_computeSignalPower(float* outputSignal_d, const float* inputSignal_d, int size), where outputSignal_d is the array storing the computed power values, inputSignal_d is the array containing the original amplitude values, and size represents the length of both arrays.\n\n>>> k_computeSignalPower(outputSignal_d, {0.0f, 1.0f, 2.0f, 3.0f, 4.0f, 5.0f, 6.0f, 7.0f, 8.0f, 9.0f}, 10) -> outputSignal_d: ({0.0f, 1.0f, 4.0f, 9.0f, 16.0f, 25.0f, 36.0f, 49.0f, 64.0f, 81.0f})\n>>> k_computeSignalPower(outputSignal_d, {2.3f, 6.9f, 1.5f, 8.1f, 3.6f, 4.8f, 7.4f, 5.0f, 9.3f, 0.4f}, 10) -> outputSignal_d: ({5.29f, 47.61f, 2.25f, 65.61f, 12.96f, 23.04f, 54.76f, 25.0f, 86.49f, 0.16f}) \n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_70 -arch=sm_60", "ld_flags": "", "declaration": "#include <cuda_runtime.h>\n#include <cstdio>\n#undef NDEBUG\n#include <cassert>\n\n#define ARRAY_SIZE 10\n#define TOLERANCE  1e-2\n\n// Macro for CUDA error checking\n#define CUDA_CHECK(call) {                                                        \\\n        cudaError_t err = call;                                                   \\\n        if (err != cudaSuccess) {                                                 \\\n            fprintf(stderr, \"CUDA error in file '%s' in line %d: %s.\\n\",          \\\n                    __FILE__, __LINE__, cudaGetErrorString(err));                 \\\n            exit(EXIT_FAILURE);                                                   \\\n        }                                                                         \\\n}\n\n// Struct to define test cases\nstruct TestCase {\n    float inputSignal_h[ARRAY_SIZE];\n    float expectedOutput_h[ARRAY_SIZE];\n};\n\n__global__ void k_computeSignalPower(float* outputSignal_d, const float* inputSignal_d, int size);\n\nvoid launch() {\n    // Create a CUDA stream\n    cudaStream_t stream;\n    CUDA_CHECK(cudaStreamCreate(&stream));\n\n    // Allocate device memory once for the largest dataset\n    float* inputSignal_d;\n    float* outputSignal_d;\n    size_t arrayBytes = ARRAY_SIZE * sizeof(float);\n\n    CUDA_CHECK(cudaMallocAsync((void**)&inputSignal_d, arrayBytes, stream));\n    CUDA_CHECK(cudaMallocAsync((void**)&outputSignal_d, arrayBytes, stream));\n\n    // Define execution configuration\n    int threadsPerBlock = 16;\n    int blocksPerGrid = (ARRAY_SIZE + threadsPerBlock - 1) / threadsPerBlock;\n    int size = ARRAY_SIZE;\n\n    // Define all test cases\n    TestCase testCases[] = {\n        // Test Case 1\n        {\n            { 0.0f, 1.0f, 2.0f, 3.0f, 4.0f, 5.0f, 6.0f, 7.0f, 8.0f, 9.0f },\n            { 0.0f, 1.0f, 4.0f, 9.0f, 16.0f, 25.0f, 36.0f, 49.0f, 64.0f, 81.0f }\n        },\n        // Test Case 2\n        {\n            { 2.3f, 6.9f, 1.5f, 8.1f, 3.6f, 4.8f, 7.4f, 5.0f, 9.3f, 0.4f },\n            { 5.29f, 47.61f, 2.25f, 65.61f, 12.96f, 23.04f, 54.76f, 25.0f, 86.49f, 0.16f }\n        },\n        // Test Case 3\n        {\n            { 3.4f, 7.6f, 1.2f, 8.9f, 5.3f, 0.2f, 6.1f, 9.8f, 2.7f, 4.5f },\n            { 11.56f, 57.76f, 1.44f, 79.21f, 28.09f, 0.04f, 37.21f, 96.04f, 7.29f, 20.25f }\n        },\n        // Test Case 4\n        {\n            { 4.1f, 5.7f, 3.9f, 2.4f, 7.5f, 1.1f, 8.2f, 9.0f, 6.3f, 0.8f },\n            { 16.81f, 32.49f, 15.21f, 5.76f, 56.25f, 1.21f, 67.24f, 81.0f, 39.69f, 0.64f }\n        },\n        // Test Case 5\n        {\n            { 7.2f, 3.5f, 4.7f, 9.1f, 2.8f, 5.6f, 1.3f, 8.4f, 0.9f, 6.0f },\n            { 51.84f, 12.25f, 22.09f, 82.81f, 7.84f, 31.36f, 1.69f, 70.56f, 0.81f, 36.0f }\n        },\n        // Test Case 6\n        {\n            { 1.9f, 8.5f, 6.7f, 4.2f, 0.5f, 7.3f, 5.8f, 2.1f, 9.6f, 3.0f },\n            { 3.61f, 72.25f, 44.89f, 17.64f, 0.25f, 53.29f, 33.64f, 4.41f, 92.16f, 9.0f }\n        },\n        // Test Case 7\n        {\n            { 0.3f, 5.9f, 7.1f, 6.4f, 1.0f, 4.6f, 3.2f, 2.5f, 9.7f, 8.8f },\n            { 0.09f, 34.81f, 50.41f, 40.96f, 1.0f, 21.16f, 10.24f, 6.25f, 94.09f, 77.44f }\n        }\n    };\n\n    const int numTestCases = sizeof(testCases) / sizeof(TestCase);\n\n    // Loop through all test cases\n    for (int tc = 0; tc < numTestCases; tc++) {\n        void* kernelArgs[] = { &outputSignal_d, &inputSignal_d, &size };\n\n        // Copy input data to device asynchronously\n        CUDA_CHECK(cudaMemcpyAsync(inputSignal_d, testCases[tc].inputSignal_h, arrayBytes, cudaMemcpyHostToDevice, stream));\n\n        // Launch the kernel asynchronously using cudaLaunchKernel\n        // Grid: (ceil(ARRAY_SIZE / 16), 1, 1)\n        // Block: (16, 1, 1)\n        CUDA_CHECK(cudaLaunchKernel((const void*)k_computeSignalPower, dim3(blocksPerGrid), dim3(threadsPerBlock), kernelArgs, 0, stream));\n\n        // Copy output data back to host asynchronously\n        float outputSignal_h[ARRAY_SIZE];\n        CUDA_CHECK(cudaMemcpyAsync(outputSignal_h, outputSignal_d, arrayBytes, cudaMemcpyDeviceToHost, stream));\n\n        // Synchronize to ensure all operations for the current test case are complete\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n\n        // Verify the results\n        for (int i = 0; i < ARRAY_SIZE; i++) {\n            assert(abs(outputSignal_h[i] - testCases[tc].expectedOutput_h[i]) < TOLERANCE);\n        }\n    }\n\n    // Free device memory asynchronously\n    CUDA_CHECK(cudaFreeAsync(inputSignal_d, stream));\n    CUDA_CHECK(cudaFreeAsync(outputSignal_d, stream));\n\n    // Destroy the CUDA stream\n    CUDA_CHECK(cudaStreamDestroy(stream));\n}\n\n// Kernel definition\n__global__ void k_computeSignalPower(float* outputSignal_d, const float* inputSignal_d, int size) {\n", "test": "int main() {\n    launch();\n}\n", "example_test": "    @example_test\n", "cuda_toolkit": "12.2"}
{"task_id": "CUDA/92", "date": "2025-03-31", "prompt": "Write a CUDA kernel to compute the difference between current and background images using managed memory.\n\nThe signature of the function is __global__ void k_backgroundSubtraction(float* currentImage, float* backgroundImage, float* output, int width), where currentImage is a pointer to the current image data array, backgroundImage is a pointer to the  back ground image data array, the output is an array with the subtraction results, and width is the number of elements of the arrays being processed.\n\n>>> k_backgroundSubtraction({100, 101, 102, 103, 104, 105, 106, 107, 108, 109}, {100, 102, 101, 105, 103, 110, 106, 105, 110, 108}, output, 10)-> output: ({0, 1, -1, 2, -1, 5, 0, -2, 2, -1})\n>>> k_backgroundSubtraction({50, 55, 60, 65, 70, 75, 80, 85, 90, 95}, {52, 54, 61, 67, 69, 78, 81, 83, 91, 97}, output, 10)-> output: ({2, -1, 1, 2, -1, 3, 1, -2, 1, 2}) \n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_70 -arch=sm_60", "ld_flags": "", "declaration": "#include <cuda_runtime.h>\n#include <cstdio>\n#undef NDEBUG\n#include <cassert>\n\nconst int BLOCK_SIZE = 16;\n\n#define CUDA_CHECK(call)                                                           \\\ndo {                                                                               \\\n    cudaError_t error = call;                                                      \\\n    if (error != cudaSuccess) {                                                    \\\n        fprintf(stderr, \"CUDA Error: %s at %s:%d\\n\", cudaGetErrorString(error),    \\\n                __FILE__, __LINE__);                                               \\\n        exit(error);                                                               \\\n    }                                                                              \\\n} while (0)\n\n__global__ void k_backgroundSubtraction(float* currentImage, float* backgroundImage, float* output, int width);\n\nvoid launch() {\n    int width = 10;\n\n    // Use a CUDA stream for asynchronous operations\n    cudaStream_t stream;\n    CUDA_CHECK(cudaStreamCreate(&stream));\n\n    float *background_d, *currentScan_d, *output_d;\n    CUDA_CHECK(cudaMallocManaged(&background_d, width * sizeof(float)));\n    CUDA_CHECK(cudaMallocManaged(&currentScan_d, width * sizeof(float)));\n    CUDA_CHECK(cudaMallocManaged(&output_d, width * sizeof(float)));\n    \n    //Test Case 1\n    {\n        // Predefined input for background and current scan\n        float backgroundData[] = { 100, 101, 102, 103, 104, 105, 106, 107, 108, 109 };\n        float currentScanData[] = { 100, 102, 101, 105, 103, 110, 106, 105, 110, 108 };\n\n        float expectedOutput[] = { 0, 1, -1, 2, -1, 5, 0, -2, 2, -1 };\n\n        // Copy predefined values to managed memory\n        for (int i = 0; i < width; ++i) {\n            background_d[i] = backgroundData[i];\n            currentScan_d[i] = currentScanData[i];\n        }\n\n        // Launch background subtraction kernel\n        \n        int grid = (width + BLOCK_SIZE - 1) / BLOCK_SIZE;\n\n        // Block: (16,1,1)\n        // Grid: (ceil(width / 16),1,1)\n        void *args[] = {&currentScan_d, &background_d, &output_d, &width};\n        CUDA_CHECK(cudaLaunchKernel((void*)k_backgroundSubtraction, grid, BLOCK_SIZE, args, BLOCK_SIZE * sizeof(int), stream));\n\n        // Check tasks in the stream has completed\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n\n        for (int i = 0; i < width; ++i) {\n            assert(output_d[i] == expectedOutput[i]);\n        }\n    }\n\n    //Test Case 2\n    {\n        // Predefined input for background and current scan\n        float backgroundData[] = { 50, 55, 60, 65, 70, 75, 80, 85, 90, 95 };\n        float currentScanData[] = { 52, 54, 61, 67, 69, 78, 81, 83, 91, 97 };\n\n        float expectedOutput[] = { 2, -1, 1, 2, -1, 3, 1, -2, 1, 2 };\n\n        float *background_d, *currentScan_d, *output_d;\n        CUDA_CHECK(cudaMallocManaged(&background_d, width * sizeof(float)));\n        CUDA_CHECK(cudaMallocManaged(&currentScan_d, width * sizeof(float)));\n        CUDA_CHECK(cudaMallocManaged(&output_d, width * sizeof(float)));\n\n        // Copy predefined values to managed memory\n        for (int i = 0; i < width; ++i) {\n            background_d[i] = backgroundData[i];\n            currentScan_d[i] = currentScanData[i];\n        }\n\n        // Launch background subtraction kernel\n        \n        int grid = (width + BLOCK_SIZE - 1) / BLOCK_SIZE;\n\n        // Block: (16,1,1)\n        // Grid: (ceil(width / 16),1,1)\n        void *args[] = {&currentScan_d, &background_d, &output_d, &width};\n        CUDA_CHECK(cudaLaunchKernel((void*)k_backgroundSubtraction, grid, BLOCK_SIZE, args, BLOCK_SIZE * sizeof(int), stream));\n\n        // Check tasks in the stream has completed\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n\n        for (int i = 0; i < width; ++i) {\n            assert(output_d[i] == expectedOutput[i]);\n        }\n    }\n\n    //Test Case 3\n    {\n        float backgroundData[] = { 200, 201, 202, 203, 204, 205, 206, 207, 208, 209 };\n        float currentScanData[] = { 205, 200, 202, 200, 203, 210, 206, 208, 210, 212 };\n\n        float expectedOutput[] = { 5, -1, 0, -3, -1, 5, 0, 1, 2, 3 };\n\n        // Copy predefined values to managed memory\n        for (int i = 0; i < width; ++i) {\n            background_d[i] = backgroundData[i];\n            currentScan_d[i] = currentScanData[i];\n        }\n\n        // Launch background subtraction kernel\n        \n        int grid = (width + BLOCK_SIZE - 1) / BLOCK_SIZE;\n\n        // Block: (16,1,1)\n        // Grid: (ceil(width / 16),1,1)\n        void *args[] = {&currentScan_d, &background_d, &output_d, &width};\n        CUDA_CHECK(cudaLaunchKernel((void*)k_backgroundSubtraction, grid, BLOCK_SIZE, args, BLOCK_SIZE * sizeof(int), stream));\n\n        // Check tasks in the stream has completed\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n\n        for (int i = 0; i < width; ++i) {\n            assert(output_d[i] == expectedOutput[i]);\n        }\n    }\n\n    //Test Case 4\n    {\n        float backgroundData[] = { 10, 20, 30, 40, 50, 60, 70, 80, 90, 100 };\n        float currentScanData[] = { 15, 18, 33, 42, 48, 65, 68, 85, 95, 105 };\n\n        float expectedOutput[] = { 5, -2, 3, 2, -2, 5, -2, 5, 5, 5 };\n\n        // Copy predefined values to managed memory\n        for (int i = 0; i < width; ++i) {\n            background_d[i] = backgroundData[i];\n            currentScan_d[i] = currentScanData[i];\n        }\n\n        // Launch background subtraction kernel\n        \n        int grid = (width + BLOCK_SIZE - 1) / BLOCK_SIZE;\n\n        // Block: (16,1,1)\n        // Grid: (ceil(width / 16),1,1)\n        void *args[] = {&currentScan_d, &background_d, &output_d, &width};\n        CUDA_CHECK(cudaLaunchKernel((void*)k_backgroundSubtraction, grid, BLOCK_SIZE, args, BLOCK_SIZE * sizeof(int), stream));\n\n        // Check tasks in the stream has completed\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n\n        for (int i = 0; i < width; ++i) {\n            assert(output_d[i] == expectedOutput[i]);\n        }\n    }\n\n    //Test Case 5\n    {\n        float backgroundData[] = { 150, 155, 160, 165, 170, 175, 180, 185, 190, 195 };\n        float currentScanData[] = { 155, 160, 165, 170, 175, 180, 185, 190, 195, 200 };\n\n        float expectedOutput[] = { 5, 5, 5, 5, 5, 5, 5, 5, 5, 5 };\n\n        // Copy predefined values to managed memory\n        for (int i = 0; i < width; ++i) {\n            background_d[i] = backgroundData[i];\n            currentScan_d[i] = currentScanData[i];\n        }\n\n        // Launch background subtraction kernel\n        \n        int grid = (width + BLOCK_SIZE - 1) / BLOCK_SIZE;\n\n        // Block: (16,1,1)\n        // Grid: (ceil(width / 16),1,1)\n        void *args[] = {&currentScan_d, &background_d, &output_d, &width};\n        CUDA_CHECK(cudaLaunchKernel((void*)k_backgroundSubtraction, grid, BLOCK_SIZE, args, BLOCK_SIZE * sizeof(int), stream));\n\n        // Check tasks in the stream has completed\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n\n        for (int i = 0; i < width; ++i) {\n            assert(output_d[i] == expectedOutput[i]);\n        }\n    }\n\n    //Test Case 6\n    {\n        float backgroundData[] = { 300, 305, 310, 315, 320, 325, 330, 335, 340, 345 };\n        float currentScanData[] = { 302, 303, 312, 317, 318, 330, 332, 337, 338, 350 };\n\n        float expectedOutput[] = { 2, -2, 2, 2, -2, 5, 2, 2, -2, 5 };\n\n        // Copy predefined values to managed memory\n        for (int i = 0; i < width; ++i) {\n            background_d[i] = backgroundData[i];\n            currentScan_d[i] = currentScanData[i];\n        }\n\n        // Launch background subtraction kernel\n        \n        int grid = (width + BLOCK_SIZE - 1) / BLOCK_SIZE;\n\n        // Block: (16,1,1)\n        // Grid: (ceil(width / 16),1,1)\n        void *args[] = {&currentScan_d, &background_d, &output_d, &width};\n        CUDA_CHECK(cudaLaunchKernel((void*)k_backgroundSubtraction, grid, BLOCK_SIZE, args, BLOCK_SIZE * sizeof(int), stream));\n\n        // Check tasks in the stream has completed\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n\n        for (int i = 0; i < width; ++i) {\n            assert(output_d[i] == expectedOutput[i]);\n        }\n    }\n\n    //Test Case 7\n    {\n        int width = 10;\n\n        float backgroundData[] = { 500, 510, 520, 530, 540, 550, 560, 570, 580, 590 };\n        float currentScanData[] = { 495, 505, 515, 535, 545, 555, 565, 575, 585, 595 };\n\n        float expectedOutput[] = { -5, -5, -5, 5, 5, 5, 5, 5, 5, 5 };\n\n        // Copy predefined values to managed memory\n        for (int i = 0; i < width; ++i) {\n            background_d[i] = backgroundData[i];\n            currentScan_d[i] = currentScanData[i];\n        }\n\n        // Launch background subtraction kernel\n        \n        int grid = (width + BLOCK_SIZE - 1) / BLOCK_SIZE;\n\n        // Block: (16,1,1)\n        // Grid: (ceil(width / 16),1,1)\n        void *args[] = {&currentScan_d, &background_d, &output_d, &width};\n        CUDA_CHECK(cudaLaunchKernel((void*)k_backgroundSubtraction, grid, BLOCK_SIZE, args, BLOCK_SIZE * sizeof(int), stream));\n\n        // Check tasks in the stream has completed\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n\n        for (int i = 0; i < width; ++i) {\n            assert(output_d[i] == expectedOutput[i]);\n        }\n    }\n    // Free managed memory\n    CUDA_CHECK(cudaFree(background_d));\n    CUDA_CHECK(cudaFree(currentScan_d));\n    CUDA_CHECK(cudaFree(output_d));\n    CUDA_CHECK(cudaStreamDestroy(stream)); \n}\n\n__global__ void k_backgroundSubtraction(float* currentImage, float* backgroundImage, float* output, int width) {\n", "test": "int main() {\n    launch();\n}\n", "example_test": "    @example_test\n", "cuda_toolkit": "12.2"}
{"task_id": "CUDA/93", "date": "2025-03-31", "prompt": "Write a CUDA kernel to convert polar coordinates (radius, angle) into Cartesian coordinates (x, y) using data parallelism to efficiently convert multiple polar coordinates. \nThe Cartesian coordinates are computed as \\( x = r \\cos(\\text{angle}) \\) and \\( y = r \\sin(\\text{angle}) \\).\n\nThe signature of the kernel is __global__ void k_polarToCartesian(float* radius, float* angle, float* x, float* y, int n), where the radius is an input array of radial distances, angle is an input array of angles in radians, x is an output array for Cartesian x-coordinates, y is an output array for Cartesian y-coordinates, and n is the total number of coordinates to convert.\n\n>>> k_polarToCartesian({2.5, 3.0, 4.0}, {0.2, 0.6, 1.0}, x, y, 3) -> {x: {2.45017, 2.47601, 2.16121} y:{0.49667, 1.69393, 3.36588}}\n>>> k_polarToCartesian({1.5, 2.0, 3.5, 4.5, 5.5}, {0.3, 0.7, 1.1, 1.5, 1.9}, x, y, 5) -> {x: {1.433, 1.52968, 1.58759, 0.318317, -1.77809},  y:{0.44328, 1.28844, 3.11923, 4.48873, 5.20465}}\n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_70 -arch=sm_60", "ld_flags": "", "declaration": "#include <cuda_runtime.h>\n#include <algorithm>\n#include <cmath>\n#include <cstdio>\n#undef NDEBUG\n#include <cassert>\n\n#define EPSILON 1e-4  // Tolerance for floating-point comparison\n\n#define CUDA_CHECK(call)                                                                               \\\ndo {                                                                                                  \\\n    cudaError_t error = call;                                                                         \\\n    if (error != cudaSuccess) {                                                                       \\\n        fprintf(stderr, \"CUDA error at %s:%d - %s\\n\", __FILE__, __LINE__, cudaGetErrorString(error)); \\\n        exit(EXIT_FAILURE);                                                                           \\\n    }                                                                                                 \\\n} while (0)\n\n__global__ void k_polarToCartesian(float* radius, float* angle, float* x, float* y, int n);\n\nvoid launch() {\n    // Device arrays\n    float *d_Radius, *d_Angle, *d_x, *d_y;\n\n    // Use a CUDA stream for asynchronous operations\n    cudaStream_t stream;\n    CUDA_CHECK(cudaStreamCreate(&stream));\n    int maxN =16;\n\n    // Allocate device memory\n    CUDA_CHECK(cudaMallocAsync(&d_Radius, maxN * sizeof(float), stream));\n    CUDA_CHECK(cudaMallocAsync(&d_Angle, maxN * sizeof(float), stream));\n    CUDA_CHECK(cudaMallocAsync(&d_x, maxN * sizeof(float), stream));\n    CUDA_CHECK(cudaMallocAsync(&d_y, maxN * sizeof(float), stream));\n\n    //Test case 1\n    {\n        int n = 3;  // Number of points\n        // Host arrays\n        float inputRadius[n] = {2.5, 3.0, 4.0};         // Example radial distances\n        float inputAngle[n] = {0.2, 0.6, 1.0};      // Example angles in radians\n        float outputX[n], outputY[n];  // Output arrays for Cartesian coordinates\n\n        // Copy data from host to device\n        CUDA_CHECK(cudaMemcpyAsync(d_Radius, inputRadius, n * sizeof(float), cudaMemcpyHostToDevice, stream));\n        CUDA_CHECK(cudaMemcpyAsync(d_Angle, inputAngle, n * sizeof(float), cudaMemcpyHostToDevice, stream));\n\n        // Block: (256, 1, 1)\n        // Grid (ceil(numBlocks/256), 1, 1)\n        int blockSize = 256;\n        int numBlocks = (n + blockSize - 1) / blockSize;\n\n        void *argsPolarToCartesian[] = {&d_Radius, &d_Angle, &d_x, &d_y, &n};\n        CUDA_CHECK(cudaLaunchKernel((void*)k_polarToCartesian, numBlocks, blockSize, argsPolarToCartesian, 0, stream));\n\n        // Copy the results back to the host\n        CUDA_CHECK(cudaMemcpyAsync(outputX, d_x, n * sizeof(float), cudaMemcpyDeviceToHost, stream));\n        CUDA_CHECK(cudaMemcpyAsync(outputY, d_y, n * sizeof(float), cudaMemcpyDeviceToHost, stream));\n        \n        // Check tasks in the stream has completed\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n\n        float expectedOutputX[n] = {2.45017, 2.47601, 2.16121};\n        float expectedOutputY[n] = {0.49667, 1.69393, 3.36588};\n        for (int j = 0; j < n; j++) {\n            assert (fabs(outputX[j] - expectedOutputX[j]) <= EPSILON);\n        }\n        for (int j = 0; j < n; j++) {\n            assert (fabs(outputY[j] - expectedOutputY[j]) <= EPSILON);\n        }\n    }\n\n    //Test case 2\n    {\n        int n = 10;  // Number of points\n        // Host arrays\n        float inputRadius[n] = {1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0};         // Example radial distances\n        float inputAngle[n] = {0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5};      // Example angles in radians\n        float outputX[n], outputY[n];  // Output arrays for Cartesian coordinates\n\n        // Copy data from host to device\n        CUDA_CHECK(cudaMemcpyAsync(d_Radius, inputRadius, n * sizeof(float), cudaMemcpyHostToDevice, stream));\n        CUDA_CHECK(cudaMemcpyAsync(d_Angle, inputAngle, n * sizeof(float), cudaMemcpyHostToDevice, stream));\n\n        // Block: (256, 1, 1)\n        // Grid (ceil(numBlocks/256), 1, 1)\n        int blockSize = 256;\n        int numBlocks = (n + blockSize - 1) / blockSize;\n\n        // Launch the kernel with enough threads to cover all points\n        void *argsPolarToCartesian[] = {&d_Radius, &d_Angle, &d_x, &d_y, &n};\n        CUDA_CHECK(cudaLaunchKernel((void*)k_polarToCartesian, numBlocks, blockSize, argsPolarToCartesian, 0, stream));\n\n        // Copy the results back to the host\n        CUDA_CHECK(cudaMemcpyAsync(outputX, d_x, n * sizeof(float), cudaMemcpyDeviceToHost, stream));\n        CUDA_CHECK(cudaMemcpyAsync(outputY, d_y, n * sizeof(float), cudaMemcpyDeviceToHost, stream));\n        \n        // Check tasks in the stream has completed\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n\n        float expectedOutputX[n] = {1, 1.75517, 1.62091, 0.282949, -2.08073, -4.80686,\n                                  -6.92995, -7.49165, -5.88279, -2.10796\n                                };\n        float expectedOutputY[n] = {0, 0.958851, 2.52441, 3.98998, 4.54649, 3.59083,\n                                  0.98784, -2.80627, -6.81122, -9.7753\n                                };\n        for (int j = 0; j < n; j++) {\n            assert (fabs(outputX[j] - expectedOutputX[j]) <= EPSILON);\n        }\n        for (int j = 0; j < n; j++) {\n            assert (fabs(outputY[j] - expectedOutputY[j]) <= EPSILON);\n        }\n    }\n\n    //Test case 3\n    {\n        int n = 5;  // Number of points\n        // Host arrays\n        float inputRadius[n] = {1.5, 2.0, 3.5, 4.5, 5.5};         // Example radial distances\n        float inputAngle[n]  = {0.3, 0.7, 1.1, 1.5, 1.9};      // Example angles in radians\n        float outputX[n], outputY[n];  // Output arrays for Cartesian coordinates\n\n        // Copy data from host to device\n        CUDA_CHECK(cudaMemcpyAsync(d_Radius, inputRadius, n * sizeof(float), cudaMemcpyHostToDevice, stream));\n        CUDA_CHECK(cudaMemcpyAsync(d_Angle, inputAngle, n * sizeof(float), cudaMemcpyHostToDevice, stream));\n\n        // Block: (256, 1, 1)\n        // Grid (ceil(numBlocks/256), 1, 1)\n        int blockSize = 256;\n        int numBlocks = (n + blockSize - 1) / blockSize;\n\n        // Launch the kernel with enough threads to cover all points\n        void *argsPolarToCartesian[] = {&d_Radius, &d_Angle, &d_x, &d_y, &n};\n        CUDA_CHECK(cudaLaunchKernel((void*)k_polarToCartesian, numBlocks, blockSize, argsPolarToCartesian, 0, stream));\n\n        // Copy the results back to the host\n        CUDA_CHECK(cudaMemcpyAsync(outputX, d_x, n * sizeof(float), cudaMemcpyDeviceToHost, stream));\n        CUDA_CHECK(cudaMemcpyAsync(outputY, d_y, n * sizeof(float), cudaMemcpyDeviceToHost, stream));\n        \n        // Check tasks in the stream has completed\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n\n        float expectedOutputX[n] = {1.433, 1.52968, 1.58759, 0.318317, -1.77809};\n        float expectedOutputY[n] = {0.44328, 1.28844, 3.11923, 4.48873, 5.20465};\n        for (int j = 0; j < n; j++) {\n            assert (fabs(outputX[j] - expectedOutputX[j]) <= EPSILON);\n        }\n        for (int j = 0; j < n; j++) {\n            assert (fabs(outputY[j] - expectedOutputY[j]) <= EPSILON);\n        }\n    }\n\n    //Test case 4\n    {\n        int n = 10;  // Number of points\n        // Host arrays\n        float inputRadius[n] = {3.1, 4.4, 5.6, 6.2, 8.1, 9.3};         // Example radial distances\n        float inputAngle[n]  = {0.4, 0.8, 1.2, 1.6, 2.0, 2.4};      // Example angles in radians\n        float outputX[n], outputY[n];  // Output arrays for Cartesian coordinates\n\n        // Copy data from host to device\n        CUDA_CHECK(cudaMemcpyAsync(d_Radius, inputRadius, n * sizeof(float), cudaMemcpyHostToDevice, stream));\n        CUDA_CHECK(cudaMemcpyAsync(d_Angle, inputAngle, n * sizeof(float), cudaMemcpyHostToDevice, stream));\n\n        // Block: (256, 1, 1)\n        // Grid (ceil(numBlocks/256), 1, 1)\n        int blockSize = 256;\n        int numBlocks = (n + blockSize - 1) / blockSize;\n\n        // Launch the kernel with enough threads to cover all points\n        void *argsPolarToCartesian[] = {&d_Radius, &d_Angle, &d_x, &d_y, &n};\n        CUDA_CHECK(cudaLaunchKernel((void*)k_polarToCartesian, numBlocks, blockSize, argsPolarToCartesian, 0, stream));\n\n        // Copy the results back to the host\n        CUDA_CHECK(cudaMemcpyAsync(outputX, d_x, n * sizeof(float), cudaMemcpyDeviceToHost, stream));\n        CUDA_CHECK(cudaMemcpyAsync(outputY, d_y, n * sizeof(float), cudaMemcpyDeviceToHost, stream));\n        \n        // Check tasks in the stream has completed\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n\n        float expectedOutputX[n] = {2.85529, 3.06551, 2.0292, -0.181037, -3.37079, -6.85776};\n        float expectedOutputY[n] = {1.2072, 3.15637, 5.21942, 6.19736, 7.36531, 6.28181};\n        for (int j = 0; j < n; j++) {\n            assert (fabs(outputX[j] - expectedOutputX[j]) <= EPSILON);\n        }\n        for (int j = 0; j < n; j++) {\n            assert (fabs(outputY[j] - expectedOutputY[j]) <= EPSILON);\n        }\n    }\n\n    //Test case 5\n    {\n        int n = 7;  // Number of points\n        // Host arrays\n        float inputRadius[n] = {1.9, 3.0, 4.2, 5.5, 7.3, 8.6, 9.9};         // Example radial distances\n        float inputAngle[n]  = {0.3, 0.7, 1.1, 1.5, 1.9, 2.3, 2.7};      // Example angles in radians\n        float outputX[n], outputY[n];  // Output arrays for Cartesian coordinates\n\n        // Copy data from host to device\n        CUDA_CHECK(cudaMemcpyAsync(d_Radius, inputRadius, n * sizeof(float), cudaMemcpyHostToDevice, stream));\n        CUDA_CHECK(cudaMemcpyAsync(d_Angle, inputAngle, n * sizeof(float), cudaMemcpyHostToDevice, stream));\n\n        // Block: (256, 1, 1)\n        // Grid (ceil(numBlocks/256), 1, 1)\n        int blockSize = 256;\n        int numBlocks = (n + blockSize - 1) / blockSize;\n\n        // Launch the kernel with enough threads to cover all points\n        void *argsPolarToCartesian[] = {&d_Radius, &d_Angle, &d_x, &d_y, &n};\n        CUDA_CHECK(cudaLaunchKernel((void*)k_polarToCartesian, numBlocks, blockSize, argsPolarToCartesian, 0, stream));\n\n        // Copy the results back to the host\n        CUDA_CHECK(cudaMemcpyAsync(outputX, d_x, n * sizeof(float), cudaMemcpyDeviceToHost, stream));\n        CUDA_CHECK(cudaMemcpyAsync(outputY, d_y, n * sizeof(float), cudaMemcpyDeviceToHost, stream));\n\n        // Check tasks in the stream has completed\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n\n        float expectedOutputX[n] = {1.81514, 2.29453, 1.9051, 0.389055, -2.36001, -5.72997, -8.95031};\n        float expectedOutputY[n] = {0.561488, 1.93265, 3.74307, 5.48622, 6.90799, 6.41307, 4.23106};\n        for (int j = 0; j < n; j++) {\n            assert (fabs(outputX[j] - expectedOutputX[j]) <= EPSILON);\n        }\n        for (int j = 0; j < n; j++) {\n            assert (fabs(outputY[j] - expectedOutputY[j]) <= EPSILON);\n        }\n    }\n\n    //Test case 6\n    {\n        int n = 10;  // Number of points\n        // Host arrays\n        float inputRadius[n] = {1.0, 2.1, 3.2, 4.3, 5.4, 6.5, 7.6, 8.7, 9.8, 10.9};         // Example radial distances\n        float inputAngle[n]  = {0.1, 0.5, 0.9, 1.3, 1.7, 2.1, 2.5, 2.9, 3.3, 3.7};      // Example angles in radians\n        float outputX[n], outputY[n];  // Output arrays for Cartesian coordinates\n\n        // Copy data from host to device\n        CUDA_CHECK(cudaMemcpyAsync(d_Radius, inputRadius, n * sizeof(float), cudaMemcpyHostToDevice, stream));\n        CUDA_CHECK(cudaMemcpyAsync(d_Angle, inputAngle, n * sizeof(float), cudaMemcpyHostToDevice, stream));\n\n        // Block: (256, 1, 1)\n        // Grid (ceil(numBlocks/256), 1, 1)\n        int blockSize = 256;\n        int numBlocks = (n + blockSize - 1) / blockSize;\n\n        // Launch the kernel with enough threads to cover all points\n        void *argsPolarToCartesian[] = {&d_Radius, &d_Angle, &d_x, &d_y, &n};\n        CUDA_CHECK(cudaLaunchKernel((void*)k_polarToCartesian, numBlocks, blockSize, argsPolarToCartesian, 0, stream));\n\n        // Copy the results back to the host\n        CUDA_CHECK(cudaMemcpyAsync(outputX, d_x, n * sizeof(float), cudaMemcpyDeviceToHost, stream));\n        CUDA_CHECK(cudaMemcpyAsync(outputY, d_y, n * sizeof(float), cudaMemcpyDeviceToHost, stream));\n        \n        // Check tasks in the stream has completed\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n\n        float expectedOutputX[n] = {0.995004, 1.84292, 1.98915, 1.15025, -0.695761,\n                                    -3.2815, -6.08869, -8.44734, -9.6773, -9.24429\n                                   };\n        float expectedOutputY[n] = {0.0998334, 1.00679, 2.50665, 4.1433, 5.35499,\n                                    5.61086, 4.54839, 2.08147, -1.54591, -5.77521};\n        for (int j = 0; j < n; j++) {\n            assert (fabs(outputX[j] - expectedOutputX[j]) <= EPSILON);\n        }\n        for (int j = 0; j < n; j++) {\n            assert (fabs(outputY[j] - expectedOutputY[j]) <= EPSILON);\n        }\n    }\n\n    //Test case 7\n    {\n        int n = 16;  // Number of points\n        // Host arrays\n        float inputRadius[n] = {0.5, 1.2, 2.0, 2.8, 3.6, 4.4, 5.2, 6.0, 6.8, 7.6, 8.4, 9.2, 10.0, 10.8, 11.6, 12.4};         // Example radial distances\n        float inputAngle[n]  = {0.2, 0.4, 0.6, 0.8, 1.0, 1.2, 1.4, 1.6, 1.8, 2.0, 2.2, 2.4, 2.6, 2.8, 3.0, 3.2    };      // Example angles in radians\n        float outputX[n], outputY[n];  // Output arrays for Cartesian coordinates\n\n        // Copy data from host to device\n        CUDA_CHECK(cudaMemcpyAsync(d_Radius, inputRadius, n * sizeof(float), cudaMemcpyHostToDevice, stream));\n        CUDA_CHECK(cudaMemcpyAsync(d_Angle, inputAngle, n * sizeof(float), cudaMemcpyHostToDevice, stream));\n\n        // Block: (256, 1, 1)\n        // Grid (ceil(numBlocks/256), 1, 1)\n        int blockSize = 256;\n        int numBlocks = (n + blockSize - 1) / blockSize;\n\n        // Launch the kernel with enough threads to cover all points\n        void *argsPolarToCartesian[] = {&d_Radius, &d_Angle, &d_x, &d_y, &n};\n        CUDA_CHECK(cudaLaunchKernel((void*)k_polarToCartesian, numBlocks, blockSize, argsPolarToCartesian, 0, stream));\n\n        // Copy the results back to the host\n        CUDA_CHECK(cudaMemcpyAsync(outputX, d_x, n * sizeof(float), cudaMemcpyDeviceToHost, stream));\n        CUDA_CHECK(cudaMemcpyAsync(outputY, d_y, n * sizeof(float), cudaMemcpyDeviceToHost, stream));\n\n        // Check tasks in the stream has completed\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n\n        float expectedOutputX[n] = {0.490033, 1.10527, 1.65067, 1.95078,\n                                    1.94509, 1.59437, 0.883829, -0.175197,\n                                    -1.54497, -3.16272, -4.94341, -6.78402,\n                                    -8.56889, -10.176, -11.4839, -12.3789\n                                    };\n        float expectedOutputY[n] = {0.0993347, 0.467302, 1.12928, 2.0086,\n                                    3.0293, 4.10097, 5.12434, 5.99744,\n                                    6.62216, 6.91066, 6.79137, 6.21426,\n                                    5.15501, 3.61787, 1.63699, -0.72384\n                                   };\n        for (int j = 0; j < n; j++) {\n            assert (fabs(outputX[j] - expectedOutputX[j]) <= EPSILON);\n        }\n        for (int j = 0; j < n; j++) {\n            assert (fabs(outputY[j] - expectedOutputY[j]) <= EPSILON);\n        }\n    }\n\n    // Free the allocated device memory\n    CUDA_CHECK(cudaFreeAsync(d_Radius, stream));\n    CUDA_CHECK(cudaFreeAsync(d_Angle, stream));\n    CUDA_CHECK(cudaFreeAsync(d_x, stream));\n    CUDA_CHECK(cudaFreeAsync(d_y, stream));\n\n    CUDA_CHECK(cudaStreamDestroy(stream)); \n}\n\n__global__ void k_polarToCartesian(float* radius, float* angle, float* x, float* y, int n) {\n", "test": "int main() {\n    launch();\n}\n", "example_test": "    @example_test\n", "cuda_toolkit": "12.2"}
{"task_id": "CUDA/94", "date": "2025-03-31", "prompt": "Write a CUDA kernel to join two large images side-by-side, processing each pixel in parallel and designed to handle large datasets.\n\nThe signature of the function is __global__ void k_joinImages(const unsigned char* image1_d, const unsigned char* image2_d, unsigned char* outputImage_d, int width, int height), where image1_d is the array of first image, image2_d is the array of second image, outputImage_d is the array of joined images, and width and height specify the dimensions of both input images.\n\n>>> k_joinImages({{1,2,3}, {4,5,6}, {7,8,9}, {10,11,12}}, {{5,6,7}, {8,9,10}, {11,12,13}, {14,15,16}}, outputImage_d, 3, 4) -> outputImage_d: ({{1,2,3,5,6,7},{4,5,6,8,9,10},{7,8,9,11,12,13},{10,11,12,14,15,16}})\n>>> k_joinImages({{1,2,3,4,5}, {6,7,8,9,10}, {11,12,13,14,15}, {16,17,18,19,20}}, {{5,6,7,8,9}, {10,11,12,13,14}, {15,16,17,18,19}, {20,21,22,23,24}},outputImage_d, 5, 4) -> outputImage_d: ({{1,2,3,4,5,5,6,7,8,9}, {6,7,8,9,10,10,11,12,13,14}, {11,12,13,14,15,15,16,17,18,19}, {16,17,18,19,20,20,21,22,23,24}})\n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_70 -arch=sm_60", "ld_flags": "", "declaration": "#include <cuda_runtime.h>\n#include <stdio.h>\n#include <stdlib.h>\n\n#define BLOCK_SIZE 16\n#define TEST_CASES 10\n#define CUDA_CHECK(call)                                                           \\\ndo {                                                                               \\\n        cudaError_t error = call;                                                  \\\n        if (error != cudaSuccess) {                                                \\\n            fprintf(stderr, \"CUDA Error: %s at %s:%d\\n\", cudaGetErrorString(error),\\\n                    __FILE__, __LINE__);                                           \\\n            exit(error);                                                           \\\n        }                                                                          \\\n} while (0)\n\ntypedef unsigned char uchar;\n\n__global__ void k_joinImages(const uchar* image1_d, \n                             const uchar* image2_d, \n                                   uchar* outputImage_d, \n                                   int    width,\n                                   int    height);\n\n#undef NDEBUG\n#include <assert.h>\nvoid launch() {\n\n    int testCaseRows[TEST_CASES] = { 4,5,8,10,12,15,17,20,22,25 };\n    int testCaseCols[TEST_CASES] = { 3,4,11,13,16,18,20,21,23,26 };\n\n    for (int testcase = 0; testcase < TEST_CASES; testcase++) {\n\n        // Initialization\n        int numRows = testCaseRows[testcase];\n        int numCols = testCaseCols[testcase];\n        uchar* image1_h = (uchar*)malloc(numRows * numCols * sizeof(uchar));\n        uchar* image2_h = (uchar*)malloc(numRows * numCols * sizeof(uchar));\n        uchar* outputImage = (uchar*)malloc((2 * numCols) * numRows * sizeof(uchar));\n\n        for (int i = 0; i < numRows * numCols; i++) {\n            image1_h[i] = i + 1;\n            image2_h[i] = i + 5;\n        }\n\n        // Running the code on CPU\n        for (int row = 0; row < numRows; row++) {\n            for (int col = 0; col < numCols; col++) {\n                outputImage[row * (2 * numCols) + col] = image1_h[row * numCols + col];\n                outputImage[row * (2 * numCols) + col + numCols] = image2_h[row * numCols + col];\n            }\n        }\n\n        // CUDA Initialization and memcpy\n        cudaStream_t stream;\n        CUDA_CHECK(cudaStreamCreate(&stream));\n        uchar* image1_d = nullptr; \n        uchar* image2_d = nullptr; \n        uchar* outputImage_d = nullptr;\n        uchar* outputImage_h = (uchar*)malloc((2 * numCols) * numRows * sizeof(uchar));\n        \n        CUDA_CHECK(cudaMallocAsync(&image1_d, numRows * numCols * sizeof(uchar), stream));\n        CUDA_CHECK(cudaMallocAsync(&image2_d, numRows * numCols * sizeof(uchar), stream));\n        CUDA_CHECK(cudaMallocAsync(&outputImage_d, (2 * numCols) * numRows * sizeof(uchar), stream));\n\n        CUDA_CHECK(cudaMemcpyAsync(image1_d, \n                                   image1_h, \n                                   numRows * numCols * sizeof(uchar), \n                                   cudaMemcpyHostToDevice, \n                                   stream));\n        CUDA_CHECK(cudaMemcpyAsync(image2_d, \n                                   image2_h, \n                                   numRows * numCols * sizeof(uchar), \n                                   cudaMemcpyHostToDevice, \n                                   stream));\n\n        // Running the code on GPU\n        dim3 blockSize(2, 2);  // Each block will handle a 2x2 tile\n        dim3 gridSize((numCols + blockSize.x - 1) / blockSize.x, (numRows + blockSize.y - 1) / blockSize.y);\n        void* args[] = { &image1_d, &image2_d, &outputImage_d, (void*)&numCols, (void*)&numRows };\n        CUDA_CHECK(cudaLaunchKernel((void*)k_joinImages, gridSize, blockSize, args, 0, stream));\n        CUDA_CHECK(cudaMemcpyAsync(outputImage_h, \n                                   outputImage_d, \n                                   (2 * numCols) * numRows * sizeof(uchar), \n                                   cudaMemcpyDeviceToHost, \n                                   stream));\n\n        // Verification\n        for (int row = 0; row < numRows; row++) {\n            for (int col = 0; col < 2 * numCols; col++) {\n                assert(outputImage[row * (2 * numCols) + col] == outputImage_h[row * (2 * numCols) + col]);\n            }\n        }\n\n        free(image1_h);\n        free(image2_h);\n        free(outputImage);\n        free(outputImage_h);\n        CUDA_CHECK(cudaFreeAsync(image1_d, stream));\n        CUDA_CHECK(cudaFreeAsync(image2_d, stream));\n        CUDA_CHECK(cudaFreeAsync(outputImage_d, stream));\n        CUDA_CHECK(cudaStreamDestroy(stream));\n    }\n}\n\n__global__ void k_joinImages(const uchar* image1_d, \n                             const uchar* image2_d, \n                             uchar*       outputImage_d, \n                             int          width, \n                             int          height) {\n", "test": "int main() {\n    launch();\n}\n", "example_test": "    @example_test\n", "cuda_toolkit": "12.2"}
{"task_id": "CUDA/95", "date": "2025-03-31", "prompt": "Write a CUDA kernel to estimate the value of $\\pi$ using the Monte Carlo simulation method. Utilize shared memory for local reduction of points that fall inside the unit circle.\n\nThe signature of the function is __global__ void k_monteCarlo(int *blockCount_d, int num_points), where blockCount_d is an array that holds the number of points within the circle for each corresponding block, and num_points represents the total number of points used in the simulation.\n\n>>> k_monteCarlo(40, 10000) -> 3.13744\n>>> k_monteCarlo(1563, 400000) -> 3.1466\n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_70 -arch=sm_60", "ld_flags": "", "declaration": "#include <limits>\n#include <cstdio>\n\n#include <cuda.h>\n#include <curand_kernel.h>\n#include <cuda_runtime.h>\n\n#include <algorithm> // For std::max_element\n#include <cassert>\n\n#define CUDA_CHECK(call)                                  \\\ndo {                                                      \\\n        cudaError_t error = call;                         \\\n        if (error != cudaSuccess) {                       \\\n            fprintf(stderr, \"CUDA error at %s:%d - %s\\n\", \\\n                    __FILE__, __LINE__,                   \\\n                    cudaGetErrorString(error));           \\\n                exit(EXIT_FAILURE);                       \\\n        }                                                 \\\n} while (0)\n\nconst int THREADS_PER_BLOCK = 256;\n\nconst float pi_actual_value = 3.14159f;\n\n__global__ void k_monteCarlo(int *blockCount_d, int num_points); \n\n#undef NDEBUG\n#include <assert.h>\n\nvoid launch() {\n    const int testCaseCount = 7; // Number of test cases\n\n    long int number_of_samples[testCaseCount] = {10, 100, 1000, 10000, 50000, 100000, 400000};\n    int maxVectorSize = *std::max_element(number_of_samples, number_of_samples + testCaseCount);\n\n    // Define number of blocks per grid\n    int blocksPerGrid = ceil(float(maxVectorSize) / THREADS_PER_BLOCK);\n\n    // Declare host and device pointers\n    int *blockCount_d = 0;\n    int *blockCount_h = 0; \n\n    // Use a CUDA stream for asynchronous operations\n    cudaStream_t stream;\n    CUDA_CHECK(cudaStreamCreate(&stream));\n\n    // Allocate memory on host and device\n    blockCount_h = (int *)malloc(sizeof(int) * blocksPerGrid);\n    CUDA_CHECK(cudaMallocAsync(&blockCount_d, sizeof(int) * blocksPerGrid, stream));\n\n    // Loop to execute each test case\n    for (int i = 0; i < testCaseCount; ++i) {\n        long int num_of_points = number_of_samples[i];\n        int count_h = 0;     \n\n        // Launch the kernel\n        // Grid: (ceil(num_of_points / THREADS_PER_BLOCK), 1, 1)\n        // Blocks: (THREADS_PER_BLOCK, 1, 1)\n        void *args[] = {&blockCount_d, &num_of_points};\n        CUDA_CHECK(cudaLaunchKernel((void*)k_monteCarlo, blocksPerGrid, THREADS_PER_BLOCK, args, THREADS_PER_BLOCK * sizeof(int), stream));\n        \n        // Copy the result back to host\n        CUDA_CHECK(cudaMemcpyAsync(blockCount_h, blockCount_d, sizeof(int) * blocksPerGrid, cudaMemcpyDeviceToHost));\n\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n\n        // Calculate the value of Pi : Pi = 4 * (number of points inside cirle / Total number of points)\n        for (int i = 0; i < blocksPerGrid; i++) {\n            count_h += blockCount_h[i];\n        }\n\n        float pi_estimated_value = 4.0f * (float(count_h) / num_of_points);\n\n        float tolerance = 0.1f + (10000.0f / num_of_points); // Lower tolerance for larger inputs\n\n        assert(fabs(pi_estimated_value - pi_actual_value) <= tolerance);\n    }\n    // Free device memory\n    CUDA_CHECK(cudaFreeAsync(blockCount_d, stream));\n    CUDA_CHECK(cudaStreamDestroy(stream));\n}\n\n__global__ void k_monteCarlo(int *blockCount_d, \n                            int num_points) \n{\n", "test": "int main() {\n    launch();\n}\n", "example_test": "    @example_test\n", "cuda_toolkit": "12.2"}
{"task_id": "CUDA/96", "date": "2025-03-31", "prompt": "Write a CUDA kernel that applies a rotation transformation to a 2D image using a specified angle theta, where each thread calculates the rotated position of a pixel and maps it to the corresponding input pixel, ensuring proper boundary handling.\n\nThe signature of the function is __global__ void k_rotateImage(float* image_d, float* rotatedImage_d, float angle, int width, int height), where image_d is the input image in row-major order, rotatedImage_d is the output image in row-major order, theta is the rotation angle in radians, width and height specify the dimensions of the image.\n\n>>> k_rotateImage({1,2,3,4,5,6,7,8,9}, rotatedImage_d, 0.707, 3, 3) -> rotatedImage_d: ({4,1,2,7,5,3,8,9,6})\n>>> k_rotateImage({1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16}, rotatedImage_d, 0.707, 4, 4)-> rotatedImage_d: ({0,5,0,2,13,9,6,3,0,14,11,8,0,15,16,12}) \n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_70 -arch=sm_60", "ld_flags": "", "declaration": "#include <cuda_runtime.h>\n#include <cstdio>\n#undef NDEBUG\n#include <assert.h>\n\n#define TOLERANCE 1E-1\n\nconstexpr int BLOCK_SIZE_X = 16;\nconstexpr int BLOCK_SIZE_Y = 16;\n\n#define CUDA_CHECK(call)                                                           \\\ndo {                                                                               \\\n        cudaError_t error = call;                                                  \\\n        if (error != cudaSuccess) {                                                \\\n            fprintf(stderr, \"CUDA Error: %s at %s:%d\\n\", cudaGetErrorString(error),\\\n                    __FILE__, __LINE__);                                           \\\n            exit(error);                                                           \\\n        }                                                                          \\\n} while (0)\n\n\n__global__ void k_rotateImage( float* image_d, \n                               float* rotatedImage_d, \n                               float angle, \n                               int width, \n                               int height);\n\nvoid launch() {\n    constexpr float PI_VALUE = 3.141592;\n\n    // Set rotation angle (in radians)\n    constexpr float angle = PI_VALUE / 4;  // 45 degrees rotation\n\n    constexpr int MAX_IMG_WIDTH = 10;\n    constexpr int MAX_IMG_HEIGHT = 10;\n    constexpr int MAX_IMG_SIZE = (MAX_IMG_WIDTH * MAX_IMG_HEIGHT);\n\n    // Use a CUDA stream for asynchronous operations\n    cudaStream_t stream;\n    CUDA_CHECK(cudaStreamCreate(&stream));\n\n    float* image_d;\n    float* rotatedImage_d;\n\n    // Allocate device memory\n    CUDA_CHECK(cudaMallocAsync(&image_d, MAX_IMG_SIZE * sizeof(float), stream));\n    CUDA_CHECK(cudaMallocAsync(&rotatedImage_d, MAX_IMG_SIZE * sizeof(float), stream));\n\n    //Test Case 1\n    {\n        constexpr int width = 3;\n        constexpr int height = 3;\n\n        float image_h[width * height] = {\n            1, 2, 3,\n            4, 5, 6,\n            7, 8, 9\n        };\n\n        float expectedOutput_h[width * height] = {\n            4, 1, 2,\n            7, 5, 3,\n            8, 9, 6\n        };\n\n        // Host and device variables\n        float rotatedImage_h[width * height] = { 0 };  // Output matrix (host)\n    \n        // Copy predefined image to device\n        CUDA_CHECK(cudaMemcpyAsync(image_d, image_h, width * height * sizeof(float), cudaMemcpyHostToDevice, stream));\n\n        // Launch kernel with block size 16x16\n        dim3 blockDim(BLOCK_SIZE_X, BLOCK_SIZE_Y);\n        dim3 gridDim((width + blockDim.x - 1) / blockDim.x, (height + blockDim.y - 1) / blockDim.y);\n\n        // Grid: (ceil(width/16),ceil(height/16),1)\n        // Block: (16,16,1)\n        void *args[] = {&image_d, &rotatedImage_d, (void*)&angle, (void*)&width, (void*)&height};        \n        CUDA_CHECK(cudaLaunchKernel((void*)k_rotateImage, gridDim, blockDim, args, 0, stream));\n\n        // Copy rotated image data back to host\n        CUDA_CHECK(cudaMemcpyAsync(rotatedImage_h, rotatedImage_d, width * height * sizeof(float), cudaMemcpyDeviceToHost, stream));\n\n        // Check tasks in the stream has completed\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n\n        for (int y = 0; y < height; y++) {\n            for (int x = 0; x < width; x++) {\n                assert(fabs(rotatedImage_h[y * width + x] - expectedOutput_h[y * width + x]) < TOLERANCE);\n            }\n        }\n    }\n\n    //Test Case 2\n    {\n        constexpr int width = 4;\n        constexpr int height = 4;\n\n        float image_h[width * height] = {\n            1,  2,  3,  4,\n            5,  6,  7,  8,\n            9, 10, 11, 12,\n            13, 14, 15, 16\n        };\n\n        float expectedOutput_h[width * height] = {\n            4, 5, 2, 2,\n            13, 9, 6, 3,\n            6, 14, 11, 8,\n            0, 15, 16, 12\n        };\n\n        // Host and device variables\n        float rotatedImage_h[width * height] = { 0 };  // Output matrix (host)\n        // Copy predefined image to device\n        CUDA_CHECK(cudaMemcpyAsync(image_d, image_h, width * height * sizeof(float), cudaMemcpyHostToDevice, stream));\n\n        // Launch kernel with block size 16x16\n        dim3 blockDim(BLOCK_SIZE_X, BLOCK_SIZE_Y);\n        dim3 gridDim((width + blockDim.x - 1) / blockDim.x, (height + blockDim.y - 1) / blockDim.y);\n\n        // Grid: (ceil(width/16),ceil(height/16),1)\n        // Block: (16,16,1)\n        void *args[] = {&image_d, &rotatedImage_d, (void*)&angle, (void*)&width, (void*)&height};        \n        CUDA_CHECK(cudaLaunchKernel((void*)k_rotateImage, gridDim, blockDim, args, 0, stream));\n\n        // Copy rotated image data back to host\n        CUDA_CHECK(cudaMemcpyAsync(rotatedImage_h, rotatedImage_d, width * height * sizeof(float), cudaMemcpyDeviceToHost, stream));\n\n        // Check tasks in the stream has completed\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n\n        for (int y = 0; y < height; y++) {\n            for (int x = 0; x < width; x++) {\n                assert(fabs(rotatedImage_h[y * width + x] - expectedOutput_h[y * width + x]) < TOLERANCE);\n            }\n        }\n    }\n\n    //Test Case 3\n    {\n        constexpr int width = 5;\n        constexpr int height = 5;\n\n        float image_h[width * height] = {\n            10,  9,  8,  7,  6,\n            5,   4,  3,  2,  1,\n            20, 19, 18, 17, 16,\n            15, 14, 13, 12, 11,\n            25, 24, 23, 22, 21\n        };\n\n        float expectedOutput_h[width * height] = {\n            4, 5, 2, 9, 13,\n            15, 20, 4, 8, 7,\n            11, 14, 18, 2, 16,\n            24, 23, 12, 17, 1,\n            0, 22, 0, 11, 0\n        };\n\n        // Host and device variables\n        float rotatedImage_h[width * height] = { 0 };  // Output matrix (host)\n\n        // Copy predefined image to device\n        CUDA_CHECK(cudaMemcpyAsync(image_d, image_h, width * height * sizeof(float), cudaMemcpyHostToDevice, stream));\n\n        // Launch kernel with block size 16x16\n        dim3 blockDim(BLOCK_SIZE_X, BLOCK_SIZE_Y);\n        dim3 gridDim((width + blockDim.x - 1) / blockDim.x, (height + blockDim.y - 1) / blockDim.y);\n\n        // Grid: (ceil(width/16),ceil(height/16),1)\n        // Block: (16,16,1)\n        void *args[] = {&image_d, &rotatedImage_d, (void*)&angle, (void*)&width, (void*)&height};        \n        CUDA_CHECK(cudaLaunchKernel((void*)k_rotateImage, gridDim, blockDim, args, 0, stream));\n\n        // Copy rotated image data back to host\n        CUDA_CHECK(cudaMemcpyAsync(rotatedImage_h, rotatedImage_d, width * height * sizeof(float), cudaMemcpyDeviceToHost, stream));\n\n        // Check tasks in the stream has completed\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n\n        for (int y = 0; y < height; y++) {\n            for (int x = 0; x < width; x++) {\n                assert(fabs(rotatedImage_h[y * width + x] - expectedOutput_h[y * width + x]) < TOLERANCE);\n            }\n        }\n    }\n\n    //Test Case 4\n    {\n        constexpr int width = 5;\n        constexpr int height = 5;\n\n        float image_h[width * height] = {\n            1,  2,  3,  4,  5,\n            6,  7,  8,  9, 10,\n            11, 12, 13, 14, 15,\n            16, 17, 18, 19, 20,\n            21, 22, 23, 24, 25\n        };\n\n        float expectedOutput_h[width * height] = {\n            4, 6, 2, 2, 13,\n            16, 11, 7, 3, 4,\n            11, 17, 13, 9, 16,\n            22, 23, 19, 14, 10,\n            0, 24, 0, 20, 0\n        };\n\n        // Host and device variables\n        float rotatedImage_h[width * height] = { 0 };  // Output matrix (host)\n\n        // Copy predefined image to device\n        CUDA_CHECK(cudaMemcpyAsync(image_d, image_h, width * height * sizeof(float), cudaMemcpyHostToDevice, stream));\n\n        // Launch kernel with block size 16x16\n        dim3 blockDim(BLOCK_SIZE_X, BLOCK_SIZE_Y);\n        dim3 gridDim((width + blockDim.x - 1) / blockDim.x, (height + blockDim.y - 1) / blockDim.y);\n\n        // Grid: (ceil(width/16),ceil(height/16),1)\n        // Block: (16,16,1)\n        void *args[] = {&image_d, &rotatedImage_d, (void*)&angle, (void*)&width, (void*)&height};        \n        CUDA_CHECK(cudaLaunchKernel((void*)k_rotateImage, gridDim, blockDim, args, 0, stream));\n\n        // Copy rotated image data back to host\n        CUDA_CHECK(cudaMemcpyAsync(rotatedImage_h, rotatedImage_d, width * height * sizeof(float), cudaMemcpyDeviceToHost, stream));\n\n        // Check tasks in the stream has completed\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n\n        for (int y = 0; y < height; y++) {\n            for (int x = 0; x < width; x++) {\n                assert(fabs(rotatedImage_h[y * width + x] - expectedOutput_h[y * width + x]) < TOLERANCE);\n            }\n        }\n    }\n\n    //Test Case 5\n    {\n        constexpr int width = 6;\n        constexpr int height = 6;\n\n        float image_h[width * height] = {\n            1,  2,  3,  4,  5,  6,\n            7,  8,  9, 10, 11, 12,\n            13, 14, 15, 16, 17, 18,\n            19, 20, 21, 22, 23, 24,\n            25, 26, 27, 28, 29, 30,\n            31, 32, 33, 34, 35, 36\n        };\n\n        float expectedOutput_h[width * height] = {\n            4, 6, 13, 8, 3, 16,\n            11, 19, 14, 4, 9, 4,\n            25, 26, 20, 15, 10, 11,\n            32, 10, 27, 22, 17, 20,\n            0, 33, 28, 29, 23, 18,\n            0, 0, 35, 0, 30, 0\n        };\n\n        // Host and device variables\n        float rotatedImage_h[width * height] = { 0 };  // Output matrix (host)\n\n        // Copy predefined image to device\n        CUDA_CHECK(cudaMemcpyAsync(image_d, image_h, width * height * sizeof(float), cudaMemcpyHostToDevice, stream));\n\n        // Launch kernel with block size 16x16\n        dim3 blockDim(BLOCK_SIZE_X, BLOCK_SIZE_Y);\n        dim3 gridDim((width + blockDim.x - 1) / blockDim.x, (height + blockDim.y - 1) / blockDim.y);\n\n        // Grid: (ceil(width/16),ceil(height/16),1)\n        // Block: (16,16,1)\n        void *args[] = {&image_d, &rotatedImage_d, (void*)&angle, (void*)&width, (void*)&height};        \n        CUDA_CHECK(cudaLaunchKernel((void*)k_rotateImage, gridDim, blockDim, args, 0, stream));\n\n        // Copy rotated image data back to host\n        CUDA_CHECK(cudaMemcpyAsync(rotatedImage_h, rotatedImage_d, width * height * sizeof(float), cudaMemcpyDeviceToHost, stream));\n\n        // Check tasks in the stream has completed\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n\n        for (int y = 0; y < height; y++) {\n            for (int x = 0; x < width; x++) {\n                assert(fabs(rotatedImage_h[y * width + x] - expectedOutput_h[y * width + x]) < TOLERANCE);\n            }\n        }\n    }\n\n    //Test Case 6\n    {\n        constexpr int width = 8;\n        constexpr int height = 8;\n\n        float image_h[width * height] = {\n            1,  2,  3,  4,  5,  6,  7,  8,\n            9, 10, 11, 12, 13, 14, 15, 16,\n            17, 18, 19, 20, 21, 22, 23, 24,\n            25, 26, 27, 28, 29, 30, 31, 32,\n            33, 34, 35, 36, 37, 38, 39, 40,\n            41, 42, 43, 44, 45, 46, 47, 48,\n            49, 50, 51, 52, 53, 54, 55, 56,\n            57, 58, 59, 60, 61, 62, 63, 64\n        }; \n\n        float expectedOutput_h[width * height] = {\n            4, 6, 25, 17, 10, 3, 4, 19,\n            14, 33, 9, 26, 19, 12, 20, 5,\n            41, 11, 34, 27, 27, 20, 13, 20,\n            49, 42, 43, 35, 28, 21, 22, 14,\n            58, 51, 30, 44, 37, 30, 0, 23,\n            59, 60, 52, 53, 46, 38, 31, 32,\n            0, 0, 61, 54, 0, 47, 40, 0,\n            0, 0, 0, 62, 55, 48, 0, 0\n        };\n\n        // Host and device variables\n        float rotatedImage_h[width * height] = { 0 };  // Output matrix (host)\n\n        // Copy predefined image to device\n        CUDA_CHECK(cudaMemcpyAsync(image_d, image_h, width * height * sizeof(float), cudaMemcpyHostToDevice, stream));\n\n        // Launch kernel with block size 16x16\n        dim3 blockDim(BLOCK_SIZE_X, BLOCK_SIZE_Y);\n        dim3 gridDim((width + blockDim.x - 1) / blockDim.x, (height + blockDim.y - 1) / blockDim.y);\n\n        // Grid: (ceil(width/16),ceil(height/16),1)\n        // Block: (16,16,1)\n        void *args[] = {&image_d, &rotatedImage_d, (void*)&angle, (void*)&width, (void*)&height};        \n        CUDA_CHECK(cudaLaunchKernel((void*)k_rotateImage, gridDim, blockDim, args, 0, stream));\n\n        // Copy rotated image data back to host\n        CUDA_CHECK(cudaMemcpyAsync(rotatedImage_h, rotatedImage_d, width * height * sizeof(float), cudaMemcpyDeviceToHost, stream));\n\n        // Check tasks in the stream has completed\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n\n        for (int y = 0; y < height; y++) {\n            for (int x = 0; x < width; x++) {\n                assert(fabs(rotatedImage_h[y * width + x] - expectedOutput_h[y * width + x]) < TOLERANCE);\n            }\n        }\n    }\n\n    //Test Case 7\n    {\n        constexpr int width = 10;\n        constexpr int height = 10;\n\n        float image_h[width * height] = {\n            1,  2,  3,  4,  5,  6,  7,  8,  9, 10,\n            11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n            21, 22, 23, 24, 25, 26, 27, 28, 29, 30,\n            31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n            41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n            51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n            61, 62, 63, 64, 65, 66, 67, 68, 69, 70,\n            71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n            81, 82, 83, 84, 85, 86, 87, 88, 89, 90,\n            91, 92, 93, 94, 95, 96, 97, 98, 99, 100\n        };\n\n        float expectedOutput_h[width * height] = {\n            4, 6, 25, 31, 22, 3, 13, 4, 14, 33,\n            9, 51, 41, 42, 32, 23, 14, 15, 5, 6,\n            27, 61, 52, 20, 43, 34, 25, 35, 16, 7,\n            71, 62, 58, 53, 44, 44, 35, 26, 0, 17,\n            82, 72, 63, 64, 54, 45, 36, 37, 27, 18,\n            61, 83, 74, 47, 65, 56, 47, 0, 38, 29,\n            93, 84, 85, 75, 66, 67, 57, 48, 49, 39,\n            0, 95, 0, 86, 77, 0, 68, 59, 0, 50,\n            0, 0, 96, 0, 87, 78, 69, 0, 60, 0,\n            0, 0, 0, 97, 88, 89, 79, 70, 0, 0\n        };\n\n        // Host and device variables\n        float rotatedImage_h[width * height] = { 0 };  // Output matrix (host)\n\n        // Copy predefined image to device\n        CUDA_CHECK(cudaMemcpyAsync(image_d, image_h, width * height * sizeof(float), cudaMemcpyHostToDevice, stream));\n\n        // Launch kernel with block size 16x16\n        dim3 blockDim(BLOCK_SIZE_X, BLOCK_SIZE_Y);\n        dim3 gridDim((width + blockDim.x - 1) / blockDim.x, (height + blockDim.y - 1) / blockDim.y);\n\n        // Grid: (ceil(width/16),ceil(height/16),1)\n        // Block: (16,16,1)\n        void *args[] = {&image_d, &rotatedImage_d, (void*)&angle, (void*)&width, (void*)&height};        \n        CUDA_CHECK(cudaLaunchKernel((void*)k_rotateImage, gridDim, blockDim, args, 0, stream));\n\n        // Copy rotated image data back to host\n        CUDA_CHECK(cudaMemcpyAsync(rotatedImage_h, rotatedImage_d, width * height * sizeof(float), cudaMemcpyDeviceToHost, stream));\n\n        // Check tasks in the stream has completed\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n\n        for (int y = 0; y < height; y++) {\n            for (int x = 0; x < width; x++) {\n                assert(fabs(rotatedImage_h[y * width + x] - expectedOutput_h[y * width + x]) < TOLERANCE);\n            }\n        }\n    }\n    // Free device memory\n    CUDA_CHECK(cudaFree(image_d));\n    CUDA_CHECK(cudaFree(rotatedImage_d));\n    CUDA_CHECK(cudaStreamDestroy(stream));\n}\n\n__global__ void k_rotateImage(  float* image_d, \n                                float* rotatedImage_d, \n                                float angle, \n                                int width, \n                                int height) {\n", "test": "int main() {\n    launch();\n}\n", "example_test": "    @example_test\n", "cuda_toolkit": "12.2"}
{"task_id": "CUDA/97", "date": "2025-03-31", "prompt": "Write a CUDA kernel to calculate the Kronecker product of two matrices. Each thread should compute an element in the Kronecker product matrix.\n\nThe signature of the kernel is __global__ void k_kroneckerProduct(float* matrixA_d, float* matrixB_d, float* matrixKronProd_d, int matARowsize, int matAColsize, int matBRowsize, int matBColsize), where matrixA_d is the pointer to the input matrix A, matrixB_d is the pointer to the input matrix B, matrixKronProd_d is the Kronecker product output of matrix A and matrix B, matARowsize, matBRowsize are the number of rows of matrix A, matrix B respectively while matAColsize, matBColsize are the number of columns of matrix A, matrix B respectively.\n\n>>> k_kroneckerProduct({{1, 2}, {3, 4}}, {{0, 5}, {6, 7}}, matrixKronProd_d, 2, 2, 2, 2) -> matrixKronProd_d:{{0, 5, 0, 10}, {6, 7, 12, 14}, {0, 15, 0, 20}, {18, 21, 24, 28}}\n>>> k_kroneckerProduct({{1}, {2}, {3}}, {{1, 2}, {3, 4}},  matrixKronProd_d, 3, 1, 2, 2) -> matrixKronProd_d:{{1, 2}, {3, 4}, {2, 4}, {6, 8}, {3, 6}, {9, 12}}\n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_70 -arch=sm_60", "ld_flags": "", "declaration": "#include <cstdio>\n#include <algorithm>\n#include <assert.h>\n#include <cuda_runtime.h>\n#undef NDEBUG\n\n#define CUDA_CHECK(call)                                                           \\\ndo {                                                                               \\\n        cudaError_t error = call;                                                  \\\n        if (error != cudaSuccess) {                                                \\\n            fprintf(stderr, \"CUDA Error: %s at %s:%d\\n\", cudaGetErrorString(error),\\\n                    __FILE__, __LINE__);                                           \\\n            exit(error);                                                           \\\n        }                                                                          \\\n} while (0)\n\n#define BLOCK_SIZE 16\n\n__global__ void k_kroneckerProduct( float* matrixA_d, \n                                    float* matrixB_d, \n                                    float* matrixKronProd_d, \n                                    int    matARowsize, \n                                    int    matAColsize, \n                                    int    matBRowsize, \n                                    int    matBColsize);\n\nvoid launch() {\n    // Testcase 1-7\n    {\n        int numTestCases = 7;\n        int matrixAHeight[numTestCases] = {2, 2, 2, 2, 1, 3, 2};\n        int matrixAWidth[numTestCases] =  {2, 2, 2, 2, 3, 1, 3};\n        int matrixBHeight[numTestCases] = {2, 1, 2, 1, 2, 2, 4};\n        int matrixBWidth[numTestCases] =  {2, 2, 1, 3, 2, 2, 4};\n        \n        int maxMatrixAHeight = *std::max_element(matrixAHeight, matrixAHeight + numTestCases);\n        int maxMatrixAWidth = *std::max_element(matrixAWidth, matrixAWidth + numTestCases);\n        int maxMatrixBHeight = *std::max_element(matrixBHeight, matrixBHeight + numTestCases);\n        int maxMatrixBWidth = *std::max_element(matrixBWidth, matrixBWidth + numTestCases);\n\n        float matrixA_h[numTestCases][maxMatrixAHeight * maxMatrixAWidth] ={{1.0, 2.0, 3.0, 4.0},\n                                                                            {1.0, 0.0, 0.0, 1.0},\n                                                                            {1.0, 0.0, 0.0, 1.0},\n                                                                            {1.0, 2.0, 3.0, 4.0},\n                                                                            {1.0, 1.0, 1.0},\n                                                                            {1.0, 2.0, 3.0},\n                                                                            {1.0, -4.0, 7.0, -2.0, 3.0, 3.0}\n                                                                            }; \n\n        float matrixB_h[numTestCases][maxMatrixBHeight * maxMatrixBWidth] = {   {0.0, 5.0, 6.0, 7.0},\n                                                                                {1.0, 1.0},\n                                                                                {1.0, 1.0},\n                                                                                {1.0, 1.0, 1.0},\n                                                                                {1.0, 2.0, 3.0, 4.0},\n                                                                                {1.0, 2.0, 3.0, 4.0},\n                                                                                {8.0, -9.0, -6.0, 5.0, 1.0, -3.0, -4.0, 7.0, 2.0, 8.0, -8.0, -3.0, 1.0, 2.0, -5.0, -1.0}\n                                                                            };\n        \n        int matrixKronProdHeight = maxMatrixAHeight * maxMatrixBHeight;\n        int matrixKronProdWidth = maxMatrixAWidth * maxMatrixBWidth;\n        float* matrixKronProd_h = (float *)calloc(matrixKronProdHeight * matrixKronProdWidth, sizeof(float)); \n        \n        float expectedOutput_h[numTestCases][matrixKronProdHeight * matrixKronProdWidth] = {  {0, 5, 0, 10, 6, 7, 12, 14, 0, 15, 0, 20, 18, 21, 24, 28},\n                                                                                {1, 1, 0, 0, 0, 0, 1, 1},\n                                                                                {1, 0, 1, 0, 0, 1, 0, 1},\n                                                                                {1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4},\n                                                                                {1, 2, 1, 2, 1, 2, 3, 4, 3, 4, 3, 4},\n                                                                                {1, 2, 3, 4, 2, 4, 6, 8, 3, 6, 9, 12},\n                                                                                {8, -9, -6,  5, -32, 36, 24, -20, 56, -63, -42, 35, \n                                                                                 1, -3, -4,  7,  -4, 12, 16, -28,  7, -21, -28, 49,\n                                                                                 2,  8, -8, -3,  -8,-32, 32,  12, 14,  56, -56, -21, \n                                                                                 1,  2, -5, -1,  -4, -8, 20,   4,  7,  14, -35,  -7, \n                                                                                 -16, 18, 12, -10, 24, -27, -18, 15, 24, -27, -18, 15,\n                                                                                 -2,  6,  8, -14, 3, -9, -12, 21, 3, -9, -12, 21,\n                                                                                 -4, -16, 16,  6,  6, 24, -24,  -9, 6,  24,  -24,  -9,\n                                                                                 -2, -4, 10,  2,  3,  6, -15,  -3,  3,  6, -15, -3}\n                                                                             };\n        cudaStream_t stream;\n        CUDA_CHECK(cudaStreamCreate(&stream));\n        \n        // Grid: (1, 1, 1)\n        dim3 gridSize(ceil((matrixKronProdHeight + BLOCK_SIZE - 1) / BLOCK_SIZE), ceil((matrixKronProdWidth + BLOCK_SIZE - 1) / BLOCK_SIZE), 1);\n        \n        // Block: (16, 16, 1)\n        dim3 blockSize(BLOCK_SIZE, BLOCK_SIZE, 1);\n        float* matrixA_d = nullptr;\n        float* matrixB_d = nullptr;\n        float* matrixKronProd_d = nullptr;\n\n        CUDA_CHECK(cudaMallocAsync(&matrixA_d, maxMatrixAHeight * maxMatrixAWidth * sizeof(float), stream));\n        CUDA_CHECK(cudaMallocAsync(&matrixB_d, maxMatrixBHeight * maxMatrixBWidth * sizeof(float), stream));\n        CUDA_CHECK(cudaMallocAsync(&matrixKronProd_d, matrixKronProdHeight * matrixKronProdWidth * sizeof(float), stream));\n\n        for (int tc=0; tc<numTestCases; tc++) {\n            matrixKronProdHeight = matrixAHeight[tc] * matrixBHeight[tc];\n            matrixKronProdWidth = matrixAWidth[tc] * matrixBWidth[tc];\n            CUDA_CHECK(cudaMemcpyAsync(matrixA_d, matrixA_h[tc], matrixAHeight[tc] * matrixAWidth[tc] * sizeof(float), cudaMemcpyHostToDevice, stream));\n            CUDA_CHECK(cudaMemcpyAsync(matrixB_d, matrixB_h[tc], matrixBHeight[tc] * matrixBWidth[tc] * sizeof(float), cudaMemcpyHostToDevice, stream));\n\n            void *args[] = {&matrixA_d, &matrixB_d, &matrixKronProd_d, &matrixAHeight[tc], &matrixAWidth[tc], &matrixBHeight[tc], &matrixBWidth[tc] };\n            CUDA_CHECK(cudaLaunchKernel((void*)k_kroneckerProduct, gridSize, blockSize, args, 0, stream));\n            CUDA_CHECK(cudaMemcpyAsync(matrixKronProd_h, matrixKronProd_d, matrixKronProdHeight * matrixKronProdWidth * sizeof(float), cudaMemcpyDeviceToHost, stream));\n            CUDA_CHECK(cudaStreamSynchronize(stream));\n            \n            for(int i = 0; i < matrixKronProdHeight * matrixKronProdWidth; i++) {\n                assert(matrixKronProd_h[i] == expectedOutput_h[tc][i]);\n            }\n        }\n\n        free(matrixKronProd_h);\n        CUDA_CHECK(cudaFreeAsync(matrixA_d, stream));\n        CUDA_CHECK(cudaFreeAsync(matrixB_d, stream));\n        CUDA_CHECK(cudaFreeAsync(matrixKronProd_d, stream));\n        CUDA_CHECK(cudaStreamDestroy(stream));\n    }\n}\n\n__global__ void k_kroneckerProduct( float* matrixA_d, \n                                    float* matrixB_d, \n                                    float* matrixKronProd_d, \n                                    int    matARowsize, \n                                    int    matAColsize, \n                                    int    matBRowsize, \n                                    int    matBColsize) {\n", "test": "int main() {\n    launch();\n}\n", "example_test": "    @example_test\n", "cuda_toolkit": "12.2"}
{"task_id": "CUDA/98", "date": "2025-03-31", "prompt": "Implement a CUDA kernel to generate a heatmap. Each kernel thread should compute an element in the input array, using minimum and maximum boundary values to clamp and normalize the data.\n\nThe signature of the CUDA kernel is __global__ void k_generateHeatmap(float * input_d, unsigned char * output_d, const float minValue, const float maxValue, const int numElementsX, const int numElementsY), where minValue and maxValue are the boundaries of input data values.\n\n>>> k_generateHeatmap({-1500.0f, -1650.0f, -1800.0f, -1950.0f, -2100.0f, 2250.0f, 2400.0f, 2550.0f, 2700.0f, 2850.0f }, output_d, 1900.0f, 2800.0f, 10, 1) -> output_d:{ 0, 0, 0, 14, 57, 99, 142, 184, 227, 255 }\n>>> k_generateHeatmap({-1.0f, -0.8f, -0.6f, -0.4f, -0.2f, 0.0f, 0.2f, 0.4f, 0.6f, 0.8f }, output_d, -1.0f, 1.0f, 10, 1) -> output_d:{ 0, 25, 51, 77, 102, 128, 153, 179, 204, 230 }\n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_75 -arch=sm_70 -arch=sm_60", "ld_flags": "", "declaration": "#undef NDEBUG\n#include <assert.h>\n#include <stdio.h>\n#include <vector>\n#include <cuda.h>\n#include <cuda_runtime.h>\n#include <device_launch_parameters.h>\n#define CUDA_CHECK(call){                                      \\\n    cudaError_t error = call;                                  \\\n    if(error != cudaSuccess){                                  \\\n        fprintf(stderr, \"CUDA error at %s: %d - %s \\n\",        \\\n                __FILE__, __LINE__, cudaGetErrorString(error));\\\n        exit(EXIT_FAILURE);                                    \\\n    }                                                          \\\n}\nconstexpr int NUM_ELEMENTS_X = 10;\nconstexpr int NUM_ELEMENTS_Y = 1;\nconstexpr int NUM_TOTAL_ELEMENTS = NUM_ELEMENTS_X * NUM_ELEMENTS_Y;\nconstexpr int SCALING_VALUE = 255;\nconstexpr int NUM_GRID_BLOCKS_X = 32;\nconstexpr int NUM_GRID_BLOCKS_Y = 8;\nconstexpr int NUM_BLOCK_THREADS_X = 16;\nconstexpr int NUM_BLOCK_THREADS_Y = 16;\n\n__global__ void k_generateHeatmap(  float * input_d, \n                                    unsigned char * output_d, \n                                    const float minValue, \n                                    const float maxValue,\n                                    const int numElementsX,\n                                    const int numElementsY);\n\nvoid launch() {\n    dim3 gridDim(NUM_GRID_BLOCKS_X, NUM_GRID_BLOCKS_Y, 1);\n    dim3 blockDim(NUM_BLOCK_THREADS_X, NUM_BLOCK_THREADS_Y, 1);\n    float * input_d;\n    unsigned char * output_d;\n    cudaStream_t stream;\n    CUDA_CHECK(cudaStreamCreate(&stream));\n    CUDA_CHECK(cudaMallocAsync(&input_d, sizeof(float) * NUM_TOTAL_ELEMENTS, stream));\n    CUDA_CHECK(cudaMallocAsync(&output_d, sizeof(unsigned char) * NUM_TOTAL_ELEMENTS, stream));\n    std::vector<float> input(NUM_TOTAL_ELEMENTS);\n    std::vector<unsigned char> output(NUM_TOTAL_ELEMENTS);\n    std::vector<unsigned char> expectedOutput(NUM_TOTAL_ELEMENTS);\n    float * input_h = input.data();\n    unsigned char * output_h = output.data();\n    // Test 1: Continuously increasing values with instances of partial overflow and underflow.\n    {\n        constexpr float minValue = 1900.0f;\n        constexpr float maxValue = 2800.0f;\n        void * args[6] = { &input_d, &output_d, (void*)&minValue, (void*)&maxValue, (void*)&NUM_ELEMENTS_X, (void*)&NUM_ELEMENTS_Y };\n        for(int i = 0; i < NUM_TOTAL_ELEMENTS; i++) {\n            input[i] = 1500 + i * 150.0f;\n            expectedOutput[i] = round(255 * (min(max(input[i], minValue), maxValue) - minValue) / (maxValue - minValue));\n        }\n        CUDA_CHECK(cudaMemcpyAsync(input_d, input_h, sizeof(float) * NUM_TOTAL_ELEMENTS, cudaMemcpyHostToDevice, stream));\n        // Block: (NUM_BLOCK_THREADS_X, NUM_BLOCK_THREADS_Y, 1)\n        // Grid: (NUM_GRID_BLOCKS_X, NUM_GRID_BLOCKS_Y, 1)\n        CUDA_CHECK(cudaLaunchKernel((void*)k_generateHeatmap, gridDim, blockDim, args, 0, stream));\n        CUDA_CHECK(cudaMemcpyAsync(output_h, output_d, sizeof(unsigned char) * NUM_TOTAL_ELEMENTS, cudaMemcpyDeviceToHost, stream));\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n        for(int i = 0; i < NUM_TOTAL_ELEMENTS; i++) {\n            assert(expectedOutput[i] == output[i]);\n        }\n    }\n    // Test 2: Duplicate Values.\n    {\n        constexpr float minValue = 1.0f;\n        constexpr float maxValue = 2.0f;\n        void * args[6] = { &input_d, &output_d, (void*)&minValue, (void*)&maxValue, (void*)&NUM_ELEMENTS_X, (void*)&NUM_ELEMENTS_Y };\n        for(int i = 0; i < NUM_TOTAL_ELEMENTS; i++) {\n            input[i] = 1.5f;\n            expectedOutput[i] = round(255 * (min(max(input[i], minValue), maxValue) - minValue) / (maxValue - minValue));\n        }\n        CUDA_CHECK(cudaMemcpyAsync(input_d, input_h, sizeof(float) * NUM_TOTAL_ELEMENTS, cudaMemcpyHostToDevice, stream));\n        // Block: (NUM_BLOCK_THREADS_X, NUM_BLOCK_THREADS_Y, 1)\n        // Grid: (NUM_GRID_BLOCKS_X, NUM_GRID_BLOCKS_Y, 1)\n        CUDA_CHECK(cudaLaunchKernel((void*)k_generateHeatmap, gridDim, blockDim, args, 0, stream));\n        CUDA_CHECK(cudaMemcpyAsync(output_h, output_d, sizeof(unsigned char) * NUM_TOTAL_ELEMENTS, cudaMemcpyDeviceToHost, stream));\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n        for(int i = 0; i < NUM_TOTAL_ELEMENTS; i++) {\n            assert(expectedOutput[i] == output[i]);\n        }\n    }\n    // Test 3: Values beyond the allowed range.\n    {\n        constexpr float minValue = 10.0f;\n        constexpr float maxValue = 100.0f;\n        void * args[6] = { &input_d, &output_d, (void*)&minValue, (void*)&maxValue, (void*)&NUM_ELEMENTS_X, (void*)&NUM_ELEMENTS_Y };\n        for(int i = 0; i < NUM_TOTAL_ELEMENTS; i++) {\n            input[i] = ((i & 1) ? 1.0f : 1000.0f);\n            expectedOutput[i] = round(255 * (min(max(input[i], minValue), maxValue) - minValue) / (maxValue - minValue));\n        }\n        CUDA_CHECK(cudaMemcpyAsync(input_d, input_h, sizeof(float) * NUM_TOTAL_ELEMENTS, cudaMemcpyHostToDevice, stream));\n        // Block: (NUM_BLOCK_THREADS_X, NUM_BLOCK_THREADS_Y, 1)\n        // Grid: (NUM_GRID_BLOCKS_X, NUM_GRID_BLOCKS_Y, 1)\n        CUDA_CHECK(cudaLaunchKernel((void*)k_generateHeatmap, gridDim, blockDim, args, 0, stream));\n        CUDA_CHECK(cudaMemcpyAsync(output_h, output_d, sizeof(unsigned char) * NUM_TOTAL_ELEMENTS, cudaMemcpyDeviceToHost, stream));\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n        for(int i = 0; i < NUM_TOTAL_ELEMENTS; i++) {\n            assert(expectedOutput[i] == output[i]);\n        }\n    }\n    // Test 4: Alternating values.\n    {\n        constexpr float minValue = 10.0f;\n        constexpr float maxValue = 100.0f;\n        void * args[6] = { &input_d, &output_d, (void*)&minValue, (void*)&maxValue, (void*)&NUM_ELEMENTS_X, (void*)&NUM_ELEMENTS_Y };\n        for(int i = 0; i < NUM_TOTAL_ELEMENTS; i++) {\n            input[i] = ((i & 1) ? 20.0f : 80.0f);\n            expectedOutput[i] = round(255 * (min(max(input[i], minValue), maxValue) - minValue) / (maxValue - minValue));\n        }\n        CUDA_CHECK(cudaMemcpyAsync(input_d, input_h, sizeof(float) * NUM_TOTAL_ELEMENTS, cudaMemcpyHostToDevice, stream));\n        // Block: (NUM_BLOCK_THREADS_X, NUM_BLOCK_THREADS_Y, 1)\n        // Grid: (NUM_GRID_BLOCKS_X, NUM_GRID_BLOCKS_Y, 1)\n        CUDA_CHECK(cudaLaunchKernel((void*)k_generateHeatmap, gridDim, blockDim, args, 0, stream));\n        CUDA_CHECK(cudaMemcpyAsync(output_h, output_d, sizeof(unsigned char) * NUM_TOTAL_ELEMENTS, cudaMemcpyDeviceToHost, stream));\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n        for(int i = 0; i < NUM_TOTAL_ELEMENTS; i++) {\n            assert(expectedOutput[i] == output[i]);\n        }\n    }\n    // Test 5: Increasing values within boundaries.\n    {\n        constexpr float minValue = 10.0f;\n        constexpr float maxValue = 100.0f;\n        void * args[6] = { &input_d, &output_d, (void*)&minValue, (void*)&maxValue, (void*)&NUM_ELEMENTS_X, (void*)&NUM_ELEMENTS_Y };\n        for(int i = 0; i < NUM_TOTAL_ELEMENTS; i++) {\n            input[i] = 10.0f + 10.0f * i;\n            expectedOutput[i] = round(255 * (min(max(input[i], minValue), maxValue) - minValue) / (maxValue - minValue));\n        }\n        CUDA_CHECK(cudaMemcpyAsync(input_d, input_h, sizeof(float) * NUM_TOTAL_ELEMENTS, cudaMemcpyHostToDevice, stream));\n        // Block: (NUM_BLOCK_THREADS_X, NUM_BLOCK_THREADS_Y, 1)\n        // Grid: (NUM_GRID_BLOCKS_X, NUM_GRID_BLOCKS_Y, 1)\n        CUDA_CHECK(cudaLaunchKernel((void*)k_generateHeatmap, gridDim, blockDim, args, 0, stream));\n        CUDA_CHECK(cudaMemcpyAsync(output_h, output_d, sizeof(unsigned char) * NUM_TOTAL_ELEMENTS, cudaMemcpyDeviceToHost, stream));\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n        for(int i = 0; i < NUM_TOTAL_ELEMENTS; i++) {\n            assert(expectedOutput[i] == output[i]);\n        }\n    }\n    // Test 6: Randomized inputs.\n    {\n        srand(1);\n        constexpr float minValue = 0.0f;\n        constexpr float maxValue = 1.0f;\n        void * args[6] = { &input_d, &output_d, (void*)&minValue, (void*)&maxValue, (void*)&NUM_ELEMENTS_X, (void*)&NUM_ELEMENTS_Y };\n        for(int i = 0; i < NUM_TOTAL_ELEMENTS; i++) {\n            input[i] = 1.0f / rand();\n            expectedOutput[i] = round(255 * (min(max(input[i], minValue), maxValue) - minValue) / (maxValue - minValue));\n        }\n        CUDA_CHECK(cudaMemcpyAsync(input_d, input_h, sizeof(float) * NUM_TOTAL_ELEMENTS, cudaMemcpyHostToDevice, stream));\n        // Block: (NUM_BLOCK_THREADS_X, NUM_BLOCK_THREADS_Y, 1)\n        // Grid: (NUM_GRID_BLOCKS_X, NUM_GRID_BLOCKS_Y, 1)\n        CUDA_CHECK(cudaLaunchKernel((void*)k_generateHeatmap, gridDim, blockDim, args, 0, stream));\n        CUDA_CHECK(cudaMemcpyAsync(output_h, output_d, sizeof(unsigned char) * NUM_TOTAL_ELEMENTS, cudaMemcpyDeviceToHost, stream));\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n        for(int i = 0; i < NUM_TOTAL_ELEMENTS; i++) {\n            assert(expectedOutput[i] == output[i]);\n        }\n    }\n    // Test 7: A negative minimum value and a positive maximum value.\n    {\n        constexpr float minValue = -1.0f;\n        constexpr float maxValue = 1.0f;\n        void * args[6] = { &input_d, &output_d, (void*)&minValue, (void*)&maxValue, (void*)&NUM_ELEMENTS_X, (void*)&NUM_ELEMENTS_Y };\n        for(int i = 0; i < NUM_TOTAL_ELEMENTS; i++) {\n            input[i] = -1.0f + i * 0.2f;\n            expectedOutput[i] = round(255 * (min(max(input[i], minValue), maxValue) - minValue) / (maxValue - minValue));\n        }\n        CUDA_CHECK(cudaMemcpyAsync(input_d, input_h, sizeof(float) * NUM_TOTAL_ELEMENTS, cudaMemcpyHostToDevice, stream));\n        // Block: (NUM_BLOCK_THREADS_X, NUM_BLOCK_THREADS_Y, 1)\n        // Grid: (NUM_GRID_BLOCKS_X, NUM_GRID_BLOCKS_Y, 1)\n        CUDA_CHECK(cudaLaunchKernel((void*)k_generateHeatmap, gridDim, blockDim, args, 0, stream));\n        CUDA_CHECK(cudaMemcpyAsync(output_h, output_d, sizeof(unsigned char) * NUM_TOTAL_ELEMENTS, cudaMemcpyDeviceToHost, stream));\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n        for(int i = 0; i < NUM_TOTAL_ELEMENTS; i++) {\n            assert(expectedOutput[i] == output[i]);\n        }\n    }\n    CUDA_CHECK(cudaFreeAsync(input_d, stream));\n    CUDA_CHECK(cudaFreeAsync(output_d, stream));\n    CUDA_CHECK(cudaStreamDestroy(stream));\n}\n\n\n__global__ void k_generateHeatmap(  float * input_d, \n                                    unsigned char * output_d, \n                                    const float minValue, \n                                    const float maxValue,\n                                    const int numElementsX,\n                                    const int numElementsY) {\n", "test": "int main() {\n    launch();\n}\n", "example_test": "    @example_test\n", "cuda_toolkit": "12.2"}
{"task_id": "CUDA/99", "date": "2025-03-31", "prompt": "Write a CUDA kernel that adjust brightness of an image leveraging data parallelism. Each thread processes a pixel by multiplying it with a brightness factor. If the resulting value exceeds the upper or lower thresholds, it is clamped to ensure the output remains within valid bounds, effectively saturating the result.\n\nThe signature of the function is __global__ void k_adjustBrightness(const float* inputImage, int upperThreshold, int lowerThreshold, float brightnessFactor, float *outputImage, int size), where inputImage is the pointer to the input image, UpperThreshold and lowerThreshold are the thresolds to ensure output is within valid values , brightnessFactor is a scaling factor to adjust brightness, outputImage is the pointer to the brightness adjusted output image, and size is total number of pixels in input image.\n\n>>> k_adjustBrightness({244.1642, 246.0466, 40.1913, 247.5012, 244.0776, 123.7708, 204.0715, 36.1810}, 250, 5, 0.7577, *outputImage, 8) -> ({185.0032, 186.4295, 30.4529, 187.5317, 184.9376, 93.7811, 154.6250, 27.4143})\n>>> k_adjustBrightness({107.5491, 233.5126, 202.0129, 244.6706, 167.2139, 9.1065, 216.5280, 238.1683, 189.4988, 100.0179}, 245, 10, 0.95, *outputImage, 10) -> ({102.1716, 221.8370, 191.9123, 232.4371, 158.8532, 10.0000, 205.7016, 226.2599, 180.0239, 95.0170})\n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_70 -arch=sm_60", "ld_flags": "", "declaration": "#include <cstdio>\n#include <algorithm>\n#include <cuda_runtime.h>\n#include <assert.h>\n\n#undef  NDEBUG\n#define EPSILON     (1e-2)\n#define BLOCK_SIZE  (256)\n#define CUDA_CHECK(call) \\\ndo { \\\n       cudaError_t error = call; \\\n       if (error != cudaSuccess) { \\\n           fprintf(stderr, \"CUDA error at %s:%d %s\\n\", \\\n                   __FILE__, __LINE__, \\\n                   cudaGetErrorString(error)); \\\n           exit(EXIT_FAILURE); \\\n       } \\\n} while(0)\n\n__global__ void k_adjustBrightness(const float* inputImage, int upperThreshold, int lowerThreshold, float brightnessFactor, float *outputImage, int size);\n\nvoid launch() {\n     // Number of test cases\n    const int TEST_CASE_COUNT = 8;\n    // Sizes of the image in each test case\n    const int INPUT_DATA_LENGTH[TEST_CASE_COUNT] = {8, 10, 10, 12, 14, 15, 11, 13};\n    // Find the maximum image size\n    const int MAX_VECTOR_SIZE = *std::max_element(INPUT_DATA_LENGTH, INPUT_DATA_LENGTH + TEST_CASE_COUNT);\n\n    // Input vectors and configurations for the tests\n    const float inputImage_h[TEST_CASE_COUNT][MAX_VECTOR_SIZE] =  {\n        {244.1642, 246.0466, 40.1913, 247.5012, 244.0776, 123.7708, 204.0715, 36.1810},\n        {107.5491, 233.5126, 202.0129, 244.6706, 167.2139, 9.1065, 216.5280, 238.1683, 189.4988, 100.0179},\n        {140.2899, 158.7311, 149.6964, 52.9743, 76.8178, 120.0855, 58.7745, 215.2987, 49.6649, 57.6101},\n        {151.6985, 66.8640,\t153.7250, 181.3600,\t56.5454, 29.9415, 75.6523, 81.2885, 108.1625, 129.5039,\t21.8065, 66.9330},\n        {100.8564, 93.6963,\t251.9354, 9.6234, 225.7178, 232.8881, 203.0269, 25.1716, 66.7772, 85.5160, 173.3306, 34.8211, 183.9130, 27.2243},\n        {126.0144, 198.6582, 182.3345, 230.4487, 227.1852, 85.2116, 178.1802, 50.4415, 7.7879, 189.7389, 127.5057, 122.3801, 230.7042, 155.5160, 157.5049},\n        {58.0544, 111.1032, 79.3311, 235.4618, 109.7029, 47.1282, 230.7446, 249.8358,\t111.9118, 28.3354, 65.8065},\n        {7.4512,\t236.8578, 186.2344, 124.5953, 147.5239, 60.5073, 117.0065, 245.5876, 139.4355, 132.8896, 59.0566, 124.6689, 159.1353}\n    };\n    const int upperThresholds[TEST_CASE_COUNT] = {\n        250, 245, 247, 244, 241, 235, 230, 225\n    };\n    const int lowerThresholds[TEST_CASE_COUNT] = {\n        5, 10, 13, 15, 18, 20, 23, 27\n    };\n    const float brightnessFactor[TEST_CASE_COUNT] = {\n        0.7577, 0.95, 0.2219, 0.5313, 1.0413, 0.8829, 0.8499, 1.1173\n    };\n\n    // expected outputs\n    const float expectedOutputData[TEST_CASE_COUNT][MAX_VECTOR_SIZE] =  {\n        {185.0032, 186.4295, 30.4529, 187.5317, 184.9376, 93.7811, 154.6250, 27.4143},\n        {102.1716, 221.8370, 191.9123, 232.4371, 158.8532, 10.0000, 205.7016, 226.2599, 180.0239, 95.0170},\n        {31.1332, 35.2257, 33.2207, 13.0000, 17.0474, 26.6494, 13.0433, 47.7792, 13.0000, 13.0000},\n        {80.5974, 35.5248, 81.6741, 96.3566, 30.0426, 15.9079, 40.1941, 43.1886, 57.4667, 68.8054, 15.0000, 35.5615},\n        {105.0218, 97.5660,\t241.0000, 18.0000, 235.0399, 241.0000, 211.4119, 26.2112, 69.5351, 89.0478,\t180.4892, 36.2592, 191.5086, 28.3487},\n        {111.2581, 175.3953, 160.9831, 203.4632, 200.5818, 75.2333, 157.3153, 44.5348, 20.0000, 167.5205, 112.5748, 108.0494, 203.6887, 137.3051, 139.0611},\n        {49.3404, 94.4266, 67.4235, 200.1190, 93.2365, 40.0543, 196.1098, 212.3354, 95.1138, 24.0823, 55.9289},\n        {27.0000, 225.0000, 208.0797, 139.2103, 164.8285, 67.6048, 130.7314, 225.0000, 155.7913, 148.4776, 65.9839, 139.2926, 177.8019}\n    };\n\n    // Use a CUDA stream for asynchronous operations\n    cudaStream_t stream;\n    CUDA_CHECK(cudaStreamCreate(&stream));\n\n    // Initialize results on the host\n    float *outputImage_h;\n    outputImage_h = (float*)malloc(MAX_VECTOR_SIZE * sizeof(float));\n\n    // Pointers for device memory (GPU)\n    float *intputImage_d, *outputImage_d;\n\n    // Allocate the memory on the device\n    CUDA_CHECK(cudaMallocAsync(&intputImage_d, MAX_VECTOR_SIZE * sizeof(float), stream));\n    CUDA_CHECK(cudaMallocAsync(&outputImage_d, MAX_VECTOR_SIZE * sizeof(float), stream));\n\n    // Loop to execute each test case\n    for (int i = 0; i < TEST_CASE_COUNT; ++i) {\n        // Copy input data to the device\n        CUDA_CHECK(cudaMemcpyAsync(intputImage_d, inputImage_h[i], INPUT_DATA_LENGTH[i] * sizeof(float), cudaMemcpyHostToDevice, stream));\n        // Initialize the result on the device\n        CUDA_CHECK(cudaMemsetAsync(outputImage_d, 0, INPUT_DATA_LENGTH[i] * sizeof(float), stream));\n\n        // Determine the number of threads and blocks\n        dim3 gridSize = dim3((INPUT_DATA_LENGTH[i] + BLOCK_SIZE - 1) / BLOCK_SIZE, 1, 1);\n        dim3 blockSize = dim3(BLOCK_SIZE, 1, 1);\n\n        // Execute the kernel\n        // Grid:  ((INPUT_DATA_LENGTH[i] + BLOCK_SIZE - 1) / BLOCK_SIZE, 1, 1)\n        // Block: (BLOCK_SIZE, 1, 1)\n        void *args[] = {&intputImage_d, (void*)&upperThresholds[i], (void*)&lowerThresholds[i], (void*)&brightnessFactor[i], &outputImage_d, (void*)&INPUT_DATA_LENGTH[i]};\n        CUDA_CHECK(cudaLaunchKernel((void*)k_adjustBrightness, gridSize, blockSize, args, 0, stream));\n\n        // Copy the result back to the host (CPU)\n        CUDA_CHECK(cudaMemcpyAsync(outputImage_h, outputImage_d, INPUT_DATA_LENGTH[i] * sizeof(float), cudaMemcpyDeviceToHost, stream));\n\n        // Check tasks in the stream has completed\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n\n        // Verify if the calculated dot product matches the expected result\n        for (int j = 0; j < INPUT_DATA_LENGTH[i]; j++) {\n            assert(fabs(outputImage_h[j] - expectedOutputData[i][j]) < EPSILON);\n        }\n    }\n    // Free device memory and stream\n    cudaFreeAsync(intputImage_d, stream);\n    cudaFreeAsync(outputImage_d, stream);\n    CUDA_CHECK(cudaStreamDestroy(stream));\n    // Free host memories\n    free(outputImage_h);\n}\n\n__global__ void k_adjustBrightness(const float* inputImage, int upperThreshold, int lowerThreshold, float brightnessFactor, float *outputImage, int size) {\n", "test": "int main() {\n    launch();\n}\n", "example_test": "    @example_test\n", "cuda_toolkit": "12.2"}
{"task_id": "CUDA/100", "date": "2025-03-31", "prompt": "Write a CUDA kernel that transforms from image positions to Geo coordinates, where each thread calculates the Geo coordinates for a corresponding pixel positions using geometric transformation:\n\nlatitude = extentWidth + imgX / (imgWidth-1) + extentLeft\nlongitude = extentHeight + imgY / (imgHeight-1) + extentTop.\n\nThe signature of the function is __global__ void k_imagePosToGeoCoord(float* imgX_d, float* imgY_d, float* lat_d, float* long_d, const float4 geoTransform, int width, int height, int imgWidth, int imgHeight), where imgX_d and imgY_d are arrays containing the image coordinates, lat_d and long_d are arrays in which the transformed world coordinates will be stored, width and height define the dimensions of the region to process within the image, while imgWidth and imgHeight represent the original image dimensions used for normalizing the coordinates.\n\n>>> k_imagePosToGeoCoord({0, 71, 142, 213, 284, 355, 426, 497, 568, 639}, {0, 53, 107, 160, 213, 267, 320, 373, 427, 479}, latitude, longitude, {73.25, 23.5, 0.35, 0.25}, 10, 1, 640, 480) -> (latitude: {73.25, 73.2889, 73.3278, 73.3667, 73.4056, 73.4444, 73.4833, 73.5222, 73.5611, 73.6}, longitude:{23.5, 23.5277, 23.5558, 23.5835, 23.6112, 23.6394, 23.667, 23.6947, 23.7229, 23.75})\n>>> k_imagePosToGeoCoord({0, 50, 100, 150, 200, 250, 300, 350, 400, 450}, {0, 50, 100, 150, 200, 250, 300, 350, 400, 450}, latitude, longitude, {73.75, 23.5, 0.35, 0.25}, 10, 1, 640, 480) -> (latitude: {73.75, 73.7774, 73.8048, 73.8322, 73.8595, 73.8869, 73.9143, 73.9417, 73.9691, 73.9965}, longitude:{23.5, 23.5261, 23.5522, 23.5783, 23.6044, 23.6305, 23.6566, 23.6827, 23.7088, 23.7349}) \n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_70 -arch=sm_60", "ld_flags": "", "declaration": "#undef NDEBUG\n#include <assert.h>\n#include <cstdio>\n#include <cuda_runtime.h>\n\n#define CUDA_CHECK(call)                                                           \\\ndo {                                                                               \\\n        cudaError_t error = call;                                                  \\\n        if (error != cudaSuccess) {                                                \\\n            fprintf(stderr, \"CUDA Error: %s at %s:%d\\n\", cudaGetErrorString(error),\\\n                    __FILE__, __LINE__);                                           \\\n            exit(error);                                                           \\\n        }                                                                          \\\n} while (0)\n\n#define TOLERANCE 1E-3\n\n__global__ void k_imagePosToGeoCoord( float* imgX_d, float* imgY_d, float* lat_d, float* long_d, \n                                const float4 geoTransform, \n                                int width, int height, int imgWidth, int imgHeight);\n\nvoid launch() {\n    constexpr int BLOCK_SIZE_X = 32;\n    constexpr int BLOCK_SIZE_Y = 8;\n    constexpr int GRID_SIZE_X = 16;\n    constexpr int GRID_SIZE_Y = 16;\n    constexpr int NUM_POINTS = 10;\n    constexpr int TEST_WIDTH = 10;\n    constexpr int TEST_HEIGHT = 1;\n    constexpr int IMG_WIDTH = 640;\n    constexpr int IMG_HEIGHT = 480;\n\n    // Use a CUDA stream for asynchronous operations.\n    cudaStream_t stream;\n    CUDA_CHECK(cudaStreamCreate(&stream));\n\n    // Allocate device memory\n    float* imgX_d, * imgY_d, * lat_d, * long_d;\n    CUDA_CHECK(cudaMallocAsync((void**)&imgX_d, NUM_POINTS * sizeof(float), stream));\n    CUDA_CHECK(cudaMallocAsync((void**)&imgY_d, NUM_POINTS * sizeof(float), stream));\n    CUDA_CHECK(cudaMallocAsync((void**)&lat_d, NUM_POINTS * sizeof(float), stream));\n    CUDA_CHECK(cudaMallocAsync((void**)&long_d, NUM_POINTS * sizeof(float), stream));\n\n    //Test Case 1: \n    {\n        // Predefined 10 x, y image coordinates (for demonstration).\n        float imgX_h[NUM_POINTS] = { 0, 71, 142, 213, 284, 355, 426, 497, 568, 639 };\n        float imgY_h[NUM_POINTS] = { 0, 53, 107, 160, 213, 267, 320, 373, 427, 479 };\n\n        float expectedOutputLat_h[NUM_POINTS] = { \n            73.25, 73.2889, 73.3278, 73.3667, 73.4056, \n            73.4444, 73.4833, 73.5222, 73.5611, 73.6 \n        };\n        float expectedOutputLon_h[NUM_POINTS] = { \n            23.5, 23.5277, 23.5558, 23.5835, 23.6112, \n            23.6394, 23.667, 23.6947, 23.7229, 23.75 \n        };\n\n        // Array for world coordinates (latitude, longitude).\n        float latitude_h[NUM_POINTS], longitude_h[NUM_POINTS];\n\n        // Image coordinates to some Extent of lat/lon.\n        float4 geoTransform;\n        // Extent Left.\n        geoTransform.x = 73.25;\n        // Extent Top.\n        geoTransform.y = 23.50;\n        // Extent Width.\n        geoTransform.z = 0.35;\n        // Extent Height.\n        geoTransform.w = 0.25;\n\n        // Copy host data to device.\n        CUDA_CHECK(cudaMemcpyAsync( imgX_d, \n                                    imgX_h, \n                                    NUM_POINTS * sizeof(float), \n                                    cudaMemcpyHostToDevice, \n                                    stream));\n        CUDA_CHECK(cudaMemcpyAsync( imgY_d, \n                                    imgY_h, \n                                    NUM_POINTS * sizeof(float), \n                                    cudaMemcpyHostToDevice, \n                                    stream));\n\n        // Define the block size and the grid size.\n        dim3 blockSize(BLOCK_SIZE_X, BLOCK_SIZE_Y);\n        dim3 gridSize(GRID_SIZE_X, GRID_SIZE_Y);\n\n        // Block: (32, 8, 1)\n        // Grid: (16, 16, 1)\n        void *args[] = {\n            &imgX_d, &imgY_d, &lat_d, &long_d, &geoTransform, \n            (void*)&TEST_WIDTH, (void*)&TEST_HEIGHT, (void*)&IMG_WIDTH, (void*)&IMG_HEIGHT\n        };\n        \n        CUDA_CHECK(cudaLaunchKernel((void*)k_imagePosToGeoCoord, \n                                    gridSize, \n                                    blockSize, \n                                    args, \n                                    0, \n                                    stream));\n\n        // Copy the results back to the host.\n        CUDA_CHECK(cudaMemcpyAsync( latitude_h, \n                                    lat_d, \n                                    NUM_POINTS * sizeof(float), \n                                    cudaMemcpyDeviceToHost, \n                                    stream));\n        CUDA_CHECK(cudaMemcpyAsync( longitude_h, \n                                    long_d, \n                                    NUM_POINTS * sizeof(float), \n                                    cudaMemcpyDeviceToHost, \n                                    stream));\n\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n\n        for (int i = 0; i < NUM_POINTS; i++) {\n            assert(abs(latitude_h[i] - expectedOutputLat_h[i]) < TOLERANCE);\n            assert(abs(longitude_h[i] - expectedOutputLon_h[i]) < TOLERANCE);\n        }\n    }\n\n    //Test Case 2: \n    {\n        // Predefined 10 x, y image coordinates.\n        float imgX_h[NUM_POINTS] = { 0, 50, 100, 150, 200, 250, 300, 350, 400, 450 };\n        float imgY_h[NUM_POINTS] = { 0, 50, 100, 150, 200, 250, 300, 350, 400, 450 };\n\n        float expectedOutputLat_h[NUM_POINTS] = { \n            73.75, 73.7774, 73.8048, 73.8322, 73.8595, \n            73.8869, 73.9143, 73.9417, 73.9691, 73.9965 \n        };\n        float expectedOutputLon_h[NUM_POINTS] = { \n            23.5, 23.5261, 23.5522, 23.5783, 23.6044, \n            23.6305, 23.6566, 23.6827, 23.7088, 23.7349 \n        };\n\n        // Array for world coordinates (latitude, longitude).\n        float latitude_h[NUM_POINTS], longitude_h[NUM_POINTS];\n\n        // Image coordinates to some Extent of lat/lon.\n        float4 geoTransform;\n        // Extent Left (longitude).\n        geoTransform.x = 73.75;\n        // Extent Top (latitude).\n        geoTransform.y = 23.50;\n        // Extent Width.\n        geoTransform.z = 0.35;\n        // Extent Height.\n        geoTransform.w = 0.25;\n\n        // Copy host data to device\n        CUDA_CHECK(cudaMemcpyAsync( imgX_d, \n                                    imgX_h, \n                                    NUM_POINTS * sizeof(float), \n                                    cudaMemcpyHostToDevice, \n                                    stream));\n        CUDA_CHECK(cudaMemcpyAsync( imgY_d, \n                                    imgY_h, \n                                    NUM_POINTS * sizeof(float), \n                                    cudaMemcpyHostToDevice, \n                                    stream));\n\n        // Define the block size and the grid size.\n        dim3 blockSize(BLOCK_SIZE_X, BLOCK_SIZE_Y);\n        dim3 gridSize(GRID_SIZE_X, GRID_SIZE_Y);\n\n        // Block: (32, 8, 1)\n        // Grid: (16, 16, 1)\n        void *args[] = {\n            &imgX_d, &imgY_d, &lat_d, &long_d, &geoTransform, \n            (void*)&TEST_WIDTH, (void*)&TEST_HEIGHT, (void*)&IMG_WIDTH, (void*)&IMG_HEIGHT\n        };\n\n        CUDA_CHECK(cudaLaunchKernel((void*)k_imagePosToGeoCoord, \n                                    gridSize, \n                                    blockSize, \n                                    args, \n                                    0, \n                                    stream));\n\n        // Copy the results back to the host.\n        CUDA_CHECK(cudaMemcpyAsync( latitude_h, \n                                    lat_d, \n                                    NUM_POINTS * sizeof(float), \n                                    cudaMemcpyDeviceToHost, \n                                    stream));\n        CUDA_CHECK(cudaMemcpyAsync( longitude_h, \n                                    long_d, \n                                    NUM_POINTS * sizeof(float), \n                                    cudaMemcpyDeviceToHost, \n                                    stream));\n\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n\n        for (int i = 0; i < NUM_POINTS; i++) {\n            assert(abs(latitude_h[i] - expectedOutputLat_h[i]) < TOLERANCE);\n            assert(abs(longitude_h[i] - expectedOutputLon_h[i]) < TOLERANCE);\n        }\n    }\n\n    //Test Case 3: \n    {\n        float imgX_h[NUM_POINTS] = { 200, 250, 300, 350, 400, 450, 500, 550, 600, 639 };\n        float imgY_h[NUM_POINTS] = { 300, 320, 340, 360, 380, 400, 420, 440, 460, 479 };\n\n        float expectedOutputLat_h[NUM_POINTS] = { \n            73.3595, 73.3869, 73.4143, 73.4417, 73.4691, \n            73.4965, 73.5239, 73.5513, 73.5786, 73.6 \n        };\n        float expectedOutputLon_h[NUM_POINTS] = { \n            23.1566, 23.167, 23.1775, 23.1879, 23.1983, \n            23.2088, 23.2192, 23.2296, 23.2401, 23.25 \n        };\n\n        // Array for world coordinates (latitude, longitude).\n        float latitude_h[NUM_POINTS], longitude_h[NUM_POINTS];\n\n        // Image coordinates to some Extent of lat/lon.\n        float4 geoTransform;\n        // Extent Left (longitude)\n        geoTransform.x = 73.25;\n        // Extent Top (latitude)\n        geoTransform.y = 23.00;\n        // Extent Width\n        geoTransform.z = 0.35;\n        // Extent Height\n        geoTransform.w = 0.25;\n\n        // Copy host data to device.\n        CUDA_CHECK(cudaMemcpyAsync( imgX_d, \n                                    imgX_h, \n                                    NUM_POINTS * sizeof(float), \n                                    cudaMemcpyHostToDevice, \n                                    stream));\n        CUDA_CHECK(cudaMemcpyAsync( imgY_d, \n                                    imgY_h, \n                                    NUM_POINTS * sizeof(float), \n                                    cudaMemcpyHostToDevice, \n                                    stream));\n\n        // Define the block size and the grid size.\n        dim3 blockSize(BLOCK_SIZE_X, BLOCK_SIZE_Y);\n        dim3 gridSize(GRID_SIZE_X, GRID_SIZE_Y);\n\n        // Block: (32, 8, 1)\n        // Grid: (16, 16, 1)\n        void *args[] = {\n            &imgX_d, &imgY_d, &lat_d, &long_d, &geoTransform, \n            (void*)&TEST_WIDTH, (void*)&TEST_HEIGHT, (void*)&IMG_WIDTH, (void*)&IMG_HEIGHT\n        };\n\n        CUDA_CHECK(cudaLaunchKernel((void*)k_imagePosToGeoCoord, \n                                    gridSize, \n                                    blockSize, \n                                    args, \n                                    0, \n                                    stream));\n\n        // Copy the results back to the host.\n        CUDA_CHECK(cudaMemcpyAsync( latitude_h, \n                                    lat_d, \n                                    NUM_POINTS * sizeof(float), \n                                    cudaMemcpyDeviceToHost, \n                                    stream));\n        CUDA_CHECK(cudaMemcpyAsync( longitude_h, \n                                    long_d, \n                                    NUM_POINTS * sizeof(float), \n                                    cudaMemcpyDeviceToHost, \n                                    stream));\n\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n\n        for (int i = 0; i < NUM_POINTS; i++) {\n            assert(abs(latitude_h[i] - expectedOutputLat_h[i]) < TOLERANCE);\n            assert(abs(longitude_h[i] - expectedOutputLon_h[i]) < TOLERANCE);\n        }\n    }\n\n    //Test Case 4: \n    {\n        float imgX_h[NUM_POINTS] = { 100, 150, 200, 250, 300, 350, 400, 450, 500, 550 };\n        float imgY_h[NUM_POINTS] = { 120, 140, 160, 180, 200, 220, 240, 260, 280, 300 };\n\n        float expectedOutputLat_h[NUM_POINTS] = { \n            72.5548, 72.5822, 72.6095, 72.6369, 72.6643, \n            72.6917, 72.7191, 72.7465, 72.7739, 72.8013\n        };\n        float expectedOutputLon_h[NUM_POINTS] = { \n            23.5626, 23.5731, 23.5835, 23.5939, 23.6044, \n            23.6148, 23.6253, 23.6357, 23.6461, 23.6566\n        };\n\n        // Array for world coordinates (latitude, longitude).\n        float latitude_h[NUM_POINTS], longitude_h[NUM_POINTS];\n\n        // image coordinates to some Extent of lat/lon.\n        float4 geoTransform;\n        // Extent Left (longitude).\n        geoTransform.x = 72.50;\n        // Extent Top (latitude).\n        geoTransform.y = 23.50;\n        // Extent Width.\n        geoTransform.z = 0.35;\n        // Extent Height.\n        geoTransform.w = 0.25;\n\n        // Copy host data to device.\n        CUDA_CHECK(cudaMemcpyAsync( imgX_d, \n                                    imgX_h, \n                                    NUM_POINTS * sizeof(float), \n                                    cudaMemcpyHostToDevice, \n                                    stream));\n        CUDA_CHECK(cudaMemcpyAsync( imgY_d, \n                                    imgY_h, \n                                    NUM_POINTS * sizeof(float), \n                                    cudaMemcpyHostToDevice, \n                                    stream));\n\n        // Define the block size and the grid size.\n        dim3 blockSize(BLOCK_SIZE_X, BLOCK_SIZE_Y);\n        dim3 gridSize(GRID_SIZE_X, GRID_SIZE_Y);\n\n        // Block: (32, 8, 1)\n        // Grid: (16, 16, 1)\n        void *args[] = {\n            &imgX_d, &imgY_d, &lat_d, &long_d, &geoTransform, \n            (void*)&TEST_WIDTH, (void*)&TEST_HEIGHT, (void*)&IMG_WIDTH, (void*)&IMG_HEIGHT\n        };\n\n        CUDA_CHECK(cudaLaunchKernel((void*)k_imagePosToGeoCoord, \n                                    gridSize, \n                                    blockSize, \n                                    args, \n                                    0, \n                                    stream));\n\n        // Copy the results back to the host.\n        CUDA_CHECK(cudaMemcpyAsync( latitude_h, \n                                    lat_d, \n                                    NUM_POINTS * sizeof(float), \n                                    cudaMemcpyDeviceToHost, \n                                    stream));\n        CUDA_CHECK(cudaMemcpyAsync( longitude_h, \n                                    long_d, \n                                    NUM_POINTS * sizeof(float), \n                                    cudaMemcpyDeviceToHost, \n                                    stream));\n\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n\n        for (int i = 0; i < NUM_POINTS; i++) {\n            assert(abs(latitude_h[i] - expectedOutputLat_h[i]) < TOLERANCE);\n            assert(abs(longitude_h[i] - expectedOutputLon_h[i]) < TOLERANCE);\n        }\n    }\n\n    //Test Case 5: \n    {\n        float imgX_h[NUM_POINTS] = { 50, 120, 180, 240, 310, 370, 420, 500, 550, 600 };\n        float imgY_h[NUM_POINTS] = { 40, 90, 150, 200, 230, 290, 340, 390, 440, 470 };\n\n        float expectedOutputLat_h[NUM_POINTS] = { \n            73.7774, 73.8157, 73.8486, 73.8815, 73.9198, \n            73.9527, 73.98, 74.0239, 74.0513, 74.0786 \n        };\n        float expectedOutputLon_h[NUM_POINTS] = { \n            23.7709, 23.797, 23.8283, 23.8544, 23.87, \n            23.9014, 23.9275, 23.9535, 23.9796, 23.9953\n        };\n\n        // Array for world coordinates (latitude, longitude).\n        float latitude_h[NUM_POINTS], longitude_h[NUM_POINTS];\n\n        // Image coordinates to some Extent of lat/lon.\n        float4 geoTransform;\n        // Extent Left (longitude).\n        geoTransform.x = 73.75;\n        // Extent Top (latitude).\n        geoTransform.y = 23.75;\n        // Extent Width.\n        geoTransform.z = 0.35;\n        // Extent Height.\n        geoTransform.w = 0.25;\n\n        // Copy host data to device.\n        CUDA_CHECK(cudaMemcpyAsync( imgX_d, \n                                    imgX_h, \n                                    NUM_POINTS * sizeof(float), \n                                    cudaMemcpyHostToDevice,\n                                    stream));\n        CUDA_CHECK(cudaMemcpyAsync( imgY_d, \n                                    imgY_h, \n                                    NUM_POINTS * sizeof(float), \n                                    cudaMemcpyHostToDevice, \n                                    stream));\n\n        // Define the block size and the grid size.\n        dim3 blockSize(BLOCK_SIZE_X, BLOCK_SIZE_Y);\n        dim3 gridSize(GRID_SIZE_X, GRID_SIZE_Y);\n\n        // Block: (32, 8, 1)\n        // Grid: (16, 16, 1)\n        void *args[] = {\n            &imgX_d, &imgY_d, &lat_d, &long_d, &geoTransform, \n            (void*)&TEST_WIDTH, (void*)&TEST_HEIGHT, (void*)&IMG_WIDTH, (void*)&IMG_HEIGHT\n        };\n\n        CUDA_CHECK(cudaLaunchKernel((void*)k_imagePosToGeoCoord, \n                                    gridSize, \n                                    blockSize, \n                                    args, \n                                    0, \n                                    stream));\n\n        // Copy the results back to the host.\n        CUDA_CHECK(cudaMemcpyAsync( latitude_h, \n                                    lat_d, \n                                    NUM_POINTS * sizeof(float), \n                                    cudaMemcpyDeviceToHost, \n                                    stream));\n        CUDA_CHECK(cudaMemcpyAsync( longitude_h, \n                                    long_d, \n                                    NUM_POINTS * sizeof(float), \n                                    cudaMemcpyDeviceToHost, \n                                    stream));\n\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n\n        for (int i = 0; i < NUM_POINTS; i++) {\n            assert(abs(latitude_h[i] - expectedOutputLat_h[i]) < TOLERANCE);\n            assert(abs(longitude_h[i] - expectedOutputLon_h[i]) < TOLERANCE);\n        }\n    }\n\n    //Test Case 6: \n    {\n        float imgX_h[NUM_POINTS] = { 100, 100, 100, 100, 100, 100, 100, 100, 100, 100 };\n        float imgY_h[NUM_POINTS] = { 0, 53, 107, 160, 213, 267, 320, 373, 427, 479 };\n\n        float expectedOutputLat_h[NUM_POINTS] = { \n            73.5548, 73.5548, 73.5548, 73.5548, 73.5548, \n            73.5548, 73.5548, 73.5548, 73.5548, 73.5548 \n        };\n        float expectedOutputLon_h[NUM_POINTS] = { \n            23.0, 23.0277, 23.0558, 23.0835, 23.1112, \n            23.1394, 23.167, 23.1947, 23.2229, 23.25\n        };\n\n        // Array for world coordinates (latitude, longitude).\n        float latitude_h[NUM_POINTS], longitude_h[NUM_POINTS];\n\n        // Image coordinates to some Extent of lat/lon.\n        float4 geoTransform;\n        // Extent Left (longitude)\n        geoTransform.x = 73.50;\n        // Extent Top (latitude)\n        geoTransform.y = 23.00;\n        // Extent Width\n        geoTransform.z = 0.35;\n        // Extent Height\n        geoTransform.w = 0.25;\n\n        // Copy host data to device.\n        CUDA_CHECK(cudaMemcpyAsync( imgX_d, \n                                    imgX_h, \n                                    NUM_POINTS * sizeof(float), \n                                    cudaMemcpyHostToDevice, \n                                    stream));\n        CUDA_CHECK(cudaMemcpyAsync( imgY_d, \n                                    imgY_h, \n                                    NUM_POINTS * sizeof(float), \n                                    cudaMemcpyHostToDevice, \n                                    stream));\n\n        // Define the block size and the grid size.\n        dim3 blockSize(BLOCK_SIZE_X, BLOCK_SIZE_Y);\n        dim3 gridSize(GRID_SIZE_X, GRID_SIZE_Y);\n\n        // Block: (32, 8, 1)\n        // Grid: (16, 16, 1)\n        void *args[] = {\n            &imgX_d, &imgY_d, &lat_d, &long_d, &geoTransform, \n            (void*)&TEST_WIDTH, (void*)&TEST_HEIGHT, (void*)&IMG_WIDTH, (void*)&IMG_HEIGHT\n        };\n\n        CUDA_CHECK(cudaLaunchKernel((void*)k_imagePosToGeoCoord, \n                                    gridSize, \n                                    blockSize, \n                                    args, \n                                    0, \n                                    stream));\n\n        // Copy the results back to the host.\n        CUDA_CHECK(cudaMemcpyAsync( latitude_h, \n                                    lat_d, \n                                    NUM_POINTS * sizeof(float), \n                                    cudaMemcpyDeviceToHost, \n                                    stream));\n        CUDA_CHECK(cudaMemcpyAsync( longitude_h, \n                                    long_d, \n                                    NUM_POINTS * sizeof(float), \n                                    cudaMemcpyDeviceToHost, \n                                    stream));\n\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n\n        for (int i = 0; i < NUM_POINTS; i++) {\n            assert(abs(latitude_h[i] - expectedOutputLat_h[i]) < TOLERANCE);\n            assert(abs(longitude_h[i] - expectedOutputLon_h[i]) < TOLERANCE);\n        }\n    }\n\n    //Test Case 7: \n    {\n        float imgX_h[NUM_POINTS] = { 0, 71, 142, 213, 284, 355, 426, 497, 568, 639 };\n        float imgY_h[NUM_POINTS] = { 300, 300, 300, 300, 300, 300, 300, 300, 300, 300 };\n\n        float expectedOutputLat_h[NUM_POINTS] = { \n            72.75, 72.7889, 72.8278, 72.8667, 72.9056, \n            72.9444, 72.9833, 73.0222, 73.0611, 73.1 \n        };\n        float expectedOutputLon_h[NUM_POINTS] = { \n            23.1566, 23.1566, 23.1566, 23.1566, 23.1566, \n            23.1566, 23.1566, 23.1566, 23.1566, 23.1566\n        };\n\n        // Array for world coordinates (latitude, longitude).\n        float latitude_h[NUM_POINTS], longitude_h[NUM_POINTS];\n\n        // Image coordinates to some Extent of lat/lon.\n        float4 geoTransform;\n        // Extent Left (longitude).\n        geoTransform.x = 72.75;\n        // Extent Top (latitude).\n        geoTransform.y = 23.00;\n        // Extent Width.\n        geoTransform.z = 0.35;\n        // Extent Height.\n        geoTransform.w = 0.25;\n\n        // Copy host data to device.\n        CUDA_CHECK(cudaMemcpyAsync( imgX_d, \n                                    imgX_h, \n                                    NUM_POINTS * sizeof(float), \n                                    cudaMemcpyHostToDevice, \n                                    stream));\n        CUDA_CHECK(cudaMemcpyAsync( imgY_d, \n                                    imgY_h, \n                                    NUM_POINTS * sizeof(float), \n                                    cudaMemcpyHostToDevice, \n                                    stream));\n\n        // Define the block size and the grid size.\n        dim3 blockSize(BLOCK_SIZE_X, BLOCK_SIZE_Y);\n        dim3 gridSize(GRID_SIZE_X, GRID_SIZE_Y);\n\n        // Block: (32, 8, 1)\n        // Grid: (16, 16, 1)\n        void *args[] = {\n            &imgX_d, &imgY_d, &lat_d, &long_d, &geoTransform, \n            (void*)&TEST_WIDTH, (void*)&TEST_HEIGHT, (void*)&IMG_WIDTH, (void*)&IMG_HEIGHT\n        };\n\n        CUDA_CHECK(cudaLaunchKernel((void*)k_imagePosToGeoCoord, \n                                    gridSize, \n                                    blockSize, \n                                    args, \n                                    0, \n                                    stream));\n\n        // Copy the results back to the host.\n        CUDA_CHECK(cudaMemcpyAsync( latitude_h, \n                                    lat_d, \n                                    NUM_POINTS * sizeof(float), \n                                    cudaMemcpyDeviceToHost, \n                                    stream));\n        CUDA_CHECK(cudaMemcpyAsync( longitude_h, \n                                    long_d, \n                                    NUM_POINTS * sizeof(float), \n                                    cudaMemcpyDeviceToHost, \n                                    stream));\n\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n\n        for (int i = 0; i < NUM_POINTS; i++) {\n            assert(abs(latitude_h[i] - expectedOutputLat_h[i]) < TOLERANCE);\n            assert(abs(longitude_h[i] - expectedOutputLon_h[i]) < TOLERANCE);\n        }\n    }\n\n    // Free up memory space on the device memory.\n    CUDA_CHECK(cudaFreeAsync(imgX_d, stream));\n    CUDA_CHECK(cudaFreeAsync(imgY_d, stream));\n    CUDA_CHECK(cudaFreeAsync(lat_d, stream));\n    CUDA_CHECK(cudaFreeAsync(long_d, stream));\n    CUDA_CHECK(cudaStreamDestroy(stream)); \n}\n\n__global__ void k_imagePosToGeoCoord( float* imgX_d, float* imgY_d, float* lat_d, float* long_d, \n                                const float4 geoTransform, \n                                int width, int height, int imgWidth, int imgHeight) {\n", "test": "int main() {\n    launch();\n}\n", "example_test": "    @example_test\n", "cuda_toolkit": "12.2"}
{"task_id": "CUDA/101", "date": "2025-03-31", "prompt": "Write a CUDA kernel that performs in place bitonic sort on a dataset. The kernel will use each thread to load a single element and compare it with adjacent elements within a block.\n\nThe signature of the function is __global__ void k_bitonicSort(float* inputData, int size), where inputData is the pointer to the unsorted input and sorted output array, and size denotes the array length of inputData.\n\n>>> k_bitonicSort({4.5, 3, 7.2, 5, 2.1}, 5) => ({2.1, 3, 4.5, 5, 7.2})\n>>> k_bitonicSort({12, 9.5, 15.3, 3, 5.8, 8}, 6) => ({3, 5.8, 8, 9.5, 12, 15.3})\n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_70 -arch=sm_60", "ld_flags": "", "declaration": "#include <cstdio>\n#include <cfloat>\n#include <algorithm>\n#include <cuda_runtime.h>\n#include <assert.h>\n\n#undef  NDEBUG\n#define BLOCK_SIZE  (256)\n#define CUDA_CHECK(call) \\\ndo { \\\n       cudaError_t error = call; \\\n       if (error != cudaSuccess) { \\\n           fprintf(stderr, \"CUDA error at %s:%d %s\\n\", \\\n                   __FILE__, __LINE__, \\\n                   cudaGetErrorString(error)); \\\n           exit(EXIT_FAILURE); \\\n       } \\\n} while(0)\n\n__global__ void k_bitonicSort(float* inputData, int size);\n\nvoid launch() {\n    // Number of test cases\n    const int TEST_CASE_COUNT = 8;\n    // Sizes of the image in each test case\n    const int INPUT_DATA_LENGTH[TEST_CASE_COUNT] = {5, 6, 5, 6, 7, 5, 6, 6};\n    // Find the maximum image size\n    const int MAX_VECTOR_SIZE = *std::max_element(INPUT_DATA_LENGTH, INPUT_DATA_LENGTH + TEST_CASE_COUNT);\n\n    // Input vectors and configurations for the tests\n    float inputImage[TEST_CASE_COUNT][MAX_VECTOR_SIZE] =  {\n        {4.5, 3, 7.2, 5, 2.1},\n        {12, 9.5, 15.3, 3, 5.8, 8},\n        {6.2, 10, 1.5, 7, 8.1},\n        {5, 4.2, 9.8, 3, 7.6, 2},\n        {9, 1.1, 3, 5.5, 6.8, 10, 7.3},\n        {13.5, 15, 7.2, 2.3, 9.9},\n        {14, 3.4, 1, 8.7, 5.3, 7.1},\n        {2, 7.4, 4.6, 6, 5, 3.1}\n    };\n    \n    // expected outputs\n    float expectedOutputData[TEST_CASE_COUNT][MAX_VECTOR_SIZE] =  {\n        {2.1, 3, 4.5, 5, 7.2}, \n        {3, 5.8, 8, 9.5, 12, 15.3}, \n        {1.5, 6.2, 7, 8.1, 10}, \n        {2, 3, 4.2, 5, 7.6, 9.8}, \n        {1.1, 3, 5.5, 6.8, 7.3, 9, 10}, \n        {2.3, 7.2, 9.9, 13.5, 15}, \n        {1, 3.4, 5.3, 7.1, 8.7, 14}, \n        {2, 3.1, 4.6, 5, 6, 7.4}\n    };\n\n    // Use a CUDA stream for asynchronous operations\n    cudaStream_t stream;\n    CUDA_CHECK(cudaStreamCreate(&stream));\n\n    // Initialize results on the host\n    float *imageData_h;\n    imageData_h = (float*)malloc(MAX_VECTOR_SIZE * sizeof(float));\n\n    // Pointers for device memory (GPU)\n    float *imageData_d;\n\n    // Allocate the memory on the device\n    CUDA_CHECK(cudaMallocAsync(&imageData_d, MAX_VECTOR_SIZE * sizeof(float), stream));\n\n    // Loop to execute each test case\n    for (int i = 0; i < TEST_CASE_COUNT; ++i) {\n        int dataLength = INPUT_DATA_LENGTH[i];\n        // Copy input data to the device\n        CUDA_CHECK(cudaMemcpyAsync(imageData_d, inputImage[i], dataLength * sizeof(float), cudaMemcpyHostToDevice, stream));\n        \n        // Determine the number of threads and blocks\n        dim3 gridSize = dim3((dataLength + BLOCK_SIZE - 1) / BLOCK_SIZE, 1, 1);\n        dim3 blockSize = dim3(BLOCK_SIZE, 1, 1);\n\n        // Execute the kernel\n        // Grid:  (1, 1, 1)\n        // Block: (256, 1, 1)\n        void *args[] = {&imageData_d, (void*)&dataLength};\n        CUDA_CHECK(cudaLaunchKernel((void*)k_bitonicSort, gridSize, blockSize, args, sizeof(float) * BLOCK_SIZE, stream));\n\n        // Copy the result back to the host (CPU)\n        CUDA_CHECK(cudaMemcpyAsync(imageData_h, imageData_d, dataLength * sizeof(float), cudaMemcpyDeviceToHost, stream));\n\n        // Check tasks in the stream has completed\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n\n        // Verify if the sorted data matches the expected output\n        for (int j = 0; j < dataLength; j++) {\n            assert(imageData_h[j] == expectedOutputData[i][j]);\n        }\n    }\n    // Free device memory and stream\n    CUDA_CHECK(cudaFreeAsync(imageData_d, stream));\n    CUDA_CHECK(cudaStreamDestroy(stream));\n    // Free host memories\n    free(imageData_h);\n}\n\n__global__ void k_bitonicSort(float* inputData, int size) {\n", "test": "int main() {\n    launch();\n}\n", "example_test": "    @example_test\n", "cuda_toolkit": "12.2"}
{"task_id": "CUDA/102", "date": "2025-03-31", "prompt": "Develop a CUDA kernel to convert the signal from the time domain to the frequency domain using the FFT(Fast Fourier Transform) algorithm. Utilize the device memory to reuse the data for every stage of the FFT.\n\nThe signature of the CUDA kernel is __global__ void k_fftButterfly(float *real_d, float *imag_d, int numElements, int logNumElements), where real_d and image_d are real and imaginary components of input complex number, numElements is the number of elements in the real_d & imag_d arrays, logNumElements is log of input size used for a number of stages in FFT.\n\n>>> k_fftButterfly(real_d{ 1,2,3,4 }, imag_d{ 0,0,0,0 }, 4, 2) --> {real_d{ 10.00000, -2.00000, -2.00000, -2.00000 } imag_d{ 0.00000, 2.00000, 0.00000, -2.00000 } }\n>>> k_fftButterfly(real_d{ 1, 2, 3, 4, 5, 6, 7, 8 }, imag_d{ 0, 0, 0, 0, 0, 0, 0, 0 }, 8, 3) --> {real_d{ 36.00000, -4.00000, -4.00000, -4.00000,-4.00000, -4.00000, -4.00000, -4.00000} imag_d{0.00000, 9.65685, 4.00000, 1.65685, 0.00000, -1.65685, -4.00000, -9.65685 } }\n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_75 -arch=sm_70 -arch=sm_60", "ld_flags": "", "declaration": "#include <assert.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <cuda_runtime.h>\n#include <cooperative_groups.h>\n\n#define CUDA_CHECK(call){                                      \\\n    cudaError_t error = call;                                  \\\n    if(error != cudaSuccess){                                  \\\n        fprintf(stderr, \"CUDA error at %s: %d - %s \\n\",        \\\n                __FILE__, __LINE__, cudaGetErrorString(error));\\\n        exit(EXIT_FAILURE);                                    \\\n    }                                                          \\\n}\n#undef NDEBUG\n\n// Tolerance for floating-point comparison.\n#define EPSILON    1e-5\n#define GRID_SIZE  5\n#define BLOCK_SIZE 128\n#define PI         3.14159265358979323846f\n\n// CUDA kernel for Fast Fourier Transform.\n__global__ void k_fftButterfly(float *real_d, float *imag_d, int numElements, int logNumElements);\n\nvoid launch() {    \n    auto performBitReversedOrdering = [](float* inputReal_h, float* inputImag_h, int numElements) {\n        int logn = log2f(numElements);\n        for (int i = 0; i < numElements; i++) {\n            unsigned int reversed_i = 0;\n            int value = i;\n            for (int j = 0; j < logn; j++) {\n                reversed_i = (reversed_i << 1) | (value & 1);\n                value >>= 1;\n            }\n\n            if (i < reversed_i) {\n                // Swap real and imaginary parts.\n                float temp_real = inputReal_h[i];\n                inputReal_h[i] = inputReal_h[reversed_i];\n                inputReal_h[reversed_i] = temp_real;\n\n                float temp_imag = inputImag_h[i];\n                inputImag_h[i] = inputImag_h[reversed_i];\n                inputImag_h[reversed_i] = temp_imag;\n            }\n        }\n    };\n\n    cudaStream_t stream;\n    CUDA_CHECK(cudaStreamCreate(&stream));\n    \n    // Allocate memory on the device.\n    int maximumTestSize = 16;\n    float *real_d;\n    float *imag_d;\n    CUDA_CHECK(cudaMallocAsync(&real_d, maximumTestSize * sizeof(float), stream));\n    CUDA_CHECK(cudaMallocAsync(&imag_d, maximumTestSize * sizeof(float), stream));\n    \n    // Test case 1.\n    {\n        // Fast Fourier Transform size (must be a power of 2)\n        int numElements = 16;\n        float inputReal_h[numElements] = { 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15,16 };\n        float inputImag_h[numElements] = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 };\n\n        int logn = log2f(numElements);\n        performBitReversedOrdering(inputReal_h, inputImag_h, numElements);\n\n        // Copy input data (already bit-reversed) to the device\n        CUDA_CHECK(cudaMemcpyAsync( real_d, inputReal_h, numElements * sizeof(float), \n                                    cudaMemcpyHostToDevice, stream));\n        CUDA_CHECK(cudaMemcpyAsync( imag_d, inputImag_h, numElements * sizeof(float), \n                                    cudaMemcpyHostToDevice, stream));\n\n        // Grid: (GRID_SIZE, 1, 1)\n        // Block: (BLOCK_SIZE, 1, 1)\n        // Launch the FFT butterfly kernel\n        void* args[]={ &real_d, &imag_d, (void*)&numElements, &logn};\n        CUDA_CHECK(cudaLaunchCooperativeKernel( (void*)k_fftButterfly, \n                                                GRID_SIZE, \n                                                BLOCK_SIZE, \n                                                args, \n                                                0, \n                                                stream));\n\n        // Copy the result back to the host\n        CUDA_CHECK(cudaMemcpyAsync( inputReal_h, real_d, numElements * sizeof(float), \n                                    cudaMemcpyDeviceToHost, stream));\n        CUDA_CHECK(cudaMemcpyAsync( inputImag_h, imag_d, numElements * sizeof(float), \n                                    cudaMemcpyDeviceToHost, stream));\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n        float expectedRealOutput[numElements] = {   136.00000, -8.00000, -8.00000, -8.00000,\n                                                    -8.00000, -8.00000, -8.00000, -8.00000,\n                                                    -8.00000, -8.00000, -8.00000, -8.00000,\n                                                    -8.00000, -8.00000, -8.00000, -8.00000 };\n        float expectedImagOutput[numElements] = {   0.00000, 40.21872, 19.31371, 11.97285,\n                                                    8.00000, 5.34543, 3.31371, 1.59130,\n                                                    0.00000, -1.59130, -3.31371, -5.34543,\n                                                    -8.00000, -11.97285, -19.31371, -40.21872 };\n\n        for (int j = 0; j < numElements; j++) {\n            assert (fabs(inputReal_h[j] - expectedRealOutput[j]) <= EPSILON);\n        }\n        for (int j = 0; j < numElements; j++) {\n            assert (fabs(inputImag_h[j] - expectedImagOutput[j]) <= EPSILON);\n        }\n    }\n\n    // Test case 2.\n    {\n        // Fast Fourier Transform size (must be a power of 2)\n        int numElements = 8;\n        float inputReal_h[numElements] = { 1, 2, 3, 4, 5, 6, 7, 8 };\n        float inputImag_h[numElements] = { 0, 0, 0, 0, 0, 0, 0, 0 };\n\n        int logn = log2f(numElements);\n        performBitReversedOrdering(inputReal_h, inputImag_h, numElements);\n\n        // Copy input data (already bit-reversed) to the device\n        CUDA_CHECK(cudaMemcpyAsync( real_d, inputReal_h, numElements * sizeof(float), \n                                    cudaMemcpyHostToDevice, stream));\n        CUDA_CHECK(cudaMemcpyAsync( imag_d, inputImag_h, numElements * sizeof(float), \n                                    cudaMemcpyHostToDevice, stream));\n\n        // Grid: (GRID_SIZE, 1, 1)\n        // Block: (BLOCK_SIZE, 1, 1)\n        // Launch the FFT butterfly kernel \n        void* args[]={ &real_d, &imag_d, (void*)&numElements, &logn};\n        CUDA_CHECK(cudaLaunchCooperativeKernel( (void*)k_fftButterfly, \n                                                GRID_SIZE, \n                                                BLOCK_SIZE, \n                                                args, \n                                                0, \n                                                stream));\n\n        // Copy the result back to the host.\n        CUDA_CHECK(cudaMemcpyAsync( inputReal_h, real_d, numElements * sizeof(float), \n                                    cudaMemcpyDeviceToHost, stream));\n        CUDA_CHECK(cudaMemcpyAsync( inputImag_h, imag_d, numElements * sizeof(float), \n                                    cudaMemcpyDeviceToHost, stream));\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n\n        float expectedRealOutput[numElements] = {   36.00000, -4.00000, -4.00000, -4.00000,\n                                                    -4.00000, -4.00000, -4.00000, -4.00000 };\n        float expectedImagOutput[numElements] = {   0.00000, 9.65685, 4.00000, 1.65685,\n                                                    0.00000, -1.65685, -4.00000, -9.65685 };\n\n        for (int j = 0; j < numElements; j++) {\n            assert (fabs(inputReal_h[j] - expectedRealOutput[j]) <= EPSILON);\n        }\n\n        for (int j = 0; j < numElements; j++) {\n            assert (fabs(inputImag_h[j] - expectedImagOutput[j]) <= EPSILON);\n        }\n    }\n\n    // Test case 3.\n    {\n        // Fast Fourier Transform size (must be a power of 2)\n        int numElements = 8;\n        float inputReal_h[numElements] = { 0.0, 0.707, 1.0, 0.707, 1.0, -0.707, -1.0, -0.707 };\n        float inputImag_h[numElements] = { 0, 0, 0, 0, 0, 0, 0, 0 };\n\n        int logn = log2f(numElements);\n        performBitReversedOrdering(inputReal_h, inputImag_h, numElements);\n\n        // Copy input data (already bit-reversed) to the device\n        CUDA_CHECK(cudaMemcpyAsync( real_d, inputReal_h, numElements * sizeof(float), \n                                    cudaMemcpyHostToDevice, stream));\n        CUDA_CHECK(cudaMemcpyAsync( imag_d, inputImag_h, numElements * sizeof(float), \n                                    cudaMemcpyHostToDevice, stream));\n\n        // Grid: (GRID_SIZE, 1, 1)\n        // Block: (BLOCK_SIZE, 1, 1)\n        // Launch the FFT butterfly kernel \n        void* args[]={ &real_d, &imag_d, (void*)&numElements, &logn};\n        CUDA_CHECK(cudaLaunchCooperativeKernel( (void*)k_fftButterfly, \n                                                GRID_SIZE, \n                                                BLOCK_SIZE, \n                                                args, \n                                                0, \n                                                stream));\n\n        // Copy the result back to the host\n        CUDA_CHECK(cudaMemcpyAsync( inputReal_h, real_d, numElements * sizeof(float), \n                                    cudaMemcpyDeviceToHost, stream));\n        CUDA_CHECK(cudaMemcpyAsync( inputImag_h, imag_d, numElements * sizeof(float), \n                                    cudaMemcpyDeviceToHost, stream));\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n\n        float expectedRealOutput[numElements] = {   1.00000, -1.00000, 1.00000, -1.00000,\n                                                    1.00000, -1.00000, 1.00000, -1.00000 };\n        float expectedImagOutput[numElements] = {   0.00000, -3.99970, 0.00000, 0.00030,\n                                                    0.00000, -0.00030, 0.00000, 3.99970 };\n\n        for (int j = 0; j < numElements; j++) {\n            assert (fabs(inputReal_h[j] - expectedRealOutput[j]) <= EPSILON);\n        }\n\n        for (int j = 0; j < numElements; j++) {\n            assert (fabs(inputImag_h[j] - expectedImagOutput[j]) <= EPSILON);\n        }\n    }\n\n    // Test case 4.\n    {\n        // Fast Fourier Transform size (must be a power of 2)\n        int numElements = 16;\n        float inputReal_h[numElements] = { 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 };\n        float inputImag_h[numElements] = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 };\n\n        int logn = log2f(numElements);\n        performBitReversedOrdering(inputReal_h, inputImag_h, numElements);\n\n        // Copy input data (already bit-reversed) to the device\n        CUDA_CHECK(cudaMemcpyAsync( real_d, inputReal_h, numElements * sizeof(float), \n                                    cudaMemcpyHostToDevice, stream));\n        CUDA_CHECK(cudaMemcpyAsync( imag_d, inputImag_h, numElements * sizeof(float), \n                                    cudaMemcpyHostToDevice, stream));\n\n        // Grid: (GRID_SIZE, 1, 1)\n        // Block: (BLOCK_SIZE, 1, 1)\n        // Launch the FFT butterfly kernel \n        void* args[]={ &real_d, &imag_d, (void*)&numElements, &logn};\n        CUDA_CHECK(cudaLaunchCooperativeKernel( (void*)k_fftButterfly, \n                                                GRID_SIZE, \n                                                BLOCK_SIZE, \n                                                args, \n                                                0, \n                                                stream));\n\n        // Copy the result back to the host\n        CUDA_CHECK(cudaMemcpyAsync( inputReal_h, real_d, numElements * sizeof(float), \n                                    cudaMemcpyDeviceToHost, stream));\n        CUDA_CHECK(cudaMemcpyAsync( inputImag_h, imag_d, numElements * sizeof(float), \n                                    cudaMemcpyDeviceToHost, stream));\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n\n        float expectedRealOutput[numElements] = {   8.00000, -1.00000, 0.00000, -1.00000,\n                                                    0.00000, -1.00000, 0.00000, -1.00000,\n                                                    0.00000, -1.00000, 0.00000, -1.00000,\n                                                    0.00000, -1.00000, 0.00000, -1.00000 };\n        float expectedImagOutput[numElements] = {   0.00000, 5.02734, 0.00000, 1.49661,\n                                                    0.00000, 0.66818, 0.00000, 0.19891,\n                                                    0.00000, -0.19891, 0.00000, -0.66818,\n                                                    0.00000, -1.49661, 0.00000, -5.02734 };\n\n        for (int j = 0; j < numElements; j++) {\n            assert (fabs(inputReal_h[j] - expectedRealOutput[j]) <= EPSILON);\n        }\n\n        for (int j = 0; j < numElements; j++) {\n            assert (fabs(inputImag_h[j] - expectedImagOutput[j]) <= EPSILON);\n        }\n    }\n\n    // Test case 5.\n    {\n        // Fast Fourier Transform size (must be a power of 2)\n        int numElements = 8;\n        float inputReal_h[numElements] = { 0.0, 0.142857, 0.285714, 0.428571, 0.571429, 0.714286, 0.857143, 1.0 };\n        float inputImag_h[numElements] = { 0, 0, 0, 0, 0, 0, 0, 0 };\n\n        int logn = log2f(numElements);\n        performBitReversedOrdering(inputReal_h, inputImag_h, numElements);\n\n        // Copy input data (already bit-reversed) to the device\n        CUDA_CHECK(cudaMemcpyAsync( real_d, inputReal_h, numElements * sizeof(float), \n                                    cudaMemcpyHostToDevice, stream));\n        CUDA_CHECK(cudaMemcpyAsync( imag_d, inputImag_h, numElements * sizeof(float), \n                                    cudaMemcpyHostToDevice, stream));\n\n        // Grid: (GRID_SIZE, 1, 1)\n        // Block: (BLOCK_SIZE, 1, 1)\n        // Launch the FFT butterfly kernel \n        void* args[]={ &real_d, &imag_d, (void*)&numElements, &logn};\n        CUDA_CHECK(cudaLaunchCooperativeKernel( (void*)k_fftButterfly, \n                                                GRID_SIZE, \n                                                BLOCK_SIZE, \n                                                args, \n                                                0, \n                                                stream));\n\n        // Copy the result back to the host\n        CUDA_CHECK(cudaMemcpyAsync( inputReal_h, real_d, numElements * sizeof(float), \n                                    cudaMemcpyDeviceToHost, stream));\n        CUDA_CHECK(cudaMemcpyAsync( inputImag_h, imag_d, numElements * sizeof(float), \n                                    cudaMemcpyDeviceToHost, stream));\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n\n        float expectedRealOutput[numElements] = {   4.00000, -0.57143, -0.57143, -0.57143,\n                                                    -0.57143, -0.57143, -0.57143, -0.57143 };\n        float expectedImagOutput[numElements] = {   0.00000, 1.37955, 0.57143, 0.23669,\n                                                    0.00000, -0.23669, -0.57143, -1.37955 };\n\n        for (int j = 0; j < numElements; j++) {\n            assert (fabs(inputReal_h[j] - expectedRealOutput[j]) <= EPSILON);\n        }\n\n        for (int j = 0; j < numElements; j++) {\n            assert (fabs(inputImag_h[j] - expectedImagOutput[j]) <= EPSILON);\n        }\n    }\n\n    // Test case 6.\n    {\n        // Fast Fourier Transform size (must be a power of 2)\n        int numElements = 4;\n        float inputReal_h[numElements] = { 1, 2, 3, 4 };\n        float inputImag_h[numElements] = { 0, 0, 0, 0 };\n\n        int logn = log2f(numElements);\n        performBitReversedOrdering(inputReal_h, inputImag_h, numElements);\n\n        // Copy input data (already bit-reversed) to the device\n        CUDA_CHECK(cudaMemcpyAsync( real_d, inputReal_h, numElements * sizeof(float), \n                                    cudaMemcpyHostToDevice, stream));\n        CUDA_CHECK(cudaMemcpyAsync( imag_d, inputImag_h, numElements * sizeof(float), \n                                    cudaMemcpyHostToDevice, stream));\n\n        // Grid: (GRID_SIZE, 1, 1)\n        // Block: (BLOCK_SIZE, 1, 1)\n        // Launch the FFT butterfly kernel \n        void* args[]={ &real_d, &imag_d, (void*)&numElements, &logn};\n        CUDA_CHECK(cudaLaunchCooperativeKernel( (void*)k_fftButterfly, \n                                                GRID_SIZE, \n                                                BLOCK_SIZE, \n                                                args, \n                                                0, \n                                                stream));\n\n        // Copy the result back to the host\n        CUDA_CHECK(cudaMemcpyAsync( inputReal_h, real_d, numElements * sizeof(float), \n                                    cudaMemcpyDeviceToHost, stream));\n        CUDA_CHECK(cudaMemcpyAsync( inputImag_h, imag_d, numElements * sizeof(float), \n                                    cudaMemcpyDeviceToHost, stream));\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n\n        float expectedRealOutput[numElements] = { 10.00000, -2.00000, -2.00000, -2.00000 };\n        float expectedImagOutput[numElements] = { 0.00000, 2.00000, 0.00000, -2.00000 };\n\n        for (int j = 0; j < numElements; j++) {\n            assert (fabs(inputReal_h[j] - expectedRealOutput[j]) <= EPSILON);\n        }\n\n        for (int j = 0; j < numElements; j++) {\n            assert (fabs(inputImag_h[j] - expectedImagOutput[j]) <= EPSILON);\n        }\n    }\n\n    // Test case 7.\n    {\n        // Fast Fourier Transform size (must be a power of 2)\n        int numElements = 8;\n        float inputReal_h[numElements] = { 0, 0, 0, 0, 1, 1, 1, 1 };\n        float inputImag_h[numElements] = { 0, 0, 0, 0, 0, 0, 0, 0 };\n\n        int logn = log2f(numElements);\n        performBitReversedOrdering(inputReal_h, inputImag_h, numElements);\n\n        // Copy input data (already bit-reversed) to the device\n        CUDA_CHECK(cudaMemcpyAsync( real_d, inputReal_h, numElements * sizeof(float), \n                                    cudaMemcpyHostToDevice, stream));\n        CUDA_CHECK(cudaMemcpyAsync( imag_d, inputImag_h, numElements * sizeof(float), \n                                    cudaMemcpyHostToDevice, stream));\n\n        // Grid: (GRID_SIZE, 1, 1)\n        // Block: (BLOCK_SIZE, 1, 1)\n        // Launch the FFT butterfly kernel \n        void* args[]={ &real_d, &imag_d, (void*)&numElements, &logn};\n        CUDA_CHECK(cudaLaunchCooperativeKernel( (void*)k_fftButterfly, \n                                                GRID_SIZE, \n                                                BLOCK_SIZE, \n                                                args, \n                                                0, \n                                                stream));\n\n        // Copy the result back to the host\n        CUDA_CHECK(cudaMemcpyAsync( inputReal_h, real_d, numElements * sizeof(float), \n                                    cudaMemcpyDeviceToHost, stream));\n        CUDA_CHECK(cudaMemcpyAsync( inputImag_h, imag_d, numElements * sizeof(float), \n                                    cudaMemcpyDeviceToHost, stream));\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n\n        float expectedRealOutput[numElements] = {   4.00000, -1.00000, 0.00000, -1.00000,\n                                                    0.00000, -1.00000, 0.00000, -1.00000 };\n        float expectedImagOutput[numElements] = {   0.00000, 2.41421, 0.00000, 0.41421,\n                                                    0.00000, -0.41421, 0.00000, -2.41421 };\n\n        for (int j = 0; j < numElements; j++) {\n            assert (fabs(inputReal_h[j] - expectedRealOutput[j]) <= EPSILON);\n        }\n        for (int j = 0; j < numElements; j++) {\n            assert (fabs(inputImag_h[j] - expectedImagOutput[j]) <= EPSILON);\n        }\n    }\n    \n    // Free device memory.\n    CUDA_CHECK(cudaFreeAsync(real_d, stream));\n    CUDA_CHECK(cudaFreeAsync(imag_d, stream));\n    CUDA_CHECK(cudaStreamDestroy(stream));\n}\n\n__global__ void k_fftButterfly(float *real_d, float *imag_d, int numElements, int logNumElements) {\n", "test": "int main() {\n    launch();\n}\n", "example_test": "    @example_test\n", "cuda_toolkit": "12.2"}
{"task_id": "CUDA/103", "date": "2025-03-31", "prompt": "Write a CUDA kernel to compute the total electromagnetic energy and net acceleration of a system of charged particles using a parallel reduction technique in shared memory, where each thread is responsible for computing the properties of a single particle. Each particle is defined by its mass, charge, three position components, and three velocity components in 3D space.\n\nThe kernel should adhere to the following signature: __global__ void k_computeElectromagneticEnergy(float* mass_d, float* charge_d, float* posX_d, float* posY_d, float* posZ_d, float* velocityX_d, float* velocityY_d, float* velocityZ_d, float* accX_d, float* accY_d, float* accZ_d, float* energy_d, unsigned int particleCount, unsigned int blockSize). Here, mass_d and charge_d are pointers to arrays containing the mass and charge of each particle, respectively; posX_d, posY_d, and posZ_d are arrays containing the x, y, and z components of each particle's position; velocityX_d, velocityY_d, and velocityZ_d are arrays containing the x, y, and z components of each particle's velocity; accX_d, accY_d, and accZ_d are arrays for storing the computed x, y, and z components of each particle's acceleration; energy_d is a pointer to an array storing the electromagnetic energy of each particle; and particleCount is the total number of particles in the system.\n\n>>> k_computeElectromagneticEnergy(mass_d:{9.377778e+00, 4.188704e+00}, charge_d:{3.666271e-07, -1.343065e-07 }, PosX_d:{7.557432e+00, 5.920792e+00}, PosY_d:{2.663286e+00, 9.004688e+00}, PosZ_d:{7.831457e+00, -9.574142e+00}, VelX_d:{4.866964e+00, 1.766176e-01}, VelY_d:{3.788892e+00, 2.608461e+00}, VelZ_d:{3.423035e+00, 8.226066e-01}, accX_d, accY_d, accZ_d, energy_d,particleCount:{2}) -> AccX:{1.201183e-08, -2.689238e-08}, AccY:{-4.654157e-08, 1.041984e-07}, AccZ:{1.277452e-07, -2.859992e-07}, energy_d: 2.490527e+02\n>>> k_computeElectromagneticEnergy(mass_d:5.075351e+00, 7.386061e+00, 4.689754e+00}, charge_d:{4.102964e-07, -1.551322e-07, -9.556600e-07}, PosX_d:{-9.194314e+00, 3.681394e+00, 9.178165e+00}, PosY_d:{ -5.453526e+00, -8.182205e+00, 9.368402e+00}, PosZ_d:{6.816517e+00, -2.430100e+00, 1.251886e+00}, VelX_d:{2.445421e+00, -1.954804e+00, 3.721204e+00}, VelY_d:{3.764471e+00, -2.396704e+00, -4.160023e+00}, VelZ_d:{1.780605e-01, 4.350655e+00, -2.173305e+00}, accX_d, accY_d, accZ_d, energy_d,particleCount:{3}) -> AccX:{-1.243298e-06, 3.900122e-07, 7.312794e-07}, AccY:{-6.476981e-07, 4.291686e-07, 2.503966e-08}, AccZ:{5.214195e-07, -7.143858e-08, -4.517800e-07}, energy_d: 2.405715e+02\n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_70", "ld_flags": "", "declaration": "\n#define BLOCK_SIZE 256\n#define MAX_ITERATIONS 100\n#define REPORT_INTERVAL 10\n\n#undef NDEBUG\n#include <assert.h>\n#include <cuda_runtime.h>\n#include <iomanip>\n#include <iostream>\n#include <random>\n\n#define CUDA_CHECK(call)                                                                           \\\n    do {                                                                                           \\\n        cudaError_t error = call;                                                                  \\\n        if(error != cudaSuccess) {                                                                 \\\n            fprintf(stderr,                                                                        \\\n                    \"CUDA Error: %s at %s:%d\\n\",                                                   \\\n                    cudaGetErrorString(error),                                                     \\\n                    __FILE__,                                                                      \\\n                    __LINE__);                                                                     \\\n            exit(error);                                                                           \\\n        }                                                                                          \\\n    } while(0)\n\n// Global variables to track validation state\nbool g_validationPassed = true;\n\n// Physical constants\nconst float KCONSTANT = 8.99e9f; // Coulomb's constant [N \u22c5 m ^2 /C^2]\nconst float MU0 = 1.256e-6f;     // Magnetic permeability [N/A^2]\nconst float PI = 3.14159265359f;\nconst float TOLERANCE = 1.0e-5f;\n\n__global__ void k_computeElectromagneticEnergy(float *mass_d,              // Particle masses\n                                               float *charge_d,            // Particle charges\n                                               float *posX_d,              // X-coordinates\n                                               float *posY_d,              // Y-coordinates\n                                               float *posZ_d,              // Z-coordinates\n                                               float *velocityX_d,         // X-velocities\n                                               float *velocityY_d,         // Y-velocities\n                                               float *velocityZ_d,         // Z-velocities\n                                               float *accX_d,              // X-accelerations\n                                               float *accY_d,              // Y-accelerations\n                                               float *accZ_d,              // Z-accelerations\n                                               float *energy_d,            // Output energy\n                                               unsigned int particleCount, // Number of particles\n                                               unsigned int blockSize      // Block size\n);\n\nvoid launch() {\n    const int NUM_TEST_CASES = 7;\n    const int PARTICLES_PER_CASE = 2;\n\n    const float VALIDATION_MASSES[7][2] = {\n        {3.631876e+00f, 9.131354e+00f},\n        {7.385075e+00f, 4.135964e+00f},\n        {9.751878e+00f, 2.960669e+00f},\n        {9.148198e+00f, 6.492680e+00f},\n        {8.672558e+00f, 7.371018e+00f},\n        {7.200110e+00f, 5.005208e+00f},\n        {5.579023e+00f, 5.783645e+00f},\n    };\n\n    const float VALIDATION_CHARGES[7][2] = {\n        {-4.155725e-07f, -1.651483e-07f},\n        {1.781762e-07f, 8.628020e-07f},\n        {-9.322497e-07f, -4.253100e-07f},\n        {-9.231530e-08f, -7.772045e-07f},\n        {9.564041e-07f, -1.491385e-07f},\n        {-8.315006e-07f, -5.551410e-07f},\n        {9.200888e-07f, -6.638066e-08f},\n    };\n\n    const float VALIDATION_POSITIONS_x[7][2] = {\n        {-8.544486e+00f, -5.482904e+00f},\n        {-7.841232e+00f, 7.503757e+00f},\n        {-4.843404e+00f, -9.931945e+00f},\n        {2.309865e+00f, -9.637021e+00f},\n        {3.924267e+00f, 3.997861e+00f},\n        {-7.573712e+00f, -6.023051e+00f},\n        {4.921102e+00f, 2.508144e+00f},\n    };\n\n    const float VALIDATION_POSITIONS_y[7][2] = {\n        {5.302430e+00f, -6.205835e-01f},\n        {-3.714027e-01f, -2.555189e-01f},\n        {-2.710483e+00f, -9.535002e+00f},\n        {-2.608790e+00f, -7.187396e+00f},\n        {7.878727e+00f, 6.448950e+00f},\n        {9.182911e-01f, -1.071891e+00f},\n        {-4.088163e+00f, 5.619675e+00f},\n    };\n\n    const float VALIDATION_POSITIONS_z[7][2] = {\n        {-4.939939e+00f, 5.555338e+00f},\n        {9.691526e+00f, -2.641640e+00f},\n        {-2.385830e+00f, -2.894819e+00f},\n        {-1.670827e+00f, -6.687011e+00f},\n        {6.146811e+00f, -7.164505e+00f},\n        {9.310335e+00f, 3.165870e+00f},\n        {2.570685e+00f, -3.728041e+00f},\n    };\n\n    const float VALIDATION_VELOCITIES_x[7][2] = {\n        {-1.090332e+00f, 4.086741e+00f},\n        {-4.921796e+00f, 2.353747e+00f},\n        {3.018028e+00f, -2.314307e+00f},\n        {1.160977e+00f, -2.353666e+00f},\n        {4.175297e+00f, 3.360822e+00f},\n        {4.767069e+00f, -2.337892e+00f},\n        {-2.360863e+00f, 2.492331e+00f},\n    };\n\n    const float VALIDATION_VELOCITIES_y[7][2] = {\n        {-3.572402e-01f, 2.205109e+00f},\n        {4.475070e+00f, -2.877292e+00f},\n        {-1.946185e+00f, 4.206961e+00f},\n        {2.165246e+00f, -8.155732e-01f},\n        {2.401717e+00f, 4.081059e-02f},\n        {2.426447e+00f, 2.710342e+00f},\n        {-4.826471e+00f, 3.618288e-01f},\n    };\n\n    const float VALIDATION_VELOCITIES_z[7][2] = {\n        {-4.849432e+00f, -4.564866e+00f},\n        {3.211321e+00f, -1.556432e+00f},\n        {-9.697361e-01f, 2.183446e+00f},\n        {1.992808e+00f, -3.939872e-01f},\n        {-2.246189e-02f, 2.275865e+00f},\n        {1.266311e+00f, -3.000744e+00f},\n        {7.873082e-01f, -1.649562e+00f},\n    };\n\n    const float VALIDATION_ACCELERATIONS_x[7][2] = {\n        {2.705547e-07f, -1.076096e-07f},\n        {3.763351e-07f, -6.719747e-07f},\n        {-2.998918e-06f, 9.877862e-06f},\n        {-3.245632e-07f, 4.573102e-07f},\n        {-4.534519e-09f, 5.335204e-09f},\n        {3.049669e-06f, -4.387020e-06f},\n        {1.437635e-07f, -1.386773e-07f},\n    };\n\n    const float VALIDATION_ACCELERATIONS_y[7][2] = {\n        {-5.234220e-07f, 2.081842e-07f},\n        {2.842045e-09f, -5.074686e-09f},\n        {-4.022012e-06f, 1.324774e-05f},\n        {-1.243878e-07f, 1.752626e-07f},\n        {8.809609e-08f, -1.036517e-07f},\n        {-3.914069e-06f, 5.630480e-06f},\n        {-5.783912e-07f, 5.579280e-07f},\n    };\n\n    const float VALIDATION_ACCELERATIONS_z[7][2] = {\n        {9.274770e-07f, -3.688917e-07f},\n        {-3.024703e-07f, 5.400835e-07f},\n        {-2.999712e-07f, 9.880479e-07f},\n        {-1.362756e-07f, 1.920125e-07f},\n        {8.201802e-07f, -9.650038e-07f},\n        {-1.208425e-05f, 1.738348e-05f},\n        {3.752769e-07f, -3.619998e-07f},\n    };\n\n    const float VALIDATION_TOTAL_ENERGIES[7] = {2.386897e+02f,\n                                                2.350626e+02f,\n                                                1.086523e+02f,\n                                                6.642221e+01f,\n                                                1.613333e+02f,\n                                                1.633776e+02f,\n                                                1.084686e+02f};\n\n    // Device pointers for particle data\n    float *mass_d, *charge_d;\n    float *posX_d, *posY_d, *posZ_d;\n    float *velocityX_d, *velocityY_d, *velocityZ_d;\n    float *accX_d, *accY_d, *accZ_d;\n    float *energy_d;\n    int particleCount = PARTICLES_PER_CASE;\n\n    // Create CUDA stream\n    cudaStream_t stream;\n    CUDA_CHECK(cudaStreamCreate(&stream));\n\n    // Allocate device memory asynchronously\n    CUDA_CHECK(cudaMallocAsync(&mass_d, PARTICLES_PER_CASE * sizeof(float), stream));\n    CUDA_CHECK(cudaMallocAsync(&charge_d, PARTICLES_PER_CASE * sizeof(float), stream));\n    CUDA_CHECK(cudaMallocAsync(&posX_d, PARTICLES_PER_CASE * sizeof(float), stream));\n    CUDA_CHECK(cudaMallocAsync(&posY_d, PARTICLES_PER_CASE * sizeof(float), stream));\n    CUDA_CHECK(cudaMallocAsync(&posZ_d, PARTICLES_PER_CASE * sizeof(float), stream));\n    CUDA_CHECK(cudaMallocAsync(&velocityX_d, PARTICLES_PER_CASE * sizeof(float), stream));\n    CUDA_CHECK(cudaMallocAsync(&velocityY_d, PARTICLES_PER_CASE * sizeof(float), stream));\n    CUDA_CHECK(cudaMallocAsync(&velocityZ_d, PARTICLES_PER_CASE * sizeof(float), stream));\n    CUDA_CHECK(cudaMallocAsync(&accX_d, PARTICLES_PER_CASE * sizeof(float), stream));\n    CUDA_CHECK(cudaMallocAsync(&accY_d, PARTICLES_PER_CASE * sizeof(float), stream));\n    CUDA_CHECK(cudaMallocAsync(&accZ_d, PARTICLES_PER_CASE * sizeof(float), stream));\n    CUDA_CHECK(cudaMallocAsync(&energy_d, sizeof(float), stream));\n\n    // Synchronize stream to ensure allocations are complete\n    CUDA_CHECK(cudaStreamSynchronize(stream));\n\n    // Host arrays for validation\n    float accX_h[PARTICLES_PER_CASE];\n    float accY_h[PARTICLES_PER_CASE];\n    float accZ_h[PARTICLES_PER_CASE];\n    float gpuEnergy;\n\n    // properties of the device\n    cudaDeviceProp deviceProp;\n    int currentDevice;\n    CUDA_CHECK(cudaGetDevice(&currentDevice));\n    CUDA_CHECK(cudaGetDeviceProperties(&deviceProp, currentDevice));\n\n    int numSMs = deviceProp.multiProcessorCount;\n    int maxBlocksPerSM = deviceProp.maxBlocksPerMultiProcessor;\n    int numBlocks = numSMs * maxBlocksPerSM;\n    unsigned int blockSize = BLOCK_SIZE;\n\n    // Run tests for each case\n    for(int testCase = 0; testCase < NUM_TEST_CASES; testCase++) {\n        // Asynchronously copy test case data to device\n        CUDA_CHECK(cudaMemcpyAsync(mass_d,\n                                   VALIDATION_MASSES[testCase],\n                                   PARTICLES_PER_CASE * sizeof(float),\n                                   cudaMemcpyHostToDevice,\n                                   stream));\n        CUDA_CHECK(cudaMemcpyAsync(charge_d,\n                                   VALIDATION_CHARGES[testCase],\n                                   PARTICLES_PER_CASE * sizeof(float),\n                                   cudaMemcpyHostToDevice,\n                                   stream));\n        CUDA_CHECK(cudaMemcpyAsync(posX_d,\n                                   VALIDATION_POSITIONS_x[testCase],\n                                   PARTICLES_PER_CASE * sizeof(float),\n                                   cudaMemcpyHostToDevice,\n                                   stream));\n        CUDA_CHECK(cudaMemcpyAsync(posY_d,\n                                   VALIDATION_POSITIONS_y[testCase],\n                                   PARTICLES_PER_CASE * sizeof(float),\n                                   cudaMemcpyHostToDevice,\n                                   stream));\n        CUDA_CHECK(cudaMemcpyAsync(posZ_d,\n                                   VALIDATION_POSITIONS_z[testCase],\n                                   PARTICLES_PER_CASE * sizeof(float),\n                                   cudaMemcpyHostToDevice,\n                                   stream));\n        CUDA_CHECK(cudaMemcpyAsync(velocityX_d,\n                                   VALIDATION_VELOCITIES_x[testCase],\n                                   PARTICLES_PER_CASE * sizeof(float),\n                                   cudaMemcpyHostToDevice,\n                                   stream));\n        CUDA_CHECK(cudaMemcpyAsync(velocityY_d,\n                                   VALIDATION_VELOCITIES_y[testCase],\n                                   PARTICLES_PER_CASE * sizeof(float),\n                                   cudaMemcpyHostToDevice,\n                                   stream));\n        CUDA_CHECK(cudaMemcpyAsync(velocityZ_d,\n                                   VALIDATION_VELOCITIES_z[testCase],\n                                   PARTICLES_PER_CASE * sizeof(float),\n                                   cudaMemcpyHostToDevice,\n                                   stream));\n\n        // Synchronize stream to ensure copies are complete before using the data\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n\n        // Reset energy\n        float zero = 0.0f;\n        CUDA_CHECK(cudaMemcpy(energy_d, &zero, sizeof(float), cudaMemcpyHostToDevice));\n\n        // Launch kernel\n        // Grid: (numBlocks, 1, 1)\n        // Block: (256, 1, 1)\n        void *args[] = {&mass_d,\n                        &charge_d,\n                        &posX_d,\n                        &posY_d,\n                        &posZ_d,\n                        &velocityX_d,\n                        &velocityY_d,\n                        &velocityZ_d,\n                        &accX_d,\n                        &accY_d,\n                        &accZ_d,\n                        &energy_d,\n                        &particleCount,\n                        &blockSize};\n        dim3 grid(numBlocks);\n        dim3 block(BLOCK_SIZE);\n        size_t sharedMemSize = BLOCK_SIZE * sizeof(float);\n\n        CUDA_CHECK(cudaLaunchKernel((void *)k_computeElectromagneticEnergy,\n                                    grid,\n                                    block,\n                                    args,\n                                    sharedMemSize,\n                                    nullptr // Default stream\n                                    ));\n\n        // Asynchronously copy results back for validation\n        CUDA_CHECK(cudaMemcpyAsync(\n            accX_h, accX_d, PARTICLES_PER_CASE * sizeof(float), cudaMemcpyDeviceToHost, stream));\n        CUDA_CHECK(cudaMemcpyAsync(\n            accY_h, accY_d, PARTICLES_PER_CASE * sizeof(float), cudaMemcpyDeviceToHost, stream));\n        CUDA_CHECK(cudaMemcpyAsync(\n            accZ_h, accZ_d, PARTICLES_PER_CASE * sizeof(float), cudaMemcpyDeviceToHost, stream));\n        CUDA_CHECK(\n            cudaMemcpyAsync(&gpuEnergy, energy_d, sizeof(float), cudaMemcpyDeviceToHost, stream));\n\n        // Synchronize stream to ensure copies are complete before validation\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n\n        // Check accelerations using relative values\n        for(int i = 0; i < PARTICLES_PER_CASE; i++) {\n            assert(std::abs(accX_h[i] - VALIDATION_ACCELERATIONS_x[testCase][i]) /\n                       VALIDATION_ACCELERATIONS_x[testCase][i] <=\n                   TOLERANCE);\n            assert(std::abs(accY_h[i] - VALIDATION_ACCELERATIONS_y[testCase][i]) /\n                       VALIDATION_ACCELERATIONS_y[testCase][i] <=\n                   TOLERANCE);\n            assert(std::abs(accZ_h[i] - VALIDATION_ACCELERATIONS_z[testCase][i]) /\n                       VALIDATION_ACCELERATIONS_z[testCase][i] <=\n                   TOLERANCE);\n        }\n\n        // Check energy\n        assert(std::abs(gpuEnergy - VALIDATION_TOTAL_ENERGIES[testCase]) /\n                   VALIDATION_TOTAL_ENERGIES[testCase] <=\n               TOLERANCE);\n    }\n\n    // Cleanup\n    CUDA_CHECK(cudaFreeAsync(mass_d, stream));\n    CUDA_CHECK(cudaFreeAsync(charge_d, stream));\n    CUDA_CHECK(cudaFreeAsync(posX_d, stream));\n    CUDA_CHECK(cudaFreeAsync(posY_d, stream));\n    CUDA_CHECK(cudaFreeAsync(posZ_d, stream));\n    CUDA_CHECK(cudaFreeAsync(velocityX_d, stream));\n    CUDA_CHECK(cudaFreeAsync(velocityY_d, stream));\n    CUDA_CHECK(cudaFreeAsync(velocityZ_d, stream));\n    CUDA_CHECK(cudaFreeAsync(accX_d, stream));\n    CUDA_CHECK(cudaFreeAsync(accY_d, stream));\n    CUDA_CHECK(cudaFreeAsync(accZ_d, stream));\n    CUDA_CHECK(cudaFreeAsync(energy_d, stream));\n    CUDA_CHECK(cudaStreamDestroy(stream));\n}\n\n__global__ void k_computeElectromagneticEnergy(float *mass_d,              // Particle masses\n                                               float *charge_d,            // Particle charges\n                                               float *posX_d,              // X-coordinates\n                                               float *posY_d,              // Y-coordinates\n                                               float *posZ_d,              // Z-coordinates\n                                               float *velocityX_d,         // X-velocities\n                                               float *velocityY_d,         // Y-velocities\n                                               float *velocityZ_d,         // Z-velocities\n                                               float *accX_d,              // X-accelerations\n                                               float *accY_d,              // Y-accelerations\n                                               float *accZ_d,              // Z-accelerations\n                                               float *energy_d,            // Output energy\n                                               unsigned int particleCount, // Number of particles\n                                               unsigned int blockSize      // Block size\n) {\n", "test": "int main() {\n    launch();\n}\n", "example_test": "    @example_test\n", "cuda_toolkit": "12.2"}
{"task_id": "CUDA/104", "date": "2025-03-31", "prompt": "Write a CUDA kernel to simulate temperature distribution across a 2D plate where each boundary point has a fixed temperature, and the plate has a thickness of one element. The kernel should utilize device memory to reuse data and update inner temperatures based on the average of the top, bottom, left, and right temperatures in each iteration of the simulation.\n\nThe signature of the function is __global__ void k_temperatureDistribution(float *temperatureValues, int numPlateElementsX, int numPlateElementsY, int numIterations), where temperatureValues is the array to the current temperature of plate, numPlateElementsX is the number of elements along the x-axis of the plate, numPlateElementsY is the number of elements along the y-axis of the plate, and numIterations is the number of iterations to simulate the temperature distribution.\n\n>>> k_temperatureDistribution(temperatureValues: {320.0, 320.0, 320.0, 320.0, 320.0, 0.0, 0.0, 320.0, 320.0, 0.0, 0.0, 320.0, 320.0, 320.0, 320.0, 320.0}, 4, 4, 3) -> temperatureValues: {320.0, 320.0, 320.00, 320.0, 320.0, 280.0, 280.0, 320.0, 320.0, 280.0, 280.0, 320.0, 320.0, 320.0, 320.0, 320.0}\n>>> k_temperatureDistribution(temperatureValues: {360.0, 366.667, 373.333, 380.0, 386.667, 460.0, 0.0, 0.0, 0.0, 393.333, 453.333, 0.0, 0.0, 0.0, 400.0, 446.667, 0.0, 0.0, 0.0, 406.667, 440.0, 433.333, 426.667, 420.0, 413.333}, 5, 5, 2) -> temperatureValues: {360.000000, 366.666656, 373.333313, 379.999969, 386.666626, 459.999847, 258.333282, 193.333313, 241.666641, 393.333282, 453.333191, 219.999939, 103.333313, 199.999969, 399.999939, 446.666534, 274.999939, 213.333282, 258.333282, 406.666595, 439.999878, 433.333221, 426.666565, 419.999908, 413.333252}\n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_75 -arch=sm_70", "ld_flags": "", "declaration": "#include <cstdio>\n#include <algorithm>\n#include <cstring>\n#include <cuda_runtime.h>\n#include <assert.h>\n#include <cooperative_groups.h>\n\nnamespace cg = cooperative_groups;\n\n#undef NDEBUG\n // Tolerance for floating-point comparison\n#define TOLERANCE               (1e-2)\n// Number of threads per block\n#define BLOCK_SIZE              (16)\n// Number of elements allocated for device memory\n#define NUM_DEVICE_MEMORY_ELEM  (1024)\n#define CUDA_CHECK(call)                                        \\\ndo {                                                            \\\n        cudaError_t error = call;                               \\\n        if (error != cudaSuccess) {                             \\\n            fprintf(stderr, \"CUDA error at %s:%d - %s\\n\",       \\\n                    __FILE__, __LINE__,                         \\\n                    cudaGetErrorString(error));                 \\\n            exit(EXIT_FAILURE);                                 \\\n        }                                                       \\\n} while(0)\n\n__global__ void k_temperatureDistribution(float *temperatureValues, int numPlateElementsX, int numPlateElementsY, int numIterations);\n\n__device__ float plateCurrentTemperatures_d[NUM_DEVICE_MEMORY_ELEM];\n__device__ float alternateBuffer_d[NUM_DEVICE_MEMORY_ELEM];\n\nvoid launch() {\n    // Number of test cases\n    const int TEST_CASE_COUNT = 9;\n    // Input number of elements of the plate in x direction\n    int numPlateElementsX[TEST_CASE_COUNT] = {2, 3, 4, 5, 6, 7, 8, 9, 10};\n    int numPlateElementsY[TEST_CASE_COUNT];\n\n    float boundaryTemperatureElementTopLeft[TEST_CASE_COUNT] =  {\n        273.0,    // test case 1\n        300.0,    // test case 2\n        320.0,    // test case 3\n        360.0,    // test case 4\n        400.0,    // test case 5\n        410.0,    // test case 6\n        440.0,    // test case 7\n        450.0,    // test case 8\n        470.0};    // test case 9\n\n    float boundaryTemperatureElementBelowTopLeft[TEST_CASE_COUNT] =  {\n        373.0,    // test case 1\n        350.0,    // test case 2\n        320.0,    // test case 3\n        460.0,    // test case 4\n        500.0,    // test case 5\n        600.0,    // test case 6\n        700.0,    // test case 7\n        800.0,    // test case 8\n        900.0};   // test case 9\n\n    int numIterations[TEST_CASE_COUNT] = {4, 5, 3, 6, 4, 3, 5, 7, 8};\n\n    // Consider a 2D square plate, so numPlateElementsY will be same as numPlateElementsX\n    std::memcpy(numPlateElementsY, numPlateElementsX, TEST_CASE_COUNT * sizeof(int));\n    int maxNumPlateElementsX = *std::max_element(numPlateElementsX, numPlateElementsX + TEST_CASE_COUNT);\n    int maxNumPlateElementsY = maxNumPlateElementsX;\n    \n    //Number of elements are greater than allocated device memory, consider increasing NUM_DEVICE_MEMORY_ELEM value\n    if(maxNumPlateElementsX * maxNumPlateElementsY > NUM_DEVICE_MEMORY_ELEM) {\n        assert(false && \"Number of elements are greater than allocated device memory, consider increasing NUM_DEVICE_MEMORY_ELEM value\");\n    }\n\n    // Expected results for each test\n    float expectedTemperatureDistribution[TEST_CASE_COUNT][maxNumPlateElementsX * maxNumPlateElementsY] =  {\n        {273.0, 306.333, 373.0, 339.667},\n        {300.0, 307.143, 314.286, 350.0, 328.571, 321.429, 342.857, 335.714, 328.571},\n        {320.0, 320.0, 320.0, 320.0, 320.0, 280.0, 280.0, 320.0, 320.0, 280.0, 280.0, 320.0, 320.0, 320.0, 320.0, 320.0},\n        {360.0, 366.667, 373.333, 380.0, 386.667, 460.0, 374.583, 346.927, 355.573, 393.333, 453.333, 376.406, 335.833, 353.594, 400.0, 446.667, 393.594, 369.74, 374.583, 406.667, 440.0, 433.333, 426.667, 420.0, 413.333},\n        {400.0, 405.263, 410.526, 415.789, 421.053, 426.316, 500.0, 350.082, 273.335, 269.243, 330.14, 431.579, 494.737, 303.063, 187.418, 180.633, 276.933, 436.842, 489.474, 307.155, 194.202, 187.418, 283.121, 442.105, 484.21, 370.025, 299.465, 293.277, 350.082, 447.368, 478.947, 473.684, 468.421, 463.158, 457.895, 452.632},\n        {410.0, 418.261, 426.522, 434.783, 443.043, 451.304, 459.565, 600, 365.937, 242.853, 213.696, 237.69, 330.312, 467.826, 591.739, 298.098, 127.283, 71.0326, 114.891, 250.598, 476.087, 583.478, 279.524, 88.0706, 31.8206, 75.6793, 234.606, 484.348, 575.217, 303.261, 139.674, 83.4239, 127.283, 264.022, 492.609, 566.956, 401.562, 290.353, 258.614, 276.929, 365.937, 500.87, 558.696, 550.435, 542.174, 533.913, 525.652, 517.391, 509.13},\n        {440.0, 449.63, 459.259, 468.889, 478.519, 488.148, 497.778, 507.407, 700.0, 462.546, 337.473, 287.512, 286.59, 326.272, 408.304, 517.037, 690.371, 420.34, 239.132, 152.297, 146.599, 211.353, 342.936, 526.667, 680.741, 392.836, 186.754, 88.6921, 81.4511, 156.115, 316.081, 536.296, 671.111, 393.757, 192.452, 95.9332, 88.6921, 163.319, 324.375, 545.926, 661.482, 431.54, 266.911, 182.936, 175.732, 239.132, 370.443, 555.556, 651.852, 516.788, 414.876, 364.267, 355.972, 387.37, 462.546, 565.185, 642.222, 632.593, 622.963, 613.333, 603.704, 594.074, 584.445, 574.815},\n        {450.0, 461.29, 472.581, 483.871, 495.161, 506.452, 517.742, 529.032, 540.323, 800.0, 536.418, 402.995, 341.383, 323.29, 340.182, 385.078, 459.613, 551.613, 788.71, 519.57, 330.103, 223.077, 189.062, 208.688, 283.178, 405.597, 562.903, 777.42, 494.961, 277.621, 153.35, 108.613, 134.055, 222.989, 377.967, 574.194, 766.129, 482.877, 264.214, 133.421, 88.6845, 113.685, 210.585, 374.229, 585.484, 754.839, 496.163, 292.01, 172.645, 128.35, 153.35, 242.206, 398.508, 596.774, 743.549, 537.487, 377.029, 277.709, 242.692, 258.491, 330.103, 450.924, 608.065, 732.258, 613.223, 516.968, 458.377, 431.938, 437.836, 471.641, 536.418, 619.355, 720.968, 709.678, 698.387, 687.097, 675.807, 664.516, 653.226, 641.936, 630.645},\n        {470.0, 482.286, 494.571, 506.857, 519.143, 531.429, 543.714, 556.0, 568.286, 580.571, 900.0, 598.148, 450.604, 377.099, 350.257, 352.48, 377.998, 428.708, 502.461, 592.857, 887.714, 597.057, 387.671, 266.379, 212.1, 208.003, 245.626, 325.772, 451.425, 605.143, 875.428, 572.863, 337.611, 190.334, 123.72, 116.53, 160.923, 262.755, 420.587, 617.428, 863.143, 556.172, 311.15, 156.719, 84.6422, 76.7293, 125.475, 236.409, 411.804, 629.714, 850.857, 553.949, 315.248, 163.909, 92.5551, 84.6422, 133.571, 245.107, 422.125, 642, 838.571, 571.964, 358.365, 219.745, 154.964, 146.869, 190.334, 293.043, 453.394, 654.286, 826.285, 618.953, 449.57, 341.235, 286.841, 278.143, 310.948, 387.671, 512.438, 666.571, 814.0, 693.835, 596.235, 529.376, 494.625, 484.304, 496.569, 535.223, 598.148, 678.857, 801.714, 789.428, 777.143, 764.857, 752.571, 740.286, 728, 715.714, 703.428, 691.143}\n    };\n\n    // Use a CUDA stream for asynchronous operations\n    cudaStream_t stream;\n    CUDA_CHECK(cudaStreamCreate(&stream));\n\n    // Declare host and device pointers\n    float *plateCurrentTemperatures_h, *deviceArray_d, *alternateDataArray_d;\n    plateCurrentTemperatures_h = (float*) malloc(maxNumPlateElementsX * maxNumPlateElementsY * sizeof(float));\n    \n    // Get pointers to the global __device__ array\n    cudaGetSymbolAddress((void**) &deviceArray_d, plateCurrentTemperatures_d);\n    cudaGetSymbolAddress((void**) &alternateDataArray_d, alternateBuffer_d);\n\n    // Loop to execute each test case\n    for (int testCaseId = 0; testCaseId < TEST_CASE_COUNT; testCaseId++) {\n\n        // Initialize inner plate temperatures to zero kelvin\n        for (int y = 1; y < numPlateElementsY[testCaseId] - 1; y++) {\n            memset(&plateCurrentTemperatures_h[y * numPlateElementsX[testCaseId] + 1], 0, (numPlateElementsX[testCaseId] - 2) * sizeof(float));\n        }\n\n        float baseGradient = 1.0f;\n        int numberOfEdges = 4;\n        int boundaryAdjustment = 5;\n        float temperatureGradient = baseGradient / (numberOfEdges * numPlateElementsX[testCaseId] - boundaryAdjustment);\n        float temperatureChange = (boundaryTemperatureElementBelowTopLeft[testCaseId] - boundaryTemperatureElementTopLeft[testCaseId]) * temperatureGradient;\n        float boundaryTemperature = boundaryTemperatureElementTopLeft[testCaseId];\n\n        // Initialize the boundary temperatures by constantly changing the temperature from the\n        // top-left corner in clockwise direction along the boundary till the element below top-left element\n        for (int j = 0; j < numPlateElementsX[testCaseId] - 1; j++) {\n            plateCurrentTemperatures_h[j] = boundaryTemperature;\n            boundaryTemperature += temperatureChange;\n        }\n\n        for (int j = 0; j < numPlateElementsY[testCaseId] - 1; j++) {\n            plateCurrentTemperatures_h[(j + 1) * numPlateElementsX[testCaseId] - 1] = boundaryTemperature;\n            boundaryTemperature += temperatureChange;\n        }\n\n        for (int j = numPlateElementsX[testCaseId] - 1; j >= 1; j--) {\n            plateCurrentTemperatures_h[(numPlateElementsY[testCaseId] - 1) * (numPlateElementsX[testCaseId]) + j] = boundaryTemperature;\n            boundaryTemperature += temperatureChange;\n        }\n\n        for (int j = numPlateElementsY[testCaseId] - 1; j >= 1; j--) {\n            plateCurrentTemperatures_h[j * numPlateElementsX[testCaseId]] = boundaryTemperature;\n            boundaryTemperature += temperatureChange;\n        }\n\n        // Copying data into device memory\n        CUDA_CHECK(cudaMemcpyAsync(deviceArray_d, plateCurrentTemperatures_h, numPlateElementsX[testCaseId] * numPlateElementsY[testCaseId] * sizeof(float), cudaMemcpyHostToDevice, stream));\n        CUDA_CHECK(cudaMemcpyAsync(alternateDataArray_d, plateCurrentTemperatures_h, numPlateElementsX[testCaseId] * numPlateElementsY[testCaseId] * sizeof(float), cudaMemcpyHostToDevice, stream));\n\n        // Determine the number of threads and blocks\n        dim3 blockSize(BLOCK_SIZE, BLOCK_SIZE, 1);\n        dim3 gridSize((numPlateElementsX[testCaseId] + BLOCK_SIZE - 1) / BLOCK_SIZE, (numPlateElementsY[testCaseId] + BLOCK_SIZE - 1) / BLOCK_SIZE);\n\n        // Launch the kernel\n        // Grid: ((numPlateElementsX[testCaseId] + BLOCK_SIZE - 1) / BLOCK_SIZE, (numPlateElementsY[testCaseId] + BLOCK_SIZE - 1) / BLOCK_SIZE)\n        // Block: (BLOCK_SIZE, BLOCK_SIZE, 1)\n        void *args[] = {&deviceArray_d, (void*) &numPlateElementsX[testCaseId], (void*) &numPlateElementsY[testCaseId], (void*) &numIterations[testCaseId]};\n        CUDA_CHECK(cudaLaunchCooperativeKernel((void*)k_temperatureDistribution, gridSize, blockSize, args, 0, stream));\n\n        // Copy the output array plateUpdatedTemperatures_d from the device (GPU) to the host (CPU)\n        CUDA_CHECK(cudaMemcpyAsync(plateCurrentTemperatures_h, deviceArray_d, numPlateElementsX[testCaseId] * numPlateElementsY[testCaseId] * sizeof(float), cudaMemcpyDeviceToHost, stream));\n\n        // Check tasks in the stream has completed\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n\n        // Verify whether the calculated plateCurrentTemperatures_h (computed by GPU) matches the expected result or not\n        for (int i = 0; i < numPlateElementsX[testCaseId] * numPlateElementsY[testCaseId]; i++) {\n            assert(fabs(plateCurrentTemperatures_h[i] - expectedTemperatureDistribution[testCaseId][i]) < TOLERANCE);\n        }\n    }\n\n    // Free host memories\n    free(plateCurrentTemperatures_h);\n\n    // Free stream\n    CUDA_CHECK(cudaStreamDestroy(stream));\n}\n\n__global__ void k_temperatureDistribution(float *temperatureValues, int numPlateElementsX, int numPlateElementsY, int numIterations) {\n", "test": "int main() {\n    launch();\n}\n", "example_test": "    @example_test\n", "cuda_toolkit": "12.2"}
{"task_id": "CUDA/105", "date": "2025-03-31", "prompt": "Write a CUDA kernel to upscale a 2D grayscale image from specified input dimensions to target output dimensions using bilinear interpolation by leveraging shared memory to cache input data tiles that are reused across multiple threads within a block.\n\nThe signature of the function is __global__ void k_bilinearInterpolation(float *inputMat, int inputWidth, int inputHeight, float *outputMat, int outputWidth, int outputHeight), where inputMat_h is the pointer to the input image array, inputWidth and inputHeight are dimensions (width & height) of the input image, respectively, outputMat is the pointer to the output array, and outputWidth & outputHeight are dimensions (width & height) of interpolated output image array.\n\n>>> k_bilinearInterpolation({{0.0, 0.1, 0.2, 0.3, 0.4}, {0.5, 0.6, 0.7, 0.8, 0.9}, {0.10, 0.11, 0.12, 0.13, 0.14}, {0.15,0.16,0.17,0.18,0.19},{0.20,0.21,0.22,0.23,0.24}}, 5, 5, outputMat, 8, 8) -> outputMat:{{0.00, 0.06, 0.11, 0.17, 0.23, 0.29, 0.34, 0.40}, {0.29, 0.33, 0.44, 0.43, 0.54, 0.53, 0.64, 0.69}, {0.44, 0.49, 0.54, 0.59, 0.64, 0.69, 0.74, 0.79}, {0.21, 0.23, 0.26, 0.27, 0.30, 0.31, 0.34, 0.36}, {0.11, 0.12, 0.13, 0.13, 0.14, 0.14, 0.15, 0.15}, {0.14, 0.15, 0.16, 0.16, 0.17, 0.17, 0.18, 0.18}, {0.17, 0.18, 0.19, 0.19, 0.20, 0.20, 0.21, 0.21}, {0.20, 0.21, 0.21, 0.22, 0.22, 0.23, 0.23, 0.24}}\n>>> k_bilinearInterpolation({{0.0, 0.1, 0.2}, {0.3, 0.4, 0.5}, {0.6, 0.7, 0.8}, {0.9, 0.10, 0.11}, {0.12, 0.13, 0.14}}, 3, 5, outputMat, 7, 11) -> outputMat: {{0.00, 0.03, 0.07, 0.10, 0.13, 0.17, 0.20}, {0.12, 0.17, 0.17, 0.22, 0.27, 0.27, 0.32}, {0.24, 0.30, 0.28, 0.34, 0.40, 0.38, 0.44}, {0.36, 0.40, 0.42, 0.46, 0.50, 0.52, 0.56}, {0.48, 0.53, 0.53, 0.58, 0.63, 0.63, 0.68}, {0.60, 0.63, 0.67, 0.70, 0.73, 0.77, 0.80}, {0.72, 0.53, 0.65, 0.46, 0.48, 0.50, 0.52}, {0.84, 0.42, 0.64, 0.22, 0.23, 0.24, 0.25}, {0.74, 0.53, 0.32, 0.11, 0.11, 0.11, 0.12}, {0.43, 0.33, 0.22, 0.12, 0.12, 0.12, 0.13}, {0.12, 0.12, 0.13, 0.13, 0.13, 0.14, 0.14}}\n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_70", "ld_flags": "", "declaration": "#include <cuda_runtime_api.h>\n#include <float.h>\n#include <math.h>\n#include <cstdio>\n#include <time.h>\n\n#define CUDA_CHECK(call)                                        \\\ndo {                                                            \\\n        cudaError_t error = call;                               \\\n        if (error != cudaSuccess) {                             \\\n            fprintf(stderr, \"CUDA error at %s:%d - %s\\n\",       \\\n                    __FILE__, __LINE__,                         \\\n                    cudaGetErrorString(error));                 \\\n            exit(EXIT_FAILURE);                                 \\\n        }                                                       \\\n} while(0)\n\n#define BLOCK_SIZE 16\n\n#undef NDEBUG\n#include <assert.h>\n\n__global__ void k_bilinearInterpolation(float *inputMat, int inputWidth, int inputHeight, float *outputMat, int outputWidth, int outputHeight);\n\nvoid launch() {\n    // Testcases count\n    int testcases = 10;\n    \n    float threshold = 0.5f;\n\n    // Input and output sizes\n    int inputSizeArray[2][testcases] =  { {5, 3, 31, 18, 6,  30, 20, 26, 40, 28 }, { 5, 5, 14, 28, 10, 33, 16, 18, 38, 12 }};\n    int outputSizeArray[2][testcases] = { {8, 7, 33, 44, 16, 32, 48, 43, 53, 33 }, { 8, 11, 37, 37, 29, 38, 29, 21, 50, 14 }};\n\n    float tcase_1[25] = { 0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24 };\n    float tcase_2[15] = { 0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.10, 0.11, 0.12, 0.13, 0.14 };\n\n    // Use a CUDA stream for asynchronous operations\n    cudaStream_t stream;\n    CUDA_CHECK(cudaStreamCreate(&stream));\n\n    // Allocating memory for the largest dataset\n    int maxWidth = 100; int maxHeight = 100;\n    float* inputMat_d; float* outputMat_d;\n    CUDA_CHECK(cudaMallocAsync(&inputMat_d, maxWidth * maxHeight * sizeof(float), stream));\n    CUDA_CHECK(cudaMallocAsync(&outputMat_d, maxWidth * maxHeight * sizeof(float), stream));\n\t\n\t// Allocate memory for input and output\n    float* outputMat_h = (float*)malloc(maxWidth * maxHeight * sizeof(float));\n    float* inputMat_h= (float*)malloc(maxWidth * maxHeight * sizeof(float));\n    float* outputMatExpected = (float*)malloc(maxWidth * maxHeight * sizeof(float));\n\n    // Running testcases\n    for (int tcase = 0; tcase < testcases; tcase++) {\n        // Settings input and output dimensions\n        int inputWidth = inputSizeArray[0][tcase];\n        int inputHeight = inputSizeArray[1][tcase];\n        int outputWidth = outputSizeArray[0][tcase];\n        int outputHeight = outputSizeArray[1][tcase];\n\n        if ((inputWidth > outputWidth) || (inputHeight > outputHeight)) {\n            assert(false && \"Output dimensions should be greater than input dimensions.\");\n        }\n\n        // Generate random inputs in the range [-10,10]\n        // Initializing random number state with present time stamp.\n        srand(time(NULL));\n        for (int y = 0; y < inputHeight * inputWidth; y++) {\n            if (tcase == 0) {\n                inputMat_h[y] = tcase_1[y];\n            } else if (tcase == 1) {\n                inputMat_h[y] = tcase_2[y];\n            } else {\n                inputMat_h[y] = (float)(rand() % 100) / 100.f;\n            }            \n        }\n\n        // Calling Bilinear interpolation on CPU\n        float xRatio = (inputWidth - 1) / (float)(outputWidth - 1);\n        float yRatio = (inputHeight - 1) / (float)(outputHeight - 1);\n        for (int y = 0; y < outputHeight; y++) {\n            for (int x = 0; x < outputWidth; x++) {\n                float dx = x * xRatio;\n                float dy = y * yRatio;\n\n                int dx_l = floorf(dx); int dx_h = ceilf(dx);\n                int dy_l = floorf(dy); int dy_h = ceilf(dy);\n\n                float p00 = inputMat_h[dy_l * inputWidth + dx_l];\n                float p01 = inputMat_h[dy_l * inputWidth + dx_h];\n                float p10 = inputMat_h[dy_h * inputWidth + dx_l];\n                float p11 = inputMat_h[dy_h * inputWidth + dx_h];\n\n                float tx = dx - dx_l;\n                float ty = dy - dy_l;\n                float tmpX1 = ((1 - tx) * p00) + (tx * p01);\n                float tmpX2 = ((1 - tx) * p11) + (tx * p10);\n                float outVal = (1 - ty) * tmpX1 + ty * tmpX2;\n\n                // Clip the outputs to the interval [0.0,1.0]\n                outVal = (outVal > 1.0) ? 1.0 : (outVal < 0.0) ? 0.0 : outVal;\n                outputMatExpected[y * outputWidth + x] = outVal;\n            }\n        }\n\n        // Calling Bilinear interpolation on GPU\n        // CUDA Initialization\n        size_t shMemX = ceilf(BLOCK_SIZE * xRatio) + 2;\n        size_t shMemY = ceilf(BLOCK_SIZE * yRatio) + 2;\n        size_t totalShMemBytes = shMemX * shMemY * sizeof(float);\n\n        dim3 blockDim(BLOCK_SIZE, BLOCK_SIZE, 1);\n        size_t blockSizeX = outputWidth / BLOCK_SIZE + 1;\n        size_t blockSizeY = outputHeight / BLOCK_SIZE + 1;\n        dim3 gridDim(blockSizeX, blockSizeY, 1);\n\n        // Using pre-allocated memory to copy input to GPU memory\n        CUDA_CHECK(cudaMemcpyAsync(inputMat_d, inputMat_h, inputWidth * inputHeight * sizeof(float), cudaMemcpyHostToDevice, stream));\n\n        // CUDA kernel Launch\n        void* args[] = { &inputMat_d, (void*)&inputWidth, (void*)&inputHeight, &outputMat_d, (void*)&outputWidth, (void*)&outputHeight };\n        CUDA_CHECK(cudaLaunchKernel((void*)k_bilinearInterpolation, gridDim, blockDim, args, totalShMemBytes, stream));\n        CUDA_CHECK(cudaMemcpyAsync(outputMat_h, outputMat_d, outputWidth * outputHeight * sizeof(float), cudaMemcpyDeviceToHost, stream));\n\n        // Verification\n        for (int y = 0; y < outputHeight; y++) {\n            for (int x = 0; x < outputWidth; x++) {\n                assert(fabsf(outputMat_h[y * outputWidth + x] - outputMatExpected[y * outputWidth + x]) < threshold);\n            }\n        }\n    }\n    \n\t// Free allocated memory\n    free(inputMat_h);\n    free(outputMatExpected);\n    free(outputMat_h);\n\n    CUDA_CHECK(cudaFreeAsync(inputMat_d, stream));\n    CUDA_CHECK(cudaFreeAsync(outputMat_d, stream));\n    CUDA_CHECK(cudaStreamDestroy(stream));\n}\n\n__global__ void k_bilinearInterpolation(float *inputMat, int inputWidth, int inputHeight, float *outputMat, int outputWidth, int outputHeight) {\n", "test": "int main() {\n    launch();\n}\n", "example_test": "    @example_test\n", "cuda_toolkit": "12.2"}
{"task_id": "CUDA/106", "date": "2025-03-31", "prompt": "Write a CUDA kernel to separate odd and even indexed elements of an array into different arrays using shared memory for coalesced global memory access while avoiding warp-divergence.\n\nThe signature of the CUDA kernel is __global__ void k_separateOddEven(int *input_d, int *oddData_d, int *evenData_d, int numElements), where input_d is the input vector containing all the input values, oddData_d is output vector for odd-indexed elements in the input_d vector, and evenData_d is output vector for even-indexed elements in the input_d vector.\n\n>>> k_separateOddEven({41, 18467, 6334, 26500, 19169, 15724, 11478, 29358, 26962, 24464}, oddData_d, evenData_d, 10) -> oddData_d: {18467, 26500, 15724, 29358, 24464 }, evenData_d:{ 41, 6334, 19169, 11478, 26962}\n>>> k_separateOddEven({5705, 28145, 23281, 16827, 9961, 491, 2995, 11942, 4827, 5436}, oddData_d, evenData_d, 10) -> oddData_d: {28145, 16827, 491, 11942, 5436 }, evenData_d:{ 5705, 23281, 9961, 2995, 4827}\n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_75 -arch=sm_70", "ld_flags": "", "declaration": "#undef NDEBUG\n#include <assert.h>\n#include <stdio.h>\n#include <cuda_runtime.h>\n\n#define CUDA_CHECK(call){                                      \\\n    cudaError_t error = call;                                  \\\n    if(error != cudaSuccess){                                  \\\n        fprintf(stderr, \"CUDA error at %s: %d - %s \\n\",        \\\n                __FILE__, __LINE__, cudaGetErrorString(error));\\\n        exit(EXIT_FAILURE);                                    \\\n    }                                                          \\\n}\n\nconstexpr int NUM_BLOCKS_PER_GRID = 256;\n\n// The number of threads per block is a multiple of 64 for the algorithm to function efficiently.\nconstexpr int NUM_THREADS_PER_BLOCK = 256;\nconstexpr int NUM_ELEMENTS = 10;\nconstexpr int NUM_OUTPUT_ELEMENTS = (NUM_ELEMENTS & 1) ? (NUM_ELEMENTS / 2 + 1) : (NUM_ELEMENTS / 2);\n\n__global__ void k_separateOddEven(int *input_d, int *oddData_d, int *evenData_d, int numElements);\n\nint launch() {\n    // Host buffers for computations.\n    int input_h[NUM_ELEMENTS];\n    int oddData_h[NUM_OUTPUT_ELEMENTS];\n    int evenData_h[NUM_OUTPUT_ELEMENTS];\n    int oddDataExpected_h[NUM_OUTPUT_ELEMENTS];\n    int evenDataExpected_h[NUM_OUTPUT_ELEMENTS];\n\n    int *input_d;\n    int *oddData_d;\n    int *evenData_d;\n\n    cudaStream_t stream;\n\n    // Allocating resources.\n    CUDA_CHECK(cudaStreamCreate(&stream));\n    CUDA_CHECK(cudaMallocAsync(&input_d, sizeof(int) * NUM_ELEMENTS, stream));\n    CUDA_CHECK(cudaMallocAsync(&oddData_d, sizeof(int) * NUM_OUTPUT_ELEMENTS, stream));\n    CUDA_CHECK(cudaMallocAsync(&evenData_d, sizeof(int) * NUM_OUTPUT_ELEMENTS, stream));\n    \n    dim3 gridDim(NUM_BLOCKS_PER_GRID, 1, 1);\n    dim3 blockDim(NUM_THREADS_PER_BLOCK, 1, 1);\n    void *args[4] = { &input_d, &oddData_d, &evenData_d, (void*)&NUM_ELEMENTS };\n    const int numTests = 7;\n    srand(1);\n\n    for(int test = 0; test < numTests; test++) {\n        for(int i = 0; i < NUM_ELEMENTS; i++) {\n            input_h[i] = rand();\n\n            if(i & 1) {\n                oddDataExpected_h[i / 2] = input_h[i];\n            } else {\n                evenDataExpected_h[i / 2] = input_h[i];\n            }\n        }\n\n        CUDA_CHECK(cudaMemcpyAsync( input_d, \n                                    input_h, \n                                    sizeof(int) * NUM_ELEMENTS, \n                                    cudaMemcpyHostToDevice, \n                                    stream));\n        // Block: (256, 1, 1)\n        // Grid: (256, 1, 1)\n        CUDA_CHECK(cudaLaunchKernel((void*)k_separateOddEven, gridDim, blockDim, args, 0, stream));\n        CUDA_CHECK(cudaMemcpyAsync( oddData_h, \n                                    oddData_d, \n                                    sizeof(int) * NUM_OUTPUT_ELEMENTS, \n                                    cudaMemcpyDeviceToHost, \n                                    stream));\n        CUDA_CHECK(cudaMemcpyAsync( evenData_h, \n                                    evenData_d, \n                                    sizeof(int) * NUM_OUTPUT_ELEMENTS, \n                                    cudaMemcpyDeviceToHost, \n                                    stream));\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n\n        for(int i = 0; i < NUM_OUTPUT_ELEMENTS; i++) {\n            // Number of odd-indexed elements is 1 less than number of even-indexed elements if input size is odd.\n            if((NUM_ELEMENTS & 1) && (i < NUM_OUTPUT_ELEMENTS - 1) || !(NUM_ELEMENTS & 1)){\n                assert(oddDataExpected_h[i] == oddData_h[i]);\n            }\n\n            assert(evenDataExpected_h[i] == evenData_h[i]);\n        }\n    }\n\n    // Releasing resources.\n    CUDA_CHECK(cudaFreeAsync(input_d, stream));\n    CUDA_CHECK(cudaFreeAsync(oddData_d, stream));\n    CUDA_CHECK(cudaFreeAsync(evenData_d, stream));\n    CUDA_CHECK(cudaStreamDestroy(stream));\n\n    return 0;\n}\n\n__global__ void k_separateOddEven(int *input_d, int *oddData_d, int *evenData_d, int numElements) {\n", "test": "int main() {\n    launch();\n}\n", "example_test": "    @example_test\n", "cuda_toolkit": "12.2"}
{"task_id": "CUDA/107", "date": "2025-03-31", "prompt": "Implement a CUDA kernel to generate chaotic results from input elements that are initial conditions, utilizing the logistic map in a data-parallel way.\n\nThe signature of the CUDA kernel is __global__ void k_calculateLogisticMap(float *input_d, float *output_d, int iterations, float growthRate, int numElements), where input_d is a pointer to the array with the input values, output_d is the pointer to store the output array, iterations is the number of times that the logistic map equation is applied, growthRate is the constant to control the dynamics of the map, and numElements is the total number of elements to process them parallel.\n\n>>> k_calculateLogisticMap({0.0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09}, output_d, 10000, 3.9, 10) -> output_d: {0.0, 0.908595, 0.923597, 0.816154, 0.513786, 0.934181, 0.275205, 0.335843, 0.504806, 0.471532}\n>>> k_calculateLogisticMap({0.0, 0.001, 0.002, 0.003, 0.004, 0.005, 0.006, 0.007, 0.008, 0.009}, output_d, 10000, 3.9, 10) -> output_d: {0.0, 0.551224, 0.884021, 0.829637, 0.967275, 0.764777, 0.410691, 0.685051, 0.666282, 0.191851}\n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_75 -arch=sm_70", "ld_flags": "", "declaration": "#undef NDEBUG\n#include <assert.h>\n#include <stdio.h>\n#include <cuda_runtime.h>\n\n#define CUDA_CHECK(call){                                      \\\n    cudaError_t error = call;                                  \\\n    if(error != cudaSuccess){                                  \\\n        fprintf(stderr, \"CUDA error at %s: %d - %s \\n\",        \\\n                __FILE__, __LINE__, cudaGetErrorString(error));\\\n        exit(EXIT_FAILURE);                                    \\\n    }                                                          \\\n}\n\n// CUDA-related constants.\nconstexpr int NUM_BLOCKS_PER_GRID = 256;\nconstexpr int NUM_THREADS_PER_BLOCK = 256;\n\n// Error tolerance for comparing floating-point variables.\nconstexpr float EPSILON = 0.00001f;\n\n// Algorithm-related constants.\nconstexpr float GROWTH_RATE = 3.9f;\nconstexpr int NUM_ITERATIONS = 10000;\n\n__global__ void k_calculateLogisticMap(float *input_d, float *output_d, int iterations, float growthRate, int numElements);\n\nvoid launch() {\n    constexpr int NUM_ELEMENTS = 10;\n    float *input_d;\n    float *output_d;\n    float input_h[NUM_ELEMENTS];\n    float output_h[NUM_ELEMENTS];\n    float expectedOutput_h[NUM_ELEMENTS];\n\n    cudaStream_t stream;\n    CUDA_CHECK(cudaStreamCreate(&stream));\n    CUDA_CHECK(cudaMallocAsync(&input_d, NUM_ELEMENTS * sizeof(float), stream));\n    CUDA_CHECK(cudaMallocAsync(&output_d, NUM_ELEMENTS * sizeof(float), stream));\n\n    void *args[5] = { &input_d, &output_d, (void*)&NUM_ITERATIONS, (void*)&GROWTH_RATE, (void*)&NUM_ELEMENTS };\n    dim3 gridDim(NUM_BLOCKS_PER_GRID, 1, 1);\n    dim3 blockDim(NUM_THREADS_PER_BLOCK, 1, 1);\n\n    // Test 1: Distant values.\n    {\n        for(int i = 0; i < NUM_ELEMENTS; i++) {\n            input_h[i] = 0.5f * i / (float) NUM_ELEMENTS;\n            float x = input_h[i];\n            \n            for(int j = 0; j < NUM_ITERATIONS; j++) {\n                x = GROWTH_RATE * x * (1.0f - x);\n            }\n\n            expectedOutput_h[i] = x;\n        }\n\n        CUDA_CHECK(cudaMemcpyAsync( input_d, \n                                    input_h, \n                                    NUM_ELEMENTS * sizeof(float), \n                                    cudaMemcpyHostToDevice, \n                                    stream));\n        // Block: (256, 1, 1)\n        // Grid: (256, 1, 1)\n        CUDA_CHECK(cudaLaunchKernel((void*)k_calculateLogisticMap, gridDim, blockDim, args, 0, stream));\n        CUDA_CHECK(cudaMemcpyAsync( output_h, \n                                    output_d, \n                                    NUM_ELEMENTS * sizeof(float), \n                                    cudaMemcpyDeviceToHost, \n                                    stream));\n\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n\n        for(int i = 0; i < NUM_ELEMENTS; i++) {\n            assert(fabsf(output_h[i] - expectedOutput_h[i]) < EPSILON);\n        }\n    }\n\n    // Test 2: Closer values.\n    {\n        for(int i = 0; i < NUM_ELEMENTS; i++) {\n            input_h[i] = 0.1f * i / (float) NUM_ELEMENTS;\n            float x = input_h[i];\n            \n            for(int j = 0; j < NUM_ITERATIONS; j++) {\n                x = GROWTH_RATE * x * (1.0f - x);\n            }\n\n            expectedOutput_h[i] = x;\n        }\n\n        CUDA_CHECK(cudaMemcpyAsync( input_d, \n                                    input_h, \n                                    NUM_ELEMENTS * sizeof(float), \n                                    cudaMemcpyHostToDevice, \n                                    stream));\n        // Block: (256, 1, 1)\n        // Grid: (256, 1, 1)\n        CUDA_CHECK(cudaLaunchKernel((void*)k_calculateLogisticMap, gridDim, blockDim, args, 0, stream));\n        CUDA_CHECK(cudaMemcpyAsync( output_h, \n                                    output_d, \n                                    NUM_ELEMENTS * sizeof(float), \n                                    cudaMemcpyDeviceToHost, \n                                    stream));\n\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n\n        for(int i = 0; i < NUM_ELEMENTS; i++) {\n            assert(fabsf(output_h[i] - expectedOutput_h[i]) < EPSILON);\n        }\n    }\n\n    // Test 3: Very close values.\n    {\n        for(int i = 0; i < NUM_ELEMENTS; i++) {\n            input_h[i] = 0.01f * i / (float) NUM_ELEMENTS;\n            float x = input_h[i];\n            \n            for(int j = 0; j < NUM_ITERATIONS; j++) {\n                x = GROWTH_RATE * x * (1.0f - x);\n            }\n\n            expectedOutput_h[i] = x;\n        }\n\n        CUDA_CHECK(cudaMemcpyAsync( input_d, \n                                    input_h, \n                                    NUM_ELEMENTS * sizeof(float), \n                                    cudaMemcpyHostToDevice, \n                                    stream));\n        // Block: (256, 1, 1)\n        // Grid: (256, 1, 1)\n        CUDA_CHECK(cudaLaunchKernel((void*)k_calculateLogisticMap, gridDim, blockDim, args, 0, stream));\n        CUDA_CHECK(cudaMemcpyAsync( output_h, \n                                    output_d, \n                                    NUM_ELEMENTS * sizeof(float), \n                                    cudaMemcpyDeviceToHost, \n                                    stream));\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n\n        for(int i = 0; i < NUM_ELEMENTS; i++) {\n            assert(fabsf(output_h[i] - expectedOutput_h[i]) < EPSILON);\n        }\n    }\n\n    // Test 4: Piecewise values.\n    {\n        input_h[0] = 0.010f;\n        input_h[1] = 0.015f;\n        input_h[2] = 0.030f;\n        input_h[3] = 0.035f;\n        input_h[4] = 0.050f;\n        input_h[5] = 0.055f;\n        input_h[6] = 0.070f;\n        input_h[7] = 0.075f;\n        input_h[8] = 0.090f;\n        input_h[9] = 0.095f;\n\n        for(int i = 0; i < NUM_ELEMENTS; i++) {\n            float x = input_h[i];\n\n            for(int j = 0; j < NUM_ITERATIONS; j++) {\n                x = GROWTH_RATE * x * (1.0f - x);\n            }\n            \n            expectedOutput_h[i] = x;\n        }\n\n        CUDA_CHECK(cudaMemcpyAsync( input_d, \n                                    input_h, \n                                    NUM_ELEMENTS * sizeof(float), \n                                    cudaMemcpyHostToDevice, \n                                    stream));\n        // Block: (256, 1, 1)\n        // Grid: (256, 1, 1)\n        CUDA_CHECK(cudaLaunchKernel((void*)k_calculateLogisticMap, gridDim, blockDim, args, 0, stream));\n        CUDA_CHECK(cudaMemcpyAsync( output_h, \n                                    output_d, \n                                    NUM_ELEMENTS * sizeof(float), \n                                    cudaMemcpyDeviceToHost, \n                                    stream));\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n\n        for(int i = 0; i < NUM_ELEMENTS; i++) {\n            assert(fabsf(output_h[i] - expectedOutput_h[i]) < EPSILON);\n        }\n    }\n\n    // Test 5: Very close values in a different region.\n    {\n        for(int i = 0; i < NUM_ELEMENTS; i++) {\n            input_h[i] = 0.5f + 0.01f * i / (float) NUM_ELEMENTS;\n            float x = input_h[i];\n\n            for(int j = 0; j < NUM_ITERATIONS; j++) {\n                x = GROWTH_RATE * x * (1.0f - x);\n            }\n\n            expectedOutput_h[i] = x;\n        }\n\n        CUDA_CHECK(cudaMemcpyAsync( input_d, \n                                    input_h, \n                                    NUM_ELEMENTS * sizeof(float), \n                                    cudaMemcpyHostToDevice, \n                                    stream));\n        // Block: (256, 1, 1)\n        // Grid: (256, 1, 1)\n        CUDA_CHECK(cudaLaunchKernel((void*)k_calculateLogisticMap, gridDim, blockDim, args, 0, stream));\n        CUDA_CHECK(cudaMemcpyAsync( output_h, \n                                    output_d, \n                                    NUM_ELEMENTS * sizeof(float), \n                                    cudaMemcpyDeviceToHost, \n                                    stream));\n\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n\n        for(int i = 0; i < NUM_ELEMENTS; i++) {\n            assert(fabsf(output_h[i] - expectedOutput_h[i]) < EPSILON);\n        }\n    }\n\n    // Test 6: Random values.\n    {\n        srand(1);\n        for(int i = 0; i < NUM_ELEMENTS; i++) {\n            input_h[i] = 0.5f * (rand() / (float)RAND_MAX);\n            float x = input_h[i];\n            \n            for(int j = 0; j < NUM_ITERATIONS; j++) {\n                x = GROWTH_RATE * x * (1.0f - x);\n            }\n\n            expectedOutput_h[i] = x;\n        }\n\n        CUDA_CHECK(cudaMemcpyAsync( input_d, \n                                    input_h, \n                                    NUM_ELEMENTS * sizeof(float), \n                                    cudaMemcpyHostToDevice, \n                                    stream));\n        // Block: (256, 1, 1)\n        // Grid: (256, 1, 1)\n        CUDA_CHECK(cudaLaunchKernel((void*)k_calculateLogisticMap, gridDim, blockDim, args, 0, stream));\n        CUDA_CHECK(cudaMemcpyAsync( output_h, \n                                    output_d, \n                                    NUM_ELEMENTS * sizeof(float), \n                                    cudaMemcpyDeviceToHost, \n                                    stream));\n\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n\n        for(int i = 0; i < NUM_ELEMENTS; i++) {\n            assert(fabsf(output_h[i] - expectedOutput_h[i]) < EPSILON);\n        }\n    }\n\n    // Test 7: Exponentially changing values.\n    {\n        for(int i = 0; i < NUM_ELEMENTS; i++) {\n            input_h[i] = 1.0f / (1.0f + abs(i * i));\n            float x = input_h[i];\n            \n            for(int j = 0; j < NUM_ITERATIONS; j++) {\n                x = GROWTH_RATE * x * (1.0f - x);\n            }\n\n            expectedOutput_h[i] = x;\n        }\n\n        CUDA_CHECK(cudaMemcpyAsync( input_d, \n                                    input_h, \n                                    NUM_ELEMENTS * sizeof(float), \n                                    cudaMemcpyHostToDevice, \n                                    stream));\n        // Block: (256, 1, 1)\n        // Grid: (256, 1, 1)\n        CUDA_CHECK(cudaLaunchKernel((void*)k_calculateLogisticMap, gridDim, blockDim, args, 0, stream));\n        CUDA_CHECK(cudaMemcpyAsync( output_h, \n                                    output_d, \n                                    NUM_ELEMENTS * sizeof(float), \n                                    cudaMemcpyDeviceToHost, \n                                    stream));\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n\n        for(int i = 0; i < NUM_ELEMENTS; i++) {\n            assert(fabsf(output_h[i] - expectedOutput_h[i]) < EPSILON);\n        }\n    }\n\n    CUDA_CHECK(cudaFreeAsync(input_d, stream));\n    CUDA_CHECK(cudaFreeAsync(output_d, stream));\n    CUDA_CHECK(cudaStreamDestroy(stream));\n}\n\n__global__ void k_calculateLogisticMap(float *input_d, float *output_d, int iterations, float growthRate, int numElements) {\n", "test": "int main() {\n    launch();\n}\n", "example_test": "    @example_test\n", "cuda_toolkit": "12.2"}
{"task_id": "CUDA/108", "date": "2025-03-31", "prompt": "Write a CUDA kernel to compute the nearest neighbors of every point in an array-A w.r.t array-B in N-Dimension, where N=3 for 3-Dimension, using shared memory to load array-B and compare it to every point in array-A to find the nearest neighbors.\n\nThe signature of the function is __global__ void k_nearestNeighbors(const float* inputVectorA_d, int nA, float* inputVectorB_d, int nB, int* nearestNeighborIndex), where for every 3D point in inputVectorA_d a nearest neighbour from inputVectorB_d is computed. The sizes of the inputs are given by nA and nB, and the number of nearest neighbors to be calculated is given by nearestNeighborIndex.\n\n>>> k_nearestNeighbors({{-0.38,-2.13,0.69},{-5.7,-4.5,-0.95},{9.23,7.69,9.65}}, 3, {{-9.57,-0.59,8.41},{-6.53,6.68,8.02},{5.11,-9.24,-1.19}},3, nearestNeighborIndex) -> nearestNeighborIndex : {2,0,1}\n>>> k_nearestNeighbors({{-3.44,-0.71,-5.57},{-1.28,-8.79,-5.71},{7.92,2.8,-8.56},{2.07,5.06,-8.3},{-2.45,-9.14,8.19}}, 5,\n    {{9.26,8.7,-4.33},{-8.07,0.91,7.17},{-5.81,-3.63,-7.7},{-8.4,2.07,-8.9}}, 4, nearestNeighborIndex) -> nearestNeighborIndex : {2,2,0,0,1}\n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_70 -arch=sm_60", "ld_flags": "", "declaration": "#include <cuda_runtime.h>\n#include <limits.h>\n#include <stdlib.h>\n#include <float.h>\n#include <cstdio>\n\n#define N_DIMS 3\n\n#define CUDA_CHECK(call)                                        \\\ndo {                                                            \\\n        cudaError_t error = call;                               \\\n        if (error != cudaSuccess) {                             \\\n            fprintf(stderr, \"CUDA error at %s:%d - %s\\n\",       \\\n                    __FILE__, __LINE__,                         \\\n                    cudaGetErrorString(error));                 \\\n            exit(EXIT_FAILURE);                                 \\\n        }                                                       \\\n} while(0)\n#undef NDEBUG\n#include <assert.h>\n\n__global__ void k_nearestNeighbors(const float* inputVectorA_d, int nA, float* inputVectorB_d, int nB, int* nearestNeighborIndex);\n\nvoid launch() {\n    const int TEST_CASES = 9;\n    const int NUMEL_A = 10;\n    const int NUMEL_B = 10;\n    \n    // Variable allocations\n    int testCaseCount = TEST_CASES; // Number of test cases\n    int numberOfPointsA = NUMEL_A;\n    int numberOfPointsB = NUMEL_B;\n    int outputIndices[TEST_CASES][NUMEL_A] = { { 4,4,9,4,0,2,7,7,2,7 },{6,2,5,7,2,5,2,7,3,3},{9,4,9,1,4,1,9,7,2,4},\n        {0,6,2,1,7,2,9,9,2,2},{8,1,5,3,1,4,9,5,3,1},{0,2,4,4,3,0,7,5,6,4},{8,6,5,6,6,2,2,9,4,5},{0,5,3,6,0,4,7,6,1,4},{3,1,9,8,5,4,7,0,6,0} };\n\n    // Test-cases\n    float inputVectorA_h[TEST_CASES][NUMEL_A][N_DIMS] = {\n        { {-0.38,-2.13,0.69},{-5.7,-4.5,-0.95},{9.23,7.69,9.65},{-6.54,2.21,4.76},{-7.71,-7.99,8.89},{7.93,-6.5,0.11},{7.06,6.76,-8.3},{4.66,9.78,-9.06},{2.19,-5.55,-2.43},{2.74,-0.14,-7.55}},\n        { {7.84,7.03,-9.84},{-9.44,-6.52,6.45},{2.12,0.52,-4.83},{-7.45,2.44,0.11},{-5.57,-9.12,-4.06},{2.29,1.76,-5.07},{-0.76,-8.89,-5.96},{-5.9,-0.69,-4.59},{9.59,1.21,0.22},{2.45,0.02,-2.54}},\n        { {-0.58,2.59,-0.67},{-9.12,-6.22,4.25},{-8.42,7.6,2.66},{6.51,6.53,-7.43},{-7.46,-9.41,4.89},{3.84,5.8,0.96},{-5.66,7.97,-0.96},{6.59,-6.21,3.64},{6.01,-0.08,-1.41},{-2.13,-5.11,4.1}},\n        { {-9.23,-2.91,3.4},{-0.08,6.44,-4.75},{8.55,-0.77,4.66},{-9.89,-8.74,-7.01},{-7.96,0.95,7.43},{0.04,-0.93,2.77},{9.04,-2.37,-4.64},{6.26,-8.58,-9.26},{8.79,1.59,-0.54},{2.47,3.21,-2.82}},\n        { {-2.4,4.12,2.49 },{-4.5,-3.22,9.07},{8.23,3.75,6.46},{-1.19,5.46,-7.21},{-7.16,-3.16,-0.67},{-9.4,1.88,6.72 },{2.39,1.27,-10.0},{9.55,1.42,2.3},{-3.57,3.,-5.04},{-5.01,-4.98,0.11}},\n        { {9.87,7.55,-8.48},{-3.5,-6.02,-7.57},{3.4,5.82,4.63},{-3.2,-0.57,5.22},{-1.63,7.42,-7.59},{9.4,-2.44,-9.08},{-6.64,-7.42,3.47},{9.35,-2.07,7.19},{8.58,-9.92,-3.92},{2.,0.9,4.47}},\n        { {-1.31,8.34,2.35},{-8.78,-9.22,7.58},{7.15,-1.11,-6.23},{8.73,-9.34,4.52},{-0.18,-9.88,8.38},{-4.89,-9.52,-2.42},{6.98,-9.17,2.01},{3.5,9.11,2.65},{-6.53,1.64,-2.79},{2.38,-1.8,-6.29}},\n        { {-8.68,8.26,4.94},{7.49,-3.7,6.07},{-7.26,-0.92,1.11},{2.04,-4.78,2.27},{-0.77,8.68,0.12},{3.,0.83,-9.32},{-1.75,8.48,-6.31},{3.34,-7.74,-5.14},{1.82,-0.09,6.36},{9.18,-5.11,-8.6}},\n        { {-8.71,-4.18,3.85},{-9.03,-6.25,5.53},{-8.79,5.75,1.31},{-1.76,-1.4,-3.47},{-8.87,-3.7,-5.4},{0.95,9.43,5.59},{-7.39,-7.35,-8.36},{-0.81,5.47,-7.43},{-3.73,-4.33,-6.09},{-6.04,4.23,-8.14}}\n    };\n\n    float inputVectorB_h[TEST_CASES][NUMEL_B][N_DIMS] = {\n        { {-9.57,-0.59,8.41},{-6.53,6.68,8.02},{5.11,-9.24,-1.19},{-3.61,0.16,9.63},{-2.25,-1.03,5.41},{-6.86,7.33,9.88},{3.78,-8.85,8.71},{2.06,5.51,-6.19},{-8.9,-7.37,-8.82},{5.0,6.25,-2.29} },\n        { {-4.2,7.89,4.},{5.15,9.23,-9.98},{-6.59,-7.03,2.68},{4.27,2.22,2.26},{3.8,-8.31,6.78},{3.02,3.67,-9.28},{5.66,8.19,-8.3},{-6.92,5.01,-1.67},{-0.43,-3.39,3.41},{0.65,7.78,-0.58} },\n        { {8.49,-9.61,2.52},{6.22,9.2,-5.7},{3.58,-2.73,-8.28},{1.68,-9.99,-7.69},{-5.01,-3.29,6.66},{-1.97,-0.42,8.51},{-8.29,5.32,8.94},{5.01,-7.73,5.46},{8.08,9.91,-4.69},{-7.84,6.52,0.11} },\n        { {-3.65,9.13,0.49},{5.2,-9.82,-1.8},{5.15,3.55,-1.13},{9.52,8.68,-7.16},{7.89,8.92,-9.82},{5.88,7.32,-4.42},{0.16,9.05,-7.79},{-9.61,9.82,9.6},{3.9,5.6,6.54},{9.47,-2.26,-9.42} },\n        { {5.16,-9.4,7.01},{-6.74,-5.58,6.86},{-7.52,7.99,-4.3},{-2.87,0.84,-8.52},{-8.65,4.42,4.61},{2.04,-6.77,6.32},{0.66,-6.78,8.48},{1.47,-4.78,-6.51},{-5.37,6.01,-0.72},{1.88,-0.22,-6.58}},\n        { {9.26,8.7,-4.33},{-8.07,0.91,7.17},{-5.81,-3.63,-7.7},{-8.4,2.07,-8.9},{-0.73,0.83,4.67},{7.6,-4.02,6.84},{2.74,-7.79,-0.22},{-5.51,-8.62,-2.62},{4.26,-6.13,5.19},{8.43,6.77,-0.31}},\n        { {-2.45,3.65,3.51},{7.96,3.24,5.56},{1.05,-7.81,0.05},{7.89,-0.54,4.28},{-5.26,5.28,-8.05},{9.05,-5.79,-5.28},{0.76,-8.21,5.34},{-3.54,8.98,7.75},{-3.52,9.01,4.49},{7.9,3.74,1.18}},\n        { {-2.56,9.32,5.24},{-1.44,-2.26,9.79},{-3.15,-0.66,-5.08},{-9.61,-3.97,-0.63},{-0.69,1.23,-8.07},{2.89,-3.38,1.94},{1.59,-4.22,1.52},{-5.25,2.93,-4.45},{-7.22,8.42,-1.66},{-7.79,5.01,-3.55}},\n        { {-4.58,8.49,-9.35},{-8.96,-4.87,7.35},{4.99,-3.15,1.41},{-8.95,-5.62,2.89},{4.3,-0.67,5.26},{-9.95,-3.37,-5.77},{-4.,-3.29,-7.81},{-5.18,-3.62,-8.81},{-4.6,-4.07,-2.66},{-8.51,0.89,0.34}}\n    };\n\n    // Use a CUDA stream for asynchronous operations\n    cudaStream_t stream;\n    CUDA_CHECK(cudaStreamCreate(&stream));\n\n    const int BLOCK_SIZE = 32; // number of threads per block\n\n    //Declaring device variables and allocating device memory for inputs\n    float* inputVectorA_d, * inputVectorB_d;\n    int* nearestNeighborIndex_h, * nearestNeighborIndex_d;\n    CUDA_CHECK(cudaMallocAsync(&inputVectorA_d, numberOfPointsA * N_DIMS * sizeof(float), stream));\n    CUDA_CHECK(cudaMallocAsync(&inputVectorB_d, numberOfPointsB * N_DIMS * sizeof(float), stream));\n    CUDA_CHECK(cudaMallocAsync(&nearestNeighborIndex_d, numberOfPointsA * sizeof(float), stream));\n    nearestNeighborIndex_h = (int*)malloc(numberOfPointsA * sizeof(int));\n\n    // Loop running through each test\n    size_t numBlocks = ((numberOfPointsA / BLOCK_SIZE) + 1);\n    for (int i = 0; i < testCaseCount; i++) {\n\n        // Copy data from host to device\n        CUDA_CHECK(cudaMemcpyAsync(inputVectorA_d, inputVectorA_h[i], numberOfPointsA * N_DIMS * sizeof(float), cudaMemcpyHostToDevice, stream));\n        CUDA_CHECK(cudaMemcpyAsync(inputVectorB_d, inputVectorB_h[i], numberOfPointsB * N_DIMS * sizeof(float), cudaMemcpyHostToDevice, stream));\n\n        // Calling nearest neighbor kernel\n        void* args[] = { &inputVectorA_d, (void*)&numberOfPointsA, &inputVectorB_d, (void*)&numberOfPointsB, &nearestNeighborIndex_d };\n        CUDA_CHECK(cudaLaunchKernel((void*)k_nearestNeighbors, numBlocks, BLOCK_SIZE, args, N_DIMS * numberOfPointsB * sizeof(float), stream));\n        \n        // Copying memory back to host from device\n        CUDA_CHECK(cudaMemcpyAsync(nearestNeighborIndex_h, nearestNeighborIndex_d, numberOfPointsA * sizeof(int), cudaMemcpyDeviceToHost, stream));\n\t\t\n\t\t// Check tasks in the stream has completed\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n\n        // Verify the test point with manually computed outputs.\n        for (int k = 0; k < numberOfPointsA; k++) {\n            assert(outputIndices[i][k] == nearestNeighborIndex_h[k]);\n        }\n    }\n\n    // Free allocated memory\n    CUDA_CHECK(cudaFreeAsync(inputVectorA_d, stream));\n    CUDA_CHECK(cudaFreeAsync(inputVectorB_d, stream));\n    CUDA_CHECK(cudaFreeAsync(nearestNeighborIndex_d, stream));\n    CUDA_CHECK(cudaStreamDestroy(stream));\n    free(nearestNeighborIndex_h);\n}\n\n__global__ void k_nearestNeighbors(const float* inputVectorA_d, int nA, float* inputVectorB_d, int nB, int* nearestNeighborIndex) {\n", "test": "int main() {\n    launch();\n}\n", "example_test": "    @example_test\n", "cuda_toolkit": "12.2"}
{"task_id": "CUDA/109", "date": "2025-03-31", "prompt": "Write a CUDA kernel that computes the Peak Signal-to-Noise Ratio (PSNR) between an original image and its compressed version using shared memory.\n\nThe signature of the kernel is __global__ void k_peakSignalToNoiseRatio(float *inputImage, float *compressedInputImage, float *peakToNoiseRatio, int imageWidth, int imageHeight), where inputImage is the pointer to the input image in row-major order, compressedInputImage is the pointer to compressed input image having same dimensions and format as inputImage, peakToNoiseRatio is the pointer to the output where computed PSNR value will be stored, imageWidth is the width in pixels, and imageHeight is the height in pixels.\n\n>>> k_peakSignalToNoiseRatio({0.452895, 0.403882, 0.69631, 0.452895, 0.403882, 0.69631, 0.452895, 0.403882, 0.69631}, {0.498184, 0.44427, 0.765941, 0.498184, 0.44427, 0.765941, 0.498184, 0.44427, 0.765941}, peakToNoiseRatio, 3, 3) -> peakToNoiseRatio : {25.4613}\n>>> k_peakSignalToNoiseRatio({0.452712, 0.747856, 0.605976, 0.452712, 0.747856, 0.605976, 0.452712, 0.747856}, {0.457239, 0.755335, 0.612036, 0.457239, 0.755335, 0.612036, 0.457239, 0.755335}, peakToNoiseRatio, 4, 2) -> peakToNoiseRatio : {44.2206}\n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_70", "ld_flags": "", "declaration": "#include <cstdio>\n#include <algorithm>\n#include <cuda_runtime.h>\n#include <assert.h>\n\n#undef NDEBUG\n#define BLOCK_SIZE  (32)\n#define EPSILON     (1e-3)\n#define CUDA_CHECK(call) \\\ndo {\\\n        cudaError_t error = call;\\\n        if (error != cudaSuccess) {\\\n            fprintf(stderr, \"CUDA error at %s:%d - %s\\n\",\\\n                    __FILE__, __LINE__,\\\n                    cudaGetErrorString(error));\\\n                exit(EXIT_FAILURE);\\\n        }\\\n} while (0)\n\n// Warp-level reduction: each thread in the warp calls this to reduce its value.\n__device__ float warpReduceSum(float val) {\n    // Full mask: all 32 threads active in the warp.\n    int mask = 0xFFFFFFFF;\n\n    for (int offset = warpSize / 2; offset > 0; offset /= 2) {\n        val += __shfl_down_sync(mask, val, offset);\n    }\n    \n    return val;\n}\n\n// Block-level reduction that uses shared memory.\n__device__ float blockReduceSum(float* sdata, int tid, int blockSize) {\n    int lane = tid % warpSize;\n    int warpId = tid / warpSize;\n\n    // Each thread's value is already stored in sdata[tid].\n    float val = sdata[tid];\n\n    // First, do warp-level reduction within each warp.\n    val = warpReduceSum(val);\n\n    // Write the reduced value of each warp to shared memory.\n    if (lane == 0) {\n        sdata[warpId] = val;\n    }\n\n    __syncthreads();\n\n    // Calculate the number of warps in the block.\n    int numWarps = (blockSize + warpSize - 1) / warpSize;\n    \n    // Only the first 'numWarps' threads need to participate in the final reduction.\n    if (tid < numWarps) {\n        val = sdata[tid];\n        val = warpReduceSum(val);\n    }\n\n    return val;\n}\n\n__global__ void k_peakSignalToNoiseRatio(float *inputImage, float *compressedInputImage, float *peakToNoiseRatio, const int imageWidth, const int imageHeight);\n\nvoid launch() {\n    const int NUM_TESTS = 7;\n    int imageWidth[NUM_TESTS] = { 3, 4, 5, 2, 3, 4, 5 };\n    int imageHeight[NUM_TESTS] = { 3, 2, 2, 4, 4, 4, 3};\n    float imageCompressionFactor[NUM_TESTS] = { 10.0f, 100.0f, 1000.0f, 10000.0f, 100000.0f, 1000000.0f, 10000000.0f};\n\n    // Calculating maximum image size (in pixels)\n    int maxImageSizeInPixels = 0;\n    for (int i = 0; i < NUM_TESTS; i++) {\n        int temp = imageWidth[i] * imageHeight[i];\n        if (temp > maxImageSizeInPixels)\n            maxImageSizeInPixels = temp;\n    }\n\n    // Input original image \n    float inputImage_h[NUM_TESTS][maxImageSizeInPixels] = {\n      {0.452895, 0.403882, 0.69631, 0.452895, 0.403882, 0.69631, 0.452895, 0.403882, 0.69631},\n      {0.452712, 0.747856, 0.605976, 0.452712, 0.747856, 0.605976, 0.452712, 0.747856},\n      {0.0344, 0.4387, 0.3816, 0.7655, 0.7952, 0.1869, 0.4898, 0.4456, 0.6463, 0.7094},\n      {0.2575, 0.8407, 0.2543, 0.8143, 0.2435, 0.9293, 0.3500, 0.1966},\n      {0.6892, 0.7482, 0.4505, 0.0838, 0.2290, 0.9133, 0.1524, 0.8258, 0.5383, 0.9961, 0.0782, 0.4427},\n      {0.8147, 0.9058, 0.1270, 0.9134, 0.6324, 0.0975, 0.2785, 0.5469, 0.9575, 0.9649, 0.1576, 0.9706, 0.9572, 0.4854, 0.8003, 0.1419},\n      {0.8308, 0.5853, 0.5497, 0.9172, 0.2858, 0.7572, 0.7537, 0.3804, 0.5678, 0.0759, 0.0540, 0.5308, 0.7792, 0.9340, 0.1299}\n    };\n\n    float expectedOutput[NUM_TESTS] = {25.4613, 44.2206, 65.299, 84.908, 104.43, 123.218, 144.059};\n\n    // Host Side Memory Allocation\n    float peakToNoiseRatio_h = 0.0f;\n    float* compressedInputImage_h = (float*)malloc(sizeof(float) * maxImageSizeInPixels);\n\n    // Device pointers initialization\n    float* inputImage_d = NULL;\n    float* compressedInputImage_d = NULL;\n    float* peakToNoiseRatio_d = NULL;\n\n    // Use a CUDA stream for asynchronous operations\n    cudaStream_t stream;\n    CUDA_CHECK(cudaStreamCreate(&stream));\n\n    // Allocate Memory on Device\n    CUDA_CHECK(cudaMallocAsync(&inputImage_d, sizeof(float) * maxImageSizeInPixels, stream));\n    CUDA_CHECK(cudaMallocAsync(&compressedInputImage_d, sizeof(float) * maxImageSizeInPixels, stream));\n    CUDA_CHECK(cudaMallocAsync(&peakToNoiseRatio_d, sizeof(float), stream));\n\n    for (int t = 0; t < NUM_TESTS; t++) {\n        //Initialising Host Input Memory\n        for (int j = 0; j < imageWidth[t]; j++) {\n            for (int k = 0; k < imageHeight[t]; k++) {\n                // Same As Original Image but Little Noise is added to the image \n                compressedInputImage_h[j + k * imageWidth[t]] = std::max(0.0f, std::min(1.0f, inputImage_h[t][j + k * imageWidth[t]] + inputImage_h[t][j + k * imageWidth[t]] / imageCompressionFactor[t]));\n            }\n        }\n\n        // Copy Input Images Data from Host To Device Memory\n        CUDA_CHECK(cudaMemcpyAsync(inputImage_d, &inputImage_h[t][0], sizeof(float) * imageWidth[t] * imageHeight[t], cudaMemcpyHostToDevice, stream));\n        CUDA_CHECK(cudaMemcpyAsync(compressedInputImage_d, compressedInputImage_h, sizeof(float) * imageWidth[t] * imageHeight[t], cudaMemcpyHostToDevice, stream));\n\n        // Determine the number of threads and blocks\n        dim3 blockSize(BLOCK_SIZE, BLOCK_SIZE, 1);\n        dim3 gridSize((imageWidth[t] + BLOCK_SIZE - 1) / BLOCK_SIZE, (imageHeight[t] + BLOCK_SIZE - 1) / BLOCK_SIZE, 1);\n\n        // Launch Kernel\n        // Grid : ((imageWidth[t] + BLOCK_SIZE - 1) / BLOCK_SIZE, (imageHeight[t] + BLOCK_SIZE - 1) / BLOCK_SIZE, 1)\n        // Block : (BLOCK_SIZE, BLOCK_SIZE, 1);\n        void* args[] = { &inputImage_d, &compressedInputImage_d, &peakToNoiseRatio_d, (void*)&imageWidth[t], (void*)&imageHeight[t] };\n        CUDA_CHECK(cudaLaunchKernel((void*)k_peakSignalToNoiseRatio, gridSize, blockSize, args, sizeof(float) * blockSize.x * blockSize.y, stream));\n\n        // Copy Device Memory to Host Memory\n        CUDA_CHECK(cudaMemcpyAsync(&peakToNoiseRatio_h, peakToNoiseRatio_d, sizeof(float), cudaMemcpyDeviceToHost, stream));\n\n        // Check tasks in the stream has completed\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n\n        // Verify the results\n        assert(fabs(peakToNoiseRatio_h - expectedOutput[t]) < EPSILON);\n    }\n\n    //Free Host Memory\n    free(compressedInputImage_h);\n\n    // Free device Side Memory\n    CUDA_CHECK(cudaFreeAsync(peakToNoiseRatio_d, stream));\n    CUDA_CHECK(cudaFreeAsync(inputImage_d, stream));\n    CUDA_CHECK(cudaFreeAsync(compressedInputImage_d, stream));\n\n    //Destroy CUDA stream\n    CUDA_CHECK(cudaStreamDestroy(stream));\n}\n\n__global__ void k_peakSignalToNoiseRatio(float *inputImage, float *compressedInputImage, float *peakToNoiseRatio, int imageWidth, int imageHeight) {\n", "test": "int main() {\n    launch();\n}\n", "example_test": "    @example_test\n", "cuda_toolkit": "12.2"}
{"task_id": "CUDA/110", "date": "2025-03-31", "prompt": "Develop a CUDA kernel to iteratively solve the distance constraints of joints for a chain under gravitational forces with endpoints pinned to their initial positions. Use the device memory to retain the states of joints until multiple iterations are complete.\nThe signature of the CUDA kernel is __global__ void k_solveConstraintUnderGravity(float *x_d, float *y_d, float *distance_d, float *mass_d, float *xOld_d, float *yOld_d, int numJoints, TempStorage temp), where x_d is a pointer to array of x-coordinate of joints, y_d is a pointer to array of y-coordinate of joints, distance_d is a pointer to array of distances between connected joints, mass_d is a pointer to an array of mass values of joints, xOld_d is a pointer to an array of x-coordinate of joints from previous simulation iteration, yOld_d is a pointer to an array of y-coordinate of joints from previous simulation iteration, and the temp is a struct of temporary arrays used in the algorithm.\n\n>>> k_solveConstraintUnderGravity(\n    { 250.0, 250.366, 255.859, 279.663, 343.75, 478.882, 724.609, 1129.27 },\n    { 140.0, 111.346, 66.4371, 69.6125, 116.323, 139.648, 106.17, 63.8523 },\n    { 28.6559, 45.2441, 24.0146, 79.3034, 137.13, 247.998, 406.87 },\n    { 14.3279, 36.95, 34.6293, 51.659, 108.217, 192.564, 327.434, 203.435 },\n    { 250.0, 250.366, 255.859, 279.663, 343.75, 478.882, 724.609, 1129.27 },\n    { 140.0, 111.346, 66.4371, 69.6125, 116.323, 139.648, 106.17, 63.8523 },\n    8,\n    temp\n) -> x_d: { 250, 250.366, 255.86, 279.663, 343.75, 478.882, 724.609, 1129.27 }, y_d: { 140, 111.347, 66.4372, 69.6154, 116.326, 139.651, 106.173, 63.8523 }\n\n>>> k_solveConstraintUnderGravity(\n    { 0.0, 10.0, 20.0, 30.0, 40.0, 50.0, 60.0, 70.0 },\n    { 0.0, 10.0, 20.0, 30.0, 40.0, 50.0, 60.0, 70.0 },\n    { 14.1421, 14.1421, 14.1421, 14.1421, 14.1421, 14.1421, 14.1421 },\n    { 7.07107, 14.1421, 14.1421, 14.1421, 14.1421, 14.1421, 14.1421, 7.07107 },\n    { 0.0, 10.0, 20.0, 30.0, 40.0, 50.0, 60.0, 70.0 },\n    { 0.0, 10.0, 20.0, 30.0, 40.0, 50.0, 60.0, 70.0 },\n    8,\n    temp\n) -> x_d: { 0.0, 9.99854, 19.9986, 29.9986, 39.9986, 49.9986, 59.9986, 70.0 }, y_d: { 0.0, 10.0015, 20.0015, 30.0015, 40.0015, 50.0015, 60.0015, 70.0 }\n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_75 -arch=sm_70", "ld_flags": "", "declaration": "#undef NDEBUG\n#include <assert.h>\n#include <stdio.h>\n#include <cuda.h>\n#include <cuda_runtime.h>\n#include <device_launch_parameters.h>\n#include <cooperative_groups.h>\n\n#define CUDA_CHECK(call) {                                      \\\n    cudaError_t error = call;                                  \\\n    if(error != cudaSuccess) {                                 \\\n        fprintf(stderr, \"CUDA error at %s: %d - %s \\n\",        \\\n                __FILE__, __LINE__, cudaGetErrorString(error));\\\n        exit(EXIT_FAILURE);                                    \\\n    }                                                          \\\n}\n\n// Number of points that connect the segments to create the chain. There are NUM_JOINTS - 1 number of segments.\nconstexpr int NUM_JOINTS = 8;\nconstexpr int SIZE_SEGMENTS = ((NUM_JOINTS - 1) * sizeof(float));\nconstexpr int SIZE_JOINTS =  (NUM_JOINTS * sizeof(float));\n\n// Less than 1.2 pixel distance error is tolerated.\nconstexpr float MAXIMUM_ABSOLUTE_ERROR = 1.2f;\n\n// CUDA-related constants.\nconstexpr int NUM_THREADS_PER_BLOCK = 32;\nconstexpr int NUM_BLOCKS_PER_GRID = 2;\nconstexpr int GRID_STRIDE_SIZE = NUM_BLOCKS_PER_GRID * NUM_THREADS_PER_BLOCK;\nconstexpr int MAX_GRID_STRIDE_ITERATIONS = 1 + (NUM_JOINTS - 1) / GRID_STRIDE_SIZE;\nconstexpr int TEMP_ARRAY_SIZE = MAX_GRID_STRIDE_ITERATIONS * GRID_STRIDE_SIZE;\n\n// Struct of arrays for temporary storage in the algorithm with grid-stride loop.\nstruct TempStorage{\n    float *x_d;\n    float *y_d;\n    float *mass_d;\n    float *xLeft_d;\n    float *yLeft_d;\n    float *massLeft_d;\n    float *distanceLeft_d;\n    float *xRight_d;\n    float *yRight_d;\n    float *massRight_d;\n    float *distanceRight_d;\n    float *xOld_d;\n    float *yOld_d;\n    bool *pinned_d;\n};\n\n// The CUDA kernel to solve the constraints of a chain that is made of multiple joints using device memory to retain all states of the joints for all iterations.\n__global__ void k_solveConstraintUnderGravity(float *x_d, float *y_d, float *distance_d, float *mass_d, float *xOld_d, float *yOld_d, int numJoints, TempStorage temp);\n\nvoid launch() {\n    // Host data for joints.\n    float x_h[NUM_JOINTS];\n    float y_h[NUM_JOINTS];\n    float distance_h[NUM_JOINTS - 1];\n    float mass_h[NUM_JOINTS];\n    cudaStream_t stream;\n\n    // Device data for joints.\n    float *x_d;\n    float *y_d;\n    float *xOld_d;\n    float *yOld_d;\n    float *mass_d;\n    TempStorage temp;\n    \n    // Distance data between joint i and joint i + 1.\n    float *distance_d;\n    CUDA_CHECK(cudaStreamCreate(&stream));\n\n    // Device memory I/O array allocations.\n    CUDA_CHECK(cudaMallocAsync(&x_d, SIZE_JOINTS, stream));\n    CUDA_CHECK(cudaMallocAsync(&y_d, SIZE_JOINTS, stream));\n    CUDA_CHECK(cudaMallocAsync(&xOld_d, SIZE_JOINTS, stream));\n    CUDA_CHECK(cudaMallocAsync(&yOld_d, SIZE_JOINTS, stream));\n    CUDA_CHECK(cudaMallocAsync(&mass_d, SIZE_JOINTS, stream));\n    CUDA_CHECK(cudaMallocAsync(&distance_d, SIZE_SEGMENTS, stream));\n\n    // Device memory temporary array allocations.\n    CUDA_CHECK(cudaMallocAsync(&temp.x_d, TEMP_ARRAY_SIZE * sizeof(float), stream));\n    CUDA_CHECK(cudaMallocAsync(&temp.y_d, TEMP_ARRAY_SIZE * sizeof(float), stream));\n    CUDA_CHECK(cudaMallocAsync(&temp.mass_d, TEMP_ARRAY_SIZE * sizeof(float), stream));\n    CUDA_CHECK(cudaMallocAsync(&temp.xLeft_d, TEMP_ARRAY_SIZE * sizeof(float), stream));\n    CUDA_CHECK(cudaMallocAsync(&temp.yLeft_d, TEMP_ARRAY_SIZE * sizeof(float), stream));\n    CUDA_CHECK(cudaMallocAsync(&temp.massLeft_d, TEMP_ARRAY_SIZE * sizeof(float), stream));\n    CUDA_CHECK(cudaMallocAsync(&temp.distanceLeft_d, TEMP_ARRAY_SIZE * sizeof(float), stream));\n    CUDA_CHECK(cudaMallocAsync(&temp.xRight_d, TEMP_ARRAY_SIZE * sizeof(float), stream));\n    CUDA_CHECK(cudaMallocAsync(&temp.yRight_d, TEMP_ARRAY_SIZE * sizeof(float), stream));\n    CUDA_CHECK(cudaMallocAsync(&temp.massRight_d, TEMP_ARRAY_SIZE * sizeof(float), stream));\n    CUDA_CHECK(cudaMallocAsync(&temp.distanceRight_d, TEMP_ARRAY_SIZE * sizeof(float), stream));\n    CUDA_CHECK(cudaMallocAsync(&temp.xOld_d, TEMP_ARRAY_SIZE * sizeof(float), stream));\n    CUDA_CHECK(cudaMallocAsync(&temp.yOld_d, TEMP_ARRAY_SIZE * sizeof(float), stream));\n    CUDA_CHECK(cudaMallocAsync(&temp.pinned_d, TEMP_ARRAY_SIZE * sizeof(unsigned char), stream));\n\n    CUDA_CHECK(cudaMemsetAsync(temp.x_d, 0, TEMP_ARRAY_SIZE * sizeof(float), stream));\n    CUDA_CHECK(cudaMemsetAsync(temp.y_d, 0, TEMP_ARRAY_SIZE * sizeof(float), stream));\n    CUDA_CHECK(cudaMemsetAsync(temp.mass_d, 0, TEMP_ARRAY_SIZE * sizeof(float), stream));\n    CUDA_CHECK(cudaMemsetAsync(temp.xLeft_d, 0, TEMP_ARRAY_SIZE * sizeof(float), stream));\n    CUDA_CHECK(cudaMemsetAsync(temp.yLeft_d, 0, TEMP_ARRAY_SIZE * sizeof(float), stream));\n    CUDA_CHECK(cudaMemsetAsync(temp.massLeft_d, 0, TEMP_ARRAY_SIZE * sizeof(float), stream));\n    CUDA_CHECK(cudaMemsetAsync(temp.distanceLeft_d, 0, TEMP_ARRAY_SIZE * sizeof(float), stream));\n    CUDA_CHECK(cudaMemsetAsync(temp.xRight_d, 0, TEMP_ARRAY_SIZE * sizeof(float), stream));\n    CUDA_CHECK(cudaMemsetAsync(temp.yRight_d, 0, TEMP_ARRAY_SIZE * sizeof(float), stream));\n    CUDA_CHECK(cudaMemsetAsync(temp.massRight_d, 0, TEMP_ARRAY_SIZE * sizeof(float), stream));\n    CUDA_CHECK(cudaMemsetAsync(temp.distanceRight_d, 0, TEMP_ARRAY_SIZE * sizeof(float), stream));\n    CUDA_CHECK(cudaMemsetAsync(temp.xOld_d, 0, TEMP_ARRAY_SIZE * sizeof(float), stream));\n    CUDA_CHECK(cudaMemsetAsync(temp.yOld_d, 0, TEMP_ARRAY_SIZE * sizeof(float), stream));\n    CUDA_CHECK(cudaMemsetAsync(temp.pinned_d, 0, TEMP_ARRAY_SIZE * sizeof(unsigned char), stream));\n\n    for(int i = 0; i < NUM_JOINTS; i++) {\n        mass_h[i] = 0.0f;\n    }\n\n    // Test 1: initial condition = periodic wave shaped chain with variable segment length.\n    {\n        for(int index = 0;index < NUM_JOINTS; index++) {\n            float x = pow(index / (float)NUM_JOINTS, 4) * 1500 + 250;\n            float y = cos(40.0f * index / (float)(NUM_JOINTS)) * 40 + 100;\n            x_h[index] = x;\n            y_h[index] = y;\n\n            if(index > 0) {\n                float dx = x - x_h[index - 1];\n                float dy = y - y_h[index - 1];\n                distance_h[index - 1] = sqrt(dx * dx + dy * dy);\n            \n                // Segment mass depends on length. Joint mass is half of masses added from each segment on sides. Assuming 1 unit mass per unit distance.\n                mass_h[index - 1] += (distance_h[index - 1] * 0.5f);\n                mass_h[index] += (distance_h[index - 1] * 0.5f);\n            }\n        }\n\n        CUDA_CHECK(cudaMemcpyAsync(x_d, x_h, SIZE_JOINTS, cudaMemcpyHostToDevice, stream));\n        CUDA_CHECK(cudaMemcpyAsync(xOld_d, x_d, SIZE_JOINTS, cudaMemcpyDeviceToDevice, stream));\n        CUDA_CHECK(cudaMemcpyAsync(y_d, y_h, SIZE_JOINTS, cudaMemcpyHostToDevice, stream));\n        CUDA_CHECK(cudaMemcpyAsync(yOld_d, y_d, SIZE_JOINTS, cudaMemcpyDeviceToDevice, stream));\n        CUDA_CHECK(cudaMemcpyAsync(distance_d, distance_h, SIZE_SEGMENTS, cudaMemcpyHostToDevice, stream));\n        CUDA_CHECK(cudaMemcpyAsync(mass_d, mass_h, SIZE_JOINTS, cudaMemcpyHostToDevice, stream));\n        \n        // Resetting mass values for next initialization.\n        for(int i = 0; i < NUM_JOINTS; i++) {\n            mass_h[i] = 0.0f;\n        }\n\n        int numJoints = NUM_JOINTS;\n        void * args[8] = { &x_d, &y_d, &distance_d, &mass_d, &xOld_d, &yOld_d, &numJoints, &temp };\n        dim3 gridDim(NUM_BLOCKS_PER_GRID, 1, 1);\n        dim3 blockDim(NUM_THREADS_PER_BLOCK, 1, 1);\n        \n        // Grid: (2, 1, 1)\n        // Block: (32, 1, 1)\n        CUDA_CHECK(cudaLaunchCooperativeKernel( (void*)k_solveConstraintUnderGravity, \n                                                gridDim, \n                                                blockDim, \n                                                args, \n                                                0, \n                                                stream));\n        CUDA_CHECK(cudaMemcpyAsync(x_h, x_d, NUM_JOINTS * sizeof(float), cudaMemcpyDeviceToHost, stream));\n        CUDA_CHECK(cudaMemcpyAsync(y_h, y_d, NUM_JOINTS * sizeof(float), cudaMemcpyDeviceToHost, stream));\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n        \n        // Checking the differences between the constrained distance and the current distance between joints.\n        for(int j = 1; j < NUM_JOINTS; j++) {\n            float dx = x_h[j - 1] - x_h[j];\n            float dy = y_h[j - 1] - y_h[j];\n            float distance = sqrt(dx * dx + dy * dy);\n            float expectedDistance = distance_h[j - 1];\n            float absoluteError = fabsf(distance - expectedDistance);\n            assert(absoluteError < MAXIMUM_ABSOLUTE_ERROR);\n        }\n    }\n\n    // Test 2: initial condition = chain with a diagonal line shape and uniform segment length.\n    {\n        for(int index = 0; index < NUM_JOINTS; index++) {\n            float x = index * 10.0f;\n            float y = index * 10.0f;\n            x_h[index] = x;\n            y_h[index] = y;\n            \n            if(index > 0) {\n                float dx = x - x_h[index - 1];\n                float dy = y - y_h[index - 1];\n                distance_h[index - 1] = sqrt(dx * dx + dy * dy);\n\n                // Segment mass depends on length. Joint mass is half of masses added from each segment on sides. Assuming 1 unit mass per unit distance.\n                mass_h[index - 1] += (distance_h[index - 1] * 0.5f);\n                mass_h[index] += (distance_h[index - 1] * 0.5f);\n            }\n        }\n\n        CUDA_CHECK(cudaMemcpyAsync(x_d, x_h, SIZE_JOINTS, cudaMemcpyHostToDevice, stream));\n        CUDA_CHECK(cudaMemcpyAsync(xOld_d, x_d, SIZE_JOINTS, cudaMemcpyDeviceToDevice, stream));\n        CUDA_CHECK(cudaMemcpyAsync(y_d, y_h, SIZE_JOINTS, cudaMemcpyHostToDevice, stream));\n        CUDA_CHECK(cudaMemcpyAsync(yOld_d, y_d, SIZE_JOINTS, cudaMemcpyDeviceToDevice, stream));\n        CUDA_CHECK(cudaMemcpyAsync(distance_d, distance_h, SIZE_SEGMENTS, cudaMemcpyHostToDevice, stream));\n        CUDA_CHECK(cudaMemcpyAsync(mass_d, mass_h, SIZE_JOINTS, cudaMemcpyHostToDevice, stream));\n        \n        // Resetting mass values for next initialization.\n        for(int i = 0; i < NUM_JOINTS; i++) {\n            mass_h[i] = 0.0f;\n        }\n        \n        int numJoints = NUM_JOINTS;\n        void * args[8] = { &x_d, &y_d, &distance_d, &mass_d, &xOld_d, &yOld_d, &numJoints, &temp };\n        dim3 gridDim(NUM_BLOCKS_PER_GRID, 1, 1);\n        dim3 blockDim(NUM_THREADS_PER_BLOCK, 1, 1);\n        \n        // Grid: (2, 1, 1)\n        // Block: (32, 1, 1)\n        CUDA_CHECK(cudaLaunchCooperativeKernel( (void*)k_solveConstraintUnderGravity, \n                                                gridDim, \n                                                blockDim, \n                                                args, \n                                                0, \n                                                stream));\n        CUDA_CHECK(cudaMemcpyAsync(x_h, x_d, NUM_JOINTS * sizeof(float), cudaMemcpyDeviceToHost, stream));\n        CUDA_CHECK(cudaMemcpyAsync(y_h, y_d, NUM_JOINTS * sizeof(float), cudaMemcpyDeviceToHost, stream));\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n        \n        // Checking the differences between the constrained distance and the current distance between joints.\n        for(int j = 1; j < NUM_JOINTS; j++) {\n            float dx = x_h[j - 1] - x_h[j];\n            float dy = y_h[j - 1] - y_h[j];\n            float distance = sqrt(dx * dx + dy * dy);\n            float expectedDistance = distance_h[j - 1];\n            float absoluteError = fabsf(distance - expectedDistance);\n            assert(absoluteError < MAXIMUM_ABSOLUTE_ERROR);\n        }\n    }\n\n    // Test 3: initial condition = chain with a horizontal line shape and uniform segment length.\n    {\n        for(int index = 0; index < NUM_JOINTS; index++) {\n            float x = index * 10.0f;\n            float y = 400.0f;\n            x_h[index] = x;\n            y_h[index] = y;\n\n            if(index > 0) {\n                float dx = x - x_h[index - 1];\n                float dy = y - y_h[index - 1];\n                distance_h[index - 1] = sqrt(dx * dx + dy * dy);\n                \n                // Segment mass depends on length. Joint mass is half of masses added from each segment on sides. Assuming 1 unit mass per unit distance.\n                mass_h[index - 1] += (distance_h[index - 1] * 0.5f);\n                mass_h[index] += (distance_h[index - 1] * 0.5f);\n            }\n        }\n\n        CUDA_CHECK(cudaMemcpyAsync(x_d, x_h, SIZE_JOINTS, cudaMemcpyHostToDevice, stream));\n        CUDA_CHECK(cudaMemcpyAsync(xOld_d, x_d, SIZE_JOINTS, cudaMemcpyDeviceToDevice, stream));\n        CUDA_CHECK(cudaMemcpyAsync(y_d, y_h, SIZE_JOINTS, cudaMemcpyHostToDevice, stream));\n        CUDA_CHECK(cudaMemcpyAsync(yOld_d, y_d, SIZE_JOINTS, cudaMemcpyDeviceToDevice, stream));\n        CUDA_CHECK(cudaMemcpyAsync(distance_d, distance_h, SIZE_SEGMENTS, cudaMemcpyHostToDevice, stream));\n        CUDA_CHECK(cudaMemcpyAsync(mass_d, mass_h, SIZE_JOINTS, cudaMemcpyHostToDevice, stream));\n        \n        // Resetting mass values for next initialization.\n        for(int i = 0; i < NUM_JOINTS; i++) {\n            mass_h[i] = 0.0f;\n        }\n\n        int numJoints = NUM_JOINTS;\n        void * args[8] = { &x_d, &y_d, &distance_d, &mass_d, &xOld_d, &yOld_d, &numJoints, &temp };\n        dim3 gridDim(NUM_BLOCKS_PER_GRID, 1, 1);\n        dim3 blockDim(NUM_THREADS_PER_BLOCK, 1, 1);\n        \n        // Grid: (2, 1, 1)\n        // Block: (32, 1, 1)\n        CUDA_CHECK(cudaLaunchCooperativeKernel( (void*)k_solveConstraintUnderGravity, \n                                                gridDim, \n                                                blockDim, \n                                                args, \n                                                0, \n                                                stream));\n        CUDA_CHECK(cudaMemcpyAsync(x_h, x_d, NUM_JOINTS * sizeof(float), cudaMemcpyDeviceToHost, stream));\n        CUDA_CHECK(cudaMemcpyAsync(y_h, y_d, NUM_JOINTS * sizeof(float), cudaMemcpyDeviceToHost, stream));\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n        \n        // Checking the differences between the constrained distance and the current distance between joints.\n        for(int j = 1; j < NUM_JOINTS; j++) {\n            float dx = x_h[j - 1] - x_h[j];\n            float dy = y_h[j - 1] - y_h[j];\n            float distance = sqrt(dx * dx + dy * dy);\n            float expectedDistance = distance_h[j - 1];\n            float absoluteError = fabsf(distance - expectedDistance);\n            assert(absoluteError < MAXIMUM_ABSOLUTE_ERROR);\n        }      \n    }\n\n    // Test 4: initial condition = chain with a vertical line shape and uniform segment length.\n    {\n        for(int index = 0; index < NUM_JOINTS; index++) {\n            float x = 500.0f;\n            float y = index * 10.0f;\n            x_h[index] = x;\n            y_h[index] = y;\n\n            if(index > 0) {\n                float dx = x - x_h[index - 1];\n                float dy = y - y_h[index - 1];\n                distance_h[index - 1] = sqrt(dx * dx + dy * dy);\n                \n                // Segment mass depends on length. Joint mass is half of masses added from each segment on sides. Assuming 1 unit mass per unit distance.\n                mass_h[index - 1] += (distance_h[index - 1] * 0.5f);\n                mass_h[index] += (distance_h[index - 1] * 0.5f);\n            }\n        }\n\n        CUDA_CHECK(cudaMemcpyAsync(x_d, x_h, SIZE_JOINTS, cudaMemcpyHostToDevice, stream));\n        CUDA_CHECK(cudaMemcpyAsync(xOld_d, x_d, SIZE_JOINTS, cudaMemcpyDeviceToDevice, stream));\n        CUDA_CHECK(cudaMemcpyAsync(y_d, y_h, SIZE_JOINTS, cudaMemcpyHostToDevice, stream));\n        CUDA_CHECK(cudaMemcpyAsync(yOld_d, y_d, SIZE_JOINTS, cudaMemcpyDeviceToDevice, stream));\n        CUDA_CHECK(cudaMemcpyAsync(distance_d, distance_h, SIZE_SEGMENTS, cudaMemcpyHostToDevice, stream));\n        CUDA_CHECK(cudaMemcpyAsync(mass_d, mass_h, SIZE_JOINTS, cudaMemcpyHostToDevice, stream));\n        \n        // Resetting mass values for next initialization.\n        for(int i = 0; i < NUM_JOINTS; i++) {\n            mass_h[i] = 0.0f;\n        }\n        \n        int numJoints = NUM_JOINTS;\n        void * args[8] = { &x_d, &y_d, &distance_d, &mass_d, &xOld_d, &yOld_d, &numJoints, &temp };\n        dim3 gridDim(NUM_BLOCKS_PER_GRID, 1, 1);\n        dim3 blockDim(NUM_THREADS_PER_BLOCK, 1, 1);\n        \n        // Grid: (2, 1, 1)\n        // Block: (32, 1, 1)\n        CUDA_CHECK(cudaLaunchCooperativeKernel( (void*)k_solveConstraintUnderGravity, \n                                                gridDim, \n                                                blockDim, \n                                                args, \n                                                0, \n                                                stream));\n        CUDA_CHECK(cudaMemcpyAsync(x_h, x_d, NUM_JOINTS * sizeof(float), cudaMemcpyDeviceToHost, stream));\n        CUDA_CHECK(cudaMemcpyAsync(y_h, y_d, NUM_JOINTS * sizeof(float), cudaMemcpyDeviceToHost, stream));\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n        \n        // Checking the differences between the constrained distance and the current distance between joints.\n        for(int j = 1; j < NUM_JOINTS; j++) {\n            float dx = x_h[j - 1] - x_h[j];\n            float dy = y_h[j - 1] - y_h[j];\n            float distance = sqrt(dx * dx + dy * dy);\n            float expectedDistance = distance_h[j - 1];\n            float absoluteError = fabsf(distance - expectedDistance);\n            assert(absoluteError < MAXIMUM_ABSOLUTE_ERROR);\n        }      \n    }\n\n    // Test 5: initial condition = chain with a horizontal line shape, uniform segment length and one joint pulled far from equilibrium position.\n    {\n        for(int index = 0; index < NUM_JOINTS; index++) {\n            float x = index * 20.0f;\n            float y = 500.0f;\n            x_h[index] = x;\n            y_h[index] = y;\n\n            if(index > 0) {\n                float dx = x - x_h[index - 1];\n                float dy = y - y_h[index - 1];\n                distance_h[index - 1] = sqrt(dx * dx + dy * dy);\n                \n                // Segment mass depends on length. Joint mass is half of masses added from each segment on sides. Assuming 1 unit mass per unit distance.\n                mass_h[index - 1] += (distance_h[index - 1] * 0.5f);\n                mass_h[index] += (distance_h[index - 1] * 0.5f);\n            }\n        }\n\n        // Pulling middle joint 100 pixels in -y direction.\n        x_h[NUM_JOINTS / 2] = (NUM_JOINTS / 2) * 20.0f;\n        y_h[NUM_JOINTS / 2] = 400.0f;\n\n        CUDA_CHECK(cudaMemcpyAsync(x_d, x_h, SIZE_JOINTS, cudaMemcpyHostToDevice, stream));\n        CUDA_CHECK(cudaMemcpyAsync(xOld_d, x_d, SIZE_JOINTS, cudaMemcpyDeviceToDevice, stream));\n        CUDA_CHECK(cudaMemcpyAsync(y_d, y_h, SIZE_JOINTS, cudaMemcpyHostToDevice, stream));\n        CUDA_CHECK(cudaMemcpyAsync(yOld_d, y_d, SIZE_JOINTS, cudaMemcpyDeviceToDevice, stream));\n        CUDA_CHECK(cudaMemcpyAsync(distance_d, distance_h, SIZE_SEGMENTS, cudaMemcpyHostToDevice, stream));\n        CUDA_CHECK(cudaMemcpyAsync(mass_d, mass_h, SIZE_JOINTS, cudaMemcpyHostToDevice, stream));\n        \n        // Resetting mass values for next initialization.\n        for(int i = 0; i < NUM_JOINTS; i++) {\n            mass_h[i] = 0.0f;\n        }\n\n        int numJoints = NUM_JOINTS;\n        void * args[8] = { &x_d, &y_d, &distance_d, &mass_d, &xOld_d, &yOld_d, &numJoints, &temp };\n        dim3 gridDim(NUM_BLOCKS_PER_GRID, 1, 1);\n        dim3 blockDim(NUM_THREADS_PER_BLOCK, 1, 1);\n        \n        // Grid: (2, 1, 1)\n        // Block: (32, 1, 1)\n        CUDA_CHECK(cudaLaunchCooperativeKernel( (void*)k_solveConstraintUnderGravity, \n                                                gridDim, \n                                                blockDim, \n                                                args, \n                                                0, \n                                                stream));\n        CUDA_CHECK(cudaMemcpyAsync(x_h, x_d, NUM_JOINTS * sizeof(float), cudaMemcpyDeviceToHost, stream));\n        CUDA_CHECK(cudaMemcpyAsync(y_h, y_d, NUM_JOINTS * sizeof(float), cudaMemcpyDeviceToHost, stream));\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n        \n        // Checking the differences between the constrained distance and the current distance between joints.\n        for(int j = 1; j < NUM_JOINTS; j++) {\n            float dx = x_h[j - 1] - x_h[j];\n            float dy = y_h[j - 1] - y_h[j];\n            float distance = sqrt(dx * dx + dy * dy);\n            float expectedDistance = distance_h[j - 1];\n            float absoluteError = fabsf(distance - expectedDistance);\n            assert(absoluteError < MAXIMUM_ABSOLUTE_ERROR);\n        }\n    }\n\n    // Test 6: initial condition = chain with a horizontal line shape, uniform segment length and two joints pulled far towards opposite directions.\n    {\n        for(int index = 0; index < NUM_JOINTS; index++) {\n            float x = index * 20.0f;\n            float y = 500.0f;\n            x_h[index] = x;\n            y_h[index] = y;\n            if(index > 0) {\n                float dx = x - x_h[index - 1];\n                float dy = y - y_h[index - 1];\n                distance_h[index - 1] = sqrt(dx * dx + dy * dy);\n                \n                // Segment mass depends on length. Joint mass is half of masses added from each segment on sides. Assuming 1 unit mass per unit distance.\n                mass_h[index - 1] += (distance_h[index - 1] * 0.5f);\n                mass_h[index] += (distance_h[index - 1] * 0.5f);\n            }\n        }\n\n        // Pulling 1 joint 100 pixels in -y direction.\n        x_h[5] = 5 * 20.0f;\n        y_h[5] = 400.0f;\n\n        // Pulling 1 joint 100 pixels in y direction.\n        x_h[NUM_JOINTS - 5] = (NUM_JOINTS - 5) * 20.0f;\n        y_h[NUM_JOINTS - 5] = 600.0f;\n\n        CUDA_CHECK(cudaMemcpyAsync(x_d, x_h, SIZE_JOINTS, cudaMemcpyHostToDevice, stream));\n        CUDA_CHECK(cudaMemcpyAsync(xOld_d, x_d, SIZE_JOINTS, cudaMemcpyDeviceToDevice, stream));\n        CUDA_CHECK(cudaMemcpyAsync(y_d, y_h, SIZE_JOINTS, cudaMemcpyHostToDevice, stream));\n        CUDA_CHECK(cudaMemcpyAsync(yOld_d, y_d, SIZE_JOINTS, cudaMemcpyDeviceToDevice, stream));\n        CUDA_CHECK(cudaMemcpyAsync(distance_d, distance_h, SIZE_SEGMENTS, cudaMemcpyHostToDevice, stream));\n        CUDA_CHECK(cudaMemcpyAsync(mass_d, mass_h, SIZE_JOINTS, cudaMemcpyHostToDevice, stream));\n        \n        // Resetting mass values for next initialization.\n        for(int i = 0; i < NUM_JOINTS; i++) {\n            mass_h[i] = 0.0f;\n        }\n        \n        int numJoints = NUM_JOINTS;\n        void * args[8] = { &x_d, &y_d, &distance_d, &mass_d, &xOld_d, &yOld_d, &numJoints, &temp };\n        dim3 gridDim(NUM_BLOCKS_PER_GRID, 1, 1);\n        dim3 blockDim(NUM_THREADS_PER_BLOCK, 1, 1);\n        \n        // Grid: (2, 1, 1)\n        // Block: (32, 1, 1)\n        CUDA_CHECK(cudaLaunchCooperativeKernel( (void*)k_solveConstraintUnderGravity, \n                                                gridDim, \n                                                blockDim, \n                                                args, \n                                                0, \n                                                stream));\n        CUDA_CHECK(cudaMemcpyAsync(x_h, x_d, NUM_JOINTS * sizeof(float), cudaMemcpyDeviceToHost, stream));\n        CUDA_CHECK(cudaMemcpyAsync(y_h, y_d, NUM_JOINTS * sizeof(float), cudaMemcpyDeviceToHost, stream));\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n        \n        // Checking the differences between the constrained distance and the current distance between joints.\n        for(int j = 1; j < NUM_JOINTS; j++) {\n            float dx = x_h[j - 1] - x_h[j];\n            float dy = y_h[j - 1] - y_h[j];\n            float distance = sqrt(dx * dx + dy * dy);\n            float expectedDistance = distance_h[j - 1];\n            float absoluteError = fabsf(distance - expectedDistance);\n            assert(absoluteError < MAXIMUM_ABSOLUTE_ERROR);\n        }      \n    }\n\n    // Test 7: initial condition = chain with a vertical line shape, uniform segment length and one joint pulled far from equilibrium position.\n    {\n        for(int index = 0; index < NUM_JOINTS; index++) {\n            float x = 500.0f;\n            float y = index * 10.0f;\n            x_h[index] = x;\n            y_h[index] = y;\n            \n            if(index > 0) {\n                float dx = x - x_h[index - 1];\n                float dy = y - y_h[index - 1];\n                distance_h[index - 1] = sqrt(dx * dx + dy * dy);\n            \n                // Segment mass depends on length. Joint mass is half of masses added from each segment on sides. Assuming 1 unit mass per unit distance.\n                mass_h[index - 1] += (distance_h[index - 1] * 0.5f);\n                mass_h[index] += (distance_h[index - 1] * 0.5f);\n            }\n        }\n\n        // Pulling 1 joint 100 pixels in x direction.\n        x_h[5] = 600.0f;\n        y_h[5] = 5 * 10.0f;\n        CUDA_CHECK(cudaMemcpyAsync(x_d, x_h, SIZE_JOINTS, cudaMemcpyHostToDevice, stream));\n        CUDA_CHECK(cudaMemcpyAsync(xOld_d, x_d, SIZE_JOINTS, cudaMemcpyDeviceToDevice, stream));\n        CUDA_CHECK(cudaMemcpyAsync(y_d, y_h, SIZE_JOINTS, cudaMemcpyHostToDevice, stream));\n        CUDA_CHECK(cudaMemcpyAsync(yOld_d, y_d, SIZE_JOINTS, cudaMemcpyDeviceToDevice, stream));\n        CUDA_CHECK(cudaMemcpyAsync(distance_d, distance_h, SIZE_SEGMENTS, cudaMemcpyHostToDevice, stream));\n        CUDA_CHECK(cudaMemcpyAsync(mass_d, mass_h, SIZE_JOINTS, cudaMemcpyHostToDevice, stream));\n        \n        // Resetting mass values for next initialization.\n        for(int i = 0; i < NUM_JOINTS; i++) {\n            mass_h[i] = 0.0f;\n        }\n\n        int numJoints = NUM_JOINTS;\n        void * args[8] = { &x_d, &y_d, &distance_d, &mass_d, &xOld_d, &yOld_d, &numJoints, &temp };\n        dim3 gridDim(NUM_BLOCKS_PER_GRID, 1, 1);\n        dim3 blockDim(NUM_THREADS_PER_BLOCK, 1, 1);\n        \n        // Grid: (2, 1, 1)\n        // Block: (32, 1, 1)\n        CUDA_CHECK(cudaLaunchCooperativeKernel( (void*)k_solveConstraintUnderGravity, \n                                                gridDim, \n                                                blockDim, \n                                                args, \n                                                0, \n                                                stream));\n        CUDA_CHECK(cudaMemcpyAsync(x_h, x_d, NUM_JOINTS * sizeof(float), cudaMemcpyDeviceToHost, stream));\n        CUDA_CHECK(cudaMemcpyAsync(y_h, y_d, NUM_JOINTS * sizeof(float), cudaMemcpyDeviceToHost, stream));\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n        \n        // Checking the differences between the constrained distance and the current distance between joints.\n        for(int j = 1; j < NUM_JOINTS; j++) {\n            float dx = x_h[j - 1] - x_h[j];\n            float dy = y_h[j - 1] - y_h[j];\n            float distance = sqrt(dx * dx + dy * dy);\n            float expectedDistance = distance_h[j - 1];\n            float absoluteError = fabsf(distance - expectedDistance);\n            assert(absoluteError < MAXIMUM_ABSOLUTE_ERROR);\n        }\n    }\n\n    CUDA_CHECK(cudaFreeAsync(x_d, stream));\n    CUDA_CHECK(cudaFreeAsync(y_d, stream));\n    CUDA_CHECK(cudaFreeAsync(xOld_d, stream));\n    CUDA_CHECK(cudaFreeAsync(yOld_d, stream));\n    CUDA_CHECK(cudaFreeAsync(distance_d, stream));\n    CUDA_CHECK(cudaFreeAsync(mass_d, stream));\n\n    CUDA_CHECK(cudaFreeAsync(temp.x_d, stream));\n    CUDA_CHECK(cudaFreeAsync(temp.y_d, stream));\n    CUDA_CHECK(cudaFreeAsync(temp.mass_d, stream));\n    CUDA_CHECK(cudaFreeAsync(temp.xLeft_d, stream));\n    CUDA_CHECK(cudaFreeAsync(temp.yLeft_d, stream));\n    CUDA_CHECK(cudaFreeAsync(temp.massLeft_d, stream));\n    CUDA_CHECK(cudaFreeAsync(temp.distanceLeft_d, stream));\n    CUDA_CHECK(cudaFreeAsync(temp.xRight_d, stream));\n    CUDA_CHECK(cudaFreeAsync(temp.yRight_d, stream));\n    CUDA_CHECK(cudaFreeAsync(temp.massRight_d, stream));\n    CUDA_CHECK(cudaFreeAsync(temp.distanceRight_d, stream));\n    CUDA_CHECK(cudaFreeAsync(temp.xOld_d, stream));\n    CUDA_CHECK(cudaFreeAsync(temp.yOld_d, stream));\n    CUDA_CHECK(cudaFreeAsync(temp.pinned_d, stream));\n    CUDA_CHECK(cudaStreamDestroy(stream));\n}\n\n__global__ void k_solveConstraintUnderGravity(float *x_d, float *y_d, float *distance_d, float *mass_d, float *xOld_d, float *yOld_d, int numJoints, TempStorage temp) {\n", "test": "int main() {\n    launch();\n}\n", "example_test": "    @example_test\n", "cuda_toolkit": "12.2"}
{"task_id": "CUDA/111", "date": "2025-03-31", "prompt": "Write a CUDA kernel to find the max-score of alignment between two sequences using the Smith-Waterman algorithm. Each block will process one diagonal, and each thread will calculate a unique cell in diagonal based on previously computed neighboring values. Assume that the block size is computed based on the lengths of the sequences.\n\nThe signature of the function is __global__ void k_smithWatermanKernel(char *firstSequence_d, char *secondSequence_d, int length1, int length2, int *scoreMatrix_d, int *maxScore_d), where firstSequence_d is a pointer to the first genome sequence, secondSequence_d is a pointer to the second genome sequence, length1 and length2 are the lengths of first and second genome sequences, scoreMatrix_d is the pointer to integer matrix that stores the intermediate alignment scores and maxScore_d is the pointer to an integer that stores maximum alignment score between the two sequences.\n\n>>> k_smithWatermanKernel(\"GATTACA\", \"GCATGCU\", 7, 7, scoreMatrix_d, maxScore_d)-> maxScore_d: 4\n>>> k_smithWatermanKernel(\"AGCT\", \"CGTACG\", 4, 6, scoreMatrix_d, maxScore_d)-> maxScore_d: 2\n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_70", "ld_flags": "", "declaration": "#include <vector>\n#include <string>\n#include <cstdio>\n#include <algorithm>\n#include <cuda_runtime.h>\n#include <cooperative_groups.h>\n#undef  NDEBUG\n#include <assert.h>\n\nnamespace cg = cooperative_groups;\n\n#define MATCH         (2)\n#define MISMATCH      (-1)\n#define GAP           (-2)\n#define INDEX(row, col, length)   ((row) * ((length) + 1) + (col))\n#define BLOCK_SIZE    (16)\n\n#define CUDA_CHECK(call)                                        \\\ndo {                                                            \\\n        cudaError_t error = call;                               \\\n        if (error != cudaSuccess) {                             \\\n            fprintf(stderr, \"CUDA error at %s:%d - %s\\n\",       \\\n                    __FILE__, __LINE__,                         \\\n                    cudaGetErrorString(error));                 \\\n            exit(EXIT_FAILURE);                                 \\\n        }                                                       \\\n} while(0)\n\nstruct TestCase {\n    std::string sequence1;\n    std::string sequence2;\n    int expected_score;\n};\n\n__global__ void k_smithWatermanKernel(char *firstSequence_d, char *secondSequence_d, int length1, int length2, int *scoreMatrix_d, int *maxScore_d);\n\nvoid launch() {\n    // Total number of test cases\n    const int NUM_TEST_CASES = 11;\n\n    TestCase testCases[] = {\n        {\"GATTACA\", \"GCATGCU\", 4},                              // Test Case 1\n        {\"AGCT\", \"CGTACG\", 2},                                  // Test Case 2\n        {\"AAAA\", \"AAA\", 6},                                     // Test Case 3\n        {\"ACTG\", \"TGCA\", 4},                                    // Test Case 4\n        {\"ACCGTGA\", \"GTGAATA\", 8},                              // Test Case 5\n        {\"GCGT\", \"GCGT\", 8},                                    // Test Case 6\n        {\"ACGTACGT\", \"TGCATGCA\", 4},                            // Test Case 7\n        {\"GATTA\", \"CTAGG\", 4},                                  // Test Case 8\n        {\"ACGTACGTACGTACGTACGT\", \"ACGTACGTACGTACGTACGT\", 40},   // Test Case 9\n        {std::string(64, 'A'), std::string(64, 'A'), 128},      // Test Case 10\n        {std::string(100, 'C'), std::string(100, 'C'), 200}     // Test Case 11\n    };\n\n    // Determine the maximum lengths among all test cases\n    size_t maxLength1 = 0;\n    size_t maxLength2 = 0;\n    \n    for (int i = 0; i < NUM_TEST_CASES; ++i) {\n        maxLength1 = std::max(maxLength1, testCases[i].sequence1.length());\n        maxLength2 = std::max(maxLength2, testCases[i].sequence2.length());\n    }\n\n    // Allocate device memory asynchronously using the maximum sizes\n    cudaStream_t stream;\n    CUDA_CHECK(cudaStreamCreate(&stream));\n    size_t maxSize1 = maxLength1 * sizeof(char);\n    size_t maxSize2 = maxLength2 * sizeof(char);\n\n    size_t scoreMatrixSizeMax = (maxLength1 + 1) * (maxLength2 + 1) * sizeof(int);\n    char *firstSequence_d, *secondSequence_d;\n    int *scoreMatrix_d, *maxScore_d;\n    CUDA_CHECK(cudaMallocAsync((void**)&firstSequence_d, maxSize1, stream));\n    CUDA_CHECK(cudaMallocAsync((void**)&secondSequence_d, maxSize2, stream));\n    CUDA_CHECK(cudaMallocAsync((void**)&scoreMatrix_d, scoreMatrixSizeMax, stream));\n    CUDA_CHECK(cudaMallocAsync((void**)&maxScore_d, sizeof(int), stream));\n\n    // Create a host vector for initializing the DP matrix.\n    std::vector<int> scoreMatrixInit((maxLength1 + 1) * (maxLength2 + 1), 0);\n\n    // For each test case, launch the kernel cooperatively.\n    for (int testIndex = 0; testIndex < NUM_TEST_CASES; testIndex++) {\n        std::string sequence1 = testCases[testIndex].sequence1;\n        std::string sequence2 = testCases[testIndex].sequence2;\n        int length1 = sequence1.length();\n        int length2 = sequence2.length();\n\n        // Copy sequences to device\n        CUDA_CHECK(cudaMemcpyAsync(firstSequence_d, sequence1.c_str(), length1 * sizeof(char), cudaMemcpyHostToDevice, stream));\n        CUDA_CHECK(cudaMemcpyAsync(secondSequence_d, sequence2.c_str(), length2 * sizeof(char), cudaMemcpyHostToDevice, stream));\n\n        // Reset score matrix and max score for the current test case\n        std::vector<int> scoreMatrix_h((length1 + 1) * (length2 + 1), 0);\n        int maxScore_h = 0;\n        CUDA_CHECK(cudaMemcpyAsync(scoreMatrix_d, scoreMatrix_h.data(), (length1 + 1) * (length2 + 1) * sizeof(int), cudaMemcpyHostToDevice, stream));\n        CUDA_CHECK(cudaMemcpyAsync(maxScore_d, &maxScore_h, sizeof(int), cudaMemcpyHostToDevice, stream));\n\n        // Calculating hardware execution limit for concurrent blocks.\n        int maxBlocksPerGrid;\n        cudaOccupancyMaxActiveBlocksPerMultiprocessor(&maxBlocksPerGrid, k_smithWatermanKernel, BLOCK_SIZE, 0);\n        int numSMs;\n        cudaDeviceGetAttribute(&numSMs, cudaDevAttrMultiProcessorCount, 0);\n        int maxTotalBlocks = maxBlocksPerGrid * numSMs;\n        \n        // Determine the number of threads and blocks\n        dim3 blockSize(BLOCK_SIZE, 1, 1);\n        maxTotalBlocks = min(maxTotalBlocks, (length1 + length2 + BLOCK_SIZE - 1) / BLOCK_SIZE);\n        dim3 gridSize = dim3(maxTotalBlocks, 1, 1);\n        \n        //  Adding check for exceeding maximum grid dimensions\n        cudaDeviceProp props;\n        CUDA_CHECK(cudaGetDeviceProperties(&props, 0));\n        if (gridSize.x > props.maxGridSize[0] || gridSize.y > props.maxGridSize[1]) {\n            assert(false && \"Grid size exceeds device limits!\");\n        }\n\n        // Prepare kernel arguments for this test case.\n        void* args[] = {\n            (void*)&firstSequence_d,\n            (void*)&secondSequence_d,\n            (void*)&length1,\n            (void*)&length2,\n            (void*)&scoreMatrix_d,\n            (void*)&maxScore_d\n        };\n\n        // Launch the cooperative kernel for this test case.\n        CUDA_CHECK(cudaLaunchCooperativeKernel((const void*)k_smithWatermanKernel, gridSize, blockSize, args, 0, stream));\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n\n        // Copy the computed max score back to host.\n        CUDA_CHECK(cudaMemcpyAsync(&maxScore_h, maxScore_d, sizeof(int), cudaMemcpyDeviceToHost, stream));\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n\n        if(maxScore_h != testCases[testIndex].expected_score) {\n            std::vector<int> localDP((length1 + 1) * (length2 + 1), 0);\n            CUDA_CHECK(cudaMemcpyAsync(localDP.data(), scoreMatrix_d, (length1 + 1) * (length2 + 1) * sizeof(int), cudaMemcpyDeviceToHost, stream));\n            CUDA_CHECK(cudaStreamSynchronize(stream));\n            assert(maxScore_h == testCases[testIndex].expected_score);\n        }\n    }\n    \n    CUDA_CHECK(cudaFreeAsync(firstSequence_d, stream));\n    CUDA_CHECK(cudaFreeAsync(secondSequence_d, stream));\n    CUDA_CHECK(cudaFreeAsync(scoreMatrix_d, stream));\n    CUDA_CHECK(cudaFreeAsync(maxScore_d, stream));\n    CUDA_CHECK(cudaStreamDestroy(stream));\n}\n\n__global__ void k_smithWatermanKernel(char *firstSequence_d, char *secondSequence_d, int length1, int length2, int *scoreMatrix_d, int *maxScore_d) {\n", "test": "int main() {\n    launch();\n}\n", "example_test": "    @example_test\n", "cuda_toolkit": "12.2"}
{"task_id": "CUDA/112", "date": "2025-03-31", "prompt": "Write a CUDA kernel to solve a partial differential equation using red black Gauss-Seidel method. The kernel should utilize device memory to load and update the solution array for each iteration.\n\nThe signature of the function is __global__ void k_solveRedBlackGaussSeidel( float *srcFunction, float *slnFunction, int size, int numIterations) where srcFunction is a pointer to the array containing right-hand side function f(x,y), slnFunction is the pointer to the solution array, size is the length of the square grid, and numIterations specifies how many iterations the solver should run.\n\n>>> k_solveRedBlackGaussSeidel({1, 1, 1, 1}, {0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0}, 2, 4) -> ({0, 0, 0, 0, 0, -0.0551, -0.0553, 0, 0, -0.0553, -0.0551, 0, 0, 0, 0, 0})\n>>> k_solveRedBlackGaussSeidel({3, 4, 5, 3.5, 4.5, 5.5, 4, 5, 6}, {0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0}, 3, 5) -> ({0, 0, 0, 0, 0, 0, -0.1522, -0.2250, -0.1968, 0, 0, -0.2116, -0.3010, -0.2652, 0, 0, -0.1745, -0.2518, -0.2191, 0, 0, 0, 0, 0, 0})\n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_70", "ld_flags": "", "declaration": "#include <cstdio>\n#include <algorithm>\n#include <cmath>\n#include <cuda_runtime.h>\n#include <assert.h>\n#include <cooperative_groups.h>\n\nnamespace cg = cooperative_groups;\n\n#undef  NDEBUG\n // Tolerance for floating-point comparison\n#define TOLERANCE               (1e-4)\n// Number of threads per block\n#define BLOCK_SIZE              (16)\n// Number of elements allocated for device memory\n#define NUM_DEVICE_MEMORY_ELEM  (1024)\n#define CUDA_CHECK(call)                                        \\\ndo {                                                            \\\n        cudaError_t error = call;                               \\\n        if (error != cudaSuccess) {                             \\\n            fprintf(stderr, \"CUDA error at %s:%d - %s\\n\",       \\\n                    __FILE__, __LINE__,                         \\\n                    cudaGetErrorString(error));                 \\\n            exit(EXIT_FAILURE);                                 \\\n        }                                                       \\\n} while(0)\n\n__global__ void k_solveRedBlackGaussSeidel( float *srcFunction, float *slnFunction, int size, int numIterations);\n\nvoid launch() {\n    // Number of test cases\n    constexpr int TEST_CASE_COUNT = 8;\n    // Single dimension of the square input grid\n    constexpr int functionGridDim[TEST_CASE_COUNT] = {2, 3, 4, 3, 4, 3, 3, 4};\n    // Number of iterations\n    constexpr int numIterations[TEST_CASE_COUNT] = {4, 5, 3, 6, 4, 3, 5, 7};\n    \n    // Find the maximum function grid dimension\n    constexpr int MAX_FUNC_GRID_DIM = *std::max_element(functionGridDim, functionGridDim + TEST_CASE_COUNT);\n    // Find the maximum function grid size\n    constexpr int MAX_FUNC_GRID_SIZE = MAX_FUNC_GRID_DIM * MAX_FUNC_GRID_DIM;\n    // Extra rows/columns \n    constexpr int EXTRA_ROW_COLUMN = 2;\n\n    // Input source function for the testcases\n    float fXy_h[TEST_CASE_COUNT][MAX_FUNC_GRID_SIZE] =  {\n        {1, 1, 1, 1},\n        {3, 4, 5, 3.5, 4.5, 5.5, 4, 5, 6},\n        {3.0000, 3.0625, 3.2500, 3.5625, 4.0000, 3.1250, 3.1875, 3.3750, 3.6875, 4.1250, 3.5000, 3.5625, 3.7500, 4.0625, 4.5000, 4.1250},\n        {0, 0, 0, 0, 1, 0, 0, 0, 0},\n        {0.1353, 0.3305, 0.3305, 0.1353, 0.3305, 0.8045, 0.8045, 0.3305, 0.3305, 0.8045, 0.8045, 0.3305, 0.1353, 0.3305, 0.3305, 0.1353},\n        {0, 0, 0, 0, 0.6065, 0, 0, 0, 0},\n        {7, 7, 7, 7, 7, 7, 7, 7, 7},\n        {0, 0.33, 0.66, 1, 0.33, 0.66, 0.99, 1.33, 0.66, 0.99, 1.32, 1.66, 1, 1.33, 1.66, 2}\n    };\n\n    // Expected outputs\n    float expectedSolution[TEST_CASE_COUNT][MAX_FUNC_GRID_SIZE] = {\n        {-0.0551, -0.0553, -0.0553, -0.0551},\n        {-0.1522, -0.2250, -0.1968, -0.2116, -0.3010, -0.2652, -0.1745, -0.2518, -0.2191},\n        {-0.0773, -0.1115, -0.1033, -0.0884, -0.1242, -0.1428, -0.1585, -0.1076, -0.1167, -0.1752, -0.1527, -0.1244, -0.0976, -0.1236, -0.1378, -0.0947},\n        {-0.0038, -0.0077, -0.0038, -0.0077, -0.0232, -0.0077, -0.0038, -0.0077, -0.0038},\n        {-0.0086, -0.0165, -0.0156, -0.0091, -0.0165, -0.0287, -0.0302, -0.0156, -0.0156, -0.0302, -0.0287, -0.0165, -0.0091, -0.0156, -0.0165, -0.0086},\n        {-0.0018, -0.0041, -0.0018, -0.0041, -0.0130, -0.0041, -0.0018, -0.0041, -0.0018},\n        {-0.2888, -0.3708, -0.2888, -0.3708, -0.4683, -0.3708, -0.2888, -0.3708, -0.2888},\n        {-0.0136, -0.0284, -0.0363, -0.0318, -0.0284, -0.0505, -0.0625, -0.0509, -0.0363, -0.0625, -0.0728, -0.0599, -0.0318, -0.0509, -0.0599, -0.0493}\n    };\n\n    unsigned maxSolutionGridSize = std::pow(MAX_FUNC_GRID_DIM + EXTRA_ROW_COLUMN, 2);\n    \n    // Use a CUDA stream for asynchronous operations\n    cudaStream_t stream;\n    CUDA_CHECK(cudaStreamCreate(&stream));\n\n    // Initialize results on the host\n    float *solution_h;\n    solution_h = (float*)malloc(maxSolutionGridSize * sizeof(float));\n    // Pointers for device memory (GPU)\n    float *pSolutionArrayU_d, *fXy_d;\n\n    CUDA_CHECK(cudaMallocAsync(&fXy_d, MAX_FUNC_GRID_SIZE * sizeof(float), stream));\n    CUDA_CHECK(cudaMallocAsync(&pSolutionArrayU_d, maxSolutionGridSize * sizeof(float), stream));\n\n    // Loop to execute each test case\n    for (int testCaseId = 0; testCaseId < TEST_CASE_COUNT; testCaseId++) {\n        unsigned inputSlnGridSize = std::pow(functionGridDim[testCaseId] + EXTRA_ROW_COLUMN, 2);\n        // Initialize solution array with zeros\n        for (size_t i = 0; i < inputSlnGridSize; ++i) {\n            solution_h[i] = 0.0f;\n        }\n\n        // Copying data into device memory\n        CUDA_CHECK(cudaMemcpyAsync(pSolutionArrayU_d, solution_h, inputSlnGridSize * sizeof(float), cudaMemcpyHostToDevice, stream));\n        CUDA_CHECK(cudaMemcpyAsync(fXy_d, &fXy_h[testCaseId][0], functionGridDim[testCaseId] * functionGridDim[testCaseId] * sizeof(float), cudaMemcpyHostToDevice, stream));\n\n        // Determine the number of threads and blocks\n        unsigned totalElemPerRowCol = functionGridDim[testCaseId] + EXTRA_ROW_COLUMN;\n        dim3 blockSize(BLOCK_SIZE, BLOCK_SIZE, 1);\n        dim3 gridSize((totalElemPerRowCol + BLOCK_SIZE - 1) / BLOCK_SIZE, (totalElemPerRowCol + BLOCK_SIZE - 1) / BLOCK_SIZE);\n        \n        //  Adding check for exceeding maximum grid dimensions\n        cudaDeviceProp props;\n        CUDA_CHECK(cudaGetDeviceProperties(&props, 0));\n        if (gridSize.x > props.maxGridSize[0] || gridSize.y > props.maxGridSize[1]) {\n            assert(false && \"Grid size exceeds device limits!\");\n        }\n        \n        // Launch the kernel\n        // Grid:  ((totalElemPerRowCol + BLOCK_SIZE - 1) / BLOCK_SIZE, (totalElemPerRowCol + BLOCK_SIZE - 1) / BLOCK_SIZE)\n        // Block: (BLOCK_SIZE, BLOCK_SIZE, 1)\n        void *args[] = {&fXy_d, &pSolutionArrayU_d, (void*) &functionGridDim[testCaseId], (void*) &numIterations[testCaseId]};\n        CUDA_CHECK(cudaLaunchCooperativeKernel((void*)k_solveRedBlackGaussSeidel, gridSize, blockSize, args, 0, stream));\n\n        // Copy the output array pSolutionArrayU_d from the device (GPU) to the host (CPU)\n        CUDA_CHECK(cudaMemcpyAsync(solution_h, pSolutionArrayU_d, inputSlnGridSize * sizeof(float), cudaMemcpyDeviceToHost, stream));\n\n        // Check tasks in the stream has completed\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n\n        // Verify whether the computed solution array matches the expected result or not\n        unsigned resultIdx, referenceIdx; \n        // Skipping first and last element of each row\n        for (int i = 1; i < totalElemPerRowCol - 1; i++) {\n            // Skipping first and last element of each row \n            for (int j = 1; j < totalElemPerRowCol - 1; j++){\n                resultIdx = i*totalElemPerRowCol + j;\n                referenceIdx = (i-1)*(totalElemPerRowCol-2) + (j-1);\n                assert(fabs(solution_h[resultIdx] - expectedSolution[testCaseId][referenceIdx]) < TOLERANCE);\n            }\n        }\n    }\n    \n    // Free host memories\n    free(solution_h);\n\n    // Free stream\n    CUDA_CHECK(cudaStreamDestroy(stream));\n}\n\n__global__ void k_solveRedBlackGaussSeidel( float *srcFunction, float *slnFunction, int size, int numIterations) {\n", "test": "int main() {\n    launch();\n}\n", "example_test": "    @example_test\n", "cuda_toolkit": "12.2"}
{"task_id": "CUDA/113", "date": "2025-03-31", "prompt": "Write a CUDA kernel to sort the elements in the array using merge sort method. Implement the kernel using two device functions, the first function should sort the elements within the blocks while the second function should merge all the sorted blocks in to a single sorted array.\n\nThe signature of the kernel is __global__ void k_mergeSort(float *input_d, float *sortedBlocks_d, float *output_d, int numElements), where input_d is the array which contains the elements to be sorted, sortedBlocks_d is the array which contains the sorted elements per block, output_d is the output array which contains the final sorted array elements of size numElements and numElements is the number of elements to be sorted.\n\nThe signature of the First device function is __device__ void d_mergeSortWithinBlock(float *input_d, float *sortedBlocks_d, int numElements), where input_d is the array which contains the elements to be sorted, sortedBlocks_d is the array which contains the sorted elements per block and numElements is the number of elements to be sorted. \n\nThe signature of the second device function is __device__ void d_mergeSortAcrossBlocks(float *sortedBlocks_d, float *output_d, int numElements), where sortedBlocks_d is the array which contains the intermediate sorted elements per block, output_d is the output array which contains the final sorted array elements of size numElements and numElements is the number of elements to be sorted. \n\n>>> k_mergeSort({25.0, 57.0, 2.0, 38.0, 49.0, 11.0, 79.0, 88.0, 5.0, 3.0}, sortedBlocks_d, output_d, 10) -> output_d: {2.0, 3.0, 5.0, 11.0, 25.0, 38.0, 49.0, 57.0, 79.0, 88.0}\n>>> d_mergeSortWithinBlock({25.0, 57.0, 2.0, 38.0, 49.0, 11.0, 79.0, 88.0, 5.0, 3.0}, sortedBlocks_d, 10) -> sortedBlocks_d: {2.0, 25.0, 38.0, 57.0, 11.0, 49.0, 79.0, 88.0, 3.0, 5.0}\n>>> d_mergeSortAcrossBlocks({2.0, 25.0, 38.0, 57.0, 11.0, 49.0, 79.0, 88.0, 3.0, 5.0}, output_d, 10) -> output_d: {2.0, 3.0, 5.0, 11.0, 25.0, 38.0, 49.0, 57.0, 79.0, 88.0}\n>>> k_mergeSort({17.0, 1.0, 15.0, 3.0, 18.0, 2.0, 11.0, 12.0}, sortedBlocks_d, output_d, 8) -> output_d: {1.0, 2.0, 3.0, 11.0, 12.0, 15.0, 17.0, 18.0}\n>>> d_mergeSortWithinBlock({17.0, 1.0, 15.0, 3.0, 18.0, 2.0, 11.0, 12.0}, sortedBlocks_d, 8) -> sortedBlocks_d: {1.0, 3.0, 15.0, 17.0, 2.0, 11.0, 12.0, 18.0}\n>>> d_mergeSortAcrossBlocks({1.0, 3.0, 15.0, 17.0, 2.0, 11.0, 12.0, 18.0}, output_d, 8) -> output_d: {1.0, 2.0, 3.0, 11.0, 12.0, 15.0, 17.0, 18.0}\n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_70", "ld_flags": "", "declaration": "#include <cstdio>\n#include <math.h>\n#include <algorithm>\n#include <assert.h>\n#include <float.h>\n#include <cuda_runtime.h>\n#include <cooperative_groups.h>\n#undef NDEBUG\n\n#define CUDA_CHECK(call)                                                           \\\ndo {                                                                               \\\n        cudaError_t error = call;                                                  \\\n        if (error != cudaSuccess) {                                                \\\n            fprintf(stderr, \"CUDA Error: %s at %s:%d\\n\", cudaGetErrorString(error),\\\n                    __FILE__, __LINE__);                                           \\\n            exit(error);                                                           \\\n        }                                                                          \\\n} while (0)\n\n\n// Define the maximum number of threads per block (adjust as needed)\n#define MAX_THREADS 1024\n#define TOLERANCE   1e-2\n#define BLOCKSIZE   4\n#define MAXVALUE    9999\n\n// This device function divides the input array in to n blocks \n// and sorts the elements with in each blocks using merge sort method. This kernel uses shared memory to store the temporary sorted blocks\n__device__ void d_mergeSortWithinBlock(float *input_d, float *sortedBlocks_d, int numElements);\n\n// This device function merges the sorted blocks in to a single sorted array.\n__device__ void d_mergeSortAcrossBlocks(float *sortedBlocks_d, float *output_d, int numElements);\n\n// This kernel will sorts the elements using merge sort technique by calling two device functions d_mergeSortWithinBlock, d_mergeSortAcrossBlocks\n__global__ void k_mergeSort(float *input_d, float *sortedBlocks_d, float *output_d, int numElements);\n\nvoid launch() {\n    const int NUMTESTCASES = 7;\n    int numElements[NUMTESTCASES] = {6, 8, 9, 10, 11, 15, 7};       // Number of input elements in the list\n    int maxNumElements = *std::max_element(numElements, numElements + NUMTESTCASES);\n    // Host input and output arrays\n    float input_h[NUMTESTCASES][maxNumElements] ={  {6.0, 5.0, 4.0, 3.0, 2.0, 1.0},\n                                                    {17.0, 1.0, 15.0, 3.0, 18.0, 2.0, 11.0, 12.0},\n                                                    {5.0, 8.0, 2.0, 4.0, 10.0, 18.0, 9.0, 25.0, 1.0},\n                                                    {25.0, 57.0, 2.0, 38.0, 49.0, 11.0, 79.0, 88.0, 5.0, 3.0},\n                                                    {12.0, 32.0, 2.5, 1.3, 55.7, 38.2, 7.0, 15.5, 1.5, 22.5, 3.8},\n                                                    {125, 133, 145, 5.8, 38.3, 55.7, 125, 133, 77.5, 33.4, 55.7, 88.6, 77.5, 4.2, 2.0},\n                                                    {1.0, 2.0, 3.0, 1.0, 2.0, 3.0, 4.0}};\n    float expectedOutput_h[NUMTESTCASES][maxNumElements] = {{1.0, 2.0, 3.0, 4.0, 5.0, 6.0},\n                                                            {1.0, 2.0, 3.0, 11.0, 12.0, 15.0, 17.0, 18.0},\n                                                            {1.0, 2.0, 4.0, 5.0, 8.0, 9.0, 10.0, 18.0, 25.0},\n                                                            {2.0, 3.0, 5.0, 11.0, 25.0, 38.0, 49.0, 57.0, 79.0, 88.0},\n                                                            {1.3, 1.5, 2.5, 3.8, 7.0, 12.0, 15.5, 22.5, 32.0, 38.2, 55.7},\n                                                            {2.0, 4.2, 5.8, 33.4, 38.3, 55.7, 55.7, 77.5, 77.5, 88.6, 125, 125, 133, 133, 145},\n                                                            {1.0, 1.0, 2.0, 2.0, 3.0, 3.0, 4.0}};\n    float *output_h = (float *) calloc(maxNumElements, sizeof(float)); \n    \n    // Device input and output pointers\n    float *input_d;\n    float *output_d;\n    float *sortedBlocks_d;\n\n    cudaStream_t stream;\n    CUDA_CHECK(cudaStreamCreate(&stream));\n    \n    // Allocate device memory\n    CUDA_CHECK(cudaMallocAsync((void**)&input_d, maxNumElements * sizeof(float), stream));\n    CUDA_CHECK(cudaMallocAsync((void**)&output_d, maxNumElements * sizeof(float), stream));\n    CUDA_CHECK(cudaMallocAsync((void**)&sortedBlocks_d, maxNumElements * sizeof(float), stream));\n\n    // Define block and grid sizes\n    int threadsPerBlock = BLOCKSIZE;\n    \n    // Blocks: (BLOCKSIZE, 1, 1)\n    dim3 blockSize(threadsPerBlock, 1, 1);\n    \n    // Grid: (ceil(maxNumElements / BLOCKSIZE), 1, 1)\n    dim3 gridSize(ceil(maxNumElements + blockSize.x - 1) / blockSize.x, 1, 1);\n\n    for(int tc = 0; tc < NUMTESTCASES; tc++){\n        // Copy input data to device\n        CUDA_CHECK(cudaMemcpyAsync(input_d, \n                                   input_h[tc], \n                                   numElements[tc] * sizeof(float), \n                                   cudaMemcpyHostToDevice, \n                                   stream));\n\n        // Launch the mergeSort kernel to sort the elements with in the block\n        void *args[] = {&input_d, &sortedBlocks_d, &output_d, &numElements[tc]};\n        CUDA_CHECK(cudaLaunchCooperativeKernel((void*)k_mergeSort, gridSize, blockSize, args, BLOCKSIZE * sizeof(float), stream));\n        \n        // Copy the output back to host\n        CUDA_CHECK(cudaMemcpyAsync(output_h, \n                                   output_d, \n                                   numElements[tc] * sizeof(float), \n                                   cudaMemcpyDeviceToHost, \n                                   stream));\n\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n\n        //validate the results\n        for(int i = 0; i < numElements[tc]; i++) {\n            assert(fabs(output_h[i] - expectedOutput_h[tc][i]) < TOLERANCE);\n        }\n    }\n\n    // Free host and device memory\n    free(output_h);    \n    CUDA_CHECK(cudaFreeAsync(input_d, stream));\n    CUDA_CHECK(cudaFreeAsync(output_d, stream));\n    CUDA_CHECK(cudaStreamDestroy(stream));\n}\n\n__device__ void d_mergeSortWithinBlock(float *input_d, float *sortedBlocks_d, int numElements) {\n    // Each block handles a portion of the array\n    int threadid = blockIdx.x * blockDim.x + threadIdx.x;\n    int blockSize = blockDim.x;\n\n    // Create shared memory for the block to work on\n    extern __shared__ float sharedData[];\n\n    // If the thread id is within bounds, load data into shared memory\n    if (threadid < numElements) {\n        sharedData[threadIdx.x] = input_d[threadid];\n    } else {\n        sharedData[threadIdx.x] = MAXVALUE;  // Fill with maximum value if out of bounds\n    }\n\n    // Synchronize threads in the block\n    __syncthreads();\n\n    // Perform the merge sort using shared memory\n    for (int divLen = 1; divLen <= blockSize / 2; divLen *= 2) {\n        // Thread ID within the block\n        int leftIdx = threadIdx.x * 2 * divLen + blockIdx.x * blockDim.x;\n        int blockStride = blockSize + blockIdx.x * blockDim.x;\n        int rightIdx = leftIdx + divLen;\n        int endIdx = leftIdx + 2 * divLen;\n\n        // Perform a merge of the two parts\n        if (leftIdx < blockStride) {\n            int i = leftIdx;\n            int j = rightIdx;\n\n            // Merge the elements\n            for (int k = leftIdx; k < endIdx; k++) {\n                float iValue = sharedData[i % blockSize];\n                float jValue = sharedData[j % blockSize];\n\n                // Merge in sorted order\n                if (i < rightIdx && (j >= endIdx || iValue <= jValue)) {\n                    sortedBlocks_d[k] = iValue;\n                    i++;\n                } else {\n                    sortedBlocks_d[k] = jValue;\n                    j++;\n                }\n            }\n        }\n\n        // Synchronize threads after each merge step\n        __syncthreads();\n\n        // Copy the sorted data from shared memory back to the output array\n        if (threadid < numElements) {\n            sharedData[threadIdx.x] = sortedBlocks_d[threadid];\n        }\n    }\n}\n\n__device__ void d_mergeSortAcrossBlocks(float *sortedBlocks_d, float *output_d, int numElements) {\n    auto grid = cooperative_groups::this_grid();\n    \n    //load the sortedBlocks in to the output\n    for(int idx = blockIdx.x * blockDim.x + threadIdx.x; idx < numElements; idx += gridDim.x * blockDim.x){\n        output_d[idx] = sortedBlocks_d[idx];\n    }\n    \n    // iterate each sorted block index from sortedBlocks_d and merge in to mergeSortedBlocks \n    for(int blockStride = blockDim.x; blockStride <= numElements; blockStride *= 2){\n        // calculate the left block start and end index.\n        int lblockStartIdx = 2 * blockIdx.x * blockStride;\n        int lblockEndIdx = min(numElements, blockStride + 2 * blockIdx.x * blockStride);\n        // calculate the right block start and end index.  \n        int rblockStartIdx = min(numElements, blockStride + 2 * blockIdx.x * blockStride);\n        int rblockEndIdx = min(numElements, blockStride * 2 + 2 * blockIdx.x * blockStride);\n        // initialize the left block and right block iterators \n        int i = lblockStartIdx, j = rblockStartIdx;\n        for(int k = lblockStartIdx; k < rblockEndIdx; k++){\n            // compare and merge the left blocks and right blocks data in to mergeSortedBlocks\n            if( i < lblockEndIdx && j < rblockEndIdx){\n                float lblockElement = output_d[i];\n                float rblockElement = output_d[j];\n                if(lblockElement < rblockElement){\n                    sortedBlocks_d[k] = lblockElement;\n                    i += 1;\n                } else {\n                    sortedBlocks_d[k] = rblockElement;\n                    j += 1;\n                }\n            } else if ( i < lblockEndIdx) {\n                float lblockElement = output_d[i]; \n                sortedBlocks_d[k] = lblockElement;\n                i += 1;\n            } else {\n                float rblockElement = output_d[j];\n                sortedBlocks_d[k] = rblockElement;\n                j += 1;\n            }\n        }\n\n        // synchronize all the threads in the grid after the merge of sorted block.\n        grid.sync();\n        \n        // copy the mergeSortedBlocks in to output array.\n        for(int idx = blockIdx.x * blockDim.x + threadIdx.x; idx < numElements; idx += gridDim.x * blockDim.x){\n            output_d[idx] = sortedBlocks_d[idx];\n        }\n        // synchronize all the threads in the grid after the copy of sortedblocks to output.\n        grid.sync();\n    }\n}\n\n// This module implements the merge sort by calling two device functions\n__global__ void k_mergeSort(float *input_d, float *sortedBlocks_d, float *output_d, int numElements){\n", "test": "int main() {\n    launch();\n}\n", "example_test": "    @example_test\n", "cuda_toolkit": "12.2"}
{"task_id": "CUDA/114", "date": "2025-03-31", "prompt": "Write a cuda kernel to perform erosion operation over a binary image. Erosion operation needs to be performed for the given number of iterations. Outputs of each iteration need to be stored on device memory and reused across iterations. \n\nThe signature of the function is __global__ void k_imageErosion(const unsigned char *inputImage_d, const unsigned char *structuringElement_d, unsigned char *outputImage_d, unsigned char *outputImageIntermediateBuffer_d, int inputImageWidth, int inputImageHeight, int structuringElementWidth, int structuringElementHeight, int numberOfErosionIterations), where inputImage_d is a pointer to input image, structuringElement_d is a pointer to structuring element, outputImage_d is a pointer to output image, outputImageIntermediateBuffer_d is a pointer to the additional buffer that is used to store output image. The parameters inputImageWidth and inputImageHeight are the width and height of the input image, structuringElementWidth and structuringElementHeight are the width and height of the structuring element, numberOfErosionIterations specifies the number of iterations of erosion to be performed.\n\n>>> k_imageErosion({1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0},  {1,1,1,1,1,1,1,1,1}, outputImage_d, 5, 5, 3, 3) -> outputImage_d: ({1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0})\n>>> k_imageErosion({0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0},  {1,1,1,1,1,1,1,1,1}, outputImage_d, 5, 5, 3, 3) -> outputImage_d: ({0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0})\n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_70", "ld_flags": "", "declaration": "#include <cstdio>\n#include <limits.h>\n#include <assert.h>\n#include <cuda_runtime.h>\n#include <cooperative_groups.h>\nusing namespace cooperative_groups;\n\n#define MIN_IMAGE_ROW_INDEX 0 \n#define MIN_IMAGE_COLUMN_INDEX 0\n#define MIN_IMAGE_PIXEL_INDEX 0\n#define FOREGROUND_PIXEL 1\n#define FALSE 0\n#define SECOND_ITERATION 1\n\n#define CUDA_CHECK(call)                                        \\\ndo {                                                            \\\n        cudaError_t error = call;                               \\\n        if (error != cudaSuccess) {                             \\\n            fprintf(stderr, \"CUDA error at %s:%d - %s\\n\",       \\\n                    __FILE__, __LINE__,                         \\\n                    cudaGetErrorString(error));                 \\\n            exit(EXIT_FAILURE);                                 \\\n        }                                                       \\\n} while(0)\n\n__global__ void k_imageErosion(const unsigned char *inputImage_d, const unsigned char *structuringElement_d, unsigned char *outputImage_d, unsigned char *outputImageIntermediateBuffer_d, int inputImageWidth, int inputImageHeight, int structuringElementWidth, int structuringElementHeight, int numberOfErosionIterations);\n\nvoid launch() {\n\n    //Initialize Constants\n    const int TEST_CASE_COUNT = 7;\n    const int MAX_INPUT_IMAGE_WIDTH = 9;\n    const int MAX_INPUT_IMAGE_HEIGHT = 9;\n    const int MAX_IMAGE_DIMENSIONS = 2;\n    const int IMAGE_HEIGHT_INDEX = 0;\n    const int IMAGE_WIDTH_INDEX = 1;\n    const int MIN_NUMBER_OF_THREADS_PER_BLOCK = 32;\n    const int MAX_NUMBER_OF_BLOCKS = 4;\n    \n    //Use CUDA Streams for Asynchronous Execution\n    cudaStream_t stream;\n    CUDA_CHECK(cudaStreamCreate(&stream));\n\n    //Allocate Device Memory\n    unsigned char *inputImage_d;\n    unsigned char *structuringElement_d;\n    unsigned char *outputImage_d;\n    unsigned char *outputImageIntermediateBuffer_d;\n    \n    CUDA_CHECK(cudaMallocAsync((void**)&inputImage_d, MAX_INPUT_IMAGE_WIDTH * MAX_INPUT_IMAGE_HEIGHT * sizeof(unsigned char), stream));\n    CUDA_CHECK(cudaMallocAsync((void**)&structuringElement_d, MAX_INPUT_IMAGE_WIDTH * MAX_INPUT_IMAGE_HEIGHT * sizeof(unsigned char), stream));\n    CUDA_CHECK(cudaMallocAsync((void**)&outputImage_d, MAX_INPUT_IMAGE_WIDTH * MAX_INPUT_IMAGE_HEIGHT * sizeof(unsigned char), stream));\n    CUDA_CHECK(cudaMallocAsync((void**)&outputImageIntermediateBuffer_d, MAX_INPUT_IMAGE_WIDTH * MAX_INPUT_IMAGE_HEIGHT * sizeof(unsigned char), stream));\n   \n    //Initialise Test Data\n    //Test Data Dimensions\n    int inputImageWidthHeight[TEST_CASE_COUNT][MAX_IMAGE_DIMENSIONS] = {\n      //Test Case - 1, {rows(height), columns(width)} \n      {4, 5},\n      //Test Case - 2\n      {5, 6},\n      //Test Case - 3\n      {6, 7},\n      //Test Case - 4\n      {7, 8},\n      //Test Case - 5\n      {8, 8},\n      //Test Case - 6\n      {9, 7},\n      //Test Case - 7\n      {9, 9}\n    };\n\n    int structuringElementWidthHeight[MAX_IMAGE_DIMENSIONS] = {3, 3};\n\n    //Input Data For Test\n    unsigned char inputImage_h[TEST_CASE_COUNT][MAX_INPUT_IMAGE_WIDTH * MAX_INPUT_IMAGE_HEIGHT] = {\n      //Test Case - 1\n      {1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1},\n      //Test Case - 2\n      {0, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 0, 0},\n      //Test Case - 3 \n      {0, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 0, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1},\n      //Test Case - 4 \n      {1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1,\n       0, 1, 1, 1, 1, 1, 0, 1},\n      //Test Case - 5 \n      {1, 1, 1, 1, 1, 1, 1, 0,\n       1, 1, 1, 1, 1, 1, 0, 1,\n       1, 1, 1, 0, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 0,\n       0, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 0, 0, 1, 1, 0, 1},\n      //Test Case - 6 \n      {1, 1, 1, 1, 1, 1, 1,\n       1, 0, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 0, 1, 1,\n       1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1,\n       1, 0, 1, 0, 0, 1, 1,\n       1, 1, 1, 1, 1, 1, 1},\n      //Test Case - 7 \n      {1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 0,\n       1, 1, 1, 1, 0, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 0, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 0, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1}\n    };\n\n    //Expected Output for Test\n    unsigned char expectedOutputImage_h[TEST_CASE_COUNT][MAX_INPUT_IMAGE_WIDTH * MAX_INPUT_IMAGE_HEIGHT] = {\n      //Test Case - 1 \n      {1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1},\n      //Test Case - 2 \n      {0, 0, 0, 1, 1, 1, \n       0, 0, 0, 1, 1, 1, \n       0, 0, 0, 0, 0, 0, \n       1, 1, 0, 0, 0, 0,\n       1, 1, 0, 0, 0, 0},\n      //Test Case - 3 \n      {0, 0, 0, 1, 1, 1, 1, \n       0, 0, 0, 0, 0, 0, 1, \n       0, 0, 0, 0, 0, 0, 1, \n       1, 0, 0, 0, 0, 0, 1, \n       1, 0, 0, 0, 0, 0, 1, \n       1, 0, 0, 0, 0, 0, 1},\n      //Test Case - 4 \n      {1, 1, 1, 1, 1, 1, 1, 1, \n       1, 1, 1, 1, 1, 1, 1, 1, \n       1, 1, 1, 1, 1, 1, 1, 1, \n       1, 1, 1, 1, 1, 1, 1, 1, \n       0, 0, 0, 1, 0, 0, 0, 0, \n       0, 0, 0, 1, 0, 0, 0, 0, \n       0, 0, 0, 1, 0, 0, 0, 0},\n      //Test Case - 5 \n      {1, 0, 0, 0, 0, 0, 0, 0, \n       1, 0, 0, 0, 0, 0, 0, 0, \n       1, 0, 0, 0, 0, 0, 0, 0, \n       0, 0, 0, 0, 0, 0, 0, 0, \n       0, 0, 0, 0, 0, 0, 0, 0, \n       0, 0, 0, 0, 0, 0, 0, 0, \n       0, 0, 0, 0, 0, 0, 0, 0, \n       0, 0, 0, 0, 0, 0, 0, 0},\n      //Test Case - 6 \n      {0, 0, 0, 0, 1, 1, 1, \n       0, 0, 0, 0, 0, 0, 0, \n       0, 0, 0, 0, 0, 0, 0, \n       0, 0, 0, 0, 0, 0, 0, \n       1, 1, 0, 0, 0, 0, 0, \n       0, 0, 0, 0, 0, 0, 0, \n       0, 0, 0, 0, 0, 0, 0, \n       0, 0, 0, 0, 0, 0, 0, \n       0, 0, 0, 0, 0, 0, 0},\n      //Test Case - 7\n      {1, 0, 0, 0, 0, 0, 0, 0, 0, \n       0, 0, 0, 0, 0, 0, 0, 0, 0, \n       0, 0, 0, 0, 0, 0, 0, 0, 0, \n       0, 0, 0, 0, 0, 0, 0, 0, 0, \n       0, 0, 0, 0, 0, 0, 0, 0, 0, \n       0, 0, 0, 0, 0, 0, 0, 0, 1, \n       0, 0, 0, 0, 0, 0, 1, 1, 1, \n       0, 0, 0, 0, 0, 0, 1, 1, 1, \n       0, 0, 0, 0, 0, 0, 1, 1, 1} \n    };\n\n    //Structuring Element\n    unsigned char structuringElement_h[MAX_INPUT_IMAGE_HEIGHT * MAX_INPUT_IMAGE_WIDTH] = {1, 1, 1, 1, 1, 1, 1, 1, 1};\n\n    \n    //Erosion Iterations\n    int erosionIterations[TEST_CASE_COUNT] = {1, 2, 2, 2, 2, 2, 3}; \n\n    //Output Image\n    unsigned char outputImage_h[MAX_INPUT_IMAGE_WIDTH * MAX_INPUT_IMAGE_HEIGHT];\n\n    //Execute Test Cases\n    for (int testCase = 0; testCase < TEST_CASE_COUNT; testCase++){\n      int inputImageHeight = inputImageWidthHeight[testCase][IMAGE_HEIGHT_INDEX];  \n      int inputImageWidth = inputImageWidthHeight[testCase][IMAGE_WIDTH_INDEX];\n      int structuringElementHeight = structuringElementWidthHeight[IMAGE_HEIGHT_INDEX];\n      int structuringElementWidth = structuringElementWidthHeight[IMAGE_WIDTH_INDEX];\n      int numberOfErosionIterations = erosionIterations[testCase];\n      \n      //copy data from host to device\n      CUDA_CHECK(cudaMemcpyAsync(inputImage_d, inputImage_h[testCase], inputImageWidth * inputImageHeight * sizeof(unsigned char), cudaMemcpyHostToDevice, stream));\n      CUDA_CHECK(cudaMemcpyAsync(structuringElement_d, structuringElement_h, structuringElementWidth * structuringElementHeight * sizeof(unsigned char), cudaMemcpyHostToDevice, stream));\n      \n      //Set Kernel Configuration\n      int numThreadsPerBlock = MIN_NUMBER_OF_THREADS_PER_BLOCK;\n      if( ceil((float)(inputImageWidth * inputImageHeight) / numThreadsPerBlock) > MAX_NUMBER_OF_BLOCKS){\n          numThreadsPerBlock = ceil((float)(inputImageWidth * inputImageHeight) / MAX_NUMBER_OF_BLOCKS) ;\n      }\n\n      int numBlocks = ceil((float)(inputImageWidth * inputImageHeight) / numThreadsPerBlock);\n      dim3 block(numThreadsPerBlock, 1, 1);\n      dim3 grid(numBlocks, 1, 1);\n      \n      //Launch Kernel\n      // Grid:  ((inputImageWidth * inputImageHeight) / numThreadsPerBlock, 1, 1)\n      // Block: (32, 1, 1)\n      void *args[] = {&inputImage_d, &structuringElement_d, &outputImage_d, &outputImageIntermediateBuffer_d, &inputImageWidth, &inputImageHeight, &structuringElementWidth, &structuringElementHeight, &numberOfErosionIterations};\n      CUDA_CHECK(cudaLaunchCooperativeKernel((void*)k_imageErosion, grid, block, args, sizeof(unsigned char), stream));\n      \n      //Copy Data from device to host\n      CUDA_CHECK(cudaMemcpyAsync(outputImage_h, outputImage_d, inputImageWidth * inputImageHeight * sizeof(unsigned char), cudaMemcpyDeviceToHost, stream));\n      \n      //Sycnhronize tasks in the stream\n      CUDA_CHECK(cudaStreamSynchronize(stream));\n      \n      //Assert device output and expected output\n      for(int rowIndex = MIN_IMAGE_ROW_INDEX; rowIndex < inputImageHeight; rowIndex++) {\n        for(int columnIndex = MIN_IMAGE_COLUMN_INDEX; columnIndex < inputImageWidth; columnIndex++) {\n            int pixelIndex = rowIndex * inputImageWidth + columnIndex;\n            assert(outputImage_h[pixelIndex] == expectedOutputImage_h[testCase][pixelIndex]);\n        }\n      }\n    }\n    \n    //Deallocate Device Memory\n    CUDA_CHECK(cudaFreeAsync(inputImage_d, stream));\n    CUDA_CHECK(cudaFreeAsync(structuringElement_d, stream));\n    CUDA_CHECK(cudaFreeAsync(outputImage_d, stream));\n    CUDA_CHECK(cudaFreeAsync(outputImageIntermediateBuffer_d, stream));\n    CUDA_CHECK(cudaStreamDestroy(stream));\n}\n\n__global__ void k_imageErosion(const unsigned char *inputImage_d, const unsigned char *structuringElement_d, unsigned char *outputImage_d, unsigned char *outputImageIntermediateBuffer_d, int inputImageWidth, int inputImageHeight, int structuringElementWidth, int structuringElementHeight, int numberOfErosionIterations) {\n", "test": "int main() {\n    launch();\n}\n", "example_test": "    @example_test\n", "cuda_toolkit": "12.2"}
{"task_id": "CUDA/115", "date": "2025-03-31", "prompt": "Create a CUDA kernel to simulate 2D wave propagation using the finite-difference method while utilizing device memory to access all intermediate states of the data. Implement reflective boundary conditions.\n\nThe signature of the CUDA kernel is __global__ void k_calculateWave2D(float *previousDisplacement_d, float *currentDisplacement_d, float *depth_d, float *previousTmp_d, float *currentTmp_d), where previousDisplacement_d is an array of previous time point states of the displacements, currentDisplacement_d is an array of current time point states of the displacements, depth_d is an array of depth values of each point that affect the speed of waves, previousTmp_d is an array for temporary storage, and currentTmp_d is another array for temporary storage.\n\n>>> k_calculateWave2D({\n    0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f,\n    0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f,\n    0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f,\n    0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f,\n    0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f,\n    0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.800000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f,\n    0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f,\n    0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f,\n    0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f\n},\n{\n    0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f,\n    0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f,\n    0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f,\n    0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f,\n    0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f,\n    0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 1.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f,\n    0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f,\n    0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f,\n    0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f\n},\n{\n    1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f,\n    1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f,\n    1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f,\n    1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f,\n    1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f,\n    1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f,\n    1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f,\n    1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f,\n    1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f\n}) ->  currentDisplacement_d: {\n    0.000000f, 0.000000f, 0.000000f, 0.000011f, 0.000149f, 0.000835f, 0.000149f, 0.000011f, 0.000000f, 0.000000f, 0.000000f,\n    0.000000f, 0.000000f, 0.000009f, 0.000186f, 0.002062f, 0.009411f, 0.002062f, 0.000186f, 0.000009f, 0.000000f, 0.000000f,\n    0.000000f, 0.000009f, 0.000247f, 0.004107f, 0.036926f, 0.129077f, 0.036926f, 0.004107f, 0.000247f, 0.000009f, 0.000000f,\n    0.000011f, 0.000186f, 0.004107f, 0.055204f, 0.376970f, 0.893490f, 0.376969f, 0.055204f, 0.004107f, 0.000186f, 0.000011f,\n    0.000149f, 0.002062f, 0.036926f, 0.376970f, 1.713494f, 1.884681f, 1.713494f, 0.376970f, 0.036926f, 0.002062f, 0.000149f,\n    0.000835f, 0.009411f, 0.129077f, 0.893492f, 1.884684f, -1.106843f, 1.884684f, 0.893492f, 0.129077f, 0.009411f, 0.000835f,\n    0.000149f, 0.002062f, 0.036926f, 0.376976f, 1.713569f, 1.885096f, 1.713569f, 0.376976f, 0.036926f, 0.002062f, 0.000149f,\n    0.000011f, 0.000186f, 0.004116f, 0.055390f, 0.379030f, 0.902888f, 0.379030f, 0.055390f, 0.004116f, 0.000186f, 0.000011f,\n    0.000001f, 0.000019f, 0.000495f, 0.008213f, 0.073852f, 0.258153f, 0.073852f, 0.008213f, 0.000495f, 0.000019f, 0.000001f\n}\n\n>>> k_calculateWave2D({\n    0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 1.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f,\n    0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 1.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f,\n    0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 1.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f,\n    0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 1.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f,\n    0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 1.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f,\n    0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 1.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f,\n    0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 1.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f,\n    0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 1.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f,\n    0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 1.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f\n},\n{\n    0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 1.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f,\n    0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 1.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f,\n    0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 1.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f,\n    0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 1.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f,\n    0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 1.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f,\n    0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 1.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f,\n    0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 1.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f,\n    0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 1.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f,\n    0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 1.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f\n},\n{\n    1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f,\n    1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f,\n    1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f,\n    1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f,\n    1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f,\n    1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f,\n    1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f,\n    1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f,\n    1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f\n}) ->  currentDisplacement_d: {\n    0.000407f, 0.004175f, 0.050254f, 0.284142f, 0.359115f, -0.395784f, 0.359115f, 0.284143f, 0.050254f, 0.004175f, 0.000407f,\n    0.000407f, 0.004175f, 0.050254f, 0.284142f, 0.359115f, -0.395784f, 0.359115f, 0.284143f, 0.050254f, 0.004175f, 0.000407f,\n    0.000407f, 0.004175f, 0.050254f, 0.284142f, 0.359115f, -0.395784f, 0.359115f, 0.284143f, 0.050254f, 0.004175f, 0.000407f,\n    0.000407f, 0.004175f, 0.050254f, 0.284142f, 0.359115f, -0.395784f, 0.359115f, 0.284143f, 0.050254f, 0.004175f, 0.000407f,\n    0.000407f, 0.004175f, 0.050254f, 0.284142f, 0.359115f, -0.395784f, 0.359115f, 0.284143f, 0.050254f, 0.004175f, 0.000407f,\n    0.000407f, 0.004175f, 0.050254f, 0.284142f, 0.359115f, -0.395784f, 0.359115f, 0.284143f, 0.050254f, 0.004175f, 0.000407f,\n    0.000407f, 0.004175f, 0.050254f, 0.284142f, 0.359115f, -0.395784f, 0.359115f, 0.284143f, 0.050254f, 0.004175f, 0.000407f,\n    0.000407f, 0.004175f, 0.050254f, 0.284142f, 0.359115f, -0.395784f, 0.359115f, 0.284143f, 0.050254f, 0.004175f, 0.000407f,\n    0.000407f, 0.004175f, 0.050254f, 0.284142f, 0.359115f, -0.395784f, 0.359115f, 0.284143f, 0.050254f, 0.004175f, 0.000407f\n}\n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_75 -arch=sm_70", "ld_flags": "", "declaration": "#undef NDEBUG\n#include <assert.h>\n#include <stdio.h>\n#include <cuda.h>\n#include <cuda_runtime.h>\n#include <cooperative_groups.h>\n#include <device_launch_parameters.h>\n#define CUDA_CHECK(call) {                                     \\\n    cudaError_t error = call;                                  \\\n    if(error != cudaSuccess) {                                 \\\n        fprintf(stderr, \"CUDA error at %s: %d - %s \\n\",        \\\n                __FILE__, __LINE__, cudaGetErrorString(error));\\\n        exit(EXIT_FAILURE);                                    \\\n    }                                                          \\\n}\n\n// Simulation-related constants.\nconstexpr int SIM_WIDTH = 11;\nconstexpr int SIM_HEIGHT = 9;\nconstexpr int SIM_SIZE_BYTES = SIM_WIDTH * SIM_HEIGHT * sizeof(float);\n// Distance between two neighbor points on the computed area for both dimensions.\nconstexpr float DELTA_DISTANCE = 0.5f;\n\n// CUDA-related constants.\nconstexpr int BLOCK_SIZE_X = 64;\nconstexpr int BLOCK_SIZE_Y = 4;\nconstexpr int GRID_SIZE_X = 3;\nconstexpr int GRID_SIZE_Y = 1;\nconstexpr int STRIDE_SIZE_X = BLOCK_SIZE_X * GRID_SIZE_X;\nconstexpr int STRIDE_SIZE_Y = BLOCK_SIZE_Y * GRID_SIZE_Y;\nconstexpr int REQUIRED_STRIDE_ITERATIONS_X = 1 + (SIM_WIDTH - 1) / STRIDE_SIZE_X;\nconstexpr int REQUIRED_STRIDE_ITERATIONS_Y = 1 + (SIM_HEIGHT - 1) / STRIDE_SIZE_Y;\n// Error tolerance for comparing floating-point variables.\nconstexpr float EPSILON = 0.001f;\n\n__global__ void k_calculateWave2D(  float *previousDisplacement_d, \n                                    float *currentDisplacement_d, \n                                    float *depth_d, \n                                    float *previousTmp_d, \n                                    float *currentTmp_d);\n\nvoid launch() {\n    // Arrays for simulation data.\n    float *depth_h;\n    float *currentDisplacement_h;\n    float *previousDisplacement_h;\n    float *depth_d;\n    float *currentDisplacement_d;\n    float *previousDisplacement_d;\n    // Temporary data arrays for preserving original input data during calculations.\n    float *previousTmp_d;\n    float *currentTmp_d;\n    cudaStream_t stream;\n\n    depth_h = new float[SIM_WIDTH * SIM_HEIGHT];\n    currentDisplacement_h = new float[SIM_WIDTH * SIM_HEIGHT];\n    previousDisplacement_h = new float[SIM_WIDTH * SIM_HEIGHT];\n    CUDA_CHECK(cudaStreamCreate(&stream));\n    CUDA_CHECK(cudaMallocAsync(&depth_d, SIM_SIZE_BYTES, stream));\n    CUDA_CHECK(cudaMallocAsync(&currentDisplacement_d, SIM_SIZE_BYTES, stream));\n    CUDA_CHECK(cudaMallocAsync(&previousDisplacement_d, SIM_SIZE_BYTES, stream));\n    CUDA_CHECK(cudaMallocAsync(&currentTmp_d, SIM_SIZE_BYTES, stream));\n    CUDA_CHECK(cudaMallocAsync(&previousTmp_d, SIM_SIZE_BYTES, stream));\n\n    // Test 1: Pulse generation at point (5, 5).\n    {\n        for (int h = 0; h < SIM_HEIGHT; h++) {\n            for (int w = 0; w < SIM_WIDTH; w++) {\n                int index = w + h * SIM_WIDTH;\n                currentDisplacement_h[index] = 0.0f;\n                previousDisplacement_h[index] = 0.0f;\n                depth_h[index] = 1.0f;\n            }\n        }\n        currentDisplacement_h[5 + 5 * SIM_WIDTH] = 1.0f;\n        previousDisplacement_h[5 + 5 * SIM_WIDTH] = 0.8f;\n        CUDA_CHECK(cudaMemcpyAsync( currentDisplacement_d, \n                                    currentDisplacement_h, \n                                    SIM_SIZE_BYTES, \n                                    cudaMemcpyHostToDevice, \n                                    stream));\n        CUDA_CHECK(cudaMemcpyAsync( previousDisplacement_d, \n                                    previousDisplacement_h, \n                                    SIM_SIZE_BYTES, \n                                    cudaMemcpyHostToDevice, \n                                    stream));\n        CUDA_CHECK(cudaMemcpyAsync( depth_d, \n                                    depth_h, \n                                    SIM_SIZE_BYTES, \n                                    cudaMemcpyHostToDevice, \n                                    stream));\n        void * args[5] = {&previousDisplacement_d, &currentDisplacement_d, &depth_d, &previousTmp_d, &currentTmp_d };\n\n        // Grid: (3, 1, 1)\n        // Block: (64, 4, 1)\n        dim3 gridDim(GRID_SIZE_X, GRID_SIZE_Y, 1);\n        dim3 blockDim(BLOCK_SIZE_X, BLOCK_SIZE_Y, 1);\n        CUDA_CHECK(cudaLaunchCooperativeKernel( (void*)k_calculateWave2D, \n                                                gridDim, \n                                                blockDim, \n                                                args, \n                                                0, \n                                                stream));\n        CUDA_CHECK(cudaMemcpyAsync( currentDisplacement_h, \n                                    currentDisplacement_d, \n                                    SIM_SIZE_BYTES, \n                                    cudaMemcpyDeviceToHost, \n                                    stream));\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n\n        float expectedDisplacement[] = {\n            0.000000f, 0.000000f, 0.000000f, 0.000011f, 0.000149f, 0.000835f, 0.000149f, 0.000011f, 0.000000f, 0.000000f, 0.000000f,\n            0.000000f, 0.000000f, 0.000009f, 0.000186f, 0.002062f, 0.009411f, 0.002062f, 0.000186f, 0.000009f, 0.000000f, 0.000000f,\n            0.000000f, 0.000009f, 0.000247f, 0.004107f, 0.036926f, 0.129077f, 0.036926f, 0.004107f, 0.000247f, 0.000009f, 0.000000f,\n            0.000011f, 0.000186f, 0.004107f, 0.055204f, 0.376970f, 0.893490f, 0.376969f, 0.055204f, 0.004107f, 0.000186f, 0.000011f,\n            0.000149f, 0.002062f, 0.036926f, 0.376970f, 1.713494f, 1.884681f, 1.713494f, 0.376970f, 0.036926f, 0.002062f, 0.000149f,\n            0.000835f, 0.009411f, 0.129077f, 0.893492f, 1.884684f, -1.106843f, 1.884684f, 0.893492f, 0.129077f, 0.009411f, 0.000835f,\n            0.000149f, 0.002062f, 0.036926f, 0.376976f, 1.713569f, 1.885096f, 1.713569f, 0.376976f, 0.036926f, 0.002062f, 0.000149f,\n            0.000011f, 0.000186f, 0.004116f, 0.055390f, 0.379030f, 0.902888f, 0.379030f, 0.055390f, 0.004116f, 0.000186f, 0.000011f,\n            0.000001f, 0.000019f, 0.000495f, 0.008213f, 0.073852f, 0.258153f, 0.073852f, 0.008213f, 0.000495f, 0.000019f, 0.000001f\n        };\n\n        for(int i = 0; i < SIM_WIDTH * SIM_HEIGHT; i++) {\n            assert(fabs(expectedDisplacement[i] - currentDisplacement_h[i]) < EPSILON);\n        }\n    }\n\n    // Test 2: Line-shaped wave generation at x = 5.\n    {\n        for (int h = 0; h < SIM_HEIGHT; h++) {\n            for (int w = 0; w < SIM_WIDTH; w++) {\n                int index = w + h * SIM_WIDTH;\n                currentDisplacement_h[index] = 0.0f;\n                previousDisplacement_h[index] = 0.0f;\n                depth_h[index] = 1.0f;\n            }\n        }\n        for(int i = 0; i < SIM_HEIGHT; i++) {\n            currentDisplacement_h[5 + i * SIM_WIDTH] = 1.0f;\n            previousDisplacement_h[5 + i * SIM_WIDTH] = 1.0f;\n        }\n        CUDA_CHECK(cudaMemcpyAsync( currentDisplacement_d, \n                                    currentDisplacement_h, \n                                    SIM_SIZE_BYTES, \n                                    cudaMemcpyHostToDevice, \n                                    stream));\n        CUDA_CHECK(cudaMemcpyAsync( previousDisplacement_d, \n                                    previousDisplacement_h, \n                                    SIM_SIZE_BYTES, \n                                    cudaMemcpyHostToDevice, \n                                    stream));\n        CUDA_CHECK(cudaMemcpyAsync( depth_d, \n                                    depth_h, \n                                    SIM_SIZE_BYTES, \n                                    cudaMemcpyHostToDevice, \n                                    stream));\n        void * args[5] = {&previousDisplacement_d, &currentDisplacement_d, &depth_d, &previousTmp_d, &currentTmp_d };\n\n        // Grid: (3, 1, 1)\n        // Block: (64, 4, 1)\n        dim3 gridDim(GRID_SIZE_X, GRID_SIZE_Y, 1);\n        dim3 blockDim(BLOCK_SIZE_X, BLOCK_SIZE_Y, 1);\n        CUDA_CHECK(cudaLaunchCooperativeKernel( (void*)k_calculateWave2D, \n                                                gridDim, \n                                                blockDim, \n                                                args, \n                                                0, \n                                                stream));\n        CUDA_CHECK(cudaMemcpyAsync( currentDisplacement_h, \n                                    currentDisplacement_d, \n                                    SIM_SIZE_BYTES, \n                                    cudaMemcpyDeviceToHost, \n                                    stream));\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n\n        float expectedDisplacement[] = {\n            0.000407f, 0.004175f, 0.050254f, 0.284142f, 0.359115f, -0.395784f, 0.359115f, 0.284143f, 0.050254f, 0.004175f, 0.000407f,\n            0.000407f, 0.004175f, 0.050254f, 0.284142f, 0.359115f, -0.395784f, 0.359115f, 0.284143f, 0.050254f, 0.004175f, 0.000407f,\n            0.000407f, 0.004175f, 0.050254f, 0.284142f, 0.359115f, -0.395784f, 0.359115f, 0.284143f, 0.050254f, 0.004175f, 0.000407f,\n            0.000407f, 0.004175f, 0.050254f, 0.284142f, 0.359115f, -0.395784f, 0.359115f, 0.284143f, 0.050254f, 0.004175f, 0.000407f,\n            0.000407f, 0.004175f, 0.050254f, 0.284142f, 0.359115f, -0.395784f, 0.359115f, 0.284143f, 0.050254f, 0.004175f, 0.000407f,\n            0.000407f, 0.004175f, 0.050254f, 0.284142f, 0.359115f, -0.395784f, 0.359115f, 0.284143f, 0.050254f, 0.004175f, 0.000407f,\n            0.000407f, 0.004175f, 0.050254f, 0.284142f, 0.359115f, -0.395784f, 0.359115f, 0.284143f, 0.050254f, 0.004175f, 0.000407f,\n            0.000407f, 0.004175f, 0.050254f, 0.284142f, 0.359115f, -0.395784f, 0.359115f, 0.284143f, 0.050254f, 0.004175f, 0.000407f,\n            0.000407f, 0.004175f, 0.050254f, 0.284142f, 0.359115f, -0.395784f, 0.359115f, 0.284143f, 0.050254f, 0.004175f, 0.000407f\n        };\n\n        for(int i = 0; i < SIM_WIDTH * SIM_HEIGHT; i++) {\n            assert(fabs(expectedDisplacement[i] - currentDisplacement_h[i]) < EPSILON);\n        }\n    }\n    // Test 3: Superposition of two waves generated from center points (3, 3) and (5, 5).\n    {\n        for (int h = 0; h < SIM_HEIGHT; h++) {\n            for (int w = 0; w < SIM_WIDTH; w++) {\n                int index = w + h * SIM_WIDTH;\n                currentDisplacement_h[index] = 0.0f;\n                previousDisplacement_h[index] = 0.0f;\n                depth_h[index] = 1.0f;\n            }\n        }\n        currentDisplacement_h[3 + 3 * SIM_WIDTH] = 1.0f;\n        currentDisplacement_h[5 + 5 * SIM_WIDTH] = 1.0f;\n        CUDA_CHECK(cudaMemcpyAsync( currentDisplacement_d, \n                                    currentDisplacement_h, \n                                    SIM_SIZE_BYTES, \n                                    cudaMemcpyHostToDevice, \n                                    stream));\n        CUDA_CHECK(cudaMemcpyAsync( previousDisplacement_d, \n                                    previousDisplacement_h, \n                                    SIM_SIZE_BYTES, \n                                    cudaMemcpyHostToDevice, \n                                    stream));\n        CUDA_CHECK(cudaMemcpyAsync( depth_d, \n                                    depth_h, \n                                    SIM_SIZE_BYTES, \n                                    cudaMemcpyHostToDevice, \n                                    stream));\n        void * args[5] = {&previousDisplacement_d, &currentDisplacement_d, &depth_d, &previousTmp_d, &currentTmp_d };\n\n        // Grid: (3, 1, 1)\n        // Block: (64, 4, 1)\n        dim3 gridDim(GRID_SIZE_X, GRID_SIZE_Y, 1);\n        dim3 blockDim(BLOCK_SIZE_X, BLOCK_SIZE_Y, 1);\n        CUDA_CHECK(cudaLaunchCooperativeKernel( (void*)k_calculateWave2D, \n                                                gridDim, \n                                                blockDim, \n                                                args, \n                                                0, \n                                                stream));\n        CUDA_CHECK(cudaMemcpyAsync( currentDisplacement_h, \n                                    currentDisplacement_d, \n                                    SIM_SIZE_BYTES, \n                                    cudaMemcpyDeviceToHost, \n                                    stream));\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n\n        float expectedDisplacement[] = {\n            0.003420f, 0.030073f, 0.287207f, 1.076589f, 0.287718f, 0.033056f, 0.002225f, 0.000099f, 0.000003f, 0.000000f, 0.000000f,\n            0.030073f, 0.216047f, 1.584911f, 4.117199f, 1.592391f, 0.251925f, 0.022567f, 0.001285f, 0.000050f, 0.000001f, 0.000000f,\n            0.287207f, 1.584911f, 7.875597f, 10.093018f, 8.018077f, 2.115627f, 0.287205f, 0.022530f, 0.001112f, 0.000037f, 0.000002f,\n            1.076589f, 4.117199f, 10.093018f, -4.031080f, 11.653681f, 8.160119f, 2.115610f, 0.251240f, 0.016528f, 0.000685f, 0.000039f,\n            0.287718f, 1.592391f, 8.018077f, 11.653681f, 15.748361f, 11.653681f, 8.017787f, 1.584858f, 0.143859f, 0.007537f, 0.000515f,\n            0.033056f, 0.251925f, 2.115627f, 8.160119f, 11.653681f, -4.031123f, 10.091420f, 4.080718f, 0.538295f, 0.036522f, 0.003045f,\n            0.002225f, 0.022567f, 0.287205f, 2.115626f, 8.018075f, 10.093014f, 7.875318f, 1.577386f, 0.143604f, 0.007531f, 0.000515f,\n            0.000099f, 0.001286f, 0.022567f, 0.251924f, 1.592390f, 4.117192f, 1.584891f, 0.215405f, 0.015037f, 0.000643f, 0.000037f,\n            0.000006f, 0.000099f, 0.002225f, 0.033056f, 0.287719f, 1.076588f, 0.287205f, 0.030011f, 0.001710f, 0.000062f, 0.000003f\n        };\n\n        for(int i = 0; i < SIM_WIDTH * SIM_HEIGHT; i++) {\n            assert(fabs(expectedDisplacement[i] - currentDisplacement_h[i]) < EPSILON);\n        }\n    }\n    // Test 4: Point at (4, 4) with a positive displacement, surrounded by points with negative displacements.\n    {\n        for (int h = 0; h < SIM_HEIGHT; h++) {\n            for (int w = 0; w < SIM_WIDTH; w++) {\n                int index = w + h * SIM_WIDTH;\n                currentDisplacement_h[index] = 0.0f;\n                previousDisplacement_h[index] = 0.0f;\n                depth_h[index] = 1.0f;\n            }\n        }\n        currentDisplacement_h[4 + 4 * SIM_WIDTH] = 1.0f;\n        currentDisplacement_h[5 + 4 * SIM_WIDTH] = -1.0f;\n        currentDisplacement_h[3 + 4 * SIM_WIDTH] = -1.0f;\n        currentDisplacement_h[4 + 5 * SIM_WIDTH] = -1.0f;\n        currentDisplacement_h[4 + 3 * SIM_WIDTH] = -1.0f;\n\n        CUDA_CHECK(cudaMemcpyAsync( currentDisplacement_d, \n                                    currentDisplacement_h, \n                                    SIM_SIZE_BYTES, \n                                    cudaMemcpyHostToDevice, \n                                    stream));\n        CUDA_CHECK(cudaMemcpyAsync( previousDisplacement_d, \n                                    previousDisplacement_h, \n                                    SIM_SIZE_BYTES, \n                                    cudaMemcpyHostToDevice, \n                                    stream));\n        CUDA_CHECK(cudaMemcpyAsync( depth_d, \n                                    depth_h, \n                                    SIM_SIZE_BYTES, \n                                    cudaMemcpyHostToDevice, \n                                    stream));\n        void * args[5] = {&previousDisplacement_d, &currentDisplacement_d, &depth_d, &previousTmp_d, &currentTmp_d };\n\n        // Grid: (3, 1, 1)\n        // Block: (64, 4, 1)\n        dim3 gridDim(GRID_SIZE_X, GRID_SIZE_Y, 1);\n        dim3 blockDim(BLOCK_SIZE_X, BLOCK_SIZE_Y, 1);\n        CUDA_CHECK(cudaLaunchCooperativeKernel( (void*)k_calculateWave2D, \n                                                gridDim, \n                                                blockDim, \n                                                args, \n                                                0, \n                                                stream));\n        CUDA_CHECK(cudaMemcpyAsync( currentDisplacement_h, \n                                    currentDisplacement_d, \n                                    SIM_SIZE_BYTES, \n                                    cudaMemcpyDeviceToHost, \n                                    stream));\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n\n        float expectedDisplacement[] = {\n            -0.000244f, -0.002939f, -0.043876f, -0.346908f, -1.036736f, -0.346908f, -0.043876f, -0.002935f, -0.000122f, -0.000003f, -0.000000f,\n            -0.002939f, -0.029316f, -0.345737f, -2.003350f, -3.900983f, -2.003350f, -0.345736f, -0.029267f, -0.001469f, -0.000049f, -0.000002f,\n            -0.043876f, -0.345737f, -2.969965f, -10.735603f, -9.690741f, -10.735603f, -2.969943f, -0.344855f, -0.021938f, -0.000882f, -0.000049f,\n            -0.346908f, -2.003350f, -10.735603f, -15.433290f, -5.506227f, -15.433290f, -10.735305f, -1.994534f, -0.173454f, -0.008821f, -0.000590f,\n            -1.036736f, -3.900983f, -9.690741f, -5.506227f, -44.551655f, -5.506173f, -9.689205f, -3.865469f, -0.518370f, -0.035556f, -0.002985f,\n            -0.346908f, -2.003350f, -10.735603f, -15.433290f, -5.506227f, -15.433290f, -10.735305f, -1.994534f, -0.173454f, -0.008821f, -0.000590f,\n            -0.043876f, -0.345737f, -2.969965f, -10.735603f, -9.690741f, -10.735603f, -2.969938f, -0.344855f, -0.021938f, -0.000882f, -0.000049f,\n            -0.002939f, -0.029316f, -0.345737f, -2.003350f, -3.900983f, -2.003350f, -0.345736f, -0.029267f, -0.001469f, -0.000049f, -0.000002f,\n            -0.000244f, -0.002939f, -0.043876f, -0.346908f, -1.036736f, -0.346908f, -0.043876f, -0.002935f, -0.000122f, -0.000003f, -0.000000f\n        };\n\n        for(int i = 0; i < SIM_WIDTH * SIM_HEIGHT; i++) {\n            assert(fabs(expectedDisplacement[i] - currentDisplacement_h[i]) < EPSILON);\n        }\n    }\n    // Test 5: Refraction of a smooth wave among four mediums with increasing wave speeds.\n    {\n        for (int h = 0; h < SIM_HEIGHT; h++) {\n            for (int w = 0; w < SIM_WIDTH; w++) {\n                int index = w + h * SIM_WIDTH;\n                currentDisplacement_h[index] = 0.0f;\n                previousDisplacement_h[index] = 0.0f;\n                depth_h[index] = 1.0f;\n            }\n        }\n        for(int h = 0; h < SIM_HEIGHT; h++) {\n            for(int w = 0; w < SIM_WIDTH; w++) {\n                depth_h[w + h * SIM_WIDTH] = 1 + (w / (SIM_WIDTH / 4));\n            }\n        }\n        // Generating a smooth wave pattern centered at point (4, 4).\n        int size = 40;\n        int pointIdxX = 4;\n        int pointIdxY = 4;\n        constexpr float SIGMA = 10.0f * DELTA_DISTANCE;\n        constexpr float AMPLITUDE = 0.01f;\n        for (int i = -size; i <= size ; i++) {\n            for (int j = -size; j <= size; j++) {\n                float dx = j;\n                float dy = i;\n                if(i + pointIdxY >= 0 && i + pointIdxY < SIM_HEIGHT && j + pointIdxX >= 0 && j + pointIdxX < SIM_WIDTH) {\n                    float value = AMPLITUDE * exp(-(dx * dx + dy * dy) / (2.0f * SIGMA * SIGMA));\n                    currentDisplacement_h[(i + pointIdxY) * SIM_WIDTH + j + pointIdxX] += value;\n                    previousDisplacement_h[(i + pointIdxY) * SIM_WIDTH + j + pointIdxX] += value * 0.5f;\n                }\n            }\n        }\n        \n        CUDA_CHECK(cudaMemcpyAsync( currentDisplacement_d, \n                                    currentDisplacement_h, \n                                    SIM_SIZE_BYTES, \n                                    cudaMemcpyHostToDevice, \n                                    stream));\n        CUDA_CHECK(cudaMemcpyAsync( previousDisplacement_d, \n                                    previousDisplacement_h, \n                                    SIM_SIZE_BYTES, \n                                    cudaMemcpyHostToDevice, \n                                    stream));\n        CUDA_CHECK(cudaMemcpyAsync( depth_d, \n                                    depth_h, \n                                    SIM_SIZE_BYTES, \n                                    cudaMemcpyHostToDevice, \n                                    stream));\n        void * args[5] = {&previousDisplacement_d, &currentDisplacement_d, &depth_d, &previousTmp_d, &currentTmp_d };\n\n        // Grid: (3, 1, 1)\n        // Block: (64, 4, 1)\n        dim3 gridDim(GRID_SIZE_X, GRID_SIZE_Y, 1);\n        dim3 blockDim(BLOCK_SIZE_X, BLOCK_SIZE_Y, 1);\n        CUDA_CHECK(cudaLaunchCooperativeKernel( (void*)k_calculateWave2D, \n                                                gridDim, \n                                                blockDim, \n                                                args, \n                                                0, \n                                                stream));\n        CUDA_CHECK(cudaMemcpyAsync( currentDisplacement_h, \n                                    currentDisplacement_d, \n                                    SIM_SIZE_BYTES, \n                                    cudaMemcpyDeviceToHost, \n                                    stream));\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n\n        float expectedDisplacement[] = {\n            0.347893f, 0.359615f, 0.384232f, 0.397982f, 0.400169f, 0.404647f, 0.407961f, 0.412704f, 0.414962f, 0.417527f, 0.417582f,\n            0.354402f, 0.362559f, 0.387474f, 0.399336f, 0.399395f, 0.403911f, 0.407326f, 0.412696f, 0.415485f, 0.418194f, 0.418206f,\n            0.379538f, 0.382708f, 0.392573f, 0.396739f, 0.395269f, 0.400201f, 0.407232f, 0.414392f, 0.416941f, 0.419505f, 0.419513f,\n            0.400508f, 0.401647f, 0.397311f, 0.391400f, 0.391836f, 0.399661f, 0.407328f, 0.415021f, 0.417777f, 0.420465f, 0.420582f,\n            0.408065f, 0.408764f, 0.399859f, 0.389530f, 0.390155f, 0.399948f, 0.407173f, 0.414455f, 0.417898f, 0.421080f, 0.421181f,\n            0.400508f, 0.401647f, 0.397311f, 0.391400f, 0.391836f, 0.399661f, 0.407328f, 0.415021f, 0.417777f, 0.420465f, 0.420582f,\n            0.379538f, 0.382708f, 0.392573f, 0.396739f, 0.395269f, 0.400201f, 0.407232f, 0.414392f, 0.416941f, 0.419505f, 0.419513f,\n            0.354402f, 0.362559f, 0.387474f, 0.399336f, 0.399395f, 0.403911f, 0.407326f, 0.412696f, 0.415485f, 0.418194f, 0.418206f,\n            0.347893f, 0.359615f, 0.384232f, 0.397982f, 0.400169f, 0.404647f, 0.407961f, 0.412704f, 0.414962f, 0.417527f, 0.417582f\n        };\n\n        for(int i = 0; i < SIM_WIDTH * SIM_HEIGHT; i++) {\n            assert(fabs(expectedDisplacement[i] - currentDisplacement_h[i]) < EPSILON);\n        }\n    }\n    // Test 6: Standing waves within a uniform medium.\n    {\n        for (int h = 0; h < SIM_HEIGHT; h++) {\n            for (int w = 0; w < SIM_WIDTH; w++) {\n                int index = w + h * SIM_WIDTH;\n                currentDisplacement_h[index] = 0.0f;\n                previousDisplacement_h[index] = 0.0f;\n                depth_h[index] = 1.0f;\n            }\n        }\n        float PI = acos(-1);\n        for (int h = 0; h < SIM_HEIGHT; h++) {\n            for (int w = 0; w < SIM_WIDTH; w++) {\n                depth_h[w + h * SIM_WIDTH] = 10.0f;\n                float xComponent = sin(w * 2.0f * PI / SIM_WIDTH);\n                float yComponent = sin(h * 2.0f * PI / SIM_HEIGHT);\n                currentDisplacement_h[w + h * SIM_WIDTH] = xComponent * yComponent;\n            }\n        }\n        \n        CUDA_CHECK(cudaMemcpyAsync( currentDisplacement_d, \n                                    currentDisplacement_h, \n                                    SIM_SIZE_BYTES, \n                                    cudaMemcpyHostToDevice, \n                                    stream));\n        CUDA_CHECK(cudaMemcpyAsync( previousDisplacement_d, \n                                    previousDisplacement_h, \n                                    SIM_SIZE_BYTES, \n                                    cudaMemcpyHostToDevice, \n                                    stream));\n        CUDA_CHECK(cudaMemcpyAsync( depth_d, \n                                    depth_h, \n                                    SIM_SIZE_BYTES, \n                                    cudaMemcpyHostToDevice, \n                                    stream));\n        void * args[5] = {&previousDisplacement_d, &currentDisplacement_d, &depth_d, &previousTmp_d, &currentTmp_d };\n\n        // Grid: (3, 1, 1)\n        // Block: (64, 4, 1)\n        dim3 gridDim(GRID_SIZE_X, GRID_SIZE_Y, 1);\n        dim3 blockDim(BLOCK_SIZE_X, BLOCK_SIZE_Y, 1);\n        CUDA_CHECK(cudaLaunchCooperativeKernel( (void*)k_calculateWave2D, \n                                                gridDim, \n                                                blockDim, \n                                                args, \n                                                0, \n                                                stream));\n        CUDA_CHECK(cudaMemcpyAsync( currentDisplacement_h, \n                                    currentDisplacement_d, \n                                    SIM_SIZE_BYTES, \n                                    cudaMemcpyDeviceToHost, \n                                    stream));\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n\n        float expectedDisplacement[] = {\n            -4.565512f, -3.878747f, -1.352703f, 1.596967f, 2.593991f, 1.282479f, -0.361835f, -0.308868f, 1.661168f, 3.383909f, 3.707297f,\n            -4.873705f, -4.317383f, -2.096274f, 0.854752f, 1.993256f, 1.196660f, 0.096432f, 0.378078f, 2.431641f, 3.895500f, 4.085439f,\n            -5.979319f, -5.596576f, -3.891480f, -1.127063f, 0.685319f, 1.363383f, 1.661052f, 2.383622f, 3.897503f, 4.545934f, 4.444734f,\n            -4.805110f, -4.710963f, -3.891645f, -2.132775f, -0.293345f, 1.234980f, 2.387169f, 3.203460f, 3.713772f, 3.467847f, 3.112700f,\n            -1.215967f, -1.188277f, -1.145949f, -1.144635f, -0.479651f, 0.509417f, 1.352975f, 1.630776f, 1.140669f, 0.806318f, 0.720348f,\n            3.029806f, 2.984275f, 2.244284f, 0.528569f, -0.373716f, -0.489784f, -0.425310f, -0.816507f, -1.924535f, -2.082408f, -1.822046f,\n            6.205341f, 5.778104f, 4.005559f, 1.235420f, -0.550474f, -1.149731f, -1.375208f, -2.076431f, -3.577414f, -4.269567f, -4.205656f,\n            7.398588f, 6.672131f, 4.149539f, 1.107315f, -1.019596f, -1.528867f, -1.543732f, -2.293873f, -3.737435f, -4.954867f, -5.159369f,\n            8.097583f, 7.194371f, 4.261105f, 1.179894f, -1.265283f, -1.851095f, -1.825434f, -2.580025f, -3.684251f, -5.034657f, -5.354953f\n        };\n\n        for(int i = 0; i < SIM_WIDTH * SIM_HEIGHT; i++) {\n            assert(fabs(expectedDisplacement[i] - currentDisplacement_h[i]) < EPSILON);\n        }\n    }\n    // Test 7: Refraction through a depth gradient.\n    {\n        for (int h = 0; h < SIM_HEIGHT; h++) {\n            for (int w = 0; w < SIM_WIDTH; w++) {\n                int index = w + h * SIM_WIDTH;\n                currentDisplacement_h[index] = 0.0f;\n                previousDisplacement_h[index] = 0.0f;\n                depth_h[index] = 1.0f;\n            }\n        }\n        for (int h = 0; h < SIM_HEIGHT; h++) {\n            for (int w = 0; w < SIM_WIDTH; w++) {\n                depth_h[w + h * SIM_WIDTH] = 1 + 3.0f * (w / (float)SIM_WIDTH);\n            }\n        }\n        currentDisplacement_h[4 + 4 * SIM_WIDTH] = 1.0f;\n\n        CUDA_CHECK(cudaMemcpyAsync( currentDisplacement_d, \n                                    currentDisplacement_h, \n                                    SIM_SIZE_BYTES, \n                                    cudaMemcpyHostToDevice, \n                                    stream));\n        CUDA_CHECK(cudaMemcpyAsync( previousDisplacement_d, \n                                    previousDisplacement_h, \n                                    SIM_SIZE_BYTES, \n                                    cudaMemcpyHostToDevice, \n                                    stream));\n        CUDA_CHECK(cudaMemcpyAsync( depth_d, \n                                    depth_h, \n                                    SIM_SIZE_BYTES, \n                                    cudaMemcpyHostToDevice, \n                                    stream));\n        void * args[5] = {&previousDisplacement_d, &currentDisplacement_d, &depth_d, &previousTmp_d, &currentTmp_d };\n        // Grid: (3, 1, 1)\n        // Block: (64, 4, 1)\n        dim3 gridDim(GRID_SIZE_X, GRID_SIZE_Y, 1);\n        dim3 blockDim(BLOCK_SIZE_X, BLOCK_SIZE_Y, 1);\n        CUDA_CHECK(cudaLaunchCooperativeKernel( (void*)k_calculateWave2D, \n                                                gridDim, \n                                                blockDim, \n                                                args, \n                                                0, \n                                                stream));\n        CUDA_CHECK(cudaMemcpyAsync( currentDisplacement_h, \n                                    currentDisplacement_d, \n                                    SIM_SIZE_BYTES, \n                                    cudaMemcpyDeviceToHost, \n                                    stream));\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n\n        float expectedDisplacement[] = {\n            0.001134f, 0.022817f, 0.330711f, 1.576588f, 2.439878f, 3.204626f, 2.912915f, 1.867793f, 0.914622f, 0.384623f, 0.236438f,\n            0.006071f, 0.089629f, 0.878308f, 2.429212f, 2.309972f, 2.962719f, 3.398280f, 2.602556f, 1.433267f, 0.656104f, 0.420436f,\n            0.042618f, 0.428976f, 2.411370f, 2.028470f, 0.929674f, -0.156735f, 1.980986f, 3.070216f, 2.306219f, 1.271462f, 0.887846f,\n            0.174350f, 1.099788f, 2.657410f, -1.640502f, 2.095705f, -0.829313f, -0.723821f, 1.726273f, 2.314209f, 1.654315f, 1.288093f,\n            0.320152f, 1.235732f, 1.381921f, 1.126383f, 1.762368f, 2.024709f, 1.159134f, 2.069403f, 2.332343f, 1.727152f, 1.389491f,\n            0.174350f, 1.099788f, 2.657410f, -1.640502f, 2.095705f, -0.829310f, -0.723821f, 1.726273f, 2.314210f, 1.654315f, 1.288092f,\n            0.042618f, 0.428976f, 2.411370f, 2.028470f, 0.929674f, -0.156735f, 1.980986f, 3.070216f, 2.306216f, 1.271461f, 0.887846f,\n            0.006071f, 0.089629f, 0.878308f, 2.429213f, 2.309974f, 2.962719f, 3.398280f, 2.602556f, 1.433266f, 0.656103f, 0.420436f,\n            0.001134f, 0.022817f, 0.330712f, 1.576589f, 2.439879f, 3.204626f, 2.912915f, 1.867793f, 0.914622f, 0.384623f, 0.236438f\n        };\n\n        for(int i = 0; i < SIM_WIDTH * SIM_HEIGHT; i++) {\n            assert(fabs(expectedDisplacement[i] - currentDisplacement_h[i]) < EPSILON);\n        }\n    }\n\n    CUDA_CHECK(cudaFreeAsync(depth_d, stream));\n    CUDA_CHECK(cudaFreeAsync(currentDisplacement_d, stream));\n    CUDA_CHECK(cudaFreeAsync(previousDisplacement_d, stream));\n    CUDA_CHECK(cudaFreeAsync(previousTmp_d, stream));\n    CUDA_CHECK(cudaFreeAsync(currentTmp_d, stream));\n    // Deleting host arrays asynchronously to the freeing of device arrays.\n    delete [] depth_h;\n    delete [] currentDisplacement_h;\n    delete [] previousDisplacement_h;\n    CUDA_CHECK(cudaStreamDestroy(stream));\n}\n\n__global__ void k_calculateWave2D(  float *previousDisplacement_d, \n                                    float *currentDisplacement_d, \n                                    float *depth_d, \n                                    float *previousTmp_d, \n                                    float *currentTmp_d) {\n", "test": "int main() {\n    launch();\n}\n", "example_test": "    @example_test\n", "cuda_toolkit": "12.2"}
{"task_id": "CUDA/116", "date": "2025-03-31", "prompt": "Write a cuda kernel to find the number of occurrences of a pattern in a sequence where each thread checks for the pattern in the input sequence in parallel and utilizes the Atomic function to aggregate the count value. \n\nThe signature of the function is __global__ void k_patternMatch(char* sequence_d, char* pattern_d, int sequenceLength, int patternLength, int* count_d), where sequence refers to the input string, pattern is the string being searched within sequence, sequenceLength and patternLength represent the lengths of sequence and pattern respectively, and count_d denotes the number of times the pattern appears in the sequence.\n\n>>> k_patternMatch(\"ATCGTGATCGAAGCCT\", \"ATC\", 16, 3, count) -> count: 2\n>>> k_patternMatch(\"ATCGTGATTGAAGCCT\", \"ATCGA\", 16, 5, count) -> count: 0 \n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_70", "ld_flags": "", "declaration": "\n#include <limits>\n#include <string>\n#include <cstdio>\n#include <assert.h>\n#include <cuda.h>\n#include <curand_kernel.h>\n#include <cuda_runtime.h>\n\n#undef NDEBUG\n\nconst int THREADS_PER_BLOCK = 256;\n\n#define CUDA_CHECK(call)                                    \\\ndo {                                                        \\\n    cudaError_t error = call;                               \\\n        if (error != cudaSuccess) {                         \\\n            fprintf(stderr, \"CUDA error at %s:%d - %s\\n\",   \\\n                    __FILE__, __LINE__,                     \\\n                    cudaGetErrorString(error));             \\\n            exit(EXIT_FAILURE);                             \\\n    }                                                       \\\n} while (0)\n\n__global__ void k_patternMatch(char* sequence_d, char* pattern_d, int sequenceLength, int patternLength, int* count_d);\n\nvoid launch() {\n    const int testCaseCount = 7;\n\n    struct testCase {\n        std::string sequence;\n        std::string pattern;\n    };\n    \n    //Input sequences and patterns for testing\n    testCase input[] = {\n        {\"ATCGTGATCGAAGCCT\",\"ATC\"},\n        {\"ATCGTGATCGAAGCCT\",\"ATCG\"},\n        {\"ATGTGATGGAATGCT\",\"ATG\"},\n        {\"Thisisthesequence\",\"the\"},\n        {\"Thisisthesequence\",\"is\"},\n        {\"ATCGTGATTGAAGCCT\",\"ATCGA\"},\n        {\"Thisisthesequence\",\"th\"},\n    };\n\n    //Expected output\n    unsigned int expectedFrequency[] = {2,2,3,1,2,0,1};\n    \n    int maxSequenceLength = 0;\n    int maxPatternLength = 0;\n\n    for (int t = 0; t < testCaseCount; t++) {\n        std::string sequence = input[t].sequence;\n        std::string pattern = input[t].pattern;\n        int sequenceLength = sequence.length();\n        maxSequenceLength += sequenceLength;\n        int patternLength = pattern.length();\n        maxPatternLength += patternLength;\n    }\n\n    //Creating cuda streams\n    cudaStream_t stream;\n    CUDA_CHECK(cudaStreamCreate(&stream));\n\n    //Device Memory Allocation\n    int *count_d;\n    char *sequence_d, *pattern_d;\n    int* count_h = (int*)malloc(sizeof(int));\n    CUDA_CHECK(cudaMallocAsync((void **)&sequence_d, maxSequenceLength*sizeof(char), stream));\n    CUDA_CHECK(cudaMallocAsync((void **)&pattern_d, maxPatternLength*sizeof(char), stream));\n    CUDA_CHECK(cudaMallocAsync((void **)&count_d, sizeof(int), stream));\n\n    // Fetch GPU properties\n    cudaDeviceProp prop;\n    cudaGetDeviceProperties(&prop, 0);\n    int maxBlocks = (prop.maxThreadsPerMultiProcessor / THREADS_PER_BLOCK) * prop.multiProcessorCount;\n\n    //Declaration of test sequence and pattern\n    for (int i = 0; i < testCaseCount; i++) {\n        std::string sequence = input[i].sequence;\n        std::string pattern = input[i].pattern;\n        int sequenceLength = sequence.length();\n        int patternLength = pattern.length();\n\n        // Set the grid dimension to the minimum of needed blocks or GPU max blocks\n        int blocksPerGrid = min(maxBlocks, (sequenceLength + THREADS_PER_BLOCK - 1) / THREADS_PER_BLOCK);\n              \n        // Copy sequences to device\n        CUDA_CHECK(cudaMemcpyAsync(sequence_d, sequence.c_str(), sequenceLength * sizeof(char), cudaMemcpyHostToDevice, stream));\n        CUDA_CHECK(cudaMemcpyAsync(pattern_d, pattern.c_str(), patternLength * sizeof(char), cudaMemcpyHostToDevice, stream));\n        CUDA_CHECK(cudaMemsetAsync(count_d, 0, sizeof(int), stream));\n\n        //Launch the kernel function\n        //Grid: (sequenceLength + THREADS_PER_BLOCK - 1) / THREADS_PER_BLOCK), 1, 1)\n        //Block: (THREADS_PER_BLOCK, 1, 1)\n        void *args[] = {&sequence_d, &pattern_d, &sequenceLength, &patternLength, &count_d};\n        CUDA_CHECK(cudaLaunchKernel((void*)k_patternMatch, blocksPerGrid, THREADS_PER_BLOCK, args, THREADS_PER_BLOCK * sizeof(int), stream));\n\n        // Copy results back to host\n        CUDA_CHECK(cudaMemcpyAsync(count_h, count_d, sizeof(int), cudaMemcpyDeviceToHost, stream));\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n\n        //Validate the results with the expected value\n        assert(expectedFrequency[i] == (*count_h)); \n    }\n\n    //Free Host and Device memory\n    free(count_h);\n    CUDA_CHECK(cudaFreeAsync(sequence_d, stream));\n    CUDA_CHECK(cudaFreeAsync(pattern_d, stream));\n    CUDA_CHECK(cudaFreeAsync(count_d, stream));\n    CUDA_CHECK(cudaStreamDestroy(stream));\n}\n\n__global__ void k_patternMatch(char* sequence_d, char* pattern_d, int sequenceLength, int patternLength, int* count_d) {\n", "test": "int main() {\n    launch();\n}\n", "example_test": "    @example_test\n", "cuda_toolkit": "12.2"}
{"task_id": "CUDA/117", "date": "2025-03-31", "prompt": "Write a CUDA kernel to perform Sparse Matrix-Vector Multiplication (SpMV) using the Compressed Sparse Row (CSR) format with shared memory optimizations. The kernel should minimize global memory accesses and maximize multiprocessor utilization.\n\nThe k_spmvCsrOptimized kernel should have the signature: __global__ void k_spmvCsrOptimized(float* values, int* colIndices, int* rowPtr, float* x, float* y, int numRows). Here, values contains non-zero elements, colIndices stores column indices, rowPtr marks row boundaries, x is the input vector, y is the output vector, and numRows is the matrix dimension.\n\n>>> k_spmvCsrOptimized(values:{1.0f, 2.0f, 3.0f}, colIndices:{0, 1, 2}, rowPtr:{0, 1, 2, 3}, x:{1.0f, 2.0f, 3.0f}, y, numRows:{3}) -> y:{1.0f, 4.0f, 9.0f}\n>>> k_spmvCsrOptimized(values:{1.0f, 4.0f, 2.0f, 5.0f, 3.0f, 6.0f}, colIndices:{0, 2, 1, 3, 0, 1}, rowPtr:{0, 2, 4, 6, 6}, x:{1.0f, 2.0f, 3.0f, 4.0f}, y, numRows:{4}) -> y:{13.0f, 24.0f, 15.0f, 0.0f}\n", "cc_flags": "-arch=sm_80 -arch=sm_70 -arch=sm_60", "ld_flags": "", "declaration": "#include <cassert>\n#include <cmath>\n#include <cooperative_groups.h>\n#include <cstdio>\n#include <cstdlib>\n#include <cuda_runtime.h>\n#include <iostream>\n#include <vector>\n\nnamespace cg = cooperative_groups;\n\nconst float TOLERANCE = 1e-5f;\n\n#define CUDA_CHECK(call)                                                                           \\\n    do {                                                                                           \\\n        cudaError_t error = call;                                                                  \\\n        if(error != cudaSuccess) {                                                                 \\\n            fprintf(stderr,                                                                        \\\n                    \"CUDA Error: %s at %s:%d\\n\",                                                   \\\n                    cudaGetErrorString(error),                                                     \\\n                    __FILE__,                                                                      \\\n                    __LINE__);                                                                     \\\n            exit(error);                                                                           \\\n        }                                                                                          \\\n    } while(0)\n\n__global__ void k_spmvCsrOptimized(float *values_d,   // Non-zero elements array\n                                   int *colIndices_d, // Column indices array\n                                   int *rowPtr_d,     // Row pointers array\n                                   float *x_d,        // Input vector\n                                   float *y_d,              // Output vector\n                                   int numRows);            // Number of rows in the matrix\n\nstruct SpmvTestCase {\n    std::vector<float> values;    // Non-zero elements\n    std::vector<int> colIndices;  // Column indices\n    std::vector<int> rowPtr;      // Row pointers\n    std::vector<float> x;         // Input vector\n    std::vector<float> expectedY; // Expected output vector\n    int numRows;                  // Number of rows in the matrix\n};\n\nstd::vector<SpmvTestCase> testCases = {\n    // Test case 0: 3x3 diagonal matrix\n    {{1.0f, 2.0f, 3.0f}, {0, 1, 2}, {0, 1, 2, 3}, {1.0f, 2.0f, 3.0f}, {1.0f, 4.0f, 9.0f}, 3},\n    // Test case 1: 4x4 complex sparsity\n    {{1.0f, 4.0f, 2.0f, 5.0f, 3.0f, 6.0f},\n     {0, 2, 1, 3, 0, 1},\n     {0, 2, 4, 6, 6},\n     {1.0f, 2.0f, 3.0f, 4.0f},\n     {13.0f, 24.0f, 15.0f, 0.0f},\n     4},\n    // Test case 2: 4x4 diagonal matrix\n    {{1.0f, 2.0f, 3.0f, 4.0f},\n     {0, 1, 2, 3},\n     {0, 1, 2, 3, 4},\n     {2.0f, 3.0f, 4.0f, 5.0f},\n     {2.0f, 6.0f, 12.0f, 20.0f},\n     4},\n    // Test case 3: Upper triangular matrix\n    {{1.0f, 2.0f, 3.0f, 4.0f},\n     {0, 1, 2, 3},\n     {0, 1, 2, 3, 4},\n     {1.0f, 1.0f, 1.0f, 1.0f},\n     {1.0f, 2.0f, 3.0f, 4.0f},\n     4},\n    // Test case 4: Large sparse matrix\n    {{1.0f, 2.0f, 3.0f},\n     {0, 2, 3},\n     {0, 1, 2, 2, 3},\n     {1.0f, 2.0f, 3.0f, 4.0f},\n     {1.0f, 6.0f, 0.0f, 12.0f},\n     4},\n    // Test case 5: Symmetric matrix\n    {{1.0f, 2.0f, 3.0f, 4.0f, 5.0f, 6.0f},\n     {0, 1, 1, 2, 0, 2},\n     {0, 2, 4, 6},\n     {1.0f, 2.0f, 3.0f},\n     {5.0f, 18.0f, 23.0f},\n     3},\n    // Test case 6: Single row matrix\n    {{1.0f, 2.0f, 3.0f}, \n      {0, 1, 2}, \n      {0, 3}, \n      {1.0f, 2.0f, 3.0f}, \n      {14.0f}, 1}};\n\nvoid launch() {\n    constexpr int BLOCK_SIZE = 256;   // 8 warps per block\n\n    cudaStream_t stream;\n    CUDA_CHECK(cudaStreamCreate(&stream));\n\n    // Get device properties for occupancy calculation\n    cudaDeviceProp prop;\n    CUDA_CHECK(cudaGetDeviceProperties(&prop, 0));\n    int numberOfMultiProcessors = prop.multiProcessorCount;\n\n    const int rowsPerBlock = BLOCK_SIZE / 32; // 8 rows per block\n    const int sharedMemSizePerBlock = rowsPerBlock * 2 * sizeof(int); // 64 bytes\n\n    // Calculate occupancy-based max blocks per multiprocessor\n    int numberOfBlocksPerMultiProcessor;\n    CUDA_CHECK(cudaOccupancyMaxActiveBlocksPerMultiprocessor(\n        &numberOfBlocksPerMultiProcessor,\n        k_spmvCsrOptimized,\n        BLOCK_SIZE,\n        sharedMemSizePerBlock));\n\n    int maxBlocks = numberOfMultiProcessors * numberOfBlocksPerMultiProcessor;\n\n    // Find maximum buffer dimensions across all test cases\n    size_t maxValuesSize = 0, maxColIndicesSize = 0, maxRowPtrSize = 0, maxXSize = 0;\n    int maxNumRows = 0;\n    for(const auto &tc : testCases) {\n        maxValuesSize = std::max(maxValuesSize, tc.values.size());\n        maxColIndicesSize = std::max(maxColIndicesSize, tc.colIndices.size());\n        maxRowPtrSize = std::max(maxRowPtrSize, tc.rowPtr.size());\n        maxXSize = std::max(maxXSize, tc.x.size());\n        maxNumRows = std::max(maxNumRows, tc.numRows);\n    }\n\n    // Allocate unified buffers once\n    float *values_d, *x_d, *y_d;\n    int *colIndices_d, *rowPtr_d;\n\n    CUDA_CHECK(cudaMallocAsync(&values_d, maxValuesSize * sizeof(float), stream));\n    CUDA_CHECK(cudaMallocAsync(&colIndices_d, maxColIndicesSize * sizeof(int), stream));\n    CUDA_CHECK(cudaMallocAsync(&rowPtr_d, maxRowPtrSize * sizeof(int), stream));\n    CUDA_CHECK(cudaMallocAsync(&x_d, maxXSize * sizeof(float), stream));\n    CUDA_CHECK(cudaMallocAsync(&y_d, maxNumRows * sizeof(float), stream));\n\n    for(const auto &tc : testCases) {\n        // Copy data to pre-allocated buffers\n        CUDA_CHECK(cudaMemcpyAsync(values_d,\n                                   tc.values.data(),\n                                   tc.values.size() * sizeof(float),\n                                   cudaMemcpyHostToDevice,\n                                   stream));\n        CUDA_CHECK(cudaMemcpyAsync(colIndices_d,\n                                   tc.colIndices.data(),\n                                   tc.colIndices.size() * sizeof(int),\n                                   cudaMemcpyHostToDevice,\n                                   stream));\n        CUDA_CHECK(cudaMemcpyAsync(rowPtr_d,\n                                   tc.rowPtr.data(),\n                                   tc.rowPtr.size() * sizeof(int),\n                                   cudaMemcpyHostToDevice,\n                                   stream));\n        CUDA_CHECK(cudaMemcpyAsync(\n            x_d, tc.x.data(), tc.x.size() * sizeof(float), cudaMemcpyHostToDevice, stream));\n        CUDA_CHECK(cudaMemsetAsync(y_d, 0, tc.numRows * sizeof(float), stream));\n\n        // Compute grid size based on occupancy\n        int desiredGridSize = (tc.numRows + rowsPerBlock - 1) / rowsPerBlock;\n        int gridSize = std::min(desiredGridSize, maxBlocks);\n        // Ensure gridSize is at least the number of multiprocessors but does not exceed occupancy limits\n        gridSize = std::max(desiredGridSize, numberOfMultiProcessors);\n        gridSize = std::min(gridSize, maxBlocks);\n\n        // Launch optimized kernel\n        int numRows = tc.numRows;\n        void *args[] = {&values_d, &colIndices_d, &rowPtr_d, &x_d, &y_d, &numRows};\n        CUDA_CHECK(cudaLaunchKernel(\n            (void *)k_spmvCsrOptimized, gridSize, BLOCK_SIZE, args, sharedMemSizePerBlock, stream));\n\n        // Verify results\n        std::vector<float> y_h(tc.numRows);\n        CUDA_CHECK(cudaMemcpyAsync(\n            y_h.data(), y_d, tc.numRows * sizeof(float), cudaMemcpyDeviceToHost, stream));\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n\n        for(int i = 0; i < tc.numRows; ++i) {\n            assert(fabs(y_h[i] - tc.expectedY[i]) < TOLERANCE); // Correctness condition check\n        }\n    }\n\n    // Single cleanup after all test cases\n    CUDA_CHECK(cudaFreeAsync(values_d, stream));\n    CUDA_CHECK(cudaFreeAsync(colIndices_d, stream));\n    CUDA_CHECK(cudaFreeAsync(rowPtr_d, stream));\n    CUDA_CHECK(cudaFreeAsync(x_d, stream));\n    CUDA_CHECK(cudaFreeAsync(y_d, stream));\n    CUDA_CHECK(cudaStreamDestroy(stream));\n}\n\n\n__global__ void k_spmvCsrOptimized(float *values_d,   // Non-zero elements array\n                                   int *colIndices_d, // Column indices array\n                                   int *rowPtr_d,     // Row pointers array\n                                   float *x_d,        // Input vector\n                                   float *y_d,        // Output vector\n                                   int numRows) {     // Number of rows in the matrix\n", "test": "int main() {\n    launch();\n}\n", "example_test": "    @example_test\n", "cuda_toolkit": "12.2"}
{"task_id": "CUDA/118", "date": "2025-03-31", "prompt": "Write a CUDA kernel to compute the total angular momentum of a system of particles using a warp parallel reduction. Each thread should be responsible for computing the angular momentum contributed by one particle.\n\nThe kernel should have the following signature is __global__ void k_computeAngularMomentum(const float *mass_d, const float3 *pos_d, const float3 *vel_d, float3 *totalAM_d, unsigned int particleCount), where mass_d is an array of particle masses, pos_d is an array of float3 containing particle positions with respect to the origin, vel_d is an array of float3 containing particle velocities, totalAM_d is a pointer to a single float3 in global memory where the total angular momentum (Lx, Ly, Lz) is stored, and particleCount is the total number of particles in the system.\n\n>>> k_computeAngularMomentum(mass_d:{4.370861e+00f, 9.556429e+00f},\n                             pos_d:{{2.319939e+00f, 9.865848e-01f, -3.439814e+00f}, {-3.440055e+00f, -4.419164e+00f, 3.661761e+00f}},\n                             vel_d:{{2.022300e-01f, 4.161452e-01f, -9.588310e-01f}, {9.398197e-01f, 6.648853e-01f, -5.753218e-01f}},\n                             totalAM_d:{0.0f, 0.0f, 0.0f},\n                             particleCount:2) -> totalAM_d: {3.152112e+00, 2.065611e+01, 2.117977e+01}\n\n>>> k_computeAngularMomentum(mass_d:{7.752083e+00f, 2.799273e+00f},\n                             pos_d:{{-1.642612e+00f, -3.415288e+00f, -1.467934e+00f}, {-1.489164e+00f, -3.154448e+00f, -2.816532e-02f}},\n                             vel_d:{{-4.435090e-01f, -6.504617e-01f, 3.839987e-01f}, {-7.099691e-01f, -5.235986e-01f, -7.185734e-01f}},\n                             totalAM_d:{0.0f, 0.0f, 0.0f},\n                             particleCount:2) -> totalAM_d: {-1.126471e+01, 6.997188e+00, -7.545882e+00}\n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_70", "ld_flags": "", "declaration": "\n#include <stdio.h>\n#include <stdlib.h>\n#include <cassert>\n\n#include <cuda_runtime.h>\n\n#define CUDA_CHECK(call)                                                                   \\\ndo {                                                                                       \\\n    cudaError_t error = call;                                                              \\\n    if(error != cudaSuccess) {                                                             \\\n        fprintf(stderr,                                                                    \\\n            \"CUDA Error: %s at %s:%d\\n\",                                                   \\\n            cudaGetErrorString(error),                                                     \\\n            __FILE__,                                                                      \\\n            __LINE__);                                                                     \\\n        exit(error);                                                                       \\\n    }                                                                                      \\\n} while(0)\n\n//CUDA Kernel to compute total angular momentum using warp-level reduction signature\n__global__ void k_computeAngularMomentum(const float *mass_d, const float3 *pos_d, const float3 *vel_d, float3 *totalAM_d, unsigned int particleCount);\n\nvoid launch() {\n    // Test case constant params\n    const unsigned int NUM_TEST_CASES = 7;\n    const unsigned int MAX_PARTICLE_COUNT = 128;\n    const unsigned int BLOCK_SIZE = 256;\n    const float TOL = 1e-4f; // For floating point validation\n    const float3 ZERO_VEC = {0.0f, 0.0f, 0.0f}; // For initializing totalAM_d\n\n    //Declaring grid size using CUDA device properties\n    cudaDeviceProp deviceProp;\n    int currentDevice;\n    CUDA_CHECK(cudaGetDevice(&currentDevice));\n    CUDA_CHECK(cudaGetDeviceProperties(&deviceProp, currentDevice));\n\n    int numSMs = deviceProp.multiProcessorCount;\n    int maxBlocksPerSM = deviceProp.maxBlocksPerMultiProcessor;\n    int numBlocks = numSMs * maxBlocksPerSM;\n\n    // Util functions for vector operations\n    auto vecDiff = [](const float3 &a, const float3 &b) -> float3 {\n            return make_float3(a.x - b.x, a.y - b.y, a.z - b.z);\n    };\n    \n    auto vecNorm = [](const float3 &v) -> float {\n            return sqrtf(v.x * v.x + v.y * v.y + v.z * v.z);\n    };\n\n    // Test case params and validation results\n    unsigned int particleCountPerCase[NUM_TEST_CASES] = {2,4,8,16,32,33,128};\n    \n    // Array of particle masses\n    float mass_h[NUM_TEST_CASES][MAX_PARTICLE_COUNT] = {\n        {6.305726e+00f, 3.704031e+00f},\n        {6.305726e+00f, 3.704031e+00f, 3.452430e+00f, 2.186230e+00f},\n        {2.251249e+00f, 8.871612e+00f, 9.438993e+00f, 3.584668e+00f, 8.645597e+00f, 9.366398e+00f, 7.400962e+00f, 7.247701e+00f},\n        {4.331704e+00f, 4.898828e+00f, 2.548335e+00f, 5.171834e+00f, 5.511504e+00f, 6.763835e+00f, 5.561555e+00f, 8.112208e+00f, 9.472290e+00f, 8.975634e+00f, 4.200112e+00f, 6.374664e+00f, 9.971392e+00f, 8.030278e+00f, 6.658707e+00f, 8.125082e+00f},\n        {2.275266e+00f, 5.098696e+00f, 9.797214e+00f, 2.016401e+00f, 1.171289e+00f, 1.328442e+00f, 8.661542e+00f, 9.056560e+00f, 8.742530e+00f, 2.549934e+00f, 2.619827e+00f, 8.414488e+00f, 6.736075e+00f, 4.372297e+00f, 1.593920e+00f, 4.680943e+00f, 3.947108e+00f, 4.839671e+00f, 5.771972e+00f, 9.963538e+00f, 9.108752e+00f, 6.941498e+00f, 6.377804e+00f, 6.909125e+00f, 6.525471e+00f, 1.278987e+00f, 2.626591e+00f, 2.935518e+00f, 1.605198e+00f, 4.397502e+00f, 9.975583e+00f, 7.712607e+00f},\n        {2.849786e+00f, 7.465053e+00f, 7.576144e+00f, 9.680149e+00f, 6.867295e+00f, 8.921378e+00f, 3.516657e+00f, 3.632348e+00f, 2.191891e+00f, 1.503679e+00f, 1.340668e+00f, 6.695363e+00f, 1.525732e+00f, 5.048642e+00f, 7.834996e+00f, 2.906834e+00f, 7.071950e+00f, 9.457268e+00f, 7.231824e+00f, 1.217171e+00f, 6.151970e+00f, 8.008360e+00f, 9.859982e+00f, 2.863102e+00f, 6.103044e+00f, 4.954607e+00f, 7.174405e+00f, 9.687495e+00f, 5.436009e+00f, 3.928871e+00f, 2.751977e+00f, 9.776078e+00f, 5.185234e+00f},\n        {6.230005e+00f, 4.989229e+00f, 1.163098e+00f, 3.555043e+00f, 4.498519e+00f, 4.846625e+00f, 1.951974e+00f, 2.702023e+00f, 9.208075e+00f, 2.410063e+00f, 4.480112e+00f, 1.170238e+00f, 8.970317e+00f, 1.559257e+00f, 7.238318e+00f, 2.015014e+00f, 2.542270e+00f, 3.559504e+00f, 8.142887e+00f, 8.896988e+00f, 5.111900e+00f, 5.827071e+00f, 2.777854e+00f, 7.896147e+00f, 9.338067e+00f, 5.151153e+00f, 3.030848e+00f, 9.451649e+00f, 9.499514e+00f, 2.648732e+00f, 2.991516e+00f, 7.706479e+00f, 3.748563e+00f, 8.329482e+00f, 5.660578e+00f, 4.432099e+00f, 5.603123e+00f, 7.825382e+00f, 4.945275e+00f, 2.901776e+00f, 9.977221e+00f, 1.609963e+00f, 6.233970e+00f, 4.647338e+00f, 9.196743e+00f, 2.595348e+00f, 1.132503e+00f, 8.986875e+00f, 7.807049e+00f, 9.555057e+00f, 9.040251e+00f, 3.662513e+00f, 6.169474e+00f, 2.276883e+00f, 5.234349e+00f, 8.037710e+00f, 6.312180e+00f, 4.532503e+00f, 3.383346e+00f, 2.739691e+00f, 3.947001e+00f, 3.634520e+00f, 2.501058e+00f, 9.497878e+00f, 4.517690e+00f, 5.822381e+00f, 8.635795e+00f, 7.518073e+00f, 7.284304e+00f, 6.553366e+00f, 1.801319e+00f, 4.439465e+00f, 7.729893e+00f, 2.885712e+00f, 4.899245e+00f, 9.678103e+00f, 9.918964e+00f, 4.713537e+00f, 8.163313e+00f, 3.315258e+00f, 3.279986e+00f, 5.908838e+00f, 9.065317e+00f, 6.877554e+00f, 4.727919e+00f, 4.586776e+00f, 7.401623e+00f, 4.574008e+00f, 4.185090e+00f, 1.489334e+00f, 7.153626e+00f, 5.608767e+00f, 6.543734e+00f, 3.737551e+00f, 2.104480e+00f, 7.206819e+00f, 6.861120e+00f, 6.679341e+00f, 3.967432e+00f, 5.570528e+00f, 8.543704e+00f, 4.115218e+00f, 7.027076e+00f, 2.335130e+00f, 4.801848e+00f, 2.868979e+00f, 7.248571e+00f, 7.540494e+00f, 6.159638e+00f, 3.657510e+00f, 3.782389e+00f, 8.993936e+00f, 7.962289e+00f, 1.535879e+00f, 5.509607e+00f, 9.412314e+00f, 1.844778e+00f, 7.550896e+00f, 6.169221e+00f, 9.601748e+00f, 5.457664e+00f, 5.980261e+00f, 2.300332e+00f, 6.672713e+00f, 7.168782e+00f, 7.404363e+00f, 8.439940e+00f, 3.308550e+00f}\n    };\n\n    // Array of particle position vectors\n    float3 pos_h[NUM_TEST_CASES][MAX_PARTICLE_COUNT] = {\n        {{-2.275078e+00f, -3.681967e+00f, 2.129892e+00f}, {-4.756183e+00f, 4.598780e+00f, -4.431842e+00f}},\n        {{2.129892e+00f, -4.756183e+00f, 4.598780e+00f}, {-4.431842e+00f, -4.658658e+00f, 4.768967e+00f}, {3.881811e+00f, 4.415114e+00f, 3.964936e+00f}, {-3.184883e+00f, 4.143817e-01f, -2.354646e+00f}},\n        {{-3.071192e+00f, 2.937396e+00f, 8.205211e-01f}, {1.242876e+00f, -1.358968e+00f, -3.994811e+00f}, {-4.356758e+00f, 5.245913e-01f, 4.083174e+00f}, {1.313590e+00f, 2.095270e+00f, 4.966117e+00f},\n        {4.335111e+00f, -4.017012e+00f, -6.681991e-01f}, {-3.886086e+00f, -2.924219e+00f, 1.165533e+00f}, {-4.974482e+00f, 2.402400e+00f, 5.673252e-01f}, {-3.406768e+00f, -1.100228e+00f, -3.278599e+00f}},\n        {{-2.906986e+00f, -4.173940e+00f, 2.410393e+00f}, {-1.914883e+00f, 4.854140e+00f, -2.080884e+00f}, {-3.875106e+00f, 1.252599e+00f, 1.101421e+00f}, {-4.581864e+00f, -4.924020e+00f, -4.099555e+00f},\n        {-1.462398e+00f, -2.184415e+00f, -3.104460e+00f}, {1.138444e-01f, -1.776347e+00f, 2.393547e+00f}, {3.912554e+00f, 4.907492e+00f, -1.227119e+00f}, {-4.480234e+00f, 4.065798e+00f, 3.156210e+00f}, {2.829215e+00f, -1.974650e+00f, -4.268644e+00f}, {4.717871e+00f, -2.468360e+00f, 4.715707e+00f}, {4.874876e+00f, -1.138112e+00f, 5.252256e-02f}, {-1.714767e-01f, 4.900725e+00f, 3.261975e+00f}, {-1.070212e+00f, 4.825401e+00f, 4.790009e+00f}, {-3.998948e+00f, 3.996485e+00f, 4.894719e+00f}, {-1.724842e+00f, 2.894416e+00f, -2.670056e+00f}, {-1.700870e+00f, 1.938847e+00f, 4.078283e+00f}},\n        {{2.045208e+00f, -4.484117e+00f, -1.305178e+00f}, {4.618757e+00f, 1.410568e+00f, -4.537319e+00f}, {3.594376e+00f, -6.412062e-01f, -4.888710e+00f}, {3.844515e+00f, -1.948384e-01f, 2.155679e+00f}, {2.503676e+00f, 3.070157e-01f, 1.556055e+00f}, {-4.969348e+00f, 2.642597e+00f, 4.901001e+00f}, {-4.458138e+00f, 3.434931e-01f, 2.305594e+00f}, {3.688495e+00f, -3.629727e+00f, 1.376880e+00f}, {-3.937233e-01f, 3.843142e+00f, 1.715606e+00f}, {-2.193628e+00f, -1.210434e+00f, -1.187508e+00f}, {3.426227e+00f, -2.682326e+00f, -4.943444e+00f}, {-1.312654e+00f, -4.954494e+00f, -3.287589e+00f}, {4.579639e+00f, 4.650867e+00f, 3.170821e+00f}, {2.829236e+00f, -1.410877e+00f, -3.370172e+00f}, {4.568838e+00f, 5.432685e-01f, 4.057890e+00f}, {-4.001314e+00f, -1.396819e+00f, -1.475678e+00f}, {-1.201569e-01f, 4.549744e+00f, -1.772546e+00f}, {-3.229885e+00f, -4.624727e+00f, 1.155209e+00f}, {2.320020e+00f, -3.329764e+00f, -8.366543e-01f}, {6.806556e-01f, 4.099345e+00f, 3.124596e+00f}, {-1.683635e-01f, 5.244406e-01f,   4.795851e+00f}, {3.488241e+00f, 1.040715e+00f, -1.208681e+00f}, {3.500111e+00f, -3.804805e+00f, 4.918727e+00f}, {6.309077e-01f, -1.706381e-01f, 2.414668e+00f}, {-4.655891e+00f, 3.058487e+00f, 4.697628e+00f}, {-7.106831e-01f, 2.857911e+00f, 3.992337e+00f}, {2.471302e+00f, 3.314782e+00f, 2.378608e+00f}, {-3.606331e+00f, 5.921252e-01f, 6.570024e-01f}, {-2.641113e+00f, -4.378033e-01f, 2.399127e+00f}, {8.068738e-01f, 2.761862e+00f, -2.483472e+00f}, {-4.380830e+00f, -1.435362e+00f, 1.096672e+00f}, {-1.925850e+00f, -1.262309e+00f, 4.151771e+00f}},\n        {{4.035610e-01f, 2.763502e+00f, -3.329502e+00f}, {2.557337e+00f, -3.500076e+00f, -3.954062e+00f}, {-6.728450e-01f, 4.525556e+00f, -3.817499e+00f}, {-4.554858e+00f, -5.590220e-01f, 1.416127e+00f}, {-3.301355e+00f, -9.415395e-01f, 4.630525e+00f}, {4.306428e+00f, 1.479900e+00f, -1.221517e+00f}, {-3.594946e-01f, -1.016933e+00f, -2.850603e-01f}, {3.021212e+00f, -2.225819e+00f, 4.796696e+00f}, {-4.366450e+00f, -3.940294e+00f, 3.085883e+00f}, {-3.589154e-01f, 7.613556e-01f, -1.577444e+00f}, {4.400881e+00f, 2.563990e+00f, 1.134522e+00f}, {4.357833e+00f, 4.192998e+00f, -9.318069e-02f}, {2.300874e+00f, 3.324171e+00f, 1.381483e+00f}, {-4.251402e-01f, -2.429702e+00f, -2.319675e+00f}, {8.415338e-01f, 3.363436e+00f, 3.360623e+00f}, {-2.356934e+00f, 9.418337e-01f, -3.803297e+00f}, {-3.109041e+00f, -1.388294e+00f, -1.589252e+00f}, {-4.890564e+00f, 1.376279e+00f, 3.502676e+00f}, {2.491196e+00f, -3.448314e+00f, -2.246576e+00f}, {-7.879013e-01f, -4.377102e+00f, 3.056221e+00f}, {-4.501870e-01f, -2.726619e+00f, -4.453272e+00f}, {4.142271e+00f, -8.397415e-01f, 2.022879e+00f}, {4.284500e+00f, 1.688954e+00f, -1.847844e-01f}, {1.223494e+00f, 4.145685e+00f, 3.926884e+00f}, {-2.376592e-02f, 1.902846e+00f, -1.383373e+00f}, {-2.617380e+00f, 4.455689e+00f, -8.598321e-01f}, {2.698901e+00f, -2.097317e+00f, 1.216935e+00f}, {2.830530e+00f, 8.142686e-01f, 3.230621e+00f}, {3.013512e+00f, 2.999836e+00f, 4.116197e+00f}, {-4.115034e+00f, -2.169927e+00f, 4.326222e+00f}, {-3.288338e+00f, 6.965108e-01f, 4.149065e+00f}, {3.265583e+00f, 3.004221e+00f, 1.831369e+00f}, {7.552939e-01f, -6.938717e-01f, 4.316593e+00f}},\n        {{1.965909e+00f, -3.253533e+00f, -4.070023e+00f}, {-3.835147e+00f, 3.680952e+00f, 2.941125e+00f}, {1.081385e+00f, 1.339433e+00f, 2.524831e+00f}, {3.227284e+00f, 2.823747e+00f, 1.378452e+00f}, {-2.261339e+00f, 8.897815e-01f, 3.866131e+00f}, {-3.877760e+00f, 3.048854e+00f, 1.488789e+00f}, {-2.793684e+00f, 4.763263e+00f, 2.434178e+00f}, {-2.271716e+00f, -3.327556e+00f, 2.585653e+00f}, {8.532545e-01f, 4.434804e+00f, -2.415042e+00f}, {-2.074468e+00f, -4.904184e-01f, 8.827049e-01f}, {2.815784e+00f, 1.213077e+00f, -1.350096e+00f}, {1.845368e+00f, -3.166410e+00f, 4.272926e-01f}, {4.793953e+00f, 3.203107e+00f, 2.327675e+00f}, {3.548812e-01f, -4.538910e+00f, 1.490019e+00f}, {-3.045772e+00f, -3.822388e+00f, 2.982699e+00f}, {9.014031e-01f, -4.934777e+00f, 4.103786e+00f}, {4.994319e+00f, 4.700922e+00f, 5.473588e-01f}, {1.694579e+00f, 1.197840e+00f, -2.529696e+00f}, {-3.183652e+00f, -1.603417e+00f, -3.845008e+00f}, {2.217615e-02f, -5.643119e-01f, -2.532745e+00f}, {4.400327e+00f, -1.932102e+00f, 2.140548e+00f}, {-2.109469e+00f, -9.999188e-01f, 1.647233e-01f}, {1.301446e+00f, -1.341591e+00f, -3.154323e+00f}, {-2.000458e+00f, -4.747647e+00f, -4.430450e+00f}, {3.347463e+00f, -3.297064e+00f, 4.813834e+00f}, {4.335286e+00f, -6.877313e-01f, 3.508019e+00f}, {-1.024601e+00f, 5.114389e-01f, 4.931698e+00f}, {4.210388e+00f, 3.007665e+00f, -4.769697e+00f}, {-1.823522e+00f, -4.427250e-01f, -1.313068e+00f}, {1.267447e+00f, -8.828737e-01f, 3.453461e+00f}, {-1.506951e+00f, -3.453529e+00f, -1.918243e+00f}, {2.130241e+00f, -1.587020e+00f, -3.077999e-01f}, {-4.236825e+00f, 3.868386e+00f, 2.351874e+00f}, {1.592374e+00f, -4.553501e-01f, -1.472028e+00f}, {-2.489038e+00f, 2.037408e-01f, 1.945853e+00f}, {1.506494e+00f, 4.602473e+00f, 3.441171e+00f}, {-3.574834e+00f, 7.608652e-01f, 1.159596e+00f}, {-2.889530e+00f, 2.394566e+00f, 3.767891e+00f}, {3.329894e+00f, -3.753486e+00f, 4.462867e+00f}, {-3.930464e+00f, -2.968160e+00f, -7.344604e-01f}, {-1.528839e+00f, -5.057491e-01f, 4.273228e+00f}, {2.663799e+00f, -3.031203e+00f, -1.502557e+00f}, {-2.625264e+00f, 2.657936e+00f, -3.037730e+00f}, {3.713301e+00f, 3.879743e+00f, -2.218921e+00f}, {-5.613011e-01f, -4.238440e+00f, 2.364269e+00f}, {-1.689198e+00f, 1.050171e+00f, -4.407266e+00f}, {-1.400140e-01f, -1.974148e+00f, -4.046062e+00f}, {-4.788751e+00f, -2.517792e+00f, 1.754034e+00f}, {7.706456e-01f, 4.740491e-01f, 1.415437e+00f}, {-4.317611e+00f, 1.925294e+00f, 3.444596e+00f}, {3.225085e+00f, 6.611386e-01f, -1.525325e+00f}, {-4.494792e+00f, -3.887234e+00f, 1.967641e+00f}, {-3.567317e+00f, -8.982728e-01f, -2.022578e+00f}, {2.104661e+00f, -3.429204e+00f, -2.002287e+00f}, {2.212588e+00f, 1.394811e+00f, 1.392552e-01f}, {-4.474920e+00f, 3.097765e+00f, -1.583866e+00f}, {-7.123605e-01f, -5.362802e-01f, 2.461345e+00f}, {-2.086424e+00f, -1.235031e+00f, -4.424115e+00f}, {1.792487e+00f, -7.629645e-02f, -2.727298e+00f}, {3.102637e+00f, 4.978288e+00f, 2.924435e+00f}, {3.158732e+00f, -2.017574e+00f, 2.590222e+00f}, {-1.907420e-01f, 4.824571e+00f, -2.072636e+00f}, {1.756453e+00f, -4.995620e+00f, 1.822817e+00f}, {2.100254e+00f, 2.581627e+00f, 4.050212e+00f}, {-4.735670e+00f, -4.026481e+00f, 4.015223e+00f}, {-6.588210e-01f, 1.026186e+00f, 4.142759e+00f}, {-5.336795e-01f, -4.178545e+00f, 4.527218e+00f}, {4.672777e+00f, -1.706113e+00f, -1.658989e+00f}, {3.734219e+00f, -1.603940e+00f, -4.530660e+00f}, {-1.170577e+00f, -3.178735e+00f, 3.583523e+00f}, {-3.078864e+00f, 1.682949e-01f, -4.358176e+00f}, {2.251821e+00f, 4.947627e+00f, 2.950648e+00f}, {5.860130e-01f, 2.602646e+00f, -1.685745e+00f}, {2.462573e-01f, 7.674553e-01f, -1.477721e+00f}, {-1.103454e+00f, 1.420827e+00f, -2.836279e+00f}, {2.460136e+00f, -3.625235e+00f, 1.797549e+00f}, {2.908060e+00f, 3.827788e+00f, -5.290062e-01f}, {7.270028e-01f, 4.227972e+00f, -4.007816e+00f}, {-4.118544e+00f, 1.325535e+00f, -3.668687e+00f}, {7.106094e-01f, -3.621823e+00f, 2.538032e+00f}, {-4.280569e+00f, -3.960515e-01f, -4.505357e-01f}, {-4.737720e+00f, -4.491311e+00f, -1.350808e+00f}, {-5.157021e-01f, 1.128148e+00f, 1.862121e+00f}, {-1.723041e-01f, -5.870779e-01f, -3.189984e+00f}, {-2.232272e+00f, 1.665155e+00f, -6.127252e-01f}, {-2.045553e+00f, -1.781240e+00f, -2.120641e+00f}, {8.222538e-02f, 3.864646e+00f, 4.890926e+00f}, {-1.965659e+00f, 7.653501e-01f, -1.165723e+00f}, {-7.954939e-02f, -1.382593e+00f, -2.953230e+00f}, {2.902025e+00f, 1.266589e+00f, 4.025815e+00f}, {-4.069696e+00f, -3.334105e+00f, 4.276571e+00f}, {-2.434192e+00f, -3.088275e+00f, -4.500433e+00f}, {-4.528368e+00f, -2.631936e+00f, 2.484423e+00f}, {1.338998e+00f, -1.842518e+00f, 1.913905e+00f}, {-3.300430e+00f, 2.946509e+00f, 9.025896e-01f}, {1.750384e+00f, 3.813303e-01f, -3.524242e+00f}, {-4.881520e+00f, -3.099045e+00f, -2.016518e+00f}, {3.560684e+00f, 3.083459e-01f, -3.312994e+00f}, {-1.751002e+00f, -4.317727e+00f, -4.456614e+00f}, {2.259564e+00f, 2.144389e+00f, -2.132514e+00f}, {4.649236e+00f, -1.139263e+00f, -4.437564e+00f}, {-4.974045e+00f, -1.085910e+00f, 2.887737e+00f}, {-2.166686e+00f, -2.949709e-01f, 1.234197e+00f}, {-1.798021e+00f, 3.933870e-02f, 3.864961e+00f}, {9.022241e-01f, -1.694293e+00f, -3.245147e+00f}, {4.328768e+00f, 1.080880e-02f, 3.320421e+00f}, {-2.558163e+00f, 4.926327e+00f, 2.584890e-01f}, {1.845173e-01f, -4.858024e+00f, -4.514737e-01f}, {3.657390e+00f, -3.872755e+00f, 4.038770e+00f}, {6.156087e-01f, -3.543546e+00f, -4.335863e+00f}, {2.734746e+00f, -1.282358e+00f, -4.707343e+00f}, {3.592180e+00f, -3.871679e+00f, -1.028764e+00f}, {4.071579e+00f, 4.330583e+00f, -2.040866e+00f}, {3.342813e+00f, 3.736383e+00f, 2.270415e-01f}, {1.412291e+00f, -2.102275e-01f, 4.992956e+00f}, {-2.359104e+00f, 4.069505e+00f, 5.468698e-01f}, {-3.082861e+00f, -3.821312e+00f, -4.700109e+00f}, {2.623562e+00f, -1.107290e+00f, -2.678829e+00f}, {1.326333e+00f, -4.696346e+00f, -3.956976e+00f}, {-2.026752e+00f, 3.336470e+00f, 1.124633e+00f}, {4.557022e+00f, -1.730802e+00f, -2.257733e+00f}, {4.552738e+00f, 4.235761e+00f, -7.469592e-01f}, {-2.100109e+00f, -1.408197e+00f, -1.306132e+00f}, {2.702259e+00f, 1.358539e+00f, -3.925478e+00f}, {2.941458e+00f, -1.821444e+00f, 3.690075e+00f}, {3.603119e+00f, -4.574076e+00f, 4.387871e+00f}, {-3.438464e+00f, 1.427378e+00f, -6.694215e-01f}, {-4.629121e+00f, -2.420004e+00f, -2.514569e+00f}}\n    };\n\n    // Array of particle velocity vectors\n    float3 vel_h[NUM_TEST_CASES][MAX_PARTICLE_COUNT] = {\n        {{-9.317315e-01f, 9.537933e-01f, 7.763622e-01f}, {8.830227e-01f, 7.929872e-01f, -6.369766e-01f}},\n        {{2.858950e-01f, -8.132153e-01f, 9.140813e-01f}, {2.353761e-01f, 5.988926e-01f, -9.769579e-01f}, {-3.992917e-01f, -5.506736e-01f, -5.077804e-01f}, {1.830518e-02f, 4.711822e-01f, -2.127832e-01f}},\n        {{6.067519e-01f, 4.326032e-04f, -1.174910e-01f}, {-1.902734e-01f, 4.381490e-01f, -6.194583e-01f}, {7.214697e-02f, -3.084746e-01f, 4.023629e-01f}, {9.407850e-01f, -4.839484e-01f, 4.301702e-01f},\n        {-8.738118e-01f, 3.354260e-01f, 9.825423e-02f}, {1.966917e-01f, 6.346071e-01f, -7.291458e-01f}, {-1.768807e-01f, -3.884967e-01f, 5.398672e-01f}, {9.102120e-01f, -5.737484e-01f, -5.496022e-01f}},\n        {{-3.046651e-01f, 9.546707e-01f, 2.889966e-01f}, {-9.911433e-01f, -7.583087e-03f, -7.356965e-02f}, {-3.253570e-02f, -1.178742e-01f, -1.107645e-02f}, {6.266414e-01f, -9.510395e-01f, 3.074681e-01f},\n        {-4.737965e-01f, -5.279757e-01f, -9.723446e-01f}, {9.753135e-01f, -2.303998e-01f, 7.685216e-01f}, {-8.106697e-01f, -5.446122e-01f, 4.468894e-01f}, {7.726008e-01f, 3.953982e-01f, 2.322978e-01f}, {-9.583548e-01f, 8.045935e-01f, -5.386540e-01f}, {-3.171421e-01f, -3.223583e-01f, 7.973992e-01f}, {1.347935e-01f, -4.699046e-01f, 1.682705e-01f}, {-8.933615e-01f, 9.763501e-01f, 3.904319e-01f}, {-7.163578e-01f, 9.807975e-01f, 7.132301e-01f}, {-5.742055e-01f, 5.440878e-02f, -1.186284e-01f}, {3.697447e-01f, -8.991011e-01f, -9.729674e-02f}, {-9.282434e-01f, 2.513422e-01f, 6.472747e-01f}},\n        {{8.525970e-01f, -9.181121e-02f, 6.097633e-01f}, {2.808775e-02f, -1.699356e-01f, -7.463535e-01f}, {7.124113e-01f, 8.057005e-01f, 3.219395e-01f}, {-4.346353e-01f, 2.098522e-01f, -8.242064e-01f}, {-3.794995e-02f, 1.383328e-01f, 4.930081e-01f}, {-6.102952e-03f, -5.806683e-01f, 5.992542e-01f}, {3.920523e-01f, -1.296073e-01f, 5.180777e-01f}, {8.744481e-01f, 9.641043e-01f, 6.909258e-01f}, {-1.605179e-01f, -3.184043e-01f, 3.430406e-01f}, {3.751722e-02f, 2.301782e-01f, -3.556249e-02f}, {-8.166144e-01f, -2.259420e-01f, -3.144305e-01f}, {2.617904e-01f, 1.610814e-01f, 8.932514e-01f}, {-1.578655e-01f, 1.772121e-01f, 8.388495e-02f}, {-2.733801e-01f, 2.768214e-01f, 4.766717e-03f}, {-1.309701e-01f, -1.022093e-01f, -6.986226e-01f}, {-2.735330e-01f, -3.548982e-01f, 2.360768e-01f}, {7.457934e-02f, -8.898571e-04f, 2.033364e-01f}, {-2.643425e-01f, 3.650686e-02f, -8.201458e-01f}, {-5.480026e-02f, 7.225544e-01f, 6.722581e-01f}, {6.266480e-01f, 9.249440e-01f, -7.367876e-02f}, {7.528203e-01f, 5.752368e-01f, 1.414387e-01f}, {-8.348589e-01f, -7.541614e-01f, -4.926441e-01f}, {-7.023179e-01f, -7.789850e-02f, 8.081877e-01f}, {4.219343e-01f, -9.497321e-01f, 2.783211e-01f}, {5.446771e-01f, 4.830468e-01f, -9.594187e-01f}, {-9.431053e-01f, 3.354955e-01f, -1.033344e-01f}, {6.259166e-01f, 3.335942e-01f, 9.829645e-01f}, {4.246914e-01f, -8.863952e-01f, -8.797460e-01f}, {4.887730e-01f, 2.044909e-02f, -6.867790e-01f}, {9.724896e-01f, -7.735108e-01f, 2.725900e-01f}, {4.144672e-01f, -6.783517e-02f, 7.797414e-01f}, {4.302712e-01f, 6.261204e-01f, 5.720875e-01f}},\n        {{9.684361e-01f, 7.234718e-01f, -5.573957e-02f}, {8.474102e-02f, -8.187421e-01f, 8.380908e-01f}, {-2.493450e-01f, -5.069617e-01f, 7.534076e-01f}, {-2.008272e-01f, 2.060775e-01f, -8.724753e-01f}, {-3.634924e-01f, 4.717516e-01f, 5.452312e-01f}, {-7.708534e-01f, 1.684785e-01f, -4.237073e-01f}, {7.648034e-02f, -9.898344e-01f, 5.538969e-01f}, {-6.604468e-01f, 6.899662e-01f, -3.977065e-01f}, {-7.287515e-01f, 7.898627e-02f, 3.215552e-01f}, {-3.400924e-01f, -7.743736e-01f, -9.418629e-01f}, {5.509237e-01f, -5.615863e-02f, 7.927946e-02f}, {-8.431290e-01f, 8.548437e-01f, -3.983287e-01f}, {-8.336574e-01f, 4.839913e-01f, -8.766864e-01f}, {9.716983e-01f, -8.929457e-01f, 8.775479e-01f}, {6.835198e-01f, 9.587708e-02f, 6.084127e-03f}, {-5.626560e-01f, 5.978458e-01f, 1.111874e-01f}, {-8.074763e-01f, -4.008999e-01f, 5.303399e-01f}, {-4.921071e-01f, 7.347534e-01f, -5.582055e-01f}, {-6.788821e-01f, 6.675236e-01f, -8.891133e-02f}, {5.005561e-01f, 4.089506e-01f, 8.980394e-01f}, {9.221888e-01f, 3.301190e-01f, -2.017709e-01f}, {-8.815134e-01f, 7.769710e-01f, 9.323795e-01f}, {9.062560e-01f, 3.588009e-01f, -5.086121e-01f}, {-9.388563e-01f, 6.177755e-01f, -3.126098e-01f}, {7.829403e-01f, 9.607211e-01f, -2.794813e-01f}, {-8.895297e-02f, -7.347724e-01f, -9.518680e-01f}, {6.147623e-01f, -3.134223e-01f, 7.721085e-01f}, {-4.789447e-01f, -3.315623e-01f, 2.347221e-01f}, {2.799664e-01f, -9.377564e-01f, -2.348072e-01f}, {9.826531e-01f, -1.401322e-01f, 5.346533e-01f}, {4.958692e-01f, -9.714148e-01f, -3.532109e-01f}, {-9.228343e-01f, -9.044589e-01f, -1.161189e-03f}, {-8.329301e-01f, -7.048896e-01f, -5.459033e-01f}},\n        {{-9.075296e-01f, 9.842724e-01f, 5.079822e-01f}, {7.370959e-01f, 3.133695e-01f, -1.599016e-01f}, {-5.466570e-01f, 5.592505e-01f, -3.661158e-01f}, {9.068619e-02f, -3.021593e-01f, -6.610025e-01f}, {8.536022e-01f, -1.004034e-01f, -8.019088e-01f}, {8.909002e-02f, -7.037996e-01f, -5.310144e-01f}, {-7.654121e-01f, 7.069585e-02f, 8.477689e-01f}, {7.240063e-02f, -6.682866e-01f, 2.734422e-01f}, {6.976751e-01f, 2.055452e-01f, -4.004589e-01f}, {-2.285962e-01f, -6.958111e-01f, 2.366111e-01f}, {-3.365386e-01f, 6.111090e-01f, -1.009735e-01f}, {7.023978e-01f, -6.242963e-01f, -6.335863e-01f}, {1.756565e-01f, 6.747211e-02f, 3.334539e-01f}, {-4.702891e-01f, -1.782619e-01f, -8.862601e-01f}, {8.590546e-01f, 1.864208e-01f, -9.188985e-01f}, {4.858919e-01f, -9.039443e-02f, -9.306768e-01f}, {9.086179e-01f, 7.591340e-01f, -4.481277e-01f}, {8.440644e-01f, -4.165405e-01f, -6.373346e-01f}, {5.647987e-01f, 9.517160e-01f, 7.718711e-01f}, {-3.194496e-01f, 2.331052e-01f, -8.953381e-01f}, {2.702734e-01f, 1.486700e-01f, 8.992223e-01f}, {-9.957747e-02f, -2.346888e-01f, 7.453298e-01f}, {4.103107e-01f, -4.237243e-01f, 3.005492e-01f}, {-1.292491e-01f, 6.531071e-01f, -8.083789e-01f}, {3.681836e-01f, 9.299848e-01f, -9.444864e-01f}, {-6.628579e-01f, 2.371312e-01f, 5.310897e-01f}, {8.013173e-01f, -3.479197e-01f, 1.753383e-01f}, {-3.743907e-02f, 1.165725e-01f, -6.638402e-02f}, {-8.594336e-01f, 1.652132e-01f, 1.834068e-01f}, {-9.856852e-01f, -2.197727e-01f, 4.463081e-01f}, {-9.117802e-01f, -7.105815e-01f, -3.489779e-01f}, {-7.870656e-01f, 4.596592e-01f, -1.458405e-01f}, {-6.602142e-01f, 1.415942e-01f, 6.413746e-01f}, {-1.664620e-01f, -3.057376e-01f, -1.827227e-01f}, {9.001108e-01f, -8.020807e-01f, 1.635986e-01f}, {3.732434e-02f, -7.387534e-01f, 8.807275e-02f}, {-3.155561e-01f, -5.828751e-01f, 4.962806e-01f}, {6.227654e-01f, 9.324084e-01f, -7.818404e-01f}, {5.515871e-01f, 7.208932e-01f, 2.326277e-01f}, {8.743528e-01f, -4.359421e-01f, 9.739390e-01f}, {2.180200e-01f, 4.578781e-02f, 5.943890e-01f}, {-9.889423e-01f, -7.567531e-02f, -5.926664e-01f}, {3.275745e-01f, 4.298897e-01f, 5.468119e-01f}, {-4.639629e-01f, -5.302101e-01f, -7.701837e-01f}, {9.203755e-01f, -1.958658e-02f, -1.918448e-01f}, {-4.650514e-02f, -1.973444e-02f, -9.385314e-01f}, {3.483800e-01f, 5.867907e-01f, -4.924437e-01f}, {-3.164448e-01f, -9.282125e-01f, 1.436908e-01f}, {4.844939e-01f, 7.594075e-01f, -9.408363e-01f}, {4.788513e-01f, -4.895897e-01f, 4.832206e-01f}, {5.959802e-01f, 7.505259e-01f, 4.254862e-02f}, {7.982241e-01f, 5.903921e-01f, -8.571386e-01f}, {-9.904973e-01f, -4.983312e-01f, 3.045862e-01f}, {5.846962e-01f, -9.118406e-01f, 5.363070e-01f}, {5.335883e-01f, -1.204512e-01f, 1.014158e-01f}, {-8.672072e-01f, 7.278236e-01f, -3.665645e-01f}, {-2.665262e-01f, -4.793269e-01f, -3.445653e-01f}, {7.381179e-01f, 7.449852e-01f, -9.875329e-01f}, {-5.530674e-01f, 3.471784e-01f, 1.891114e-01f}, {1.926859e-01f, -6.706795e-01f, 4.954980e-02f}, {8.079341e-01f, -5.851161e-01f, -4.794894e-02f}, {-6.504124e-01f, -2.689075e-02f, -5.507391e-01f}, {8.114744e-01f, -7.052837e-01f, -2.083493e-02f}, {5.773110e-01f, -2.562691e-01f, -1.904774e-01f}, {3.263202e-01f, 1.481019e-01f, 5.927627e-02f}, {1.864418e-01f, 1.795782e-02f, -1.943076e-01f}, {-8.704956e-01f, 6.167983e-01f, 6.641350e-01f}, {8.702223e-01f, 4.033018e-01f, 7.274230e-01f}, {4.051882e-01f, 8.447918e-01f, 3.487469e-01f}, {2.658674e-01f, -3.010800e-03f, 7.619650e-01f}, {-6.061619e-01f, -3.017940e-01f, 2.311356e-01f}, {3.893036e-01f, 5.501674e-02f, 4.969019e-01f}, {6.536043e-01f, 4.697610e-01f, 7.082964e-01f}, {-2.665765e-01f, -1.813440e-01f, 5.320937e-01f}, {-3.331599e-01f, -2.941637e-01f, 9.723650e-01f}, {-4.537313e-01f, -3.540045e-01f, 5.605747e-01f}, {-8.615083e-01f, 6.645209e-01f, 9.809833e-02f}, {-5.629299e-01f, -9.456634e-01f, -8.850762e-01f}, {7.418134e-02f, -3.604313e-01f, 8.766578e-01f}, {1.816789e-01f, -7.634428e-01f, 3.647814e-01f}, {8.054800e-01f, 3.251360e-01f, -5.046228e-01f}, {-2.076218e-01f, 8.982510e-01f, 7.208526e-01f}, {3.887964e-01f, 1.501774e-01f, -9.263656e-01f}, {3.938331e-01f, 4.873082e-01f, -1.137143e-01f}, {-5.761319e-02f, -4.138619e-01f, -4.183334e-02f}, {2.747716e-01f, -1.509529e-02f, -5.831297e-01f}, {-8.147560e-01f, 7.235356e-01f, 4.148483e-01f}, {-3.976076e-01f, 1.508900e-01f, 8.645421e-01f}, {7.930680e-01f, -2.820343e-01f, 6.139995e-01f}, {2.735764e-02f, 4.620913e-01f, 6.319771e-01f}, {1.143838e-01f, 5.657853e-02f, 2.133671e-01f}, {-5.073606e-01f, -2.855733e-01f, -9.876691e-01f}, {5.088544e-01f, 7.067468e-02f, -2.635247e-01f}, {-2.802616e-01f, -9.392417e-01f, -9.326564e-01f}, {7.125054e-01f, -4.644208e-01f, -1.698428e-01f}, {9.780695e-01f, -6.236805e-01f, -7.716354e-01f}, {9.208031e-01f, -8.824762e-01f, 7.022352e-01f}, {2.818166e-01f, -9.164856e-01f, 4.769336e-01f}, {4.147383e-01f, 9.051742e-01f, 9.756441e-02f}, {7.200351e-02f, -7.401485e-01f, 9.269646e-01f}, {1.420399e-01f, -5.099404e-01f, 9.815450e-01f}, {3.635858e-01f, -9.523637e-01f, 7.410683e-01f}, {-7.317662e-01f, -1.043338e-01f, -5.692595e-01f}, {-7.227266e-02f, -3.570465e-01f, 7.219854e-01f}, {-7.162228e-01f, -2.895437e-01f, 4.832046e-02f}, {2.554188e-02f, -4.476272e-01f, -8.388043e-01f}, {7.410040e-01f, 5.541715e-01f, -4.596182e-01f}, {9.062824e-01f, 9.743793e-01f, -5.429886e-01f}, {3.968561e-01f, 4.342410e-01f, 6.220111e-02f}, {4.465133e-01f, -8.898095e-01f, -2.285851e-01f}, {-3.627377e-01f, -7.879012e-01f, 4.604100e-01f}, {3.091025e-01f, 4.588333e-01f, 5.825194e-02f}, {-2.871659e-03f, -2.973274e-01f, -5.648703e-01f}, {5.895313e-01f, -1.714089e-01f, 1.878830e-01f}, {1.627569e-01f, 9.316477e-01f, -7.941564e-01f}, {6.777208e-01f, 3.924180e-01f, 1.342747e-01f}, {-5.015327e-01f, 6.293574e-01f, 1.224798e-01f}, {-6.418504e-01f, -1.685388e-01f, -8.918917e-02f}, {-3.926910e-01f, 4.608928e-01f, 1.887488e-01f}, {-8.749324e-01f, 2.668775e-01f, 3.986096e-01f}, {-2.152847e-01f, -8.525114e-01f, -4.905011e-01f}, {4.515696e-01f, 8.095310e-01f, 4.572438e-01f}, {7.571378e-01f, -9.930643e-02f, 4.935106e-01f}, {5.184089e-01f, 1.292789e-01f, 5.520440e-01f}, {-3.932113e-01f, -9.712086e-01f, 5.891526e-01f}, {3.420169e-01f, 2.147453e-01f, 9.279557e-01f}, {-6.548538e-01f, 4.285311e-01f, -4.813838e-01f}, {6.029108e-01f, 9.912634e-01f, 4.690613e-01f}}\n    };\n\n    // Valid total angular momentum for each test case\n    float3 validTotalAM_h[NUM_TEST_CASES] = {\n        {-2.866796e+01, -2.709299e+01, -6.432711e+01},\n        {4.477622e+00, -1.610214e+01, -1.270816e+01},\n        {6.149367e+01, 8.838241e+00, 4.890832e+00},\n        {-4.621698e+01, -5.488707e+01, 8.224401e+01},\n        {-1.476430e+02, 4.598140e+01, 4.528759e+01},\n        {-1.153948e+02, -1.224836e+02, 3.769198e+01},\n        {-6.532889e+01, 8.917376e+01, 1.030329e+02}\n    };\n\n    // Test loop\n    for (unsigned int i = 0; i < NUM_TEST_CASES; ++i) {\n\n        float *mass_d;\n        float3 *pos_d, *vel_d, *totalAM_d;\n        unsigned int particleCount = particleCountPerCase[i];\n\n        float3 gpuTotalAM_h;\n\n        //Declare CUDA stream for Async operations\n        cudaStream_t stream;\n        CUDA_CHECK(cudaStreamCreate(&stream));\n\n        //Allocate memory on device\n        CUDA_CHECK(cudaMallocAsync(&mass_d, particleCount * sizeof(float), stream));\n        CUDA_CHECK(cudaMallocAsync(&pos_d, particleCount * sizeof(float3), stream));\n        CUDA_CHECK(cudaMallocAsync(&vel_d, particleCount * sizeof(float3), stream));\n        CUDA_CHECK(cudaMallocAsync(&totalAM_d, sizeof(float3), stream));\n\n        // Copy input data to device\n        CUDA_CHECK(cudaMemcpyAsync(mass_d, mass_h[i], particleCount * sizeof(float), cudaMemcpyHostToDevice, stream));\n        CUDA_CHECK(cudaMemcpyAsync(pos_d, pos_h[i], particleCount * sizeof(float3), cudaMemcpyHostToDevice, stream));\n        CUDA_CHECK(cudaMemcpyAsync(vel_d, vel_h[i], particleCount * sizeof(float3), cudaMemcpyHostToDevice, stream));\n\n        // Initialize total angular momentum to zero\n        CUDA_CHECK(cudaMemcpyAsync(totalAM_d, &ZERO_VEC, sizeof(float3), cudaMemcpyHostToDevice, stream));\n\n        // Configure kernel launch parameters\n        void *args[] = {&mass_d,\n                        &pos_d,\n                        &vel_d,\n                        &totalAM_d,\n                        &particleCount};\n\n        // Block: (256, 1, 1)\n        // Grid: (numBlocks, 1, 1)\n        dim3 gridDim(numBlocks);\n        dim3 blockDim(BLOCK_SIZE);\n\n        // Launch kernel\n        CUDA_CHECK(cudaLaunchKernel((void*)k_computeAngularMomentum,\n                                    gridDim,\n                                    blockDim,\n                                    args,\n                                    0,\n                                    stream\n                                    ));\n\n        // Wait for the kernel to complete.\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n\n        // Copy result back to host\n        CUDA_CHECK(cudaMemcpyAsync(&gpuTotalAM_h, totalAM_d, sizeof(float3), cudaMemcpyDeviceToHost));\n\n        //Validate result\n        assert(vecNorm(vecDiff(gpuTotalAM_h, validTotalAM_h[i])) < TOL);\n\n        // Memory Cleanup\n        CUDA_CHECK(cudaFreeAsync(mass_d, stream));\n        CUDA_CHECK(cudaFreeAsync(pos_d, stream));\n        CUDA_CHECK(cudaFreeAsync(vel_d, stream));\n        CUDA_CHECK(cudaFreeAsync(totalAM_d, stream));\n        CUDA_CHECK(cudaStreamDestroy(stream));\n    }\n}\n\n// CUDA kernel to compute total angular momentum using warp-level reduction\n__global__ void k_computeAngularMomentum(const float *mass_d, const float3 *pos_d, const float3 *vel_d, float3 *totalAM_d, unsigned int particleCount) {\n", "test": "int main() {\n    launch();\n}\n", "example_test": "    @example_test\n", "cuda_toolkit": "12.2"}
{"task_id": "CUDA/119", "date": "2025-03-31", "prompt": "Write a CUDA kernel to detect collisions between two polygons using the separating axes theorem method on 2D objects.\n\nThe signature of the kernel is __global__ void k_satCollisionDetectionKernel(const Point* firstShape, int numVertices1, const Point* secondShape, int numVertices2, int* collisionDetected), where firstShape is the pointer to an array of points representing the vertices of the first polygon in device memory, secondShape is the pointer to an array of points representing the vertices of the second polygon in device memory, numVertices1 is the number of vertices in the first polygon, numVertices2 is the number of vertices in the second polygon, and collisionDetected is a pointer to an integer flag in device memory that will be set to 1 if collision detected and 0 otherwise.\n\n>>> k_satCollisionDetectionKernel({{0, 0}, {4, 0}, {4, 4}, {0, 4}}, 4, {{2, 2}, {6, 2}, {6, 6}, {2, 6}}, 4, collisionDetected)-> collisionDetected: 1\n>>> k_satCollisionDetectionKernel({{0, 0}, {4, 0}, {4, 4}, {0, 4}}, 4, {{5, 5}, {9, 5}, {9, 9}, {5, 9}}, 4, collisionDetected)-> collisionDetected: 0 \n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_70", "ld_flags": "", "declaration": "#include <cuda_runtime.h>\n#include <float.h>\n#include <cstdio>\n#undef NDEBUG\n#include <assert.h>\n\n#define CUDA_CHECK(call)                                                                                  \\\ndo {                                                                                                      \\\n    cudaError_t error = call;                                                                         \\\n    if (error != cudaSuccess) {                                                                       \\\n        fprintf(stderr, \"CUDA error at %s:%d - %s\\n\", __FILE__, __LINE__, cudaGetErrorString(error)); \\\n        exit(EXIT_FAILURE);                                                                           \\\n    }                                                                                                 \\\n} while (0)\n\n#define BLOCK_SIZE 128\n#define EPSILON 1e-5\n\n// Structure to represent a 2D point\nstruct Point {\n    float x;\n    float y;\n};\n\n// Structure to represent a Testcase\nstruct TestCase {\n    Point* firstShape;\n    int numVertices1;\n    Point* secondShape;\n    int numVertices2;\n    bool expectedCollision;\n};\n\n__global__ void k_satCollisionDetectionKernel(const Point* firstShape, int numVertices1, const Point* secondShape, int numVertices2, int* collisionDetected);\n\nvoid launch() {\n    \n    Point firstShape1[] = {{0, 0}, {4, 0}, {4, 4}, {0, 4}}; //Square 1\n    Point secondShape1[] = {{2, 2}, {6, 2}, {6, 6}, {2, 6}}; //Square 2\n\n    TestCase TestCase1 = {firstShape1, 4, secondShape1, 4, true}; // Squares Colliding\n    Point firstShape2[] = {{0, 0}, {4, 0}, {4, 4}, {0, 4}};\n    Point secondShape2[] = {{5, 5}, {9, 5}, {9, 9}, {5, 9}};\n\n    TestCase TestCase2 = {firstShape2, 4, secondShape2, 4, false}; // Squares Non Colliding\n    Point firstShape3[] = {{1, 1}, {3, 1}, {4, 2}, {3, 4}, {1, 4}, {0, 2}};\n    Point secondShape3[] = {{2, 3}, {5, 3}, {5, 5}, {2, 5}};\n\n    TestCase TestCase3 = {firstShape3, 6 , secondShape3, 4, true}; // Hexagon and Quadrilateral Colliding\n    Point firstShape4[] = {{1, 1}, {5, 1}, {5, 2}, {1, 2}};\n    Point secondShape4[] = {{3, 0}, {4, 1}, {3, 2}, {2, 1}};\n\n    TestCase TestCase4 = {firstShape4, 4, secondShape4, 4, true}; // Rectangle and Square Colliding\n    Point firstShape5[] = {{0, 0}, {2, 1}, {3, 3}, {1, 4}, {-1, 2}};\n    Point secondShape5[] = {{5, 5}, {7, 6}, {6, 8}};\n\n    TestCase TestCase5 = {firstShape5, 5, secondShape5, 3, false}; // Pentagon and Triangle Non-Colliding\n    Point firstShape6[] = {{0, 0}, {3, 0}, {3, 2}, {0, 2}};\n    Point secondShape6[] = {{5, 5}, {7, 5}, {8, 7}, {7, 9}, {5, 9}, {4, 7}, {4, 6}};\n\n    TestCase TestCase6 = {firstShape6, 4, secondShape6, 7, false}; // Quadrilateral and Heptagon Non-Colliding\n    Point firstShape7[] = {{0, 4}, {2, 4}, {3, 5}, {3, 7}, {2, 8}, {0, 8}, {-1, 7}, {-1, 5}};\n    Point secondShape7[] = {{5, 0}, {8, 2}, {6, 4}};\n\n    TestCase TestCase7 = {firstShape7, 8, secondShape7, 3, false}; // Octagon and Triangle Non-Colliding\n    Point firstShape8[] = {{0, 0}, {1, 0}, {2, 0}, {3, 0}, {4, 0}, {5, 0}, {6, 0}, {7, 0}, {8, 0}, {9, 0}, {9, 1}, {8, 1}, {7, 1}, {6, 1}, {5, 1}, {4, 1}, {3, 1}, {2, 1}, {1, 1}, {0, 1}, {0, 2}, {1, 2}, {2, 2}, {3, 2}, {4, 2}, {5, 2}, {6, 2}, {7, 2}, {8, 2}, {9, 2}, {9, 3}, {8, 3}, {7, 3}, {6, 3}, {5, 3}, {4, 3}, {3, 3}, {2, 3}, {1, 3}, {0, 3}};\n    Point secondShape8[] = {{15, 15}, {16, 15}, {17, 15}, {18, 15}, {19, 15}, {20, 15}, {21, 15}, {22, 15}, {23, 15}, {24, 15}, {24, 16}, {23, 16}, {22, 16}, {21, 16}, {20, 16}, {19, 16}, {18, 16}, {17, 16}, {16, 16}, {15, 16}, {15, 17}, {16, 17}, {17, 17}, {18, 17}, {19, 17}, {20, 17}, {21, 17}, {22, 17}, {23, 17}, {24, 17}, {24, 18}, {23, 18}, {22, 18}, {21, 18}, {20, 18}, {19, 18}, {18, 18}, {17, 18}, {16, 18}, {15, 18}};\n\n    TestCase TestCase8 = {firstShape8, 40, secondShape8, 40, false}; // Two Shapes with 40 points Non-Colliding\n    TestCase TestCases[] ={TestCase1, TestCase2, TestCase3, TestCase4, TestCase5, TestCase6, TestCase7, TestCase8};\n    \n    // Preallocate device memory for shapes and collision result\n    Point *firstShape_d, *secondShape_d;\n    int *collision_d;\n    \n    // Assuming maximum number of vertices in any test case is 40 for allocation\n    size_t maxVertices1 = 40;\n    size_t maxVertices2 = 40;\n\n    // Create CUDA stream for asynchronous operations\n    cudaStream_t stream;\n    cudaStreamCreate(&stream);\n\n    // No dynamic shared memory is allocated during launch\n    size_t sharedMemSize = 0; \n\n    // Allocate maximum required device memory once asynchronously\n    CUDA_CHECK(cudaMallocAsync((void **)&firstShape_d, maxVertices1 * sizeof(Point), stream));\n    CUDA_CHECK(cudaMallocAsync((void **)&secondShape_d, maxVertices2 * sizeof(Point), stream));\n    CUDA_CHECK(cudaMallocAsync((void **)&collision_d, sizeof(int), stream));\n\n    int numTestCases = sizeof(TestCases) / sizeof(TestCase);\n    for (int tc = 0; tc < numTestCases; ++tc) {\n        TestCase currentTest = TestCases[tc];\n\n        // Initialize collision flag\n        int collision_h = 1;\n        CUDA_CHECK(cudaMemcpyAsync(collision_d, &collision_h, sizeof(int), cudaMemcpyHostToDevice, stream));\n\n        // Copy shapes to device\n        CUDA_CHECK(cudaMemcpyAsync(firstShape_d, currentTest.firstShape, currentTest.numVertices1 * sizeof(Point), cudaMemcpyHostToDevice, stream));\n        CUDA_CHECK(cudaMemcpyAsync(secondShape_d, currentTest.secondShape, currentTest.numVertices2 * sizeof(Point), cudaMemcpyHostToDevice, stream));\n\n        // Calculate number of normals\n        int numOfNormals = currentTest.numVertices1 + currentTest.numVertices2;\n\n        // Calculate number of blocks needed to process all axes\n        int blocksPerGrid = (numOfNormals + BLOCK_SIZE - 1) / BLOCK_SIZE;\n\n        // Define grid and block dimensions with dim3\n        dim3 gridSize(blocksPerGrid, 1, 1);\n        dim3 blockSize(BLOCK_SIZE, 1, 1);\n\n        // Prepare kernel arguments\n        void* kernelArgs[] = {(void*)&firstShape_d, (void*)&currentTest.numVertices1, (void*)&secondShape_d, (void*)&currentTest.numVertices2, (void*)&collision_d};\n\n        // Grid: (ceil(N/256), 1, 1) -> (1, 1, 1)\n        // Block: (256, 1, 1)\n        // Launch the kernel asynchronously without dynamic shared memory\n        CUDA_CHECK(cudaLaunchKernel((const void*)k_satCollisionDetectionKernel, gridSize, blockSize, kernelArgs, sharedMemSize, stream));\n\n        // Copy the result back to host\n        CUDA_CHECK(cudaMemcpyAsync(&collision_h, collision_d, sizeof(int), cudaMemcpyDeviceToHost, stream));\n\n        // Synchronize the stream to ensure kernel completion and memcpy completion\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n        \n        // Validate the result\n        assert(collision_h == currentTest.expectedCollision);\n    }\n\n    // Clean up\n    CUDA_CHECK(cudaFreeAsync(firstShape_d, stream));\n    CUDA_CHECK(cudaFreeAsync(secondShape_d, stream));\n    CUDA_CHECK(cudaFreeAsync(collision_d, stream));\n    CUDA_CHECK(cudaStreamDestroy(stream));\n}\n\n__global__ void k_satCollisionDetectionKernel(const Point* firstShape, int numVertices1, const Point* secondShape, int numVertices2, int* collisionDetected) {\n", "test": "int main() {\n    launch();\n}\n", "example_test": "    @example_test\n", "cuda_toolkit": "12.2"}
{"task_id": "CUDA/120", "date": "2025-03-31", "prompt": "Write a CUDA kernel to count 2D points inside 2D polygons, given as vertex lists, by assigning each polygon to a block and each point to a thread, using warp-level reduction for local count accumulation and atomicAdd for global total.\n\nThe kernel signature is __global__ void k_countPointsInPolygons(const float2* points_d, const int* polyOffsets_d, const float2* polyVertices_d, int* counts_d, int numPoints, int numPolygons), where points_d is the array of points, polyOffsets_d defines the subset vertices in polyVertices_d for the respective polygon, polyVertices is the total vertices set of all polygons, counts_d is the computed result, numPoints is the total number of points, and numPolygons is the total number of polygons in the data set.\n\n>>> k_countPointsInPolygons(points_d:{{2.54f, 3.59f}, {93.56f, 77.84f}},\n                            polyOffsets_d:{0, 3, 6},\n                            polyVertices_d:{{108.63f, 88.34f}, {80.57f, 76.69f}, {-42.25f, 54.29f}, {94.08f, 163.08f}, {52.27f, -4.073f},{111.56f, 72.67f}},\n                            counts_d: {0},\n                            numPoints: 2,\n                            numPolygons: 2) -> counts_d: {0, 1};\n>>> k_countPointsInPolygons(points_d:{{52.75f, 88.66f}, {37.12f, 11.27f}},\n                            polyOffsets_d:{0, 7, 14},\n                            polyVertices_d:{{73.40f, 74.87f}, {63.12f, 73.70f}, {50.87f, 89.70f}, {12.73f, 115.39f}, {24.85f, 75.04f}, {-27.41f, 40.11f}, {-8.50f, 26.75f}, {68.34f, 60.59f}, {-67.15f, 59.18f}, {-29.74f, 36.99f}, {-19.55f, -62.04f}, {-6.79f, -71.06f}, {30.69f, -50.15f}, {110.93f, 7.72f}},\n                            counts_d: {0},\n                            numPoints: 2,\n                            numPolygons: 2) -> counts_d: {0, 1};\n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_70", "ld_flags": "", "declaration": "\n#include <stdio.h>\n#include <stdlib.h>\n#include <cassert>\n\n#include <cuda_runtime.h>\n\n#define CUDA_CHECK(call)                                                                   \\\ndo {                                                                                       \\\n    cudaError_t error = call;                                                              \\\n    if(error != cudaSuccess) {                                                             \\\n        fprintf(stderr,                                                                    \\\n            \"CUDA Error: %s at %s:%d\\n\",                                                   \\\n            cudaGetErrorString(error),                                                     \\\n            __FILE__,                                                                      \\\n            __LINE__);                                                                     \\\n        exit(error);                                                                       \\\n    }                                                                                      \\\n} while(0)\n\n\n// CUDA Kernel signature to count points in polygons using warp-level reduction\n__global__ void k_countPointsInPolygons(const float2* points_d, const int* polyOffsets_d, const float2* polyVertices_d, int* counts_d, int numPoints, int numPolygons);\n\nvoid launch() {\n    const unsigned int NUM_TEST_CASES = 6;\n    const unsigned int MAX_POINTS_COUNT = 16;\n    const unsigned int MAX_POLYGONS_COUNT = 23;\n    const unsigned int MAX_TOTAL_VERTICES_COUNT = 119;\n\n    const unsigned int BLOCK_SIZE = 256;\n    int numPointsPerCase[NUM_TEST_CASES] = {0, 15, 10, 12, 16, 14};\n    int numPolygonsPerCase[NUM_TEST_CASES] = {0, 2, 10, 12, 8, 23};\n\n    float2 pointsPerCase[NUM_TEST_CASES][MAX_POINTS_COUNT] = {\n        {},\n        {{25.3935f, 15.9624f}, {78.6924f, 80.5324f}, {74.2756f, 1.8979f}, {72.6130f, 65.2378f}, {51.3578f, 80.0843f}, {19.1614f, 14.4334f}, {82.8588f, 62.6612f}, {44.3258f, 36.3087f}, {64.8938f, 93.8025f}, {43.0081f, 9.7263f}, {61.5176f, 97.9455f}, {63.7261f, 46.6297f}, {78.2126f, 18.8877f}, {51.3325f, 79.7097f}, {23.3491f, 25.6204f}},\n        {{84.0023f, 20.5858f}, {78.2397f, 80.0574f}, {16.2814f, 1.6055f}, {36.4122f, 58.2603f}, {45.8549f, 90.1331f}, {77.7861f, 15.7065f}, {65.9692f, 73.8676f}, {68.9573f, 84.1485f}, {9.9052f, 71.8982f}, {22.8545f, 65.1325f}},\n        {{68.9511f, 9.5930f}, {34.3738f, 8.4515f}, {72.2493f, 14.2196f}, {20.5987f, 7.7860f}, {99.2154f, 51.0257f}, {4.6489f, 51.3185f}, {81.9002f, 9.2764f}, {15.7800f, 3.3111f}, {29.6356f, 12.8318f}, {99.9346f, 35.9169f}, {36.7388f, 0.8057f}, {80.3509f, 82.8087f}},\n        {{5.9535f, 87.1826f}, {65.9460f, 68.5129f}, {39.0313f, 9.3470f}, {70.8545f, 25.8169f}, {5.5400f, 92.1123f}, {37.9600f, 12.1133f}, {86.6538f, 35.3229f}, {97.1403f, 40.4937f}, {0.8192f, 41.8948f}, {45.6392f, 59.6516f}, {80.8463f, 81.4288f}, {4.7672f, 73.0398f}, {94.5803f, 96.5074f}, {3.7246f, 22.8596f}, {82.4363f, 23.5031f}, {27.5142f, 42.0012f}},\n        {{61.3136f, 21.5347f}, {13.8689f, 94.5953f}, {94.1111f, 37.1791f}, {85.1030f, 92.3827f}, {10.1354f, 35.0836f}, {5.6592f, 40.2589f}, {72.4078f, 3.6739f}, {53.0263f, 83.1622f}, {72.6549f, 27.2877f}, {84.5994f, 77.4742f}, {21.9356f, 20.3580f}, {23.1267f, 1.1188f}, {38.6358f, 23.4979f}, {2.4899f, 49.1200f}}\n    };\n\n    int polyOffsetsPerCase[NUM_TEST_CASES][MAX_POLYGONS_COUNT+1] = {\n        {},\n        {0, 3, 11},\n        {0, 3, 11, 14, 20, 24, 31, 36, 44, 51, 58},\n        {0, 3, 7, 10, 17, 23, 31, 38, 44, 47, 53, 60, 65},\n        {0, 3, 8, 15, 18, 25, 29, 37, 42},\n        {0, 4, 10, 18, 22, 27, 30, 34, 37, 45, 48, 54, 60, 65, 72, 80, 86, 92, 95, 98, 103, 109, 113, 119}\n    };\n\n    float2 polyVerticesPerCase[NUM_TEST_CASES][MAX_TOTAL_VERTICES_COUNT] = {\n        {},\n        {{134.3617f, 67.3507f}, {46.8174f, 70.9466f}, {87.7588f, 22.4348f}, {-53.3826f, 79.5700f}, {-22.3968f, 75.9385f}, {-33.3050f, 64.6587f}, {-30.1813f, 63.1465f}, {0.1456f, 59.8312f}, {11.2200f, 48.6946f}, {19.4059f, 50.3045f}, {20.7879f, 78.7427f}},\n        {{56.6479f, 56.7658f}, {40.8065f, 55.8632f}, {80.9999f, 22.6961f}, {109.7568f, 24.4861f}, {75.7384f, 14.8199f}, {54.5859f, 43.8566f}, {65.9880f, 12.7185f}, {64.2804f, 11.1368f}, {64.2785f, -30.7154f}, {70.1765f, -10.9582f}, {99.9139f, 1.8788f}, {72.9123f, 97.6707f}, {42.3471f, 74.1175f}, {76.7311f, 72.6132f}, {139.3859f, 96.7507f}, {105.8097f, 110.3992f}, {104.6479f, 125.0762f}, {92.8866f, 130.7146f}, {87.2788f, 78.7460f}, {104.7586f, 87.7257f}, {89.0710f, 99.7146f}, {74.2983f, 102.4218f}, {63.6623f, 106.0967f}, {54.7968f, 60.1081f}, {44.7593f, 20.8099f}, {25.1003f, 14.5671f}, {19.4293f, 30.8442f}, {8.5566f, 42.3731f}, {-5.2437f, 40.2896f}, {10.5937f, -5.0472f}, {22.7524f, -18.6959f}, {41.5925f, 34.5525f}, {-3.9213f, 64.4598f}, {-7.7634f, 20.7071f}, {1.5913f, -0.8251f}, {26.5296f, 12.5197f}, {82.6740f, 116.5693f}, {72.2261f, 117.5951f}, {48.9520f, 94.9286f}, {48.4285f, 92.7039f}, {47.5101f, 90.9926f}, {33.2878f, 67.9994f}, {53.2091f, 62.1639f}, {57.0307f, 73.4961f}, {38.6922f, 108.9444f}, {28.8120f, 115.8366f}, {-5.7458f, 97.4224f}, {-6.8593f, 86.1534f}, {-2.5615f, 83.6504f}, {19.8517f, 46.1851f}, {23.2992f, 75.9435f}, {24.5139f, 80.3184f}, {41.2134f, 95.6397f}, {5.9310f, 114.0931f}, {-0.1396f, 77.0662f}, {-19.3324f, 68.8902f}, {14.5231f, 60.2121f}, {20.1672f, 69.3018f}},\n        {{55.2293f, 77.5417f}, {8.1647f, 34.0828f}, {37.0258f, 54.0557f}, {50.3118f, 50.0981f}, {6.2364f, 27.4681f}, {74.0279f, 0.2347f}, {59.4276f, 18.6317f}, {62.3479f, 59.9583f}, {51.9358f, 48.0523f}, {35.0476f, 0.8496f}, {67.0537f, 23.2495f}, {56.7724f, 51.3218f}, {43.0253f, 13.6831f}, {48.1178f, 8.3985f}, {52.8082f, 6.4274f}, {80.7712f, -4.0188f}, {90.2737f, -12.3314f}, {98.3461f, 101.2590f}, {77.8754f, 93.8470f}, {81.5063f, 111.8132f}, {57.5432f, 64.3428f}, {77.8353f, 78.8151f}, {94.3956f, 79.2274f}, {125.8321f, 50.9257f}, {109.9831f, 51.2148f}, {128.0208f, 76.2115f}, {99.6804f, 55.2562f}, {83.4562f, 85.8732f}, {99.5332f, 39.5124f}, {111.8878f, 10.3778f}, {117.6762f, 21.4250f}, {108.7409f, 69.2312f}, {97.3609f, 41.2653f}, {62.5299f, 46.4012f}, {70.4528f, 33.9400f}, {113.5160f, 14.7360f}, {124.3545f, 16.9632f}, {109.9968f, 27.0882f}, {63.8445f, 32.5492f}, {33.0780f, 17.3937f}, {41.3715f, 0.0632f}, {52.4508f, 3.4700f}, {81.3959f, -9.2477f}, {79.0691f, 1.3259f}, {92.0092f, 18.6972f}, {68.9770f, 13.5766f}, {85.7376f, -14.7095f}, {69.1550f, 59.1593f}, {55.9092f, 43.5145f}, {62.1752f, 35.3168f}, {54.5189f, 35.4208f}, {76.5204f, -3.2246f}, {102.1076f, 13.8841f}, {120.1010f, 40.7706f}, {87.2862f, 51.3812f}, {87.9691f, 49.4913f}, {71.7630f, 56.0025f}, {94.3277f, 36.7140f}, {82.6369f, 31.0020f}, {94.5882f, 21.7822f}, {29.0014f, 75.2209f}, {6.5746f, 100.2372f}, {-19.1631f, 69.1360f}, {-7.9727f, 67.8200f}, {50.7670f, 55.8857f}},\n        {{15.9238f, 33.6296f}, {-10.7460f, 42.7896f}, {-29.1164f, -1.1826f}, {108.0594f, 7.8457f}, {77.7694f, 53.0625f}, {77.1891f, 10.5083f}, {61.2914f, 1.1518f}, {61.4407f, -39.4808f}, {39.9643f, 84.4824f}, {16.2293f, 101.0130f}, {-5.1434f, 71.2431f}, {7.9201f, 59.1707f}, {-36.4552f, 27.7391f}, {-41.9747f, 10.7190f}, {57.7363f, 29.2877f}, {31.5345f, 22.9040f}, {4.9472f, 24.7763f}, {24.4523f, -5.4072f}, {24.5965f, 23.4213f}, {-1.7690f, 24.9921f}, {27.6597f, 11.5915f}, {-20.5477f, 12.5831f}, {35.9704f, -0.5741f}, {66.2204f, -6.1002f}, {62.2674f, 4.7513f}, {23.7963f, 78.5591f}, {39.9877f, 26.5168f}, {47.2572f, 9.0889f}, {48.3022f, 41.8915f}, {88.1789f, 86.2978f}, {58.4967f, 55.3120f}, {55.9288f, 53.3836f}, {12.0736f, 105.7440f}, {26.1890f, 56.5114f}, {-11.1118f, 46.5306f}, {15.6433f, -29.8749f}, {98.0036f, 6.0696f}, {136.6720f, 70.3806f}, {110.1534f, 49.4757f}, {130.9519f, 100.2367f}, {101.7868f, 94.4242f}, {142.3286f, 7.7358f}},\n        {{39.1525f, 136.0314f}, {58.9527f, 21.5976f}, {65.3684f, 48.2486f}, {94.4780f, 58.4242f}, {113.4197f, 104.9353f}, {113.5203f, 126.1892f}, {75.1015f, 69.9775f}, {35.7762f, 23.6532f}, {65.0925f, 27.7896f}, {35.1015f, -0.3997f}, {53.3435f, 36.4378f}, {18.7757f, 25.0511f}, {-53.6928f, 43.0815f}, {-30.1476f, -26.8485f}, {-6.6556f, -25.5359f}, {5.1446f, -36.1802f}, {19.9754f, 8.9401f}, {86.1090f, 1.6709f}, {84.0523f, 54.8230f}, {14.4555f, 18.0797f}, {-8.8044f, -18.3477f}, {61.9279f, -15.3647f}, {123.0983f, 81.0299f}, {107.5528f, 75.7157f}, {43.2018f, 74.8049f}, {28.0695f, -11.1196f}, {60.5985f, 16.9425f}, {51.9968f, 112.0940f}, {58.1027f, 30.0324f}, {91.8453f, 82.6109f}, {154.5059f, 54.5475f}, {90.7442f, 61.6303f}, {52.6430f, 72.0547f}, {130.3504f, 44.4099f}, {63.3580f, 61.7601f}, {54.8624f, 51.9889f}, {47.0117f, 31.9965f}, {118.7183f, 30.6116f}, {82.8192f, 73.8630f}, {57.0713f, 50.1101f}, {42.9553f, 84.8396f}, {51.9142f, 52.2758f}, {17.0512f, 58.4076f}, {25.6934f, 41.6060f}, {62.8683f, 22.4418f}, {-34.9576f, 104.2821f}, {-45.3225f, 59.2706f}, {6.3679f, 5.0496f}, {0.0253f, 153.6205f}, {-3.3306f, 165.4586f}, {-54.6575f, 156.1308f}, {-65.4280f, 110.2866f}, {-67.3530f, 82.1265f}, {32.0247f, 82.6117f}, {-30.2746f, 97.5766f}, {-10.4899f, 57.6101f}, {-26.6975f, 11.4278f}, {-10.3067f, -2.7274f}, {13.2934f, 43.7130f}, {81.1809f, 14.3672f}, {28.5567f, 19.9525f}, {40.3849f, -13.0171f}, {59.8539f, -31.8926f}, {62.8342f, 22.4079f}, {76.9268f, 19.4592f}, {34.6956f, 91.9640f}, {55.0788f, 93.2257f}, {51.9831f, 117.0970f}, {40.3579f, 154.7361f}, {-27.8643f, 154.3441f}, {-26.0759f, 58.6327f}, {-0.5718f, 66.9588f}, {69.4333f, 91.5448f}, {27.1546f, 91.1009f}, {74.2780f, 132.1854f}, {60.2099f, 139.3727f}, {46.6496f, 141.5777f}, {-19.4228f, 64.2178f}, {66.6184f, 78.3575f}, {68.8609f, 79.9441f}, {29.1608f, 74.5063f}, {25.3886f, 96.5535f}, {16.6441f, 113.7130f}, {-14.5048f, 62.2992f}, {-21.0423f, 27.7603f}, {24.4740f, 46.4402f}, {-6.2913f, 94.7375f}, {17.4469f, 54.7311f}, {11.3791f, 50.0966f}, {-27.6568f, 22.8939f}, {28.1530f, 3.7590f}, {35.4558f, 44.1193f}, {41.4080f, 153.0871f}, {110.5694f, 69.4201f}, {126.7183f, 68.1848f}, {20.6167f, 38.5994f}, {-24.0773f, -13.4292f}, {76.1802f, -8.1312f}, {16.1107f, 58.8548f}, {25.5474f, 41.0822f}, {21.1624f, 31.2073f}, {8.7804f, -5.4628f}, {54.0051f, 36.9842f}, {74.1395f, 117.6636f}, {65.3431f, 82.4008f}, {62.0612f, 78.9988f}, {-9.2448f, 67.3225f}, {-1.7858f, 61.1156f}, {140.9129f, 35.1002f}, {50.5060f, 80.4414f}, {16.9206f, 60.2410f}, {50.8593f, 20.8864f}, {75.9331f, 24.3188f}, {77.5725f, 113.3023f}, {61.7046f, 124.4735f}, {21.8253f, 101.6042f}, {-16.4761f, 142.8666f}, {2.7119f, 97.5965f}, {60.4517f, 57.3037f}}\n    };\n\n    int validCountsPerCasePerPolygon[NUM_TEST_CASES][MAX_POLYGONS_COUNT] = {\n        {},\n        {2, 0},\n        {0, 0, 2, 0, 2, 1, 0, 0, 1, 1},\n        {0, 0, 0, 2, 1, 1, 1, 2, 2, 2, 1, 0},\n        {0, 2, 5, 0, 3, 0, 9, 0},\n        {1, 1, 4, 5, 2, 1, 0, 0, 2, 0, 1, 2, 0, 1, 2, 3, 3, 0, 2, 2, 2, 1, 2}\n    };\n\n    cudaDeviceProp deviceProp;\n    int currentDevice;\n    CUDA_CHECK(cudaGetDevice(&currentDevice));\n    CUDA_CHECK(cudaGetDeviceProperties(&deviceProp, currentDevice));\n\n    int warpSize = deviceProp.warpSize;\n    int numSMs = deviceProp.multiProcessorCount;\n    int maxBlocksPerSM = deviceProp.maxBlocksPerMultiProcessor;\n    int maxNumBlocks = numSMs * maxBlocksPerSM;\n\n    for (int t = 0; t < NUM_TEST_CASES; t++) {\n        // Setting input params for test\n        int numPoints_h = numPointsPerCase[t];\n        int numPolygons_h = numPolygonsPerCase[t];\n        float2 *points_h = pointsPerCase[t];\n        float2 *polyVertices_h = polyVerticesPerCase[t];\n        int *polyOffsets_h = polyOffsetsPerCase[t];\n        int  *validCounts_h = validCountsPerCasePerPolygon[t];\n\n        // Allocate device memory for inputs and output counts.\n        float2 *points_d;\n        float2 *polyVertices_d;\n        int *polyOffsets_d;\n        int *counts_d;\n\n        size_t pointsSize = numPoints_h * sizeof(float2);\n        size_t offsetsSize = (numPolygons_h + 1) * sizeof(int);\n        size_t countsSize = numPolygons_h * sizeof(int);\n\n        int numVerts = polyOffsets_h[numPolygons_h];\n        size_t verticesSize = numVerts * sizeof(float2);\n\n        int gpuCounts_h[MAX_POLYGONS_COUNT] = {0};\n\n        cudaStream_t stream;\n        CUDA_CHECK(cudaStreamCreate(&stream));\n\n        // Locate memory space on device.\n        CUDA_CHECK(cudaMallocAsync(&points_d, pointsSize, stream));\n        CUDA_CHECK(cudaMallocAsync(&polyOffsets_d, offsetsSize, stream));\n        CUDA_CHECK(cudaMallocAsync(&polyVertices_d, verticesSize, stream));\n        CUDA_CHECK(cudaMallocAsync(&counts_d, countsSize, stream));\n\n        // Duplicate input data on to device.\n        CUDA_CHECK(cudaMemcpyAsync(points_d, points_h, pointsSize, cudaMemcpyHostToDevice, stream));\n        CUDA_CHECK(cudaMemcpyAsync(polyOffsets_d, polyOffsets_h, offsetsSize, cudaMemcpyHostToDevice, stream));\n        CUDA_CHECK(cudaMemcpyAsync(polyVertices_d, polyVertices_h, verticesSize, cudaMemcpyHostToDevice, stream));\n\n        CUDA_CHECK(cudaMemsetAsync(counts_d, 0, countsSize, stream));\n\n        void *args[] = {&points_d,\n                        &polyOffsets_d,\n                        &polyVertices_d,\n                        &counts_d,\n                        &numPoints_h,\n                        &numPolygons_h};\n\n        int numBlocks = max(1, min(numPolygons_h,maxNumBlocks));\n    \tint numWarps = (BLOCK_SIZE + warpSize - 1) / warpSize;\n    \tint shmemBytes = numWarps * sizeof(int);\n\n        // Launch kernel\n        // Grid: (numBlocks, 1, 1)\n        // Block: (256, 1, 1)\n        dim3 blockSize(BLOCK_SIZE);\n        dim3 gridSize(numBlocks);\n        CUDA_CHECK(cudaLaunchKernel((void*)k_countPointsInPolygons,\n                                    gridSize,\n                                    blockSize,\n                                    args,\n                                    shmemBytes,\n                                    stream));\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n\n        // Validation\n        CUDA_CHECK(cudaMemcpyAsync(gpuCounts_h, counts_d, countsSize, cudaMemcpyDeviceToHost, stream));\n        for (int i = 0; i < numPolygons_h; i++) {\n           assert(gpuCounts_h[i] == validCounts_h[i]);\n        }\n\n        //Memory clean up\n        CUDA_CHECK(cudaFreeAsync(points_d, stream));\n        CUDA_CHECK(cudaFreeAsync(polyOffsets_d, stream));\n        CUDA_CHECK(cudaFreeAsync(polyVertices_d, stream));\n        CUDA_CHECK(cudaFreeAsync(counts_d, stream));\n        CUDA_CHECK(cudaStreamDestroy(stream));\n    }\n}\n\n\n__global__ void k_countPointsInPolygons(const float2* points_d, const int* polyOffsets_d, const float2* polyVertices_d, int* counts_d, int numPoints, int numPolygons) {\n", "test": "int main() {\n    launch();\n}\n", "example_test": "    @example_test\n", "cuda_toolkit": "12.2"}
{"task_id": "CUDA/121", "date": "2025-03-31", "prompt": "Write a CUDA kernel to apply a bilateral filter for edge\u2011preserving and smoothing on a 2D image.\n\nThe signature of the function is __global__ void k_bilateralFilterKernel(float *inputImage, float *filteredImage, int widthOfImage, int heightOfImage, int radiusOfFilter, float sigmaOfSpatial, float sigmaOfRange), where inputImage represents the input image pixel data, filteredImage represents the output image where the filtered result is stored, widthOfImage gives the width (number of pixels per row) of the input image, heightOfImage represents the height of the input image, radiusOfFilter represents the radius of the filter window, sigmaOfSpatial the standard deviation for the spatial (distance) weighting in the gaussian function, sigmaOfRange The standard deviation for the range (intensity difference) weighting in the gaussian function.\n\n>>> k_bilateralFilterKernel({4, 4}, filteredImage, 3, 3.0f, 25.0f) -> filteredImage: ({123.260002f, 7.377082f, 95.625015f, 95.624985f, 183.872910f})\n>>> k_bilateralFilterKernel({128, 128}, filteredImage, 5, 4.0f, 30.0f ) -> filteredImage: ({127.500031f, 2.302135f, 126.503929f, 126.503883f, 250.705582f})\n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_70 -arch=sm_60", "ld_flags": "", "declaration": "#include <cuda_runtime.h>\n#include <cstdio>\n#include <cmath>\n#include <algorithm>\n#include <assert.h>\n#include <iostream>\n\n#define BLOCK_SIZE 16\n#define TOLERANCE 0.01f\n#define EPSILON 1e-5f\n\n#define CUDA_CHECK(call)                                                           \\\ndo {                                                                               \\\n    cudaError_t error = call;                                                      \\\n    if (error != cudaSuccess) {                                                    \\\n        fprintf(stderr, \"CUDA Error: %s at %s:%d\\n\", cudaGetErrorString(error),    \\\n                __FILE__, __LINE__);                                               \\\n        exit(error);                                                               \\\n    }                                                                              \\\n} while (0)\n\n__global__ void k_bilateralFilterKernel(float *inputImage, float *filteredImage, int widthOfImage, int heightOfImage, int radiusOfFilter, float sigmaOfSpatial, float sigmaOfRange);\n\nvoid launch() {\n\n    // 2D image test cases\n    const int NUMBER_OF_TESTS = 8;\n    int widthOfImages[NUMBER_OF_TESTS] = {4, 64, 128, 128, 256, 256,  32, 100 };\n    int heightOfImages[NUMBER_OF_TESTS] = {4, 64, 128, 128, 256, 256,  32, 100 };\n    int radii[NUMBER_OF_TESTS] = {3, 2, 3, 5, 3, 5, 1, 2 };\n    float sigmaOfSpatials[NUMBER_OF_TESTS] = {3.0f, 2.0f, 3.0f, 4.0f, 3.0f, 4.0f, 1.0f, 2.0f};\n    float sigmaOfRanges[NUMBER_OF_TESTS] = {25.0f, 20.0f, 25.0f, 30.0f, 25.0f, 30.0f, 15.0f, 20.0f};\n\n    // For each test case, we store 5 expected values center, topLeft, topRight, bottomLeft, bottomRight\n    float expectedOutput[NUMBER_OF_TESTS][5] = {\n        {123.260002f, 7.377082f, 95.625015f, 95.624985f, 183.872910f},  \n        {127.499992f, 2.067940f, 125.507812f, 125.507812f, 248.947693f},  \n        {127.499985f, 1.517415f, 126.503914f, 126.503883f, 251.490356f},  \n        {127.500031f, 2.302135f, 126.503929f, 126.503883f, 250.705582f}, \n        {127.499992f, 0.761391f, 127.001984f, 127.001968f, 253.242493f},  \n        {127.500046f, 1.157711f, 127.001938f, 127.001915f, 252.846146f}, \n        {127.500000f, 2.099976f, 123.515625f, 123.515640f, 244.931259f},  \n        {127.499985f, 1.335109f, 126.224991f, 126.225006f, 251.114883f}   \n    };\n    \n    // Find the maximum image size\n    int maxWidth = *std::max_element(widthOfImages, widthOfImages + NUMBER_OF_TESTS);\n    int maxHeight = *std::max_element(heightOfImages, heightOfImages + NUMBER_OF_TESTS);\n    int maxSize = maxWidth * maxHeight;\n\n    // Allocate device memory asynchronously\n    float *inputImage_d, *filteredImage_d;\n    float *inputImage_h, *filteredImage_h;\n\n    // Create a CUDA stream for asynchronous operations\n    cudaStream_t stream;\n    CUDA_CHECK(cudaStreamCreate(&stream));\n\n    // Allocate host memory\n    inputImage_h = new float[maxSize];\n    filteredImage_h = new float[maxSize];\n\n    // Allocate device memory asynchronously\n    CUDA_CHECK(cudaMallocAsync(&inputImage_d, maxSize * sizeof(float), stream));\n    CUDA_CHECK(cudaMallocAsync(&filteredImage_d, maxSize * sizeof(float), stream));\n     \n    // Make sure allocations are complete before proceeding\n    CUDA_CHECK(cudaStreamSynchronize(stream));\n\n    // Run the 2D image test cases\n    for (int testCase = 0; testCase < NUMBER_OF_TESTS; testCase++) {\n        int width = widthOfImages[testCase];\n        int height = heightOfImages[testCase];\n        int size = width * height;\n        \n        // Initialize input with a gradient pattern\n        for (int y = 0; y < height; y++) {\n            for (int x = 0; x < width; x++) {\n                inputImage_h[y * width + x] = (float)(x + y) / (width + height) * 255.0f;\n            }\n        }\n\n        // Async copy from host to device\n        CUDA_CHECK(cudaMemcpyAsync(inputImage_d, inputImage_h, size * sizeof(float), cudaMemcpyHostToDevice, stream));\n\n        // Define block and grid sizes \n        dim3 blockSize(BLOCK_SIZE, BLOCK_SIZE, 1);\n        \n        // Calculate grid size using fewer blocks\n        int gridX = (width + BLOCK_SIZE - 1) / BLOCK_SIZE;\n        int gridY = (height + BLOCK_SIZE - 1) / BLOCK_SIZE;\n        \n        // Cap the grid dimensions to reduce number of blocks\n        gridX = min(gridX, 16);\n        gridY = min(gridY, 16);\n        \n        dim3 gridSize(gridX, gridY, 1);\n\n        // Create argument array for kernel launch\n        int radius = radii[testCase];\n        float sigmaS = sigmaOfSpatials[testCase];\n        float sigmaR = sigmaOfRanges[testCase];\n        \n        //Kernel Launch \n        void* kernelArgs[] = {(void*)&inputImage_d, (void*)&filteredImage_d, (void*)&width, (void*)&height, (void*)&radius,         (void*)&sigmaS, (void*)&sigmaR};\n        \n        // Launch the bilateral filter kernel asynchronously using cudaLaunchKernel\n        CUDA_CHECK(cudaLaunchKernel((const void*)k_bilateralFilterKernel, gridSize, blockSize, kernelArgs, 0, stream));\n\n        // Async copy from device to host\n        CUDA_CHECK(cudaMemcpyAsync(filteredImage_h, filteredImage_d, size * sizeof(float), cudaMemcpyDeviceToHost, stream));\n        \n        // Synchronize the stream to ensure results are ready\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n\n        // Define indices for key pixels\n        int centerIdx = (height/2) * width + (width/2);\n        int topLeftIdx = 0;\n        int topRightIdx = width - 1;\n        int bottomLeftIdx = (height - 1) * width;\n        int bottomRightIdx = (height - 1) * width + (width - 1);\n        \n        // Check sample pixels against expected values\n        assert(fabs(filteredImage_h[centerIdx] - expectedOutput[testCase][0]) < TOLERANCE);\n        assert(fabs(filteredImage_h[topLeftIdx] - expectedOutput[testCase][1]) < TOLERANCE);\n        assert(fabs(filteredImage_h[topRightIdx] - expectedOutput[testCase][2]) < TOLERANCE);\n        assert(fabs(filteredImage_h[bottomLeftIdx] - expectedOutput[testCase][3]) < TOLERANCE);\n        assert(fabs(filteredImage_h[bottomRightIdx] - expectedOutput[testCase][4]) < TOLERANCE);\n    }\n\n    // Cleanup with async free operations\n    CUDA_CHECK(cudaFreeAsync(inputImage_d, stream));\n    CUDA_CHECK(cudaFreeAsync(filteredImage_d, stream));\n    CUDA_CHECK(cudaStreamSynchronize(stream));\n    CUDA_CHECK(cudaStreamDestroy(stream));\n}\n\n// Bilateral Filter Kernel Applies an edge-preserving and smoothing filter,\n// each output pixel is computed as a weighted average of its neighborhood,\n// where the weights depend on both the spatial distance and the intensity difference.\n__global__ void k_bilateralFilterKernel(float *inputImage, float *filteredImage, int widthOfImage, int heightOfImage, int radiusOfFilter, float sigmaOfSpatial, float sigmaOfRange) {\n", "test": "int main() {\n    launch();\n}\n", "example_test": "    @example_test\n", "cuda_toolkit": "12.2"}
{"task_id": "CUDA/122", "date": "2025-03-31", "prompt": "Write a CUDA kernel to perform matrix multiplication by using tensor cores by using mma ptx instruction of dimension m16n8k8 for Ampere Architecture.\nConfigure it in row major by column major format, using bf16 data type for input matrices A (row major) and B (column major), and f32 for accumulator matrix C(row major), all input\nmatrices will have m16n8k8 compatible dimensions.\n\nThe signature of the function is __global__ void k_mmaTensorMatMul(__nv_bfloat16 *inputLayerA_d, __nv_bfloat16 *inputLayerB_d, float *outputLayer_d, int mDim, int nDim, int kDim), where inputLayerA_d is first input layer matrix with dimension mDim x kDim, inputLayerB_d is second input layer matrix with dimension kDim x nDim, outputLayer_d is output matrix with dimension mDim x nDim.\n\n>>> k_mmaTensorMatMul({3, 6, 7, 5}, {3, 5}, outputLayer_d, 2, 1, 2)-> outputLayer_d: ({44, 43})\n>>> k_mmaTensorMatMul({3, 6, 17, 15}, {13, 15}, outputLayer_d, 2, 1, 2)-> outputLayer_d: ({294, 303})\n", "cc_flags": "-arch=sm_80", "ld_flags": "", "declaration": "\n#include <cstdio>\n#include <cassert>\n#include <cstdint>\n#include <random>\n#include <cuda_runtime.h>\n#include <mma.h>\n\n#define CUDA_CHECK(call)                                                           \\\ndo {                                                                               \\\n        cudaError_t error = call;                                                  \\\n        if (error != cudaSuccess) {                                                \\\n            fprintf(stderr, \"CUDA Error: %s at %s:%d\\n\", cudaGetErrorString(error),\\\n                    __FILE__, __LINE__);                                           \\\n            exit(error);                                                           \\\n        }                                                                          \\\n} while (0)\n#undef NDEBUG\n\n#define MMA_M 16\n#define MMA_N 8\n#define MMA_K 8\n\n__global__ void k_mmaTensorMatMul(__nv_bfloat16 *inputLayerA_d, __nv_bfloat16 *inputLayerB_d, float *outputLayer_d, int mDim, int nDim, int kDim);\n\n// Function to compute valid reference result\nvoid cpuMatMulReference(const __nv_bfloat16* A,\n                        const __nv_bfloat16* B,\n                        float* cpuRefC,\n                        int M,\n                        int N,\n                        int K) {\n    for (int i = 0; i < M; i++) {\n        for (int j = 0; j < N; j++) {\n            float sum = 0.0f;\n            for (int k = 0; k < K; k++) {\n                float a_val = static_cast<float>(A[i*K + k]);\n                float b_val = static_cast<float>(B[k*N + j]);\n                sum += a_val * b_val;\n            }\n            cpuRefC[i*N + j] = sum;\n        }\n    }\n}\n\nvoid launch() {\n    const int TEST_CASE_COUNT = 7;\n    //Test case dimensions {M, N, K}\n    const int TEST_CASES_DIMS[TEST_CASE_COUNT][3] = {{16,16,16}, {512,512,512}, {32,16,32}, {256, 256, 256}, {64, 64, 64} , {64, 32, 32}, {128, 128, 128}};\n\n    //Tolerance for validation, set to 1% due to nature of half precision operations\n    const float TOLERANCE  = 0.01;\n    const int BLOCK_SIZE = 256;\n\n    //Set up random number generation\n    std::random_device randomSeedSource; // Automatically configure high quality seed using system info\n    std::mt19937 randEngine(randomSeedSource());\n\n    // Bounded random distribution for test case initialization\n    std::uniform_real_distribution<float> randDist(1.0f, 100.0f);\n\n    for (int i = 0; i < TEST_CASE_COUNT; i++) {\n        // Dimensions of the input and output layers\n        int M = TEST_CASES_DIMS[i][0]; //Number of Rows in Matrix A\n        int N = TEST_CASES_DIMS[i][1]; //Number of Columns in Matrix B\n        int K = TEST_CASES_DIMS[i][2]; //Number of Columns in Matrix A and Rows in Matrix B\n\n        //Pointers for Host Memory\n        __nv_bfloat16* A_h =(__nv_bfloat16*)malloc(M * K * sizeof(__nv_bfloat16));\n        __nv_bfloat16* B_h =(__nv_bfloat16*)malloc(K * N * sizeof(__nv_bfloat16));\n\n        float* cpuC_h =(float*)malloc(M * N * sizeof(float)); // Reference Matrix space allocation on host\n        float* gpuC_h = (float*)malloc(M * N * sizeof(float));// GPU result Matrix space allocation on host\n\n        //Pointers for device memory (GPU)\n        __nv_bfloat16* A_d;\n        __nv_bfloat16* B_d;\n        float* C_d;\n\n        //Populating input matrices with random values\n        for (int i = 0; i < M * K; i++) {\n            float val = randDist(randEngine);\n            A_h[i] = __nv_bfloat16(val);\n        }\n\n        for (int i = 0; i < K * N; i++) {\n            float val = randDist(randEngine);\n            B_h[i] = __nv_bfloat16(val);\n        }\n\n        // Use a CUDA stream for asynchronous operations\n        cudaStream_t stream;\n        CUDA_CHECK(cudaStreamCreate(&stream));\n\n        // Allocate the memory on the device\n        CUDA_CHECK(cudaMallocAsync(&A_d, M * K * sizeof(__nv_bfloat16), stream));\n        CUDA_CHECK(cudaMallocAsync(&B_d, K * N * sizeof(__nv_bfloat16), stream));\n        CUDA_CHECK(cudaMallocAsync(&C_d, M * N * sizeof(float), stream));\n\n        //Load Test Cases\n        CUDA_CHECK(cudaMemcpyAsync(A_d, A_h, M * K * sizeof(__nv_bfloat16), cudaMemcpyHostToDevice, stream));\n        CUDA_CHECK(cudaMemcpyAsync(B_d, B_h, K * N * sizeof(__nv_bfloat16), cudaMemcpyHostToDevice, stream));\n\n        // Initialize the result on the device\n        CUDA_CHECK(cudaMemsetAsync(C_d, 0, M * N * sizeof(float), stream));\n\n        //Check if the dimensions are divisible by the block tile dimensions\n        assert(M % MMA_M == 0);\n        assert(N % MMA_N == 0);\n        assert(K % MMA_K == 0);\n\n        dim3 gridDim((N + MMA_N - 1) / MMA_N, (M + MMA_M - 1) / MMA_M);\n        dim3 blockDim(BLOCK_SIZE);  // one warp per block\n        int shmemBytes = (MMA_M * MMA_K + MMA_K * MMA_N) * sizeof(__nv_bfloat16);\n\n        // Launch kernel\n        // Grid: ((N + MMA_N - 1/ MMA_N), (M + MMA_M - 1)/ MMA_M, 1)\n        // Block: (256, 1, 1)\n        void *args[] = {&A_d,\n                        &B_d,\n                        &C_d,\n                        (void*)&M,\n                        (void*)&N,\n                        (void*)&K};\n\n        CUDA_CHECK(cudaLaunchKernel((void*)k_mmaTensorMatMul,\n                                    gridDim,\n                                    blockDim,\n                                    args,\n                                    shmemBytes,\n                                    stream));\n\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n\n        cpuMatMulReference(A_h, B_h, cpuC_h, M, N, K);\n\n        //Copying the result back to the host\n        CUDA_CHECK(cudaMemcpyAsync(gpuC_h, C_d, M * N * sizeof(float), cudaMemcpyDeviceToHost, stream));\n\n        //Validate the result, with in 1% tolerance\n        for(int t = 0; t < M*N; ++t) {\n            assert(std::fabs((gpuC_h[t] - cpuC_h[t]) / std::fabs(cpuC_h[t])) <= TOLERANCE);\n        }\n\n        //Free up resources\n        CUDA_CHECK(cudaFreeAsync(A_d, stream));\n        CUDA_CHECK(cudaFreeAsync(B_d, stream));\n        CUDA_CHECK(cudaFreeAsync(C_d, stream));\n        CUDA_CHECK(cudaStreamDestroy(stream));\n        free(A_h);\n        free(B_h);\n        free(cpuC_h);\n        free(gpuC_h);\n    }\n}\n\n// Storing 16x8 Matrix Tile\n__device__ __forceinline__ void d_storeMatrixTile16x8(__nv_bfloat16* dst, __nv_bfloat16* (&reg)[4], int dstStrideBytes) {\n   int lane = threadIdx.x % 32;\n\n    //Casting 2x bf16 elements into 4 byte space of uint32_t\n    uint32_t (&regInt)[2] = reinterpret_cast<uint32_t(&)[2]>(reg);\n    uint32_t* dstPtr = reinterpret_cast<uint32_t*>(dst);\n    dstStrideBytes /= sizeof(uint32_t);\n\n    int fragmentRow = lane / 4;\n    int fragmentCol = lane % 4;\n\n    // Adjacent Threads store 4 bytes each\n    dstPtr[fragmentRow * dstStrideBytes + fragmentCol] = regInt[0];\n    fragmentRow += 8;\n    dstPtr[fragmentRow * dstStrideBytes + fragmentCol] = regInt[1];\n}\n\n__device__ __forceinline__ uint32_t d_cvtaToSharedU32(const void* ptr) {\n    unsigned long long address;\n    asm volatile(\"cvta.to.shared.u64 %0, %1;\" : \"=l\"(address) : \"l\"(ptr));\n    return static_cast<uint32_t>(address);\n}\n\n__device__ __forceinline__ void d_storeMatrixTile16x8_f32(float* dst, float reg[4], int n) {\n    int lane = threadIdx.x % 32;  // 0..31\n    int r = lane / 4;        // 0..7 for the top half\n    int c = (lane % 4) * 2;    // columns: 0,2,4,6\n    dst[r * n + c] = reg[0];\n    dst[r * n + c + 1] = reg[1];\n    dst[(r + 8) * n + c] = reg[2];\n    dst[(r + 8) * n + c + 1] = reg[3];\n}\n\n// Kernel: Multiply bf16 matrices inputLayerA_d (mDimx kDim) and inputLayerB_d (kDim x nDim) to produce an output outputLayer_d (mDim x nDim) in f32.\n// Each block (a single warp) computes one 16\u00d78 output tile using MMA instructions.\n__global__ void k_mmaTensorMatMul(__nv_bfloat16 *inputLayerA_d, __nv_bfloat16 *inputLayerB_d, float *outputLayer_d, int mDim, int nDim, int kDim) {\n", "test": "int main() {\n    launch();\n}\n", "example_test": "    @example_test\n", "cuda_toolkit": "12.2"}
{"task_id": "CUDA/123", "date": "2025-03-31", "prompt": "Write a CUDA kernel to simulate a logic circuit such as a MIMD (multiple instruction multiple data) pipeline, using shared-memory lookup table to accelerate the redundant lookups. Use circuit selection codes for each stage in the instruction code and compute the circuit output by a single lookup for each stage the data goes through.\n\nSignature of the CUDA kernel is __global__ void k_simulateLogicCircuit(uint32_t* input_d, uint8_t* output_d, uint8_t* lookupTable_d), where input_d is pointer to input array with each element representing 24 bit instruction and 8bit data, output_d is pointer to output array of 8 bit results of simulated logic circuit, and lookupTable_d is pointer to the truth table of all circuits used in the simulated MIMD pipeline.\n\n>>> k_simulateLogicCircuit({\n    256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270\n}, output_d,{\n    0, 0, 0, 0, 0, 1, 2, 3, 0, 2, 4, 6, 0, 3, 6, 9, \n    0, 4, 8, 12, 0, 5, 10, 15, 0, 6, 12, 18, 0, 7, 14, 21\n}) -> output_d: {\n    0, 0, 0, 0, 0, 1, 2, 3, 0, 2, 4, 6, 0, 3, 6\n}\n\n>>> k_simulateLogicCircuit({\n    256, 257, 258, 259, 260, 261, 262, 263, 256, 257, 258, 259, 260, 261, 262\n}, output_d,{\n    0, 1, 1, 2, 2, 3, 3, 4\n}) -> output_d: {\n    0, 1, 1, 2, 2, 3, 3, 4, 0, 1, 1, 2, 2, 3, 3\n}\n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_75 -arch=sm_70 -arch=sm_60", "ld_flags": "", "declaration": "#undef NDEBUG\n#include <assert.h>\n#include <cstdio>\n#include <cstdint>\n#include <cuda.h>\n#include <cuda_runtime.h>\n#include <device_launch_parameters.h>\n#define CUDA_CHECK(call) {                                     \\\n    cudaError_t error = call;                                  \\\n    if(error != cudaSuccess) {                                 \\\n        fprintf(stderr, \"CUDA error at %s: %d - %s \\n\",        \\\n                __FILE__, __LINE__, cudaGetErrorString(error));\\\n        exit(EXIT_FAILURE);                                    \\\n    }                                                          \\\n}\n\n// Algorithm-related constants.\n// Number of instances of pipelines to simulate. Each CUDA thread simulates a single pipeline in the MIMD pipeline.\nconstexpr int NUM_PIPELINES_OF_CIRCUIT = 15;\nconstexpr int NUM_STAGES_PER_PIPELINE = 12;\n// 2-bit selector value to end computations.\nconstexpr int NO_OPERATION = 0;\n// Input data and output data are 8-bit integers. Maximum 256 unique cases are possible.\nconstexpr int NUM_ALL_POSSIBLE_STATES = 256;\n// This is supposed to be constant for this test due to using only 2-bit selector code per pipeline stage.\nconstexpr int NUM_CIRCUITS = 3;\n// Each data is single byte inside a 32bit instruction input.\nconstexpr int NUM_BITS_OF_DATA = 8;\nconstexpr int MASK_SELECT_DATA = 0b11111111;\nconstexpr int INSERT_INSTRUCTION_0 = 0;\nconstexpr int INSERT_INSTRUCTION_1 = 2;\nconstexpr int INSERT_INSTRUCTION_2 = 4;\nconstexpr int INSERT_INSTRUCTION_3 = 6;\nconstexpr int INSERT_INSTRUCTION_4 = 8;\nconstexpr int INSERT_INSTRUCTION_5 = 10;\nconstexpr int INSERT_INSTRUCTION_6 = 12;\nconstexpr int INSERT_INSTRUCTION_7 = 14;\nconstexpr int INSERT_INSTRUCTION_8 = 16;\nconstexpr int INSERT_INSTRUCTION_9 = 18;\nconstexpr int INSERT_INSTRUCTION_10 = 20;\nconstexpr int INSERT_INSTRUCTION_11 = 22;\n\nconstexpr int INTERRUPT_DIVIDE_BY_ZERO = 0b11111111;\nconstexpr int NUM_LOOKUP_TABLE_BYTES = sizeof(uint8_t) * NUM_ALL_POSSIBLE_STATES * NUM_CIRCUITS;\nconstexpr int NUM_INPUT_BYTES = sizeof(uint32_t) * NUM_PIPELINES_OF_CIRCUIT;\n\n\n// CUDA-related constans.\nconstexpr int MINIMUM_ALLOWED_NUMBER_OF_THREADS_PER_BLOCK = 4;\nconstexpr int MINIMUM_ALLOWED_NUMBER_OF_BLOCKS_PER_GRID = 1;\n\n__global__ void k_simulateLogicCircuit(uint32_t* input_d, uint8_t* output_d, uint8_t* lookupTable_d);\n\nvoid launch() {\n    cudaDeviceProp props;\n    CUDA_CHECK(cudaGetDeviceProperties(&props, 0));\n    // Dynamically scaling the number of CUDA threads for the workload size.\n    int numThreadsPerBlock = NUM_PIPELINES_OF_CIRCUIT / props.multiProcessorCount;\n    numThreadsPerBlock = (numThreadsPerBlock / 32) * 32;\n    if(numThreadsPerBlock > props.maxThreadsPerBlock) {\n        numThreadsPerBlock = props.maxThreadsPerBlock;\n    }\n    if(numThreadsPerBlock < MINIMUM_ALLOWED_NUMBER_OF_THREADS_PER_BLOCK) {\n        numThreadsPerBlock = MINIMUM_ALLOWED_NUMBER_OF_THREADS_PER_BLOCK;\n    }\n    \n    int numBlocksPerGrid = NUM_PIPELINES_OF_CIRCUIT / numThreadsPerBlock;\n    if(numBlocksPerGrid > props.maxBlocksPerMultiProcessor * props.multiProcessorCount) {\n        numBlocksPerGrid = props.maxBlocksPerMultiProcessor * props.multiProcessorCount;\n    }\n    if(numBlocksPerGrid < MINIMUM_ALLOWED_NUMBER_OF_BLOCKS_PER_GRID) {\n        numBlocksPerGrid = MINIMUM_ALLOWED_NUMBER_OF_BLOCKS_PER_GRID;\n    }\n\n    dim3 gridDim(numBlocksPerGrid, 1, 1);\n    dim3 blockDim(numThreadsPerBlock, 1, 1);\n\n    // Dynamically allocating host arrays.\n    uint32_t* input_h = new uint32_t[NUM_PIPELINES_OF_CIRCUIT];\n    uint8_t* output_h = new uint8_t[NUM_PIPELINES_OF_CIRCUIT];\n    uint8_t* lookupTable_h = new uint8_t[NUM_ALL_POSSIBLE_STATES * NUM_CIRCUITS];\n    cudaStream_t stream;\n    uint32_t* input_d;\n    uint8_t* output_d;\n    uint8_t* lookupTable_d;\n    CUDA_CHECK(cudaStreamCreate(&stream));\n    // Dynamically allocating device arrays.\n    CUDA_CHECK(cudaMallocAsync(&input_d, NUM_INPUT_BYTES, stream));\n    CUDA_CHECK(cudaMallocAsync(&output_d, sizeof(uint8_t) * NUM_PIPELINES_OF_CIRCUIT, stream));\n    CUDA_CHECK(cudaMallocAsync(&lookupTable_d, NUM_LOOKUP_TABLE_BYTES, stream));\n    void* args[3] = { &input_d, &output_d, &lookupTable_d };\n    // Dynamic size of shared memory.\n    int sharedMemorySize = NUM_CIRCUITS * NUM_ALL_POSSIBLE_STATES * sizeof(uint8_t);\n\n    auto hToD = cudaMemcpyHostToDevice;\n    auto dToH = cudaMemcpyDeviceToHost;\n\n    // Test 1: 2-stage pipeline. Passing the data through a 2-bit adder (adds 2 bit parts into 4 bit parts) and then a 4-bit adder (2 nibbles into one 8-bit integer).\n    {\n        for(int i = 0; i < NUM_CIRCUITS * NUM_ALL_POSSIBLE_STATES; i++) {\n            lookupTable_h[i] = 0;\n        }\n        uint32_t circuit1 = 1;\n        uint32_t circuit2 = 2;\n        // LUT for for 2-bit adder working on 4 parts of the 8-bit input.\n        for (uint32_t i = 0; i < NUM_ALL_POSSIBLE_STATES; i++) {\n            uint8_t input = i;\n            uint8_t variable1 = input & 0b11;\n            uint8_t variable2 = (input >> 2) & 0b11;\n            uint8_t variable3 = (input >> 4) & 0b11;\n            uint8_t variable4 = (input >> 6) & 0b11;\n            uint8_t sum1 = (variable1 + variable2);\n            uint8_t sum2 = (variable3 + variable4);\n            uint8_t output = sum1 | (sum2 << 4);\n            lookupTable_h[i + (circuit1 - 1) * NUM_ALL_POSSIBLE_STATES] = output;\n        }\n        // LUT for for 4-bit adder working on 2 parts of the 8-bit input.\n        for (uint32_t i = 0; i < NUM_ALL_POSSIBLE_STATES; i++) {\n            uint8_t input = i;\n            uint8_t variable1 = input & 0b1111;\n            uint8_t variable2 = (input >> 4) & 0b1111;\n            uint8_t sum = variable1 + variable2;\n            uint8_t output = sum;\n            lookupTable_h[i + (circuit2 - 1) * NUM_ALL_POSSIBLE_STATES] = output;\n        }\n        for (uint32_t i = 0; i < NUM_PIPELINES_OF_CIRCUIT; i++) {\n            // Instruction is made of two selector codes. Circuit1 and circuit2. Circuit1 will be selected during the first stage of pipeline and circuit2 will be selected during the second stage of pipeline.\n            uint32_t instruction = (circuit1 << INSERT_INSTRUCTION_0) | (circuit2 << INSERT_INSTRUCTION_1);\n            uint32_t inputData = i % 256;\n            // Instruction and the data is encoded as a single input.\n            input_h[i] = ((instruction << NUM_BITS_OF_DATA) | inputData);\n        }\n        CUDA_CHECK(cudaMemcpyAsync(input_d, input_h, NUM_INPUT_BYTES, hToD, stream));\n        CUDA_CHECK(cudaMemcpyAsync(lookupTable_d, lookupTable_h, NUM_LOOKUP_TABLE_BYTES, hToD, stream));\n        // Grid:(3, 1, 1)\n        // Block: (4, 1, 1)\n        CUDA_CHECK(cudaLaunchKernel((void*)k_simulateLogicCircuit, gridDim, blockDim, args, sharedMemorySize, stream));\n        CUDA_CHECK(cudaMemcpyAsync(output_h, output_d, sizeof(uint8_t) * NUM_PIPELINES_OF_CIRCUIT, dToH, stream));\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n        for (int i = 0; i < NUM_PIPELINES_OF_CIRCUIT; i++) {\n            uint8_t data = input_h[i] & MASK_SELECT_DATA;\n            uint8_t value1 = data & 0b11;\n            uint8_t value2 = (data>>2) & 0b11;\n            uint8_t value3 = (data>>4) & 0b11;\n            uint8_t value4 = (data>>6) & 0b11;\n            uint8_t sum = value1 + value2 + value3 + value4;\n            assert(sum == output_h[i]);\n        }\n    }\n    // Test 2: Single operation. Reversing the bits of all odd-indexed elements and inverting the bits of all even-indexed elements.\n    {\n        for(int i = 0; i < NUM_CIRCUITS * NUM_ALL_POSSIBLE_STATES; i++) {\n            lookupTable_h[i] = 0;\n        }\n        uint32_t circuit1 = 1;\n        uint32_t circuit2 = 2;\n        // LUT for reversed bits.\n        for (uint32_t i = 0; i < NUM_ALL_POSSIBLE_STATES; i++) {\n            uint32_t x = ((i & 0xF0) >> 4) | ((i & 0x0F) << 4);\n            x = ((x & 0xCC) >> 2) | ((x & 0x33) << 2);\n            x = ((x & 0xAA) >> 1) | ((x & 0x55) << 1);\n            lookupTable_h[i + (circuit1 - 1) * NUM_ALL_POSSIBLE_STATES] = x;\n        }\n        // LUT for inverted bits\n        for (uint32_t i = 0; i < NUM_ALL_POSSIBLE_STATES; i++) {\n            lookupTable_h[i + (circuit2 - 1) * NUM_ALL_POSSIBLE_STATES] = ~i;\n        }\n        for (uint32_t i = 0; i < NUM_PIPELINES_OF_CIRCUIT; i++) {\n            // Instruction is made of only one of selector codes. Circuit1 or circuit2. Pipeline will run only single stage for any input.\n            uint32_t instruction = (i % 2 == 1) ? circuit1 : circuit2;\n            uint32_t inputData = i % 256;\n            input_h[i] = ((instruction << NUM_BITS_OF_DATA) | inputData);\n        }\n        CUDA_CHECK(cudaMemcpyAsync(input_d, input_h, NUM_INPUT_BYTES, hToD, stream));\n        CUDA_CHECK(cudaMemcpyAsync(lookupTable_d, lookupTable_h, NUM_LOOKUP_TABLE_BYTES, hToD, stream));\n        // Grid:(3, 1, 1)\n        // Block: (4, 1, 1)\n        CUDA_CHECK(cudaLaunchKernel((void*)k_simulateLogicCircuit, gridDim, blockDim, args, sharedMemorySize, stream));\n        CUDA_CHECK(cudaMemcpyAsync(output_h, output_d, sizeof(uint8_t) * NUM_PIPELINES_OF_CIRCUIT, dToH, stream));\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n        for (int i = 0; i < NUM_PIPELINES_OF_CIRCUIT; i++) {\n            uint8_t data = input_h[i] & MASK_SELECT_DATA;\n            if ((i % 2) == 1) {\n                assert(lookupTable_h[data + (circuit1 - 1) * NUM_ALL_POSSIBLE_STATES] == output_h[i]);\n            }\n            else {\n                assert(lookupTable_h[data + (circuit2 - 1) * NUM_ALL_POSSIBLE_STATES] == output_h[i]);\n            }\n        }\n    }\n    // Test 3: 5-stage pipeline with 3 different circuits used. x = x * 2, x = x - 1, x = x * 2, x = x - 1, and majority voting applied.\n    {\n        for(int i = 0; i < NUM_CIRCUITS * NUM_ALL_POSSIBLE_STATES; i++) {\n            lookupTable_h[i] = 0;\n        }\n        uint32_t circuit1 = 1;\n        uint32_t circuit2 = 2;\n        uint32_t circuit3 = 3;\n        // LUT for x = x * 2\n        for (uint32_t i = 0; i < NUM_ALL_POSSIBLE_STATES; i++) {\n            lookupTable_h[i + (circuit1 - 1) * NUM_ALL_POSSIBLE_STATES] = i * 2;\n        }\n        // LUT for x = x - 1\n        for (uint32_t i = 0; i < NUM_ALL_POSSIBLE_STATES; i++) {\n            lookupTable_h[i + (circuit2 - 1) * NUM_ALL_POSSIBLE_STATES] = i - 1;\n        }\n        // LUT for majority voting.\n        for (uint32_t i = 0; i < NUM_ALL_POSSIBLE_STATES; i++) {\n#if defined(_WIN64) || defined(_WIN32)\n            lookupTable_h[i + (circuit3 - 1) * NUM_ALL_POSSIBLE_STATES] = (__popcnt(i) > 4 ? 1 : 0);\n#endif\n#ifdef __unix__  \n            lookupTable_h[i + (circuit3 - 1) * NUM_ALL_POSSIBLE_STATES] = (__builtin_popcount(i) > 4 ? 1 : 0);\n#endif\n        }\n        for (uint32_t i = 0; i < NUM_PIPELINES_OF_CIRCUIT; i++) {\n            // Instruction is made of five selector codes. Circuit1, circuit2, circuit1, circuit2, circuit3. Pipeline will run five stages for five different operations for all data in parallel.\n            uint32_t instruction = (circuit1 << INSERT_INSTRUCTION_0) | (circuit2 << INSERT_INSTRUCTION_1) | (circuit1 << INSERT_INSTRUCTION_2) | (circuit2 << INSERT_INSTRUCTION_3) | (circuit3 << INSERT_INSTRUCTION_4);\n            uint32_t inputData = i % 256;\n            input_h[i] = ((instruction << NUM_BITS_OF_DATA) | inputData);\n        }\n        CUDA_CHECK(cudaMemcpyAsync(input_d, input_h, NUM_INPUT_BYTES, hToD, stream));\n        CUDA_CHECK(cudaMemcpyAsync(lookupTable_d, lookupTable_h, NUM_LOOKUP_TABLE_BYTES, hToD, stream));\n        // Grid:(3, 1, 1)\n        // Block: (4, 1, 1)\n        CUDA_CHECK(cudaLaunchKernel((void*)k_simulateLogicCircuit, gridDim, blockDim, args, sharedMemorySize, stream));\n        CUDA_CHECK(cudaMemcpyAsync(output_h, output_d, sizeof(uint8_t) * NUM_PIPELINES_OF_CIRCUIT, dToH, stream));\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n        for (int i = 0; i < NUM_PIPELINES_OF_CIRCUIT; i++) {\n            uint8_t data = input_h[i] & MASK_SELECT_DATA;\n            uint8_t hostResult = data;\n            hostResult = hostResult * 2 - 1;\n            hostResult = hostResult * 2 - 1;\n#if defined(_WIN64) || defined(_WIN32)\n            hostResult = (__popcnt(hostResult) > 4 ? 1 : 0);\n#endif\n#ifdef __unix__ \n            hostResult = (__builtin_popcount(hostResult) > 4 ? 1 : 0);\n#endif\n            assert(hostResult == output_h[i]);\n        }\n    }\n    // Test 4: 1 bit + 2 bit adder using single circuit.\n    {\n        for(int i = 0; i < NUM_CIRCUITS * NUM_ALL_POSSIBLE_STATES; i++) {\n            lookupTable_h[i] = 0;\n        }\n        uint32_t circuit1 = 1;\n        // LUT for 1 bit + 2 bit adder, returning 3 bits.\n        constexpr int NUM_STATES_FOR_1BIT_2BIT_ADDER = 8;\n        for (uint32_t i = 0; i < NUM_STATES_FOR_1BIT_2BIT_ADDER; i++) {\n            uint8_t value1Bit = i & 1; \n            uint8_t value2Bit = (i / 2) & 3; \n            lookupTable_h[i + (circuit1 - 1) * NUM_ALL_POSSIBLE_STATES] = value1Bit + value2Bit;\n        }\n        for (uint32_t i = 0; i < NUM_PIPELINES_OF_CIRCUIT; i++) {\n            uint32_t inputData = i % NUM_STATES_FOR_1BIT_2BIT_ADDER;\n            uint32_t instruction = (circuit1 << INSERT_INSTRUCTION_0);\n            input_h[i] = ((instruction << NUM_BITS_OF_DATA) | inputData);\n        }\n        CUDA_CHECK(cudaMemcpyAsync(input_d, input_h, NUM_INPUT_BYTES, hToD, stream));\n        CUDA_CHECK(cudaMemcpyAsync(lookupTable_d, lookupTable_h, NUM_LOOKUP_TABLE_BYTES, hToD, stream));\n        // Grid:(3, 1, 1)\n        // Block: (4, 1, 1)\n        CUDA_CHECK(cudaLaunchKernel((void*)k_simulateLogicCircuit, gridDim, blockDim, args, sharedMemorySize, stream));\n        CUDA_CHECK(cudaMemcpyAsync(output_h, output_d, sizeof(uint8_t) * NUM_PIPELINES_OF_CIRCUIT, dToH, stream));\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n        for (int i = 0; i < NUM_PIPELINES_OF_CIRCUIT; i++) {\n            uint8_t data = input_h[i] & MASK_SELECT_DATA;\n            uint8_t value1Bit = data & 1; \n            uint8_t value2Bit = (data / 2) & 3; \n            assert(value1Bit + value2Bit == output_h[i]);\n        }\n    }\n    // Test 5: 8-stage pipeline. Four times repeated linear congruential generator that calculates seed = (5 * seed + 7) mod 256 where modulo is automatically calculated for the 8bit variable assignment.\n    {\n        for(int i = 0; i < NUM_CIRCUITS * NUM_ALL_POSSIBLE_STATES; i++) {\n            lookupTable_h[i] = 0;\n        }\n        uint32_t circuit1 = 1;\n        uint32_t circuit2 = 2;\n        // LUT for x = x * 5\n        for (uint32_t i = 0; i < NUM_ALL_POSSIBLE_STATES; i++) {\n            lookupTable_h[i + (circuit1 - 1) * NUM_ALL_POSSIBLE_STATES] = i * 5;\n        }\n        // LUT for x = x + 7\n        for (uint32_t i = 0; i < NUM_ALL_POSSIBLE_STATES; i++) {\n            lookupTable_h[i + (circuit2 - 1) * NUM_ALL_POSSIBLE_STATES] = i + 7;\n        }\n        for (uint32_t i = 0; i < NUM_PIPELINES_OF_CIRCUIT; i++) {\n            // Instruction is made of eight selector codes. Circuit1, circuit2, circuit1, circuit2,circuit1, circuit2,circuit1, circuit2. Pipeline will run eight stages for eight different operations for all data in parallel.\n            uint32_t instruction = (circuit1 << INSERT_INSTRUCTION_0) | (circuit2 << INSERT_INSTRUCTION_1) | (circuit1 << INSERT_INSTRUCTION_2) | (circuit2 << INSERT_INSTRUCTION_3) | (circuit1 << INSERT_INSTRUCTION_4) | (circuit2 << INSERT_INSTRUCTION_5) | (circuit1 << INSERT_INSTRUCTION_6) | (circuit2 << INSERT_INSTRUCTION_7);\n            uint32_t inputData = i % 256;\n            input_h[i] = ((instruction << NUM_BITS_OF_DATA) | inputData);\n        }\n        CUDA_CHECK(cudaMemcpyAsync(input_d, input_h, NUM_INPUT_BYTES, hToD, stream));\n        CUDA_CHECK(cudaMemcpyAsync(lookupTable_d, lookupTable_h, NUM_LOOKUP_TABLE_BYTES, hToD, stream));\n        // Grid:(3, 1, 1)\n        // Block: (4, 1, 1)\n        CUDA_CHECK(cudaLaunchKernel((void*)k_simulateLogicCircuit, gridDim, blockDim, args, sharedMemorySize, stream));\n        CUDA_CHECK(cudaMemcpyAsync(output_h, output_d, sizeof(uint8_t) * NUM_PIPELINES_OF_CIRCUIT, dToH, stream));\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n        for (int i = 0; i < NUM_PIPELINES_OF_CIRCUIT; i++) {\n            uint8_t data = input_h[i] & MASK_SELECT_DATA;\n            uint8_t hostResult = ((((data * 5 + 7) * 5 + 7) * 5 + 7) * 5 + 7);\n            assert(hostResult == output_h[i]);\n        }\n    }\n    // Test 6: Two-stage pipeline. Right-shift for (data % 4) bits, twice.\n    {\n        for(int i = 0; i < NUM_CIRCUITS * NUM_ALL_POSSIBLE_STATES; i++) {\n            lookupTable_h[i] = 0;\n        }\n        uint32_t circuit1 = 1;\n        // LUT for x = x >> (x % 4).\n        for (uint32_t i = 0; i < NUM_ALL_POSSIBLE_STATES; i++) {\n            uint8_t value = i >> (i % 4);\n            lookupTable_h[i + (circuit1 - 1) * NUM_ALL_POSSIBLE_STATES] = value;\n        }\n        for (uint32_t i = 0; i < NUM_PIPELINES_OF_CIRCUIT; i++) {\n            // Two-stage pipeline is defined.\n            uint32_t instruction = (circuit1 << INSERT_INSTRUCTION_0) | (circuit1 << INSERT_INSTRUCTION_1);\n            uint32_t inputData = i % 256;\n            input_h[i] = ((instruction << NUM_BITS_OF_DATA) | inputData);\n        }\n        CUDA_CHECK(cudaMemcpyAsync(input_d, input_h, NUM_INPUT_BYTES, hToD, stream));\n        CUDA_CHECK(cudaMemcpyAsync(lookupTable_d, lookupTable_h, NUM_LOOKUP_TABLE_BYTES, hToD, stream));\n        // Grid:(3, 1, 1)\n        // Block: (4, 1, 1)\n        CUDA_CHECK(cudaLaunchKernel((void*)k_simulateLogicCircuit, gridDim, blockDim, args, sharedMemorySize, stream));\n        CUDA_CHECK(cudaMemcpyAsync(output_h, output_d, sizeof(uint8_t) * NUM_PIPELINES_OF_CIRCUIT, dToH, stream));\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n        for (int i = 0; i < NUM_PIPELINES_OF_CIRCUIT; i++) {\n            uint8_t data = input_h[i] & MASK_SELECT_DATA;\n            uint8_t value1 = data >> (data % 4);\n            uint8_t value2 = value1 >> (value1 % 4);\n            uint8_t hostResult = value2;\n            assert(hostResult == output_h[i]);\n        }\n    }\n    // Test 7: Passing the data through a 4-bit divider. Lower half of 8-bit input is divided by the higher half of 8-bit input and the result is written to the output. If division by zero is requested, it returns INTERRUPT_DIVIDE_BY_ZERO to define an undefined 4-bit division result.\n    {\n        for(int i = 0; i < NUM_CIRCUITS * NUM_ALL_POSSIBLE_STATES; i++) {\n            lookupTable_h[i] = 0;\n        }\n        uint32_t circuit1 = 1;\n        // LUT for for 4-bit divider.\n        for (uint32_t i = 0; i < NUM_ALL_POSSIBLE_STATES; i++) {\n            uint8_t input = i;\n            uint8_t value1 = input & 0b1111;\n            uint8_t value2 = (input >> 2) & 0b1111;\n            uint8_t division = value2 == 0 ? INTERRUPT_DIVIDE_BY_ZERO : (value1 / value2);\n            lookupTable_h[i + (circuit1 - 1) * NUM_ALL_POSSIBLE_STATES] = division;\n        }\n        for (uint32_t i = 0; i < NUM_PIPELINES_OF_CIRCUIT; i++) {\n            // Single operation is defined which is the division operation of a 4-bit value by another 4-bit value within the 8-bit integer input.\n            uint32_t instruction = circuit1;\n            uint32_t inputData = i % 256;\n            input_h[i] = ((instruction << NUM_BITS_OF_DATA) | inputData);\n        }\n        CUDA_CHECK(cudaMemcpyAsync(input_d, input_h, NUM_INPUT_BYTES, hToD, stream));\n        CUDA_CHECK(cudaMemcpyAsync(lookupTable_d, lookupTable_h, NUM_LOOKUP_TABLE_BYTES, hToD, stream));\n        // Grid:(3, 1, 1)\n        // Block: (4, 1, 1)\n        CUDA_CHECK(cudaLaunchKernel((void*)k_simulateLogicCircuit, gridDim, blockDim, args, sharedMemorySize, stream));\n        CUDA_CHECK(cudaMemcpyAsync(output_h, output_d, sizeof(uint8_t) * NUM_PIPELINES_OF_CIRCUIT, dToH, stream));\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n        for (int i = 0; i < NUM_PIPELINES_OF_CIRCUIT; i++) {\n            uint8_t data = input_h[i] & MASK_SELECT_DATA;\n            uint8_t value1 = data & 0b1111;\n            uint8_t value2 = (data>>2) & 0b1111;\n            uint8_t division = value2 == 0 ? INTERRUPT_DIVIDE_BY_ZERO : (value1 / value2);\n            assert(division == output_h[i]);\n        }\n    }\n    // Test 8: 2 bit * 3 bit multiplier using single circuit.\n    {\n        for(int i = 0; i < NUM_CIRCUITS * NUM_ALL_POSSIBLE_STATES; i++) {\n            lookupTable_h[i] = 0;\n        }\n        uint32_t circuit1 = 1;\n        // LUT for 2 bit + 3 bit multiplier, returning 5 bits.\n        constexpr int NUM_STATES_FOR_2BIT_3BIT_MULTIPLIER = 32;\n        for (uint32_t i = 0; i < NUM_STATES_FOR_2BIT_3BIT_MULTIPLIER; i++) {\n            uint8_t value2Bit = i & 3; \n            uint8_t value3Bit = (i / 4) & 7; \n            lookupTable_h[i + (circuit1 - 1) * NUM_ALL_POSSIBLE_STATES] = value2Bit * value3Bit;\n        }\n        for (uint32_t i = 0; i < NUM_PIPELINES_OF_CIRCUIT; i++) {\n            uint32_t inputData = i % NUM_STATES_FOR_2BIT_3BIT_MULTIPLIER;\n            uint32_t instruction = (circuit1 << INSERT_INSTRUCTION_0);\n            input_h[i] = ((instruction << NUM_BITS_OF_DATA) | inputData);\n        }\n        CUDA_CHECK(cudaMemcpyAsync(input_d, input_h, NUM_INPUT_BYTES, hToD, stream));\n        CUDA_CHECK(cudaMemcpyAsync(lookupTable_d, lookupTable_h, NUM_LOOKUP_TABLE_BYTES, hToD, stream));\n        // Grid:(3, 1, 1)\n        // Block: (4, 1, 1)\n        CUDA_CHECK(cudaLaunchKernel((void*)k_simulateLogicCircuit, gridDim, blockDim, args, sharedMemorySize, stream));\n        CUDA_CHECK(cudaMemcpyAsync(output_h, output_d, sizeof(uint8_t) * NUM_PIPELINES_OF_CIRCUIT, dToH, stream));\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n        for (int i = 0; i < NUM_PIPELINES_OF_CIRCUIT; i++) {\n            uint8_t data = input_h[i] & MASK_SELECT_DATA;\n            uint8_t value2Bit = data & 3; \n            uint8_t value3Bit = (data / 4) & 7; \n            assert(value2Bit * value3Bit == output_h[i]);\n        }\n    }\n    // Freeing the unused memory space.\n    CUDA_CHECK(cudaFreeAsync(input_d, stream));\n    CUDA_CHECK(cudaFreeAsync(output_d, stream));\n    CUDA_CHECK(cudaFreeAsync(lookupTable_d, stream));\n    // Deleting host arrays while device arrays are freed asynchronously.\n    delete[] input_h;\n    delete[] output_h;\n    delete[] lookupTable_h;\n    CUDA_CHECK(cudaStreamDestroy(stream));\n}\n\n// This CUDA kernel simulates up to 12 stages of a MIMD pipeline where each parallel pipeline is computed by a different CUDA thread.\n// The MIMD pipeline works in parallel to process all input elements and writes results to the output elements.\n// The logic calculation of each circuit is made by a single lookup from a shared-memory table, inside each stage.\n__global__ void k_simulateLogicCircuit(uint32_t* input_d, uint8_t* output_d, uint8_t* lookupTable_d) {\n", "test": "int main() {\n    launch();\n}\n", "example_test": "    @example_test\n", "cuda_toolkit": "12.2"}
{"task_id": "CUDA/124", "date": "2025-03-31", "prompt": "Write a cuda kernel to sort integers using parallel bubble sort algorithm. This algorithm sorts the integers in N iterations, where N is the size of the input array. In each iteration the adjacent pairs of integers across the array are compared in two steps, in first step pairs with even index are compared and in second step pairs with odd index are compared. \n\nThe signature of the function is __global__ void k_bubbleSort(int *inputOutput_d, int numElements), where inputOutput_d is a pointer to an array of unsorted integers that are sorted inplace, numElements denotes the number of integers in the input. \n\n>>> k_bubbleSort({9, 3, 4, 6, 2, 5}, 6) -> inputOutput_d: ({2, 3, 4, 5, 6, 9})\n>>> k_bubbleSort({19, 17, 13, 18, 21, 24}, 6) -> inputOutput_d: ({13, 17, 18, 19, 21, 24})\n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_70", "ld_flags": "", "declaration": "#include <cstdio>\n#include <limits.h>\n#include <assert.h>\n#include <cuda_runtime.h>\n#include <cooperative_groups.h>\nusing namespace cooperative_groups;\n\n#define SET_TO_ZERO 0\n#define DIVIDE_BY_TWO 2\n\n#define CUDA_CHECK(call)                                        \\\ndo {                                                            \\\n        cudaError_t error = call;                               \\\n        if (error != cudaSuccess) {                             \\\n            fprintf(stderr, \"CUDA error at %s:%d - %s\\n\",       \\\n                    __FILE__, __LINE__,                         \\\n                    cudaGetErrorString(error));                 \\\n            exit(EXIT_FAILURE);                                 \\\n        }                                                       \\\n} while(0)\n\n__global__ void k_bubbleSort(int *inputOutput_d, int numElements);\n\nvoid launch() {\n\n    //Initialize Constants\n    const int TEST_CASE_COUNT = 7;\n    const int NUMBER_OF_THREADS_PER_BLOCK = 16;\n    const int SHARED_MEMORY_SIZE_IN_BYTES = 0;\n  \n    //Initialise Test Data\n    //Test Data Dimensions\n    int inputArraySize[TEST_CASE_COUNT] = {9, 12, 16, 24, 32, 48, 64};\n\n    //Identify max input size\n    int maxInputSize = 0;\n    for(int index = 0; index < TEST_CASE_COUNT; index++) {\n        maxInputSize = max(maxInputSize, inputArraySize[index]);\n    }\n\n    //Input Data For Test\n    int input_h[TEST_CASE_COUNT][maxInputSize] = {\n        //Test Case - 1\n        {19, 4, 1, 5, 25, 24, 13, 17, 16},\n        //Test Case - 2\n        {4, 5, 28, 36, 20, 21, 37, 10, 6, 45, 16, 18},\n        //Test Case - 3\n        {36, 9, 27, 2, 8, 13, 7, 14, 29, 20, 19, 5, 37, 22, 24, 12},\n        //Test Case - 4\n        {30, 33, 55, 8, 9, 16, 43, 58, 57, 54, 34, 56, 51, 21, 26, 25, 24, 48, 14, 50, 15, 44, 18, 41},\n        //Test Case - 5\n        {16, 24, 17, 11, 3, 1, 28, 23, 46, 45, 26, 48, 37, 22, 34, 43, 51, 15, 39, 40, 13, 58, 54, 41, 6, 29, 4, 50, 56, 32, 38, 27},\n        //Test Case - 6\n        {30, 46, 65, 13, 25, 53, 52, 34, 16, 69, 39, 55, 61, 35, 57, 48, 23, 9, 31, 36, 11, 38, 68, 24, 50, 19, 62, 27, 4, 37, 60, 49, 20, 44, 43, 33, 21, 17, 64, 18, 29, 45, 66, 40, 63, 6, 12, 10},\n        //Test Case - 7\n        {56, 48, 90, 99, 2, 27, 26, 38, 8, 3, 20, 75, 55, 93, 51, 28, 64, 30, 16, 82, 53, 49, 11, 54, 17, 67, 24, 44, 71, 86, 87, 95, 94, 18, 78, 42, 25, 34, 60, 1, 88, 52, 80, 5, 14, 91, 23, 96, 47, 15, 59, 58, 6, 36, 79, 12, 74, 85, 37, 31, 21, 46, 33, 92}\n    };\n    \n    //Expected Output for Test\n    int expectedOutput_h[TEST_CASE_COUNT][maxInputSize] = {\n        //Test Case - 1\n        {1, 4, 5, 13, 16, 17, 19, 24, 25},\n        //Test Case - 2\n        {4, 5, 6, 10, 16, 18, 20, 21, 28, 36, 37, 45},\n        //Test Case - 3\n        {2, 5, 7, 8, 9, 12, 13, 14, 19, 20, 22, 24, 27, 29, 36, 37},\n        //Test Case - 4\n        {8, 9, 14, 15, 16, 18, 21, 24, 25, 26, 30, 33, 34, 41, 43, 44, 48, 50, 51, 54, 55, 56, 57, 58},\n        //Test Case - 5\n        {1, 3, 4, 6, 11, 13, 15, 16, 17, 22, 23, 24, 26, 27, 28, 29, 32, 34, 37, 38, 39, 40, 41, 43, 45, 46, 48, 50, 51, 54, 56, 58},\n        //Test Case - 6\n        {4, 6, 9, 10, 11, 12, 13, 16, 17, 18, 19, 20, 21, 23, 24, 25, 27, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 43, 44, 45, 46, 48, 49, 50, 52, 53, 55, 57, 60, 61, 62, 63, 64, 65, 66, 68, 69},\n        //Test Case - 7\n        {1, 2, 3, 5, 6, 8, 11, 12, 14, 15, 16, 17, 18, 20, 21, 23, 24, 25, 26, 27, 28, 30, 31, 33, 34, 36, 37, 38, 42, 44, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 58, 59, 60, 64, 67, 71, 74, 75, 78, 79, 80, 82, 85, 86, 87, 88, 90, 91, 92, 93, 94, 95, 96, 99}\n    };\n\n    //Output of device on host\n    int output_h[maxInputSize] = {};\n\n    //Use CUDA Streams for Asynchronous Execution\n    cudaStream_t stream;\n    CUDA_CHECK(cudaStreamCreate(&stream));\n \n    //Allocate Device Memory\n    int *inputOutput_d;\n\n    CUDA_CHECK(cudaMallocAsync((void**)&inputOutput_d, maxInputSize * sizeof(int), stream));\n    \n    //Execute Test Cases\n    for (int testCase = 0; testCase < TEST_CASE_COUNT; testCase++) {\n        \n        int numElements = inputArraySize[testCase];\n\n        //Reset Output\n        CUDA_CHECK(cudaMemsetAsync(inputOutput_d, SET_TO_ZERO, maxInputSize * sizeof(int), stream));\n\n        //Copy input data from host to device\n        CUDA_CHECK(cudaMemcpyAsync(inputOutput_d, input_h[testCase], numElements * sizeof(int), cudaMemcpyHostToDevice, stream));\n\n        //Get Device Properties\n        cudaDeviceProp prop;\n        int device;\n        cudaGetDevice(&device);\n        cudaGetDeviceProperties(&prop, device);\n\n        //Set Kernel Configuration\n        int numThreadsPerBlock = NUMBER_OF_THREADS_PER_BLOCK;\n        numThreadsPerBlock = min(numThreadsPerBlock, prop.maxThreadsDim[0]);\n        \n        //Only numElements / 2 threads are required\n        int halfNumElements = numElements / DIVIDE_BY_TWO;\n        int numBlocks = ceil((float)(halfNumElements) / numThreadsPerBlock);\n        numBlocks = min(numBlocks, prop.maxGridSize[0]);\n\n        dim3 block(numThreadsPerBlock, 1, 1);\n        dim3 grid(numBlocks, 1, 1);\n\n        //Launch Kernel\n        //Grid: (numElements/16, 1, 1)\n        //Block: (16, 1, 1)\n        void *args[] = {&inputOutput_d, &numElements};\n        CUDA_CHECK(cudaLaunchCooperativeKernel((void*)k_bubbleSort, grid, block, args, SHARED_MEMORY_SIZE_IN_BYTES, stream));\n        \n        //Copy Data from device to host\n        CUDA_CHECK(cudaMemcpyAsync(output_h, inputOutput_d, numElements * sizeof(int), cudaMemcpyDeviceToHost, stream));\n        \n        //Synchronize tasks in the stream\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n\n        //Assert device output and expected output\n        for(int index = 0; index < numElements; index++) {\n            assert(output_h[index] == expectedOutput_h[testCase][index]);\n        }\n      \n    }\n    \n    //Deallocate Device Memory\n    CUDA_CHECK(cudaFreeAsync(inputOutput_d, stream));\n    CUDA_CHECK(cudaStreamDestroy(stream));\n\n}\n\n__global__ void k_bubbleSort(int *inputOutput_d, int numElements) {\n", "test": "int main() {\n    launch();\n}\n", "example_test": "    @example_test\n", "cuda_toolkit": "12.2"}
{"task_id": "CUDA/125", "date": "2025-03-31", "prompt": "Write a CUDA kernel to detect presence of a signal using energy detection algorithm. Given an input signal vector $a$ with $n$ elements and an energy window of length $m$ ($m < $n). The kernel should use warp shuffles, reductions and atomics to determine the index corresponding to the peak output.\n\nThe signature of the function is __global__ void k_calculateMovingEnergy(int *inputVector, int windowLength, int *maxResult, int *maxResultIdx, int size), where inputVector is the input signal array, windowLength is the length of the window to calculate energy, maxResult is the peak energy window output, maxResultIdx contains index of peak energy and size is the length of the input signal array.\n\n>>> k_calculateMovingEnergy({1, 2, 3, 4, 5, 6, 7}, 2, maxResult, maxResultIdx, 7) -> maxResult : 85, maxResultIdx : 5\n>>> k_calculateMovingEnergy({3, 4, 2, 7, 9, 8, 1}, 3, maxResult, maxResultIdx, 7) -> maxResult : 194, maxResultIdx : 3\n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_70", "ld_flags": "", "declaration": "#include <cstdio>\n#include <algorithm>\n#include <cuda_runtime.h>\n#undef    NDEBUG\n#include <assert.h>\n\n#define BLOCK_SIZE        (512)\n#define CUDA_CHECK(call)                                        \\\ndo {                                                            \\\n        cudaError_t error = call;                               \\\n        if (error != cudaSuccess) {                             \\\n            fprintf(stderr, \"CUDA error at %s:%d - %s\\n\",       \\\n                    __FILE__, __LINE__,                         \\\n                    cudaGetErrorString(error));                 \\\n            exit(EXIT_FAILURE);                                 \\\n        }                                                       \\\n} while(0)\n\n__global__ void k_calculateMovingEnergy(int *inputVector, int windowLength, int *maxResult, int *maxResultIdx, int size);\n\nvoid launch() {\n    // Number of test cases\n    constexpr int TEST_CASE_COUNT = 10;\n    int inputDataLength[TEST_CASE_COUNT] = {7, 7, 10, 11, 12, 13, 14, 15, 35, 520}; // Sizes of the vectors in each test case\n    const int MAX_VECTOR_SIZE = *std::max_element(inputDataLength, inputDataLength + TEST_CASE_COUNT);\n\n    // Input vectors for the tests\n    int inputData_h[TEST_CASE_COUNT][MAX_VECTOR_SIZE] =  {\n        {1,2,3,4,5,6,7},                  // test case 1\n        {3,4,2,7,9,8,1},                  // test case 2\n        {5,2,10,4,3,1,3,1,6,8},           // test case 3\n        {7,1,1,8,10,6,2,9,4,3,8},         // test case 4\n        {1,1,7,7,6,8,8,8,3,7,6,4},        // test case 5\n        {1,8,4,7,8,2,2,6,5,9,8,8,1},      // test case 6\n        {1,1,8,10,7,2,8,2,2,7,4,7,8,6},   // test case 7\n        {8,3,8,10,9,1,4,4,7,6,8,4,3,1,8}, // test case 8\n        {5,1,3,10,2,9,6,10,1,5,2,10,1,8,9,9,1,4,3,9,5,10,2,3,2,2,9,6,6,2,9,7,4,6,5}, // test case 9\n        {5,5,4,8,7,8,10,10,2,2,7,1,6,6,9,5,4,7,8,6,4,2,6,3,1,8,3,5,7,4,8,4,7,8,5,1,4,5,3,2,9,5,9,4,8,4,9,8,4,3,8,10,4,7,5,9,8,2,9,10,6,9,6,2,2,5,8,9,8,4,6,1,2,2,7,5,2,5,2,1,9,6,10,7,6,9,9,10,1,9,7,10,6,5,9,3,5,10,6,9,8,6,3,7,1,7,7,8,9,10,8,6,10,6,1,2,9,5,9,3,6,7,1,7,4,1,5,2,2,3,2,2,1,7,3,6,7,5,6,5,2,5,9,9,3,3,6,7,5,3,10,1,2,2,2,7,6,1,10,8,8,1,9,10,10,9,8,6,2,4,2,1,10,4,3,4,5,7,1,9,6,9,4,5,1,2,7,4,9,2,10,6,8,10,3,5,5,8,9,2,2,4,1,6,4,2,3,10,7,5,10,2,8,8,6,2,6,3,2,3,9,1,3,1,5,1,9,2,1,4,5,2,10,4,3,1,3,1,6,8,7,1,1,8,10,6,2,9,4,3,8,1,1,7,7,6,8,8,8,3,7,6,4,1,8,4,7,8,2,2,6,5,9,8,8,1,1,1,8,10,7,2,8,2,2,7,4,7,8,6,8,3,8,10,9,1,4,4,7,6,8,4,3,1,8,3,4,6,3,7,5,2,8,2,3,3,6,1,5,2,2,8,3,7,10,5,7,8,5,7,2,10,2,3,8,5,8,4,3,1,7,5,5,7,1,4,8,7,2,2,1,1,5,7,8,6,2,7,2,2,1,2,2,2,4,4,3,3,9,8,6,2,3,1,10,8,6,4,2,7,10,2,3,4,1,7,5,10,5,7,2,4,2,8,9,4,7,3,6,9,6,4,3,5,5,4,6,8,5,5,2,1,3,4,7,10,10,5,3,8,8,8,8,2,7,5,3,1,9,2,2,7,9,6,8,2,10,6,7,1,9,8,2,6,4,6,4,5,2,3,1,10,7,10,2,10,8,6,5,3,8,3,1,8,7,8,7,5,4,9,4,9,8,9,6,7,10,5,1,9,7,4,10,3,7,7,4,2,1,5,2,8,4,9,8,6,2,10,3,10,3,4,1,7,2,1,8,4,7,4,7,1,10,9,8,9,4,7,6,6}\n    };\n\n    int windowLength_h[TEST_CASE_COUNT] = {\n        2, 3, 3, 3, 3, 3, 4, 4, 4, 5\n    };\n\n    // expected outputs\n    int expectedMaxIndex[TEST_CASE_COUNT] = {5, 3, 0, 3, 5, 9, 2, 1, 11, 162};\n\n    int expectedMaxEnergy[TEST_CASE_COUNT] = {\n      85, 194, 129, 200, 192, 209, 217, 254, 246, 426\n    };\n\n    // Use a CUDA stream for asynchronous operations\n    cudaStream_t stream;\n    CUDA_CHECK(cudaStreamCreate(&stream));\n\n    // Initialize result on the host\n    int *maxResultIdx_h, *maxResult_h;\n    maxResultIdx_h = (int*)malloc(sizeof(int));\n    maxResult_h = (int*)malloc(sizeof(int));\n\n    // Pointers for device memory (GPU)\n    int *inputVector_d, *maxResultIdx_d, *maxResult_d;\n\n    // Allocate the memory on the device\n    CUDA_CHECK(cudaMallocAsync(&inputVector_d, MAX_VECTOR_SIZE * sizeof(int), stream));\n    CUDA_CHECK(cudaMallocAsync(&maxResultIdx_d, sizeof(int), stream));\n    CUDA_CHECK(cudaMallocAsync(&maxResult_d, sizeof(int), stream));\n\n    // Loop to execute each test case\n    for (int i = 0; i < TEST_CASE_COUNT; ++i) {\n\n        // Copy input data to the device\n        CUDA_CHECK(cudaMemcpyAsync(inputVector_d, inputData_h[i], inputDataLength[i] * sizeof(int), cudaMemcpyHostToDevice, stream));\n        // Initialize the result on the device\n        CUDA_CHECK(cudaMemsetAsync(maxResultIdx_d, 0, sizeof(int), stream));\n        CUDA_CHECK(cudaMemsetAsync(maxResult_d, 0, sizeof(int), stream));\n\n        // Determine the number of threads and blocks\n        dim3 gridSize = dim3((inputDataLength[i] + BLOCK_SIZE - 1) / BLOCK_SIZE, 1, 1);\n        dim3 blockSize = dim3(BLOCK_SIZE, 1, 1);\n\n        //  Adding check for exceeding maximum grid dimensions\n        cudaDeviceProp props;\n        CUDA_CHECK(cudaGetDeviceProperties(&props, 0));\n        if (gridSize.x > props.maxGridSize[0] || gridSize.y > props.maxGridSize[1]) {\n            assert(false && \"Grid size exceeds device limits!\");\n        }\n        int warpSize = props.warpSize;\n\n        // Execute the kernel\n        // Grid:  ((inputDataLength[i] + BLOCK_SIZE - 1) / BLOCK_SIZE, 1, 1)\n        // Block: (BLOCK_SIZE, 1, 1)\n        size_t sharedMemorySize =  2 * ((BLOCK_SIZE + warpSize - 1)/warpSize) * sizeof(int);\n        void *args[] = {&inputVector_d, (void*)&windowLength_h[i], &maxResult_d, &maxResultIdx_d, (void*)&inputDataLength[i]};\n        CUDA_CHECK(cudaLaunchKernel((void*)k_calculateMovingEnergy, gridSize, blockSize, args, sharedMemorySize, stream));\n\n        // Copy the result back to the host (CPU)\n        CUDA_CHECK(cudaMemcpyAsync(maxResultIdx_h, maxResultIdx_d, sizeof(int), cudaMemcpyDeviceToHost, stream));\n        CUDA_CHECK(cudaMemcpyAsync(maxResult_h, maxResult_d, sizeof(int), cudaMemcpyDeviceToHost, stream));\n\n        // Check tasks in the stream has completed\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n\n        assert(maxResultIdx_h[0] == expectedMaxIndex[i]);\n        assert(maxResult_h[0] == expectedMaxEnergy[i]);\n    }\n    // Free device memory and stream\n    CUDA_CHECK(cudaFreeAsync(inputVector_d, stream));\n    CUDA_CHECK(cudaFreeAsync(maxResultIdx_d, stream));\n    CUDA_CHECK(cudaFreeAsync(maxResult_d, stream));\n    CUDA_CHECK(cudaStreamDestroy(stream));\n    // Free host memories\n    free(maxResultIdx_h);\n    free(maxResult_h);\n}\n\n// Each thread is computing energy within a window, each warp is calculating peak index of the output and the\n// result is saved in shared memory, a block level reduction is then performed to find the final maximum across\n// different warps in a block\n__global__ void k_calculateMovingEnergy(int *inputVector, int windowLength, int *maxResult, int *maxResultIdx, int size) {\n", "test": "int main() {\n    launch();\n}\n", "example_test": "    @example_test\n", "cuda_toolkit": "12.2"}
{"task_id": "CUDA/126", "date": "2025-03-31", "prompt": "This CUDA kernel computes the Histogram of Oriented Gradients (HOG) for images using signed gradients (0\u00b0 to 180\u00b0) and 20\u00b0 bins (9 bins total). Each thread processes a single pixel, computes gradients via the Sobel operator, and updates a block-level shared memory histogram, which is then stored in global memory.\n\nThe signature of the function is __global__ void k_computeHOG(unsigned char *image, int *hogDescriptor, int width, int height), where the image is the input grayscale image stored in a 1D array, hogDescriptor is the output histogram array (9-bin histogram per block),\nwidth and height are image dimensions.\n\n>>> k_computeHOG({50,55,60,65,70,75,80,85,90,95,100,105,110,115,120,125,130,135,140,145,150,155,160,165,170,175,180,185,190,195,200,205,210,215,220,225,230,235,240,245,250,255,245,235,225,215,205,195,185,175,\n165,155,145,135,125,115,105,95,85,75,65,55,45,35}, hogDescriptor, 8, 8)->hogDescriptor:{0, 16, 0, 304, 672, 32, 0, 0, 0}\n>>> k_computeHOG({200,180,160,140,40,20,200,180,80,60,40,20,120,100,80,60,160,140,120,100,200,180,160,140,40,20,200,180,80,60,40,20}, hogDescriptor, 4, 8)->hogDescriptor:{0, 0, 0, 64, 128, 224, 32, 64, 0}\n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_70", "ld_flags": "", "declaration": "#include <cstdio>\n#include <cfloat>\n#include <algorithm>\n#include <cuda_runtime.h>\n#include <assert.h>\n#include <iostream>\n\n#undef  NDEBUG\n#define BLOCK_SIZE  16  // 16x16 thread block\n\nconst int HOG_BINS = 9;\n\n#define CUDA_CHECK(call)                                        \\\ndo {                                                            \\\n        cudaError_t error = call;                               \\\n        if (error != cudaSuccess) {                             \\\n            fprintf(stderr, \"CUDA error at %s:%d - %s\\n\",       \\\n                    __FILE__, __LINE__,                         \\\n                    cudaGetErrorString(error));                 \\\n            exit(EXIT_FAILURE);                                 \\\n        }                                                       \\\n} while(0)\n\n__global__ void k_computeHOG(unsigned char *image, int *hogDescriptor, int width, int height);\n\nvoid launch() {\n    const int maxImageWidth = 8;\n    const int maxImageHeight = 8;\n    const int MAX_IMAGE_SIZE = maxImageWidth * maxImageHeight;\n\n    // Use a CUDA stream for asynchronous operations\n    cudaStream_t stream;\n    CUDA_CHECK(cudaStreamCreate(&stream));\n\n    // Allocate device memory\n    unsigned char *image_d;\n    int *hogDescriptor_d;\n    CUDA_CHECK(cudaMallocAsync(&image_d, MAX_IMAGE_SIZE * sizeof(unsigned char), stream));\n    CUDA_CHECK(cudaMallocAsync(&hogDescriptor_d, HOG_BINS * sizeof(int), stream));\n\n    // Copy results back to host\n    int hogResult_h[HOG_BINS];\n\n    cudaDeviceProp deviceProp;\n    cudaGetDeviceProperties(&deviceProp, 0);  // Assuming device 0\n\n    int maxGridX = deviceProp.maxGridSize[0];  // Max blocks in x-direction\n    int maxGridY = deviceProp.maxGridSize[1];  // Max blocks in y-direction\n\n    // Test Case 1\n    {\n      int imageWidth = 8;\n      int imageHeight = 8;\n      int imageSize = imageWidth * imageHeight;\n\n      unsigned char imageData[]= {\n        50, 55, 60, 65, 70, 75, 80, 85,\n        90, 95, 100, 105, 110, 115, 120, 125,\n        130, 135, 140, 145, 150, 155, 160, 165,\n        170, 175, 180, 185, 190, 195, 200, 205,\n        210, 215, 220, 225, 230, 235, 240, 245,\n        250, 255, 245, 235, 225, 215, 205, 195,\n        185, 175, 165, 155, 145, 135, 125, 115,\n        105, 95, 85, 75, 65, 55, 45, 35\n      };\n\n      int expectedHOG[HOG_BINS] = {0, 16, 0, 304, 672, 32, 0, 0, 0};\n\n      // Copy input image to device\n      CUDA_CHECK(cudaMemcpyAsync(image_d, imageData, imageSize * sizeof(unsigned char), cudaMemcpyHostToDevice, stream));\n      CUDA_CHECK(cudaMemsetAsync(hogDescriptor_d, 0, HOG_BINS * sizeof(int), stream));\n\n      int gridX = (imageWidth + BLOCK_SIZE - 1) / BLOCK_SIZE;  // Ceiling division\n      int gridY = (imageHeight + BLOCK_SIZE - 1) / BLOCK_SIZE;\n\n      if (gridX > maxGridX) {\n          gridX = maxGridX;\n      }\n      if (gridY > maxGridY) {\n          gridY = maxGridY;\n      }\n\n      // Launch kernel\n      dim3 gridSize(gridX, gridY);        \n      dim3 blockSize(BLOCK_SIZE, BLOCK_SIZE);\n\n      // Execute the kernel\n      // Grid:  (ceil(imageWidth/16), ceil(imageHeight/16), 1)\n      // Block: (16, 16, 1)\n      void *args[] = {&image_d, &hogDescriptor_d, &imageWidth, &imageHeight};\n      CUDA_CHECK(cudaLaunchKernel((void*)k_computeHOG, gridSize, blockSize, args, sizeof(int) * HOG_BINS, stream));\n\n      CUDA_CHECK(cudaMemcpyAsync(hogResult_h, hogDescriptor_d, HOG_BINS * sizeof(int), cudaMemcpyDeviceToHost, stream));\n\n      // Check tasks in the stream has completed\n      CUDA_CHECK(cudaStreamSynchronize(stream));\n\n      for (int j = 0; j < HOG_BINS; j++) {\n        assert(hogResult_h[j] == expectedHOG[j]);\n      }\n    }\n\n    // Test Case 2\n    {\n      int imageWidth = 8;\n      int imageHeight = 8;\n      int imageSize = imageWidth * imageHeight;\n\n      unsigned char imageData[]= {\n        200, 180, 160, 140, 120, 100, 80, 60,\n        40, 20, 200, 180, 160, 140, 120, 100,\n        80, 60, 40, 20, 200, 180, 160, 140,\n        120, 100, 80, 60, 40, 20, 200, 180,\n        160, 140, 120, 100, 80, 60, 40, 20,\n        200, 180, 160, 140, 120, 100, 80, 60,\n        40, 20, 200, 180, 160, 140, 120, 100,\n        80, 60, 40, 20, 200, 180, 160, 140\n      };\n\n      int expectedHOG[HOG_BINS] = {16, 0, 0, 144, 96, 496, 144, 128, 0};\n\n      // Copy input image to device\n      CUDA_CHECK(cudaMemcpyAsync(image_d, imageData, imageSize * sizeof(unsigned char), cudaMemcpyHostToDevice, stream));\n      CUDA_CHECK(cudaMemsetAsync(hogDescriptor_d, 0, HOG_BINS * sizeof(int), stream));\n\n      int gridX = (imageWidth + BLOCK_SIZE - 1) / BLOCK_SIZE;  // Ceiling division\n      int gridY = (imageHeight + BLOCK_SIZE - 1) / BLOCK_SIZE;\n\n      if (gridX > maxGridX) {\n          gridX = maxGridX;\n      }\n      if (gridY > maxGridY) {\n          gridY = maxGridY;\n      }\n\n      // Launch kernel\n      dim3 gridSize(gridX, gridY);        \n      dim3 blockSize(BLOCK_SIZE, BLOCK_SIZE);\n\n      // Execute the kernel\n      // Grid:  (ceil(imageWidth/16), ceil(imageHeight/16), 1)\n      // Block: (16, 16, 1)\n      void *args[] = {&image_d, &hogDescriptor_d, &imageWidth, &imageHeight};\n      CUDA_CHECK(cudaLaunchKernel((void*)k_computeHOG, gridSize, blockSize, args, sizeof(int) * HOG_BINS, stream));\n\n      CUDA_CHECK(cudaMemcpyAsync(hogResult_h, hogDescriptor_d, HOG_BINS * sizeof(int), cudaMemcpyDeviceToHost, stream));\n\n      // Check tasks in the stream has completed\n      CUDA_CHECK(cudaStreamSynchronize(stream));\n\n      for (int j = 0; j < HOG_BINS; j++) {\n        assert(hogResult_h[j] == expectedHOG[j]);\n      }\n    }\n\n    // Test Case 3\n    {\n      int imageWidth = 8;\n      int imageHeight = 8;\n      int imageSize = imageWidth * imageHeight;\n\n      unsigned char imageData[]= {\n        10, 20, 30, 40, 50, 60, 70, 80,\n        20, 30, 40, 50, 60, 70, 80, 90,\n        30, 40, 50, 60, 70, 80, 90, 100,\n        40, 50, 60, 70, 80, 90, 100, 110,\n        50, 60, 70, 80, 90, 100, 110, 120,\n        60, 70, 80, 90, 100, 110, 120, 130,\n        70, 80, 90, 100, 110, 120, 130, 140,\n        80, 90, 100, 110, 120, 130, 140, 150\n      };\n\n      int expectedHOG[HOG_BINS] = {0, 192, 640, 192, 0, 0, 0, 0, 0};\n\n      // Copy input image to device\n      CUDA_CHECK(cudaMemcpyAsync(image_d, imageData, imageSize * sizeof(unsigned char), cudaMemcpyHostToDevice, stream));\n      CUDA_CHECK(cudaMemsetAsync(hogDescriptor_d, 0, HOG_BINS * sizeof(int), stream));\n\n      int gridX = (imageWidth + BLOCK_SIZE - 1) / BLOCK_SIZE;  // Ceiling division\n      int gridY = (imageHeight + BLOCK_SIZE - 1) / BLOCK_SIZE;\n\n      if (gridX > maxGridX) {\n          gridX = maxGridX;\n      }\n      if (gridY > maxGridY) {\n          gridY = maxGridY;\n      }\n\n      // Launch kernel\n      dim3 gridSize(gridX, gridY);        \n      dim3 blockSize(BLOCK_SIZE, BLOCK_SIZE);\n\n      // Execute the kernel\n      // Grid:  (ceil(imageWidth/16), ceil(imageHeight/16), 1)\n      // Block: (16, 16, 1)\n      void *args[] = {&image_d, &hogDescriptor_d, &imageWidth, &imageHeight};\n      CUDA_CHECK(cudaLaunchKernel((void*)k_computeHOG, gridSize, blockSize, args, sizeof(int) * HOG_BINS, stream));\n\n      CUDA_CHECK(cudaMemcpyAsync(hogResult_h, hogDescriptor_d, HOG_BINS * sizeof(int), cudaMemcpyDeviceToHost, stream));\n\n      // Check tasks in the stream has completed\n      CUDA_CHECK(cudaStreamSynchronize(stream));\n\n      for (int j = 0; j < HOG_BINS; j++) {\n        assert(hogResult_h[j] == expectedHOG[j]);\n      }\n    }\n\n    // Test Case 4\n    {\n      int imageWidth = 8;\n      int imageHeight = 8;\n      int imageSize = imageWidth * imageHeight;\n\n      unsigned char imageData[]= {\n        50, 55, 60, 65, 70, 75, 80, 85,\n        90, 95, 100, 105, 110, 115, 120, 125,\n        130, 135, 140, 145, 150, 155, 160, 165,\n        170, 175, 180, 185, 190, 195, 200, 205,\n        210, 215, 220, 225, 230, 235, 240, 245,\n        250, 255, 245, 235, 225, 215, 205, 195,\n        185, 175, 165, 155, 145, 135, 125, 115,\n        105, 95, 85, 75, 65, 55, 45, 35\n      };\n\n      int expectedHOG[HOG_BINS] = {0, 16, 0, 304, 672, 32, 0, 0, 0};\n\n      // Copy input image to device\n      CUDA_CHECK(cudaMemcpyAsync(image_d, imageData, imageSize * sizeof(unsigned char), cudaMemcpyHostToDevice, stream));\n      CUDA_CHECK(cudaMemsetAsync(hogDescriptor_d, 0, HOG_BINS * sizeof(int), stream));\n\n      int gridX = (imageWidth + BLOCK_SIZE - 1) / BLOCK_SIZE;  // Ceiling division\n      int gridY = (imageHeight + BLOCK_SIZE - 1) / BLOCK_SIZE;\n\n      if (gridX > maxGridX) {\n          gridX = maxGridX;\n      }\n      if (gridY > maxGridY) {\n          gridY = maxGridY;\n      }\n\n      // Launch kernel\n      dim3 gridSize(gridX, gridY);        \n      dim3 blockSize(BLOCK_SIZE, BLOCK_SIZE);\n\n      // Execute the kernel\n      // Grid:  (ceil(imageWidth/16), ceil(imageHeight/16), 1)\n      // Block: (16, 16, 1)\n      void *args[] = {&image_d, &hogDescriptor_d, &imageWidth, &imageHeight};\n      CUDA_CHECK(cudaLaunchKernel((void*)k_computeHOG, gridSize, blockSize, args, sizeof(int) * HOG_BINS, stream));\n\n      CUDA_CHECK(cudaMemcpyAsync(hogResult_h, hogDescriptor_d, HOG_BINS * sizeof(int), cudaMemcpyDeviceToHost, stream));\n\n      // Check tasks in the stream has completed\n      CUDA_CHECK(cudaStreamSynchronize(stream));\n\n      for (int j = 0; j < HOG_BINS; j++) {\n        assert(hogResult_h[j] == expectedHOG[j]);\n      }\n    }\n\n    // Test Case 5\n    {\n      int imageWidth = 4;\n      int imageHeight = 8;\n      int imageSize = imageWidth * imageHeight;\n\n      unsigned char imageData[]= {\n        200, 180, 160, 140,\n        40, 20, 200, 180,\n        80, 60, 40, 20,\n        120, 100, 80, 60,\n        160, 140, 120, 100,\n        200, 180, 160, 140,\n        40, 20, 200, 180,\n        80, 60, 40, 20\n      };\n\n      int expectedHOG[HOG_BINS] = {0, 0, 0, 64, 128, 224, 32, 64, 0};\n\n      // Copy input image to device\n      CUDA_CHECK(cudaMemcpyAsync(image_d, imageData, imageSize * sizeof(unsigned char), cudaMemcpyHostToDevice, stream));\n      CUDA_CHECK(cudaMemsetAsync(hogDescriptor_d, 0, HOG_BINS * sizeof(int), stream));\n\n      int gridX = (imageWidth + BLOCK_SIZE - 1) / BLOCK_SIZE;  // Ceiling division\n      int gridY = (imageHeight + BLOCK_SIZE - 1) / BLOCK_SIZE;\n\n      if (gridX > maxGridX) {\n          gridX = maxGridX;\n      }\n      if (gridY > maxGridY) {\n          gridY = maxGridY;\n      }\n\n      // Launch kernel\n      dim3 gridSize(gridX, gridY);        \n      dim3 blockSize(BLOCK_SIZE, BLOCK_SIZE);\n\n      // Execute the kernel\n      // Grid:  (ceil(imageWidth/16), ceil(imageHeight/16), 1)\n      // Block: (16, 16, 1)\n      void *args[] = {&image_d, &hogDescriptor_d, &imageWidth, &imageHeight};\n      CUDA_CHECK(cudaLaunchKernel((void*)k_computeHOG, gridSize, blockSize, args, sizeof(int) * HOG_BINS, stream));\n\n      CUDA_CHECK(cudaMemcpyAsync(hogResult_h, hogDescriptor_d, HOG_BINS * sizeof(int), cudaMemcpyDeviceToHost, stream));\n\n      // Check tasks in the stream has completed\n      CUDA_CHECK(cudaStreamSynchronize(stream));\n\n      for (int j = 0; j < HOG_BINS; j++) {\n        assert(hogResult_h[j] == expectedHOG[j]);\n      }\n    }\n\n    // Test Case 6\n    {\n      int imageWidth = 8;\n      int imageHeight = 4;\n      int imageSize = imageWidth * imageHeight;\n\n      unsigned char imageData[]= {\n        10, 20, 30, 40, 50, 60, 70, 80,\n        20, 30, 40, 50, 60, 70, 80, 90,\n        30, 40, 50, 60, 70, 80, 90, 100,\n        40, 50, 60, 70, 80, 90, 100, 110\n      };\n\n      int expectedHOG[HOG_BINS] = {0, 192, 256, 64, 0, 0, 0, 0, 0};\n\n      // Copy input image to device\n      CUDA_CHECK(cudaMemcpyAsync(image_d, imageData, imageSize * sizeof(unsigned char), cudaMemcpyHostToDevice, stream));\n      CUDA_CHECK(cudaMemsetAsync(hogDescriptor_d, 0, HOG_BINS * sizeof(int), stream));\n\n      int gridX = (imageWidth + BLOCK_SIZE - 1) / BLOCK_SIZE;  // Ceiling division\n      int gridY = (imageHeight + BLOCK_SIZE - 1) / BLOCK_SIZE;\n\n      if (gridX > maxGridX) {\n          gridX = maxGridX;\n      }\n      if (gridY > maxGridY) {\n          gridY = maxGridY;\n      }\n\n      // Launch kernel\n      dim3 gridSize(gridX, gridY);        \n      dim3 blockSize(BLOCK_SIZE, BLOCK_SIZE);\n\n      // Execute the kernel\n      // Grid:  (ceil(imageWidth/16), ceil(imageHeight/16), 1)\n      // Block: (16, 16, 1)\n      void *args[] = {&image_d, &hogDescriptor_d, &imageWidth, &imageHeight};\n      CUDA_CHECK(cudaLaunchKernel((void*)k_computeHOG, gridSize, blockSize, args, sizeof(int) * HOG_BINS, stream));\n\n      CUDA_CHECK(cudaMemcpyAsync(hogResult_h, hogDescriptor_d, HOG_BINS * sizeof(int), cudaMemcpyDeviceToHost, stream));\n\n      // Check tasks in the stream has completed\n      CUDA_CHECK(cudaStreamSynchronize(stream));\n\n      // Verify results\n      for (int j = 0; j < HOG_BINS; j++) {\n        assert(hogResult_h[j] == expectedHOG[j]);\n      }\n    }\n\n    // Test Case 7\n    {\n      int imageWidth = 5;\n      int imageHeight = 8;\n      int imageSize = imageWidth * imageHeight;\n\n      unsigned char imageData[]= {\n        5, 15, 25, 35, 45,\n        15, 25, 35, 45, 55,\n        25, 35, 45, 55, 65,\n        35, 45, 55, 65, 75,\n        45, 55, 65, 75, 85,\n        55, 65, 75, 85, 95,\n        65, 75, 85, 95, 105,\n        75, 85, 95, 105, 115\n      };\n\n      int expectedHOG[HOG_BINS] = {0, 96, 352, 192, 0, 0, 0, 0, 0};\n\n      // Copy input image to device\n      CUDA_CHECK(cudaMemcpyAsync(image_d, imageData, imageSize * sizeof(unsigned char), cudaMemcpyHostToDevice, stream));\n      CUDA_CHECK(cudaMemsetAsync(hogDescriptor_d, 0, HOG_BINS * sizeof(int), stream));\n\n      int gridX = (imageWidth + BLOCK_SIZE - 1) / BLOCK_SIZE;  // Ceiling division\n      int gridY = (imageHeight + BLOCK_SIZE - 1) / BLOCK_SIZE;\n\n      if (gridX > maxGridX) {\n          gridX = maxGridX;\n      }\n      if (gridY > maxGridY) {\n          gridY = maxGridY;\n      }\n\n      // Launch kernel\n      dim3 gridSize(gridX, gridY);        \n      dim3 blockSize(BLOCK_SIZE, BLOCK_SIZE);\n\n      // Execute the kernel\n      // Grid:  (ceil(imageWidth/16), ceil(imageHeight/16), 1)\n      // Block: (16, 16, 1)\n      void *args[] = {&image_d, &hogDescriptor_d, &imageWidth, &imageHeight};\n      CUDA_CHECK(cudaLaunchKernel((void*)k_computeHOG, gridSize, blockSize, args, sizeof(int) * HOG_BINS, stream));\n\n      CUDA_CHECK(cudaMemcpyAsync(hogResult_h, hogDescriptor_d, HOG_BINS * sizeof(int), cudaMemcpyDeviceToHost, stream));\n\n      // Check tasks in the stream has completed\n      CUDA_CHECK(cudaStreamSynchronize(stream));\n\n      for (int j = 0; j < HOG_BINS; j++) {\n        assert(hogResult_h[j] == expectedHOG[j]);\n      }\n    }\n\n    // Test Case 8\n    {\n      int imageWidth = 8;\n      int imageHeight = 6;\n      int imageSize = imageWidth * imageHeight;\n\n      unsigned char imageData[]= {\n        255, 245, 235, 225, 215, 205, 195, 185,\n        175, 165, 155, 145, 135, 125, 115, 105,\n        95, 85, 75, 65, 55, 45, 35, 25,\n        15, 5, 255, 245, 235, 225, 215, 205,\n        195, 185, 175, 165, 155, 145, 135, 125,\n        115, 105, 95, 85, 75, 65, 55, 45\n      };\n\n      int expectedHOG[HOG_BINS] = {0, 32, 0, 192, 384, 160, 0, 0, 0};\n\n      // Copy input image to device\n      CUDA_CHECK(cudaMemcpyAsync(image_d, imageData, imageSize * sizeof(unsigned char), cudaMemcpyHostToDevice, stream));\n      CUDA_CHECK(cudaMemsetAsync(hogDescriptor_d, 0, HOG_BINS * sizeof(int), stream));\n\n      int gridX = (imageWidth + BLOCK_SIZE - 1) / BLOCK_SIZE;  // Ceiling division\n      int gridY = (imageHeight + BLOCK_SIZE - 1) / BLOCK_SIZE;\n\n      if (gridX > maxGridX) {\n          gridX = maxGridX;\n      }\n      if (gridY > maxGridY) {\n          gridY = maxGridY;\n      }\n\n      // Launch kernel\n      dim3 gridSize(gridX, gridY);        \n      dim3 blockSize(BLOCK_SIZE, BLOCK_SIZE);\n\n      // Execute the kernel\n      // Grid:  (ceil(imageWidth/16), ceil(imageHeight/16), 1)\n      // Block: (16, 16, 1)\n      void *args[] = {&image_d, &hogDescriptor_d, &imageWidth, &imageHeight};\n      CUDA_CHECK(cudaLaunchKernel((void*)k_computeHOG, gridSize, blockSize, args, sizeof(int) * HOG_BINS, stream));\n\n      CUDA_CHECK(cudaMemcpyAsync(hogResult_h, hogDescriptor_d, HOG_BINS * sizeof(int), cudaMemcpyDeviceToHost, stream));\n\n      // Check tasks in the stream has completed\n      CUDA_CHECK(cudaStreamSynchronize(stream));\n\n      for (int j = 0; j < HOG_BINS; j++) {\n        assert(hogResult_h[j] == expectedHOG[j]);\n      }\n    }\n\n    // Free device memory\n    CUDA_CHECK(cudaFreeAsync(image_d, stream));\n    CUDA_CHECK(cudaFreeAsync(hogDescriptor_d, stream));\n    CUDA_CHECK(cudaStreamDestroy(stream));\n}\n\n__global__ void k_computeHOG(unsigned char *image, int *hogDescriptor, int width, int height) {\n", "test": "int main() {\n    launch();\n}\n", "example_test": "    @example_test\n", "cuda_toolkit": "12.2"}
{"task_id": "CUDA/127", "date": "2025-03-31", "prompt": "Write a CUDA kernel to find the maximum value in a large integer array using parallel reduction with warp shuffle operations and shared memory optimizations.\n\nThe signature of the kernel is __global__ void k_findMax(int* input_d, int* result_d, size_t numElements, int warpsPerBlock, int warpSize), where input_d is a device pointer to the input array of 32-bit integers, result_d is a single-element device pointer to store the maximum value, numElements is the total number of elements in the input array, warpsPerBlock is the number of warps per block (calculated from device properties) and warpSize is the Size of the warp (calculated from device properties)\n\nThe implementation must use __shfl_down_sync for warp-level reduction, utilize shared memory for block-level aggregation, implement grid-stride loops for scalable input handling, use atomicMax for final global maximum update, and handle arbitrary input sizes including non-multiples of block size.\n\n>>> k_findMax({1, 2, 3, 98765}, result_d, 4,  warpsPerBlock, warpSize) -> 98765\n>>> k_findMax({-5, -3, 0, -10, -8}, result_d, 5,   warpsPerBlock, warpSize) -> 0\n", "cc_flags": "-arch=sm_90a -arch=sm_89 -arch=sm_80 -arch=sm_70", "ld_flags": "", "declaration": "#include <assert.h>\n#include <limits>\n#include <cstdio>\n#include <limits>\n#include <vector>\n#include <cuda_runtime.h>\n\n#define CUDA_CHECK(call)                                                                   \\\ndo {                                                                                       \\\n    cudaError_t error = call;                                                              \\\n    if(error != cudaSuccess) {                                                             \\\n        fprintf(stderr,                                                                    \\\n            \"CUDA Error: %s at %s:%d\\n\",                                                   \\\n            cudaGetErrorString(error),                                                     \\\n            __FILE__,                                                                      \\\n            __LINE__);                                                                     \\\n        exit(error);                                                                       \\\n    }                                                                                      \\\n} while(0)\n\n\n__global__ void k_findMax(\n    int* input_d,            // [in] Device pointer to input array of integers to search\n    int* result_d,           // [out] Single-element device pointer to store global maximum result\n    size_t numElements,      // [in] Total number of elements in input array\n    int warpsPerBlock,      // [in] Number of warps per block (calculated from device properties)\n    int warpSize              // [in] Size of the warp (calculated from device properties)\n);\n\nconstexpr int BLOCK_SIZE = 256;\nconstexpr int INITIAL_MAX = std::numeric_limits<int>::min();\n\nstruct TestCase {               // [in] Total number of elements in test case\n    size_t numElements;         // [in] Input data for test case\n    std::vector<int> input;     // [in] Reference maximum value for validation\n    int expectedMax;            // [in] Expected result\n};\n\nstd::vector<TestCase> testCases = {\n    {4, {1, 2, 3, 98765}, 98765},\n    {5, {-5, -3, 0, -10, -8}, 0},\n    {513, std::vector<int>(513, 314), 314},  \n    {1<<20, [](){ \n        std::vector<int> vec(1<<20, 0);\n        vec[1000] = 42;\n        return vec;\n    }(), 42},\n    {1000, std::vector<int>(1000, 100), 100},\n    {1, {-42}, -42},\n    {7, {-5, 3, -2, 10, -1, 9, 0}, 10}\n};\n\nvoid launch() {\n    cudaDeviceProp prop;\n    CUDA_CHECK(cudaGetDeviceProperties(&prop, 0));\n    \n    // Calculate warps per block and shared memory per block\n    int warpSize = prop.warpSize;\n    int warpsPerBlock = BLOCK_SIZE / warpSize;\n    size_t sharedMemPerBlock = warpsPerBlock * sizeof(int);\n    \n    // Calculate occupancy parameters once\n    int numBlocksPerSM = 0;\n    CUDA_CHECK(cudaOccupancyMaxActiveBlocksPerMultiprocessor(\n        &numBlocksPerSM,\n        k_findMax,\n        BLOCK_SIZE,\n        sharedMemPerBlock  // Shared memory per block\n    ));\n    \n    int maxBlocks = prop.multiProcessorCount * numBlocksPerSM;\n    \n    // Create a stream per test case for concurrent execution\n    constexpr int MAX_CONCURRENT_TESTS = 4;  // Limit concurrent tests to avoid resource exhaustion\n    const int numTests = static_cast<int>(testCases.size());  // All 7 test cases\n    const int numStreams = std::min(numTests, MAX_CONCURRENT_TESTS);\n    \n    // Create CUDA streams for concurrent execution\n    cudaStream_t streams[MAX_CONCURRENT_TESTS];\n    for (int i = 0; i < numStreams; ++i) {\n        CUDA_CHECK(cudaStreamCreate(&streams[i]));\n    }\n    \n    // Allocate resources for results\n    std::vector<int*> input_d(numTests, nullptr);\n    std::vector<int*> result_d(numTests, nullptr);\n    std::vector<int> result_h(numTests);\n    \n    // Asynchronously launch all test cases\n    for (int tc = 0; tc < numTests; ++tc) {\n        // Select stream in round-robin fashion\n        cudaStream_t stream = streams[tc % numStreams];\n        TestCase& test = testCases[tc];\n        \n        // Asynchronously allocate device memory\n        CUDA_CHECK(cudaMallocAsync(&input_d[tc], test.numElements * sizeof(int), stream));\n        CUDA_CHECK(cudaMallocAsync(&result_d[tc], sizeof(int), stream));\n        \n        // Initialize result with minimum value\n        int initial = INITIAL_MAX;\n        CUDA_CHECK(cudaMemcpyAsync(result_d[tc], &initial, sizeof(int), \n                                  cudaMemcpyHostToDevice, stream));\n        \n        // Copy input data asynchronously\n        CUDA_CHECK(cudaMemcpyAsync(input_d[tc], test.input.data(), \n                                  test.numElements * sizeof(int), \n                                  cudaMemcpyHostToDevice, stream));\n        \n        // Optimized grid configuration\n        int desiredBlocks = (test.numElements + BLOCK_SIZE - 1) / BLOCK_SIZE;\n        dim3 block(BLOCK_SIZE);\n        dim3 grid(std::min(desiredBlocks, maxBlocks));\n        \n        // Prepare kernel arguments array\n        void* args[] = { \n            &input_d[tc],      // Device input array pointer\n            &result_d[tc],     // Device output pointer\n            &test.numElements, // Number of elements in input array\n            &warpsPerBlock,   // Warps per block calculated from device properties\n            &warpSize           // Size of the warp as per device properties\n        };\n        \n        // Launch kernel with explicit error checking\n        CUDA_CHECK(cudaLaunchKernel(\n            (const void*)k_findMax,  // Kernel function pointer\n            grid,                    // Grid dimensions (blocks per grid)\n            block,                   // Block dimensions (threads per block)\n            args,                    // Array of kernel arguments\n            sharedMemPerBlock,       // Dynamic shared memory size\n            stream                   // Stream ID\n        ));\n            \n        // Queue asynchronous memory transfer of result\n        CUDA_CHECK(cudaMemcpyAsync(&result_h[tc], result_d[tc], sizeof(int),\n                                  cudaMemcpyDeviceToHost, stream));\n    }\n    \n    // Synchronize all streams and validate results\n    for (int tc = 0; tc < numTests; ++tc) {\n        cudaStream_t stream = streams[tc % numStreams];\n        CUDA_CHECK(cudaStreamSynchronize(stream));\n        \n        // Silent C-style assertion for validation\n        assert(result_h[tc] == testCases[tc].expectedMax);\n        \n        // Free allocated resources asynchronously\n        CUDA_CHECK(cudaFreeAsync(input_d[tc], stream));\n        CUDA_CHECK(cudaFreeAsync(result_d[tc], stream));\n    }\n    \n    // Synchronize all streams before destroying them to ensure all operations complete\n    for (int i = 0; i < numStreams; ++i) {\n        CUDA_CHECK(cudaStreamSynchronize(streams[i]));\n        CUDA_CHECK(cudaStreamDestroy(streams[i]));\n    }\n}\n\n\n__global__ void k_findMax(int* input_d, int* result_d, size_t numElements, int warpsPerBlock, int warpSize) {\n", "test": "int main() {\n    launch();\n}\n", "example_test": "    @example_test\n", "cuda_toolkit": "12.2"}